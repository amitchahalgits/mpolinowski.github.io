<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-Development/Python/2022-10-22-python-nlp/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Python - Natural Language Processing | Mike Polinowski</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mpolinowski.github.io/docs/Development/Python/2022-10-22-python-nlp/2022-10-22"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Python - Natural Language Processing | Mike Polinowski"><meta data-rh="true" name="description" content="Python Natural Language Toolkit - Stemming, Similarity, Sentiment Examples"><meta data-rh="true" property="og:description" content="Python Natural Language Toolkit - Stemming, Similarity, Sentiment Examples"><link data-rh="true" rel="icon" href="/img/icons/favicon-32x32.png"><link data-rh="true" rel="canonical" href="https://mpolinowski.github.io/docs/Development/Python/2022-10-22-python-nlp/2022-10-22"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/Development/Python/2022-10-22-python-nlp/2022-10-22" hreflang="en"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/Development/Python/2022-10-22-python-nlp/2022-10-22" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Mike Polinowski RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Mike Polinowski Atom Feed">




<link rel="icon" href="/img/angular_momentum.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37,194,160)">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#000">
<link rel="apple-touch-icon" href="/img/angular_momentum.png">
<link rel="mask-icon" href="/img/angular_momentum.png" color="rgb(33,33,33)">
<meta name="msapplication-TileImage" content="/img/angular_momentum.png">
<meta name="msapplication-TileColor" content="#000">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-P74BDWF0C6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-P74BDWF0C6",{})</script><link rel="stylesheet" href="/assets/css/styles.08c8c484.css">
<script src="/assets/js/runtime~main.afcb95e1.js" defer="defer"></script>
<script src="/assets/js/main.fb0a52c3.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Mike Polinowski</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/docs/tags">Tags</a><a class="navbar__item navbar__link" href="/Search">Search</a><a href="https://mpolinowski.github.io/Personal" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/development">Development</a><button aria-label="Collapse sidebar category &#x27;Development&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/javascript">Javascript</a><button aria-label="Expand sidebar category &#x27;Javascript&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/category/python">Python</a><button aria-label="Collapse sidebar category &#x27;Python&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-08-14-python-scikit-image-opencv/2023-08-14">OpenCV &amp; SciPy and Scikit Image Cheat Sheet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-07-09-python-scikit-image-intro/2023-07-09">Introduction to Scikit-Image</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-28-telco-churn-cohort-study/2023-05-28">Supervised Learning with Scikit-Learn</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-20-python-sklearn-cheat-sheet/2023-05-20">SciKit-Learn Cheat Sheet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-18-python-asserts/2023-05-18">Python Asserts in Data Science Cheat Sheet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-17-fandango-ratings-controversy/2023-05-17">FiveThirtyEight Fandango Dataset</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-16-seaborn-cc-churn-vis/2023-05-16">Seaborn to Explore the CC Churn Dataset</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-14-visualizing-text-datasets/2023-05-14">Plotly &amp; Seaborn to Explore Text Dataset</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-12-matplotlib-seaborn-titanic-dataset/2023-05-12">Seaborn Titanic Dataset Exploration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-10-plotly-COVID19-dataset/2023-05-10">Plotly COVID19 Dataset Exploration</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-07-python-seaborn-cheat-sheet/2023-05-07">Seaborn Cheat Sheet 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-07-python-scipy-introduction/2023-05-07">A little bit of SciPy...</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-05-03-python-matplotlib-cheat-sheet/2023-05-03">Matplotlib Pyplot Cheat Sheet 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-04-24-python-pandas-cheat-sheet/2023-04-24">Pandas Cheat Sheet 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2023-01-16-python-3-11-features/2023-01-16">Python 3.11 New Features</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-12-11-pipenv/2022-12-11">Pipenv - Welcome NPM</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/Development/Python/2022-10-22-python-nlp/2022-10-22">Python - Natural Language Processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-15-python-rest-server/2022-10-15">Python - Build a REST API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-14-python-rest-elastic/2022-10-14">Python - Working with the Elasticsearch REST API</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-13-python-rest-api/2022-10-13">Python - Working with REST API Requests</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-12-python-regular-expressions/2022-10-12">Python - RE</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-10-python-filesystem/2022-10-10">Python - The Filesystem</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-09-python-flask-elasticsearch/2022-10-09">Python - Flask Frontend to generate Elasticsearch Docs from Sitemaps</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-08-python-desktop-app/2022-10-08">Python - PyQt Desktop App</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-08-python-flask-app/2022-10-08">Python - Deploying a Web App with Flask</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-07-python-docusaurus-elasticsearch/2022-10-07">Python - Build an Elasticsearch Index for your Docusaurus Blog</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-06-python-minify-text/2022-10-06">Python - Minify Text for Elasticsearch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-10-05-python-text-processing/2022-10-05">Python - Text Processing with</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-09-17-python-video-processing/2022-09-17">Python - Video Processing with OpenCV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-06-27-python-web-scraping/2022-06-27">Web Scraping Essentials with Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2022-06-01-python-pyscript/2022-06-01">Introduction to PyScript</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2017-12-13--getting-started-with-python-part-ii/2017-12-13">Getting started with Python Part II</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2017-12-11--getting-started-with-python/2017-12-11">Getting started with Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/Development/Python/2017-12-17--python-ssh-logger/2017-12-17">Python Network Logger</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/go">Go</a><button aria-label="Expand sidebar category &#x27;Go&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/graphs">Graphs</a><button aria-label="Expand sidebar category &#x27;Graphs&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/react-native">React Native</a><button aria-label="Expand sidebar category &#x27;React Native&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/magento">Magento</a><button aria-label="Expand sidebar category &#x27;Magento&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/misc">Misc</a><button aria-label="Expand sidebar category &#x27;Misc&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/devops">DevOps</a><button aria-label="Expand sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/machine-learning-ai-and-computer-vision">Machine Learning, AI and Computer Vision</a><button aria-label="Expand sidebar category &#x27;Machine Learning, AI and Computer Vision&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/automation-deep-vision-and-robotics">Automation, Deep Vision and Robotics</a><button aria-label="Expand sidebar category &#x27;Automation, Deep Vision and Robotics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/development"><span itemprop="name">Development</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/python"><span itemprop="name">Python</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Python - Natural Language Processing</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Python - Natural Language Processing</h1></header><p><img alt="Sham Sui Po, Hong Kong" src="/assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-5f44d483789c3ce79f05418f930f5cd2.jpg" width="1500" height="548"></p>
<ul>
<li><a href="#natural-language-toolkit">Natural Language Toolkit</a>
<ul>
<li><a href="#finding-word-stems">Finding Word Stems</a></li>
<li><a href="#lemmatizing-flow-text">Lemmatizing Flow Text</a></li>
<li><a href="#compare-word-stems">Compare Word Stems</a></li>
<li><a href="#similarity-coefficient">Similarity Coefficient</a></li>
<li><a href="#sentiment-analysis">Sentiment Analysis</a></li>
<li><a href="#online-search-wikipedia">Online Search (Wikipedia)</a></li>
</ul>
</li>
</ul>
<p><a href="https://github.com/mpolinowski/python-nltk">Github Repository</a></p>
<h2 id="natural-language-toolkit">Natural Language Toolkit</h2>
<h3 id="finding-word-stems">Finding Word Stems</h3>
<p>Use a Lemmatisation function to find the root of a word and compare different forms of the same word - e.g. <code>be</code>, <code>was</code>, <code>is</code>, etc. Install the <strong>nltk</strong> package:</p>
<pre><code class="language-bash">pip install nltk
</code></pre>
<p>And <a href="https://www.nltk.org/data.html">download all the data</a> with <code>python -m nltk.downloader all</code> or just the requiered files to the default location <code>/home/myuser/nltk_data</code> by adding the following lines to your code:</p>
<pre><code class="language-py">nltk.download(&#x27;wordnet)
nltk.download(&#x27;omw-1.4&#x27;)
</code></pre>
<p>A quick loop through the following dictionary reveals that all those words have the identical stem - <code>be</code>:</p>
<pre><code class="language-py">import nltk

nltk.download(&#x27;wordnet&#x27;)
nltk.download(&#x27;omw-1.4&#x27;)

words = [&#x27;was&#x27;, &#x27;is&#x27;, &#x27;am&#x27;, &#x27;be&#x27;]

lemmatizer = nltk.stem.WordNetLemmatizer()


for word in words:
    lemma = lemmatizer.lemmatize(word, &#x27;v&#x27;) # n = noun, v =verb, a = adjective, r = adverbs, s = satellite adjectives
    print(lemma)
</code></pre>
<h3 id="lemmatizing-flow-text">Lemmatizing Flow Text</h3>
<p>To work with full sentences we first need to tonkenize the sentence - breaking it up into single words. And also apply the word definition (noun, verb, etc.) dynamically.</p>
<pre><code class="language-py">import nltk

# only run once
# nltk.download(&#x27;wordnet&#x27;)
# nltk.download(&#x27;omw-1.4&#x27;)
# nltk.download(&#x27;punkt&#x27;)
# nltk.download(&#x27;averaged_perceptron_tagger&#x27;)

text = &#x27;Experiments on mice at Boston University have spotlighted an ambiguous U.S. policy for research on potentially dangerous pathogens.&#x27;
# break text up into single words toLowerCase
tokens = nltk.word_tokenize(text.lower())
# get the pos tag for each token (check if it is verb, noun, etc.)
tags = nltk.pos_tag(tokens)

# print(tags)
# [(&#x27;experiments&#x27;, &#x27;NNS&#x27;), (&#x27;on&#x27;, &#x27;IN&#x27;), (&#x27;mice&#x27;, &#x27;NNS&#x27;), (&#x27;at&#x27;, &#x27;IN&#x27;), (&#x27;boston&#x27;, &#x27;NN&#x27;), (&#x27;university&#x27;, &#x27;NN&#x27;), (&#x27;have&#x27;, &#x27;VBP&#x27;), (&#x27;spotlighted&#x27;, &#x27;VBN&#x27;), (&#x27;an&#x27;, &#x27;DT&#x27;), (&#x27;ambiguous&#x27;, &#x27;JJ&#x27;), (&#x27;u.s.&#x27;, &#x27;NN&#x27;), (&#x27;policy&#x27;, &#x27;NN&#x27;), (&#x27;for&#x27;, &#x27;IN&#x27;), (&#x27;research&#x27;, &#x27;NN&#x27;), (&#x27;on&#x27;, &#x27;IN&#x27;), (&#x27;potentially&#x27;, &#x27;RB&#x27;), (&#x27;dangerous&#x27;, &#x27;JJ&#x27;), (&#x27;pathogens&#x27;, &#x27;NNS&#x27;), (&#x27;.&#x27;, &#x27;.&#x27;)]

lemmatizer = nltk.stem.WordNetLemmatizer()
text_lemmas = []

for token, tag in zip (tokens, tags):
    # extract part-of-speach tag
    tag_pos = tag[1][0].lower()
    # print(token, tag_pos)
    # exclude prepositions, articles, etc
    if tag_pos in [&#x27;n&#x27;, &#x27;v&#x27;, &#x27;a&#x27;, &#x27;r&#x27;]:
        lemma = lemmatizer.lemmatize(token, tag_pos)
        text_lemmas.append(lemma)


print(text_lemmas)
# [&#x27;experiment&#x27;, &#x27;mouse&#x27;, &#x27;boston&#x27;, &#x27;university&#x27;, &#x27;have&#x27;, &#x27;spotlight&#x27;, &#x27;u.s.&#x27;, &#x27;policy&#x27;, &#x27;research&#x27;, &#x27;potentially&#x27;, &#x27;pathogen&#x27;]
</code></pre>
<h3 id="compare-word-stems">Compare Word Stems</h3>
<pre><code class="language-py">import nltk

# only run once
# nltk.download(&#x27;wordnet&#x27;)
# nltk.download(&#x27;omw-1.4&#x27;)
# nltk.download(&#x27;punkt&#x27;)
# nltk.download(&#x27;averaged_perceptron_tagger&#x27;)

text1 = &#x27;The Experiments on mice...&#x27;
text2 = &#x27;The Experiment on a mouse...&#x27;

lemmatizer = nltk.stem.WordNetLemmatizer()

def get_lemmas(text):
    # break text up into single words toLowerCase
    tokens = nltk.word_tokenize(text.lower())
    tags = nltk.pos_tag(tokens)

    text_lemmas = []

    for token, tag in zip (tokens, tags):
        # extract part-of-speech tag
        tag_pos = tag[1][0].lower()
        # exclude prepositions, articles, etc
        if tag_pos in [&#x27;n&#x27;, &#x27;v&#x27;, &#x27;a&#x27;, &#x27;r&#x27;]:
            lemma = lemmatizer.lemmatize(token, tag_pos)
            text_lemmas.append(lemma)

    # print(text_lemmas)
    return text_lemmas

source1 = get_lemmas(text1)
source2 = get_lemmas(text2)


print(source1 == source2)
# True
</code></pre>
<h3 id="similarity-coefficient">Similarity Coefficient</h3>
<p>Compare a set of sentences to a query string and return the string with the highest similarity:</p>
<pre><code class="language-py">import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

lemmatizer = nltk.stem.WordNetLemmatizer()

# only run once
# nltk.download(&#x27;wordnet&#x27;)
# nltk.download(&#x27;omw-1.4&#x27;)
# nltk.download(&#x27;punkt&#x27;)
# nltk.download(&#x27;averaged_perceptron_tagger&#x27;)

json_response = { &quot;articles&quot;: [
        { &quot;id&quot;: &quot;432rsde34t&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;abstract&quot;: &quot;Experiments on mice at Boston University have spotlighted an ambiguous U.S. policy for research on potentially dangerous pathogens.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;},
        { &quot;id&quot;: &quot;67Gfdhnd4&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;abstract&quot;: &quot;The move puts President Biden’s debt relief plan on hold. The court granted a stay in response to an appeal filed by six Republican-led states.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;},
        { &quot;id&quot;: &quot;sHB8679iasd&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;abstract&quot;: &quot;The new Communist Party elite will limit potential resistance to Mr. Xi’s agenda of bolstering security and expanding state sway over the economy.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;},
        { &quot;id&quot;: &quot;dhg456wASF&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;abstract&quot;: &quot;When Laurene Powell Jobs unveiled a website dedicated to her husband, many wondered if it could change how influential people burnish their legacies.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;},
        { &quot;id&quot;: &quot;gfdh346Nr&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;abstract&quot;: &quot;If former President Trump turns down the drama of testifying, his legal team could mount several constitutional and procedural arguments in court.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;}
    ]
}

# print(json_response[&#x27;articles&#x27;][0][&#x27;abstract&#x27;])

text = &quot;&quot;

# extract article abstracts and combine them
for article in json_response[&#x27;articles&#x27;]:
    # print(article[&#x27;abstract&#x27;])
    text = text + article[&#x27;abstract&#x27;] + &#x27; &#x27;

# print(text)


# compare articles to the following search query
query = &#x27;University Boston Experiment&#x27;

# get list of single sentences out of combined text
sentences = nltk.sent_tokenize(text)
# print(sentences)
# append query sentence to list
sentences.append(query)


def get_lemmas(text):
    # break text up into single words toLowerCase
    tokens = nltk.word_tokenize(text.lower())
    tags = nltk.pos_tag(tokens)

    text_lemmas = []

    for token, tag in zip (tokens, tags):
        # extract part-of-speech tag
        tag_pos = tag[1][0].lower()
        # exclude prepositions, articles, etc
        if tag_pos in [&#x27;n&#x27;, &#x27;v&#x27;, &#x27;a&#x27;, &#x27;r&#x27;]:
            lemma = lemmatizer.lemmatize(token, tag_pos)
            text_lemmas.append(lemma)

    return text_lemmas

# get lemmas out of list of sentences
tv = TfidfVectorizer(tokenizer=get_lemmas)
# generate matrix with weights for each lemma in the given text (how often do they appear)
tf = tv.fit_transform(sentences)

# import pandas as pd
# df = pd.DataFrame(tf.toarray(), columns=tv.get_feature_names_out())
# print(df)
# this returns the matrix of words and their relative weight.
# each row represents a sentence that we fed into the function.
# the last row tf[-1] is the query string
# #      agenda    appeal  argument   bolster   boston   burnish  ...  university    unveil   website    wonder        xi         ’
# # 0  0.000000  0.000000  0.000000  0.000000  0.26162  0.000000  ...     0.26162  0.000000  0.000000  0.000000  0.000000  0.000000
# # 1  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000  ...     0.00000  0.000000  0.000000  0.000000  0.000000  0.305598
# # 2  0.000000  0.395963  0.000000  0.000000  0.00000  0.000000  ...     0.00000  0.000000  0.000000  0.000000  0.000000  0.000000
# # 3  0.263724  0.000000  0.000000  0.263724  0.00000  0.000000  ...     0.00000  0.000000  0.000000  0.000000  0.263724  0.218913
# # 4  0.000000  0.000000  0.000000  0.000000  0.00000  0.288675  ...     0.00000  0.288675  0.288675  0.288675  0.000000  0.000000
# # 5  0.000000  0.000000  0.326545  0.000000  0.00000  0.000000  ...     0.00000  0.000000  0.000000  0.000000  0.000000  0.000000
# # 6  0.000000  0.000000  0.000000  0.000000  0.57735  0.000000  ...     0.57735  0.000000  0.000000  0.000000  0.000000  0.000000

# # [7 rows x 59 columns]

# Now we can calculate the relative similarity
# of each sentence to the query string

coefficients = cosine_similarity(tf[-1], tf)

# print(coefficients)
# the result is that the query string matches itself by 100%
# and the next best match is the first sentence
# [[0.4531384 0.        0.        0.        0.        0.        1.]]

# now we can sort that list and extract the matching sentence
# index = coefficients.argsort()[0]
# the result is a nested list use zero index or flatten() to extract
# print(index)

# 6 represents the query string and 0 is the position of the best match
# [1 2 3 4 5 0 6]

# so we need to extract the second to last
index = coefficients.argsort().flatten()[-2]

# we can use the index to get the sentence with the best match
print(sentences[index])

# Result:
# Experiments on mice at Boston University have spotlighted an ambiguous U.S. policy for research on potentially dangerous pathogens.
</code></pre>
<h3 id="sentiment-analysis">Sentiment Analysis</h3>
<p>Analyze the overall sentiment towards a product based on it&#x27;s customer reviews:</p>
<pre><code class="language-py">from nltk.sentiment import SentimentIntensityAnalyzer

# run once
# import nltk
# nltk.download(&#x27;vader_lexicon&#x27;)

analyzer = SentimentIntensityAnalyzer()

json_response = { &quot;reviews&quot;: [
        { &quot;id&quot;: &quot;432rsde34t&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;text&quot;: &quot;I regret this purchase... Only buy if you enjoy a keyboard that goes to sleep even when hardwired and takes like 5 seconds to wake up. This means copy and paste will sometimes fail on the copy because keyboard was sleeping or you think you are typing but you are not lol. So if you throw in the fact that you will get random stuck keys and sometimes profile changes what you actually have is just an annoying keyboard. I have never done so many updates on a review, this is what a mistake it is to purchase this hardware. And take it from me, someone who has a lot of razer products and all of which have similar issues... look else where, Razer is not the company you remember, very disappointing.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;},
        { &quot;id&quot;: &quot;67Gfdhnd4&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;text&quot;: &quot;I do have a couple of complaints, though. The software is a bit slow and bloated and seems to slow down my startup time on my computer. I am also having issues with the volume wheel - sometimes it will scroll web pages for some reason and does weird things like jump from 50 to 100 or turn up when i turn down. I also wish it was a bit cheaper, but for my requirements, I did not really have much choice.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;},
        { &quot;id&quot;: &quot;sHB8679iasd&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;text&quot;: &quot;I purchased the full length Halo Infinite edition with green switches for the tactile clickiness. Needed a second keyboard for work, thought why not try a smaller form factor from the same product line with the same green switches. I am guessing it is from the phantom keycaps, but the green switches are somewhat muffled and mushy in this form factor. I am 50/50 on the phantom edition keycaps for this form factor. I am new to it, so where my muscle memory puts the keys is incorrect. And without static backlighting set, I feel lost while trying to blaze through a long work email. I decided to use my full length version for work and this for my personal gaming desktop since I mainly use a controller or a Logitech G13 when controllers are not supported.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;},
        { &quot;id&quot;: &quot;dhg456wASF&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;text&quot;: &quot;I was REALLY enjoying this keyboard (and my wife was enjoying hers too) - however, both keyboard developped an extra keystroke when typing. This lead to extra letters being inputted, which made the keyboard unuseable. Its a shame, because for the price it was a great keyboard. It also fit really well into our Razer ecosystem AND had amazing battery life with the RGB on. Alas, the keystroke issue is too big a hassle to try again, sadly.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;},
        { &quot;id&quot;: &quot;gfdh346Nr&quot;,
          &quot;title&quot;: &quot;Some Title&quot;,
          &quot;text&quot;: &quot;This keyboard is excellent, but only if you mod this keyboard, like add some foam, lube the switches, add some painters tape, bandaid mod the stabs and lube them, then switch for some Durocks (cus razer is trying to be cool again and make their own, which quite frankly it&#x27;s the same as plate mount stabs unlike the huntsman mini) so for the price of this keyboard it is good when amazon discount it but in general for 200$ Nah pass (but I got a deal for only 126$). I kind of get where they use premium metal, good lithium battery, two signal receivers, three battery cutoff the PCB, the power monitor and distribute board with, and the battery integrated itself but still, only if people knew this. They might appreciate it a little more. Still, the transparent bottom plastic with the glowing razer logo scratches way too quickly; that is all I have to say about this keyboard.&quot;,
          &quot;author&quot;: &quot;Some Author&quot;}
    ]
}

polarity_scores = []

# extract reviews text and combine them
for review in json_response[&#x27;reviews&#x27;]:
    score = analyzer.polarity_scores(review[&#x27;text&#x27;])
    polarity_scores.append(score)

# print(polarity_scores)
# [{&#x27;neg&#x27;: 0.149, &#x27;neu&#x27;: 0.823, &#x27;pos&#x27;: 0.027, &#x27;compound&#x27;: -0.953}, {&#x27;neg&#x27;: 0.042, &#x27;neu&#x27;: 0.91, &#x27;pos&#x27;: 0.047, &#x27;compound&#x27;: 0.1027}, {&#x27;neg&#x27;: 0.042, &#x27;neu&#x27;: 0.958, &#x27;pos&#x27;: 0.0, &#x27;compound&#x27;: -0.659}, {&#x27;neg&#x27;: 0.085, &#x27;neu&#x27;: 0.683, &#x27;pos&#x27;: 0.231, &#x27;compound&#x27;: 0.9397}, {&#x27;neg&#x27;: 0.053, &#x27;neu&#x27;: 0.822, &#x27;pos&#x27;: 0.125, &#x27;compound&#x27;: 0.9109}]

# neg = negativity score
# neu = neutrality score
# pos = positivity score
# compound = sentiment score can range from -1 to 1. closer to 1 = more positive

sentiment_sum = 0

for compound_sentiment in polarity_scores:
    # print(compound_sentiment[&#x27;compound&#x27;])
    sentiment_sum = sentiment_sum + float(compound_sentiment[&#x27;compound&#x27;])

average_sentiment = sentiment_sum / len(polarity_scores)

# print(average_sentiment)
# # 0.06825999999999999

if average_sentiment &gt; 1.3:
    print(&#x27;INFO :: The average sentiment is POSITIVE&#x27;)
elif average_sentiment &lt; -0.3:
    print(&#x27;INFO :: The average sentiment is NEGATIVE&#x27;)
else:
    print(&#x27;INFO :: The average sentiment is NEUTRAL&#x27;)


# INFO :: The average sentiment is NEUTRAL
</code></pre>
<h3 id="online-search-wikipedia">Online Search (Wikipedia)</h3>
<pre><code class="language-py">import nltk
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

import wikipedia

lemmatizer = nltk.stem.WordNetLemmatizer()

# only run once
# nltk.download(&#x27;wordnet&#x27;)
# nltk.download(&#x27;omw-1.4&#x27;)
# nltk.download(&#x27;punkt&#x27;)
# nltk.download(&#x27;averaged_perceptron_tagger&#x27;)

wiki = wikipedia.page(&#x27;List of Game of Thrones characters&#x27;, auto_suggest=False).content

# get list of single sentences out of combined text
response = nltk.sent_tokenize(wiki)


def get_lemmas(text):
    # break text up into single words toLowerCase
    tokens = nltk.word_tokenize(text.lower())
    tags = nltk.pos_tag(tokens)

    text_lemmas = []

    for token, tag in zip (tokens, tags):
        # extract part-of-speech tag
        tag_pos = tag[1][0].lower()
        # exclude prepositions, articles, etc
        if tag_pos in [&#x27;n&#x27;, &#x27;v&#x27;, &#x27;a&#x27;, &#x27;r&#x27;]:
            lemma = lemmatizer.lemmatize(token, tag_pos)
            text_lemmas.append(lemma)

    return text_lemmas


def find_similarity(response, query):
    # get lemmas out of list of sentences
    tv = TfidfVectorizer(tokenizer=get_lemmas)
    # generate matrix with weights for each lemma in the given text (how often do they appear)
    tf = tv.fit_transform(response)
    # Now we can calculate the relative similarity
    # of each sentence to the query string
    coefficients = cosine_similarity(tf[-1], tf)
    # so we need to extract the second to last
    index = coefficients.argsort().flatten()[-2]
    score = coefficients.flatten()[index]
    if score &gt; 0:
        return &#x27;:: RESULT :: &#x27; + response[index] + &#x27; :: SCORE :: &#x27; + str(score) + &#x27; ::&#x27;
    else:
        return &#x27;:: INFO :: No Match Found&#x27;


while True:
    query = input(&#x27;:: Query Input:: &#x27;)
    if query == &#x27;quit&#x27;:
        print(&#x27;:: INFO :: Shutting down...&#x27;)
        quit()
    else:
        response.append(query)
        output = find_similarity(response=response, query=query)
        print(output)
</code></pre></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/python">Python</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Development/Python/2022-10-22-python-nlp/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/Development/Python/2022-12-11-pipenv/2022-12-11"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Pipenv - Welcome NPM</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/Development/Python/2022-10-15-python-rest-server/2022-10-15"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Python - Build a REST API</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#natural-language-toolkit" class="table-of-contents__link toc-highlight">Natural Language Toolkit</a><ul><li><a href="#finding-word-stems" class="table-of-contents__link toc-highlight">Finding Word Stems</a></li><li><a href="#lemmatizing-flow-text" class="table-of-contents__link toc-highlight">Lemmatizing Flow Text</a></li><li><a href="#compare-word-stems" class="table-of-contents__link toc-highlight">Compare Word Stems</a></li><li><a href="#similarity-coefficient" class="table-of-contents__link toc-highlight">Similarity Coefficient</a></li><li><a href="#sentiment-analysis" class="table-of-contents__link toc-highlight">Sentiment Analysis</a></li><li><a href="#online-search-wikipedia" class="table-of-contents__link toc-highlight">Online Search (Wikipedia)</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Research</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Notebook</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tags">Tags</a></li><li class="footer__item"><a class="footer__link-item" href="/Curriculum-Vitae">CV</a></li></ul></div><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/mike-polinowski-6396ba121/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/MikePolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.flickr.com/people/149680084@N06/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Flickr<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Mike Polinowski, INSTAR Deutschland GmbH, Shenzhen - China.</div></div></div></footer></div>
</body>
</html>