<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">DLIB Face Recognition | Mike Polinowski</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/2023-10-01"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="DLIB Face Recognition | Mike Polinowski"><meta data-rh="true" name="description" content="Detect faces in images and compare their feature vector to known entities"><meta data-rh="true" property="og:description" content="Detect faces in images and compare their feature vector to known entities"><link data-rh="true" rel="icon" href="/img/icons/favicon-32x32.png"><link data-rh="true" rel="canonical" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/2023-10-01"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/2023-10-01" hreflang="en"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/2023-10-01" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Mike Polinowski RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Mike Polinowski Atom Feed">




<link rel="icon" href="/img/angular_momentum.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37,194,160)">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#000">
<link rel="apple-touch-icon" href="/img/angular_momentum.png">
<link rel="mask-icon" href="/img/angular_momentum.png" color="rgb(33,33,33)">
<meta name="msapplication-TileImage" content="/img/angular_momentum.png">
<meta name="msapplication-TileColor" content="#000">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-P74BDWF0C6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-P74BDWF0C6",{})</script><link rel="stylesheet" href="/assets/css/styles.08c8c484.css">
<script src="/assets/js/runtime~main.d611b206.js" defer="defer"></script>
<script src="/assets/js/main.35b0b7ac.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Mike Polinowski</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/docs/tags">Tags</a><a class="navbar__item navbar__link" href="/Search">Search</a><a href="https://mpolinowski.github.io/Personal" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/development">Development</a><button aria-label="Expand sidebar category &#x27;Development&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/devops">DevOps</a><button aria-label="Expand sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/machine-learning-ai-and-computer-vision">Machine Learning, AI and Computer Vision</a><button aria-label="Collapse sidebar category &#x27;Machine Learning, AI and Computer Vision&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/category/machine-learning">Machine Learning</a><button aria-label="Collapse sidebar category &#x27;Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/2023-10-01">DLIB Face Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-23--yolo8-listen/2023-09-23">Audio Classification with Computer Vision</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/2023-09-21">CVAT Semi-automatic and Automatic Annotation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-19--cvat-computer-vision-annotation-tool/2023-09-19">Computer Vision Annotation Tool (CVAT) Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/2023-09-17">YOLOv8 Nightshift</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/2023-09-15">YOLOv8 License Plate Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-10--model-explainability-shap/2023-09-11">Scikit-Learn ML Model Explainability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-05--semantic-segmentation-in-opencv/2023-09-05">Using Tensorflow Models in OpenCV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-01--yolo-i-know-flowers/2023-09-01">YOLOv8 Image Classifier</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/2023-08-31">Detectron Object Detection with OpenImages Dataset (WIP)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-30--instance_segmentation_detectron2_model_zoo_mask_rcnn/2023-08-30">Instance Segmentation with PyTorch (Mask RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-29--semantic-segmentation-detectron2-model-zoo-faster-rcnn/2023-08-29">Image Segmentation with PyTorch (Faster RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-28--semantic-segmentation-detectron2-model-zoo/2023-08-28">Image Segmentation with PyTorch (RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-27--image-segmentation-with-pytorch/2023-08-27">Image Segmentation with PyTorch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/2023-08-21">Containerized PyTorch Dev Workflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-13-tensorflow-i-know-flowers-model-eval/2023-08-13">Tensorflow Image Classifier - Model Evaluation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-12-tensorflow-i-know-flowers-xception/2023-08-12">Tensorflow Image Classifier - Xception</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-11-tensorflow-i-know-flowers-vit/2023-08-11">Tensorflow Image Classifier - ViT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-10-tensorflow-i-know-flowers-nasnetmobile/2023-08-10">Tensorflow Image Classifier - NASNetMobile</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-09-tensorflow-i-know-flowers-mobilenetv3small/2023-08-09">Tensorflow Image Classifier - MobileNetV3Small</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-08-tensorflow-i-know-flowers-mobilenetv3large/2023-08-08">Tensorflow Image Classifier - MobileNetV3Large</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-07-tensorflow-i-know-flowers-mobilenetv2/2023-08-07">Tensorflow Image Classifier - MobileNetV2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/2023-08-06">Tensorflow Image Classifier - InceptionV3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-05-tensorflow-i-know-flowers-efficientnetv2s/2023-08-05">Tensorflow Image Classifier - EfficientNetV2S</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-04-tensorflow-i-know-flowers-efficientnetv2b0/2023-08-04">Tensorflow Image Classifier - EfficientNetV2B0</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit/2023-08-03">Tensorflow Image Classifier - Data-efficient Image Transformers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-02-tensorflow-i-know-flowers-preprocessing/2023-08-02">Tensorflow Image Classifier - Data Pre-processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-01-tensorflow-i-know-flowers-intro/2023-08-01">Tensorflow Image Classifier - Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-27-tensorflow-vision-transformer/2023-07-27">Tensorflow VITs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/2023-07-26">Human Emotion Detection with Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/2023-07-25">Working with ONNX Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-21-introduction-to-pytorch-caffe2/2023-07-21">Introduction to Caffe2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-02-sql-in-data-science-ml/2023-07-02">SQL in Data Science - Machine Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-30-sql-in-data-science-advanced/2023-06-30">SQL in Data Science - Slightly more Advanced Queries</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-27-sql-in-data-science-basics/2023-06-27">SQL in Data Science - The Basics using Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-26-autogluon-transit-photometry-dataset/2023-06-26">Detection of Exoplanets using Transit Photometry</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-19-tensorflow-natural-language-processing/2023-04-19">(Re) Introduction to Tensorflow Natural Language Processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-16-deep-3d-image-segmentation/2023-04-16">3D Image Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-14-manifold-learning-for-image-segmentation/2023-04-14">Dimensionality Reduction for Image Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-fisher-discriminant-analysis/2023-04-13">Fisher Linear Discriminant Analysis (LDA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-isometric-mapping/2023-04-13">Isometric Mapping (ISOMAP)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-multi-dimensional-scaling/2023-04-13">Multidimensional Scaling (MDS)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-12-tstochastic-neighbor-embedding/2023-04-12">tStochastic Neighbor Embedding (t-SNE)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-11-locally-linear-embedding/2023-04-11">Locally Linear Embedding (LLE)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-09-principal-component-analysis/2023-04-09">Principal Component Analysis (PCA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-generative-adversial-networks/2023-03-26">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05">Tensorflow 2 - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03">Tensorflow 2 - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02">Tensorflow 2 - Neural Network Classifications</a><button aria-label="Expand sidebar category &#x27;Tensorflow 2 - Neural Network Classifications&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28">Tensorflow 2 - Neural Network Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27">Tensorflow 2 - Neural Network Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22">Tensorflow 2 - An (Re)Introduction 2023 (3)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21">Tensorflow 2 - An (Re)Introduction 2023 (2)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19">Tensorflow 2 - An (Re)Introduction 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-vgg16/2023-02-18">Keras for Tensorflow - VGG16 Network Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-rnn/2023-02-18">Keras for Tensorflow - Recurrent Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/2023-02-17">Keras for Tensorflow - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-16-keras-introduction-ann/2023-02-16">Keras for Tensorflow - Artificial Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-15-as-one-yolo-object-tracking/2023-02-15">YOLOv8 with AS-One</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-14-keras-introduction/2023-02-14">Keras for Tensorflow - An (Re)Introduction 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-30-predicting-wine-quality/2023-01-30">SciKit Wine Quality</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-28-opencv-coin-counter/2023-01-28">OpenCV Count My Money</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-14-yolov7_to_tensorflow/2023-01-14">YOLOv7 to Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-13-yolov7_data_conversion/2023-01-13">YOLOv7 Label Conversion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-10-yolov7_custom_data/2023-01-10">YOLOv7 Training with Custom Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-08-depth-vision-midas/2023-01-08">MiDaS Depth Vision</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-05-yolov7/2023-01-05">YOLOv7 Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-31-tf-rnn-text-generation/2022-12-31">Recurrent Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/2022-12-28">Deep Convolutional Generative Adversarial Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21">Tensorflow Downsampling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-deepdream/2022-12-21">Tensorflow Deep Dream</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-20-tf-representation/2022-12-19">Tensorflow Representation Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-19-tf-hub/2022-12-19">Tensorflow Hub</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/2022-12-18">Tensorflow Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-16-tf-cifar/2022-12-16">Tensorflow Image Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part6/2022-12-12">Breast Histopathology Image Segmentation Part 6</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part5/2022-12-12">Breast Histopathology Image Segmentation Part 5</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part4/2022-12-11">Breast Histopathology Image Segmentation Part 4</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part3/2022-12-11">Breast Histopathology Image Segmentation Part 3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part2/2022-12-11">Breast Histopathology Image Segmentation Part 2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/2022-12-10">Breast Histopathology Image Segmentation Part 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27">Deep Docker on Arch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/2022-04-04">Face Restoration with GFPGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-03-pytorch-real-super-resolution/2022-04-03">Super Resolution with Real-ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-02-pytorch-super-resolution/2022-04-02">Super Resolution with ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01">Deep Audio</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20">Yolo App - YOLOv5 Data Preparation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19">Yolo App - Flask Web Application</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18">Yolo App - Tesseract Optical Character Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-17--yolo-app-prediction-pipeline/2022-02-17">Yolo App - Pipeline Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16">Yolo App - Train a Model with Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15">Yolo App - Data Collection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-10--opencv-optical-flow-tracking/2021-12-10">OpenCV Optical Flow Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-09--opencv-camshift-tracking/2021-12-09">OpenCV CAMshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-08--opencv-meanshift-tracking/2021-12-08">OpenCV Meanshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/2021-12-07">OpenCV Object Detection and Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/2021-12-06">OpenCV Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-05--opencv-face-detection/2021-12-05">OpenCV Face Detection and Privacy</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/2021-12-04">OpenCV Image Objects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-03--opencv-image-operations/2021-12-03">OpenCV Image Operations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-02--opencv-with-videos/2021-12-02">OpenCV, Streams and Video Files</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-01--opencv-with-images/2021-12-01">OpenCV and Images</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-15--facebook-prophet-introduction/2021-11-15">Introduction into FB Prophet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-14--tensorflow-model-for-tfjs/2021-11-14">Tensorflow.js React App</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/2021-11-13">Tensorflow2 Model Zoo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-12--tensorflow-crash-course-part-v/2021-11-12">Tensorflow2 Crash Course - Part V</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-11--tensorflow-crash-course-part-iv/2021-11-11">Tensorflow2 Crash Course - Part IV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-10--tensorflow-crash-course-part-iii/2021-11-10">Tensorflow2 Crash Course - Part III</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-09--tensorflow-crash-course-part-ii/2021-11-09">Tensorflow2 Crash Course - Part II</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-08--tensorflow-crash-course-part-i/2021-11-08">Tensorflow Crash Course - Part I</a><button aria-label="Expand sidebar category &#x27;Tensorflow Crash Course - Part I&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-07--opencv-crash-course-part-ii/2021-11-07">OpenCV Crash Course Part II</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-06--opencv-crash-course-part-i/2021-11-06">OpenCV Crash Course Part I</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-05--license-plates-yolov4-opencv-tesseract/2021-11-05">License Plate Recognition with YOLOv4, OpenCV and Tesseract</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-04--installing-yolov4/2021-11-04">Installing YOLOv4 with Anaconda</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/2021-11-03">Streamlit user interface for openCV/Mediapipe face mesh app</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-02--spacy_ner_predictions/2021-11-02">spaCy NER Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-01--spacy_natural_language_processing/2021-11-01">spaCy NER on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-04-01--introduction-to-keras/2019-04-01">Introduction to Keras</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/2021-10-31">Tesseract OCR on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-03-31--introduction-to-tensorflow-2-beta/2019-03-31">Introduction to TensorFlow 2 Beta</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/2018-01-02">Machine Learning with SciKit Learn</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/aiops">AIOps</a><button aria-label="Expand sidebar category &#x27;AIOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/automation-deep-vision-and-robotics">Automation, Deep Vision and Robotics</a><button aria-label="Expand sidebar category &#x27;Automation, Deep Vision and Robotics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/machine-learning-ai-and-computer-vision"><span itemprop="name">Machine Learning, AI and Computer Vision</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/machine-learning"><span itemprop="name">Machine Learning</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">DLIB Face Recognition</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>DLIB Face Recognition</h1></header><p><img alt="TST, Hongkong" src="/assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-252551beac0b36b4ba53ccd380897f8e.jpg" width="1500" height="620"></p>
<ul>
<li><a href="#detect-face-location-cpu">Detect Face Location (CPU)</a>
<ul>
<li><a href="#crop-location">Crop Location</a></li>
<li><a href="#get-all-the-training-images">Get all the Training Images</a></li>
</ul>
</li>
<li><a href="#face-recognition">Face Recognition</a>
<ul>
<li><a href="#compare-faces">Compare Faces</a>
<ul>
<li><a href="#test-image-1">Test Image 1</a></li>
<li><a href="#test-image-2">Test Image 2</a></li>
<li><a href="#test-image-3">Test Image 3</a></li>
<li><a href="#test-image-4">Test Image 4</a></li>
<li><a href="#test-image-5">Test Image 5</a></li>
<li><a href="#test-image-6">Test Image 6</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#detect-face-location-gpu--batch-processing">Detect Face Location (GPU + Batch Processing)</a></li>
<li><a href="#draw-bounding-boxes">Draw Bounding Boxes</a></li>
<li><a href="#save-feature-vector">Save Feature Vector</a></li>
</ul>
<ul>
<li>
<p><a href="https://github.com/mpolinowski/yolo-listen">Github Repository</a></p>
</li>
<li>
<p><a href="https://github.com/ageitgey/face_recognition">Face Recognition</a></p>
</li>
</ul>
<p>Recognize and manipulate faces from Python or from the command line with the world&#x27;s simplest face recognition library. Built using <a href="http://dlib.net/">dlib</a>&#x27;s state-of-the-art face recognition built with deep learning. The model has an accuracy of 99.38% on the <a href="http://vis-www.cs.umass.edu/lfw/">Labeled Faces in the Wild</a> benchmark.</p>
<pre><code class="language-python">!pip install face_recognition
</code></pre>
<pre><code class="language-python">import face_recognition
import numpy as np
</code></pre>
<pre><code class="language-python">img_bobby =&quot;faces/bobbie_w_draper.jpg&quot;
img_jim =&quot;faces/jim_holden.jpg&quot;
img_amos =&quot;faces/amos_burton.jpg&quot;
img_camina =&quot;faces/camina_drummer.jpg&quot;
img_naomi =&quot;faces/naomi_nagata.jpg&quot;
img_chrisjen =&quot;faces/chrisjen_avasarala.jpg&quot;

image_path = img_bobby
</code></pre>
<h2 id="detect-face-location-cpu">Detect Face Location (CPU)</h2>
<p>Re-run the following steps for all training images above:</p>
<pre><code class="language-python">image = face_recognition.load_image_file(image_path)
face_locations = face_recognition.face_locations(image)
</code></pre>
<h3 id="crop-location">Crop Location</h3>
<pre><code class="language-python">import cv2 as cv
import matplotlib.pyplot as plt
</code></pre>
<pre><code class="language-python">img = cv.imread(image_path)
img = cv.cvtColor(img, cv.COLOR_BGR2RGB)
</code></pre>
<pre><code class="language-python">plt.imshow(img)
plt.axis(&#x27;off&#x27;)

for face_location in face_locations:  
    plt.plot(face_location[3], face_location[0], &#x27;ro&#x27;) 
    plt.plot(face_location[1], face_location[0], &#x27;r+&#x27;)     
    plt.plot(face_location[3], face_location[2], &#x27;bo&#x27;)
    plt.plot(face_location[1], face_location[2], &#x27;b+&#x27;)

plt.show()
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_10_0-3fc99340460a5394b27cc4f3f5c9d7fd.png" width="373" height="389"></p>
<pre><code class="language-python">for face_location in face_locations: 
    x1, y1 = face_location[3], face_location[2]
    x2, y2 = face_location[1], face_location[2]
    x3, y3 = face_location[1], face_location[0]
    x4, y4 = face_location[3], face_location[0]

top_left_x = min([x1,x2,x3,x4])
top_left_y = min([y1,y2,y3,y4])
bot_right_x = max([x1,x2,x3,x4])
bot_right_y = max([y1,y2,y3,y4])

cropped_image = img[top_left_y:bot_right_y, top_left_x:bot_right_x]
</code></pre>
<pre><code class="language-python">plt.imshow(cropped_image)
plt.axis(&#x27;off&#x27;)
</code></pre>
<p>(-0.5, 267.5, 266.5, -0.5)</p>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_12_1-34ededf10548acc3e3dac3d0586e6145.png" width="390" height="389"></p>
<pre><code class="language-python">cv.imwrite(&#x27;faces/cut/bobbie_w_draper.jpg&#x27;, cv.cvtColor(cropped_image, cv.COLOR_RGB2BGR))
</code></pre>
<p>True</p>
<h3 id="get-all-the-training-images">Get all the Training Images</h3>
<pre><code class="language-python">bobby_train = face_recognition.load_image_file(img_bobby)
jim_train = face_recognition.load_image_file(img_jim)
amos_train = face_recognition.load_image_file(img_amos)
camina_train = face_recognition.load_image_file(img_camina)
naomi_train = face_recognition.load_image_file(img_naomi)
chrisjen_train = face_recognition.load_image_file(img_chrisjen)

bobby_encoding = face_recognition.face_encodings(bobby_train)[0]
jim_encoding = face_recognition.face_encodings(jim_train)[0]
amos_encoding = face_recognition.face_encodings(amos_train)[0]
camina_encoding = face_recognition.face_encodings(camina_train)[0]
naomi_encoding = face_recognition.face_encodings(naomi_train)[0]
chrisjen_encoding = face_recognition.face_encodings(chrisjen_train)[0]
</code></pre>
<pre><code class="language-python">from glob import glob

cropped_images = glob(&#x27;./faces/cut/*.jpg&#x27;)
</code></pre>
<pre><code class="language-python">plt.figure(figsize=(12, 8))
plt.suptitle(&#x27;Training Images&#x27;)

ax = plt.subplot(2, 3, 1)
img_path = cropped_images[0]
img_title = &#x27;face: &#x27; + cropped_images[0][12:-4]
plt.title(img_title, fontsize=&#x27;medium&#x27;)
image = plt.imread(img_path)
plt.imshow(image, cmap=plt.cm.binary)

ax = plt.subplot(2, 3, 2)
img_path = cropped_images[1]
img_title = &#x27;face: &#x27; + cropped_images[1][12:-4]
plt.title(img_title, fontsize=&#x27;medium&#x27;)
image = plt.imread(img_path)
plt.imshow(image, cmap=plt.cm.binary)

ax = plt.subplot(2, 3, 3)
img_path = cropped_images[2]
img_title = &#x27;face: &#x27; + cropped_images[2][12:-4]
plt.title(img_title, fontsize=&#x27;medium&#x27;)
image = plt.imread(img_path)
plt.imshow(image, cmap=plt.cm.binary)

ax = plt.subplot(2, 3, 4)
img_path = cropped_images[3]
img_title = &#x27;face: &#x27; + cropped_images[3][12:-4]
plt.title(img_title, fontsize=&#x27;medium&#x27;)
image = plt.imread(img_path)
plt.imshow(image, cmap=plt.cm.binary)

ax = plt.subplot(2, 3, 5)
img_path = cropped_images[4]
img_title = &#x27;face: &#x27; + cropped_images[4][12:-4]
plt.title(img_title, fontsize=&#x27;medium&#x27;)
image = plt.imread(img_path)
plt.imshow(image, cmap=plt.cm.binary)

ax = plt.subplot(2, 3, 6)
img_path = cropped_images[5]
img_title = &#x27;face: &#x27; + cropped_images[5][12:-4]
plt.title(img_title, fontsize=&#x27;medium&#x27;)
image = plt.imread(img_path)
plt.imshow(image, cmap=plt.cm.binary)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_17_1-4418223b167876be1fa8babce9252dc7.png" width="986" height="737"></p>
<h2 id="face-recognition">Face Recognition</h2>
<p>Loading a bunch of test images with &quot;unknown&quot; faces:</p>
<pre><code class="language-python">test_image1 = face_recognition.load_image_file(&quot;faces/test/unknown_01.jpg&quot;)
test_image2 = face_recognition.load_image_file(&quot;faces/test/unknown_02.jpg&quot;)
test_image3 = face_recognition.load_image_file(&quot;faces/test/unknown_03.jpg&quot;)
test_image4 = face_recognition.load_image_file(&quot;faces/test/unknown_04.jpg&quot;)
test_image5 = face_recognition.load_image_file(&quot;faces/test/unknown_05.jpg&quot;)
test_image6 = face_recognition.load_image_file(&quot;faces/test/unknown_06.jpg&quot;)

test1_encoding = face_recognition.face_encodings(test_image1)
test2_encoding = face_recognition.face_encodings(test_image2)
test3_encoding = face_recognition.face_encodings(test_image3)
test4_encoding = face_recognition.face_encodings(test_image4)
test5_encoding = face_recognition.face_encodings(test_image5)
test6_encoding = face_recognition.face_encodings(test_image6)
</code></pre>
<h3 id="compare-faces">Compare Faces</h3>
<p>Compare all detected images in the test dataset to the training images:</p>
<pre><code class="language-python">trained_images = [bobby_encoding, jim_encoding, amos_encoding, camina_encoding, naomi_encoding, chrisjen_encoding]
trained_faces = np.array([&quot;bobbie_w_draper&quot;, &quot;jim_holden&quot;, &quot;amos_burton&quot;, &quot;camina_drummer&quot;, &quot;naomi_nagata&quot;, &quot;chrisjen_avasarala&quot;])
</code></pre>
<h4 id="test-image-1">Test Image 1</h4>
<pre><code class="language-python">test1_results = []

for detection in test1_encoding:
    result = face_recognition.compare_faces(trained_images, detection)
    test1_results.append(trained_faces[result])
</code></pre>
<pre><code class="language-python">test_img1 = plt.imread(&#x27;faces/test/unknown_01.jpg&#x27;)
plt.title(&#x27;detected faces: \n&#x27; + str(test1_results), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img1)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_24_1-f63226da303d670adfec0d4b4026bacc.png" width="515" height="321"></p>
<h4 id="test-image-2">Test Image 2</h4>
<pre><code class="language-python">test2_results = []

for detection in test2_encoding:
    result = face_recognition.compare_faces(trained_images, detection)
    test1_results.append(trained_faces[result])
</code></pre>
<pre><code class="language-python">test_img2 = plt.imread(&#x27;faces/test/unknown_02.jpg&#x27;)
plt.title(&#x27;detected faces: \n&#x27; + str(test2_results), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img2)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_27_1-a0008dd355ec2171e6e929f44c33f48e.png" width="515" height="332"></p>
<h4 id="test-image-3">Test Image 3</h4>
<pre><code class="language-python">test3_results = []

for detection in test3_encoding:
    result = face_recognition.compare_faces(trained_images, detection)
    test3_results.append(trained_faces[result])

test3_results
</code></pre>
<pre><code class="language-python">test_img3 = plt.imread(&#x27;faces/test/unknown_03.jpg&#x27;)
plt.title(&#x27;detected faces: \n&#x27; + str(test3_results), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img3)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_30_1-351af2c686b85232dc0209d055fe7c2b.png" width="512" height="422"></p>
<h4 id="test-image-4">Test Image 4</h4>
<pre><code class="language-python">test4_results = []

for detection in test4_encoding:
    result = face_recognition.compare_faces(trained_images, detection)
    test4_results.append(trained_faces[result])
</code></pre>
<pre><code class="language-python">test_img4 = plt.imread(&#x27;faces/test/unknown_04.jpg&#x27;)
plt.title(&#x27;detected faces: \n&#x27; + str(test4_results), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img4)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_33_1-d8ba9c2f02a6b87fab02cf050cda3194.png" width="702" height="306"></p>
<h4 id="test-image-5">Test Image 5</h4>
<pre><code class="language-python">test5_results = []

for detection in test5_encoding:
    result = face_recognition.compare_faces(trained_images, detection)
    test5_results.append(trained_faces[result])
</code></pre>
<pre><code class="language-python">test_img5 = plt.imread(&#x27;faces/test/unknown_05.jpg&#x27;)
plt.title(&#x27;detected faces: \n&#x27; + str(test5_results), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img5)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_36_1-8138e3bdc663ad0b2245d5a557597a43.png" width="664" height="332"></p>
<h4 id="test-image-6">Test Image 6</h4>
<pre><code class="language-python">test6_results = []

for detection in test6_encoding:
    result = face_recognition.compare_faces(trained_images, detection)
    test6_results.append(trained_faces[result])
</code></pre>
<pre><code class="language-python">test_img6 = plt.imread(&#x27;faces/test/unknown_06.jpg&#x27;)
plt.title(&#x27;detected faces: \n&#x27; + str(test6_results), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img6)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_39_1-194c400485fe4b708793d0be5d119a6a.png" width="515" height="384"></p>
<h2 id="detect-face-location-gpu--batch-processing">Detect Face Location (GPU + Batch Processing)</h2>
<pre><code class="language-python">all_training_images = glob(&#x27;./faces/*.jpg&#x27;)
len(all_training_images)
</code></pre>
<p>60</p>
<pre><code class="language-python">ran_gen = np.random.default_rng()

plt.figure(figsize=(14, 12))
plt.suptitle(&#x27;Training Images&#x27;)

for i in range(16):
    ax = plt.subplot(4, 4, i+1)
    random_index = ran_gen.integers(low=0, high=59, size=1)
    i = random_index[0]
    img_loc = all_training_images[i]
    img_title = &#x27;label: &#x27; + all_training_images[i][8:-4]
    image = plt.imread(img_loc)
    plt.imshow(image)
    plt.title(img_title, fontsize=&#x27;small&#x27;)
    plt.axis(False)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_42_0-0f8929362920e806619fe16c01b757ed.png" width="1048" height="1064"></p>
<p>For this experiment I collected 10 images from all faces that I used before. All training images only contain one face - so I expect only getting one location that I can map to the image label:</p>
<pre><code class="language-python">image_labels = []
face_locations = []

for image_path in all_training_images:
    image_labels.append(image_path[8:-5])
    image = face_recognition.load_image_file(image_path)
    location = face_recognition.face_locations(image, model=&quot;cnn&quot;)
    face_locations.append(location)
</code></pre>
<pre><code class="language-python">print(len(image_labels), len(face_locations))
</code></pre>
<p>60 60</p>
<p>Now I can get the feature vector for every detected face by it&#x27;s bounding box:</p>
<pre><code class="language-python">face_encodings = []
i = 0

for location in face_locations:
    image = face_recognition.load_image_file(all_training_images[i])
    encoding = face_recognition.face_encodings(image, location)[0]

    face_encodings.append(encoding)
    i+=1
</code></pre>
<pre><code class="language-python">len(face_encodings)
</code></pre>
<p>60</p>
<pre><code class="language-python">testcnn1_results = []

for detection in test1_encoding:
    result = face_recognition.compare_faces(face_encodings, detection)
    testcnn1_results.append(np.array(image_labels)[result])
</code></pre>
<pre><code class="language-python">classes = []

test_img1 = plt.imread(&#x27;faces/test/unknown_01.jpg&#x27;)

for result in testcnn1_results:
    label, count = np.unique(result, return_counts=True)
    classes.append(
        (
            # check for unlabeled faces
            count[0] if 0 &lt; len(count) else None, 
            label[0] if 0 &lt; len(label) else None
        )
    )
    
plt.title(str(classes), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img1)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_50_1-73608f4bd670f7c287a2dbbe52e8e996.png" width="515" height="317"></p>
<pre><code class="language-python">testcnn2_results = []

for detection in test2_encoding:
    result = face_recognition.compare_faces(face_encodings, detection)
    testcnn2_results.append(np.array(image_labels)[result])
</code></pre>
<pre><code class="language-python">classes = []

test_img2 = plt.imread(&#x27;faces/test/unknown_02.jpg&#x27;)

for result in testcnn2_results:
    label, count = np.unique(result, return_counts=True)
    classes.append(
        (
            # check for unlabeled faces
            count[0] if 0 &lt; len(count) else None, 
            label[0] if 0 &lt; len(label) else None
        )
    )
    
plt.title(str(classes), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img2)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_52_1-e3f4ebb76c4e94450785d19ebc6cb6f1.png" width="515" height="317"></p>
<pre><code class="language-python">testcnn3_results = []

for detection in test3_encoding:
    result = face_recognition.compare_faces(face_encodings, detection)
    testcnn3_results.append(np.array(image_labels)[result])
</code></pre>
<pre><code class="language-python">classes = []
test_img3 = plt.imread(&#x27;faces/test/unknown_03.jpg&#x27;)

for result in testcnn3_results:
    label, count = np.unique(result, return_counts=True)
    classes.append(
        (
            # check for unlabeled faces
            count[0] if 0 &lt; len(count) else None, 
            label[0]
 if 0 &lt; len(label) else None
        )
    )
    
plt.title(str(classes), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img3)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_54_1-5574a5145b291dbfda722e0e69be9a1b.png" width="512" height="407"></p>
<pre><code class="language-python">testcnn4_results = []

for detection in test4_encoding:
    result = face_recognition.compare_faces(face_encodings, detection)
    testcnn4_results.append(np.array(image_labels)[result])
</code></pre>
<pre><code class="language-python">classes = []
test_img4 = plt.imread(&#x27;faces/test/unknown_04.jpg&#x27;)

for result in testcnn4_results:
    label, count = np.unique(result, return_counts=True)
    classes.append(
        (
            # check for unlabeled faces
            count[0] if 0 &lt; len(count) else None, 
            label[0] if 0 &lt; len(label) else None
        )
    )
    
plt.title(str(classes), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img4)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_56_1-0820cc189b3250cc40e7b6a8b70733ab.png" width="515" height="291"></p>
<pre><code class="language-python">testcnn5_results = []

for detection in test5_encoding:
    result = face_recognition.compare_faces(face_encodings, detection)
    testcnn5_results.append(np.array(image_labels)[result])
</code></pre>
<pre><code class="language-python">classes = []
test_img5 = plt.imread(&#x27;faces/test/unknown_05.jpg&#x27;)

for result in testcnn5_results:
    label, count = np.unique(result, return_counts=True)
    classes.append(
        (
            # check for unlabeled faces
            count[0] if 0 &lt; len(count) else None, 
            label[0] if 0 &lt; len(label) else None
        )
    )
    
plt.title(str(classes), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img5)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_58_1-e6bd78a118a0ea887a49ee266a3ebd7a.png" width="515" height="317"></p>
<pre><code class="language-python">testcnn6_results = []

for detection in test6_encoding:
    result = face_recognition.compare_faces(face_encodings, detection)
    testcnn6_results.append(np.array(image_labels)[result])
</code></pre>
<pre><code class="language-python">classes = []
test_img6 = plt.imread(&#x27;faces/test/unknown_06.jpg&#x27;)

for result in testcnn6_results:
    label, count = np.unique(result, return_counts=True)
    classes.append(
        (
            # check for unlabeled faces
            count[0] if 0 &lt; len(count) else None, 
            label[0] if 0 &lt; len(label) else None
        )
    )
    
plt.title(str(classes), fontsize=&#x27;small&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(test_img6)
</code></pre>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_60_1-e1999a249a86692234578015252719de.png" width="515" height="369"></p>
<h2 id="draw-bounding-boxes">Draw Bounding Boxes</h2>
<pre><code class="language-python">from PIL import Image, ImageDraw
</code></pre>
<p>I&#x27;m using the encodings/labels for the 60 training images generated above:</p>
<pre><code class="language-python">print(len(face_encodings), len(image_labels))
</code></pre>
<p>60 60</p>
<p>Load a test image that contains one of the faces above:</p>
<pre><code class="language-python">unknown_image = face_recognition.load_image_file(&#x27;faces/test/unknown_01.jpg&#x27;)

# Find all the faces and face encodings in the unknown image
found_faces = face_recognition.face_locations(unknown_image)
found_face_encodings = face_recognition.face_encodings(unknown_image, found_faces)

# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library
pil_image = Image.fromarray(unknown_image)
</code></pre>
<pre><code class="language-python"># Create a Pillow ImageDraw Draw instance to draw with
draw = ImageDraw.Draw(pil_image)

# Loop through each face found in the unknown image
for (top, right, bottom, left), face_encoding in zip(found_faces, found_face_encodings):
    # See if the face is a match for the known face(s)
    matches = face_recognition.compare_faces(face_encodings, face_encoding)

    name = &quot;Unknown&quot;

    # If a match was found in face_encodings, just use the first one.
    # if True in matches:
    #     first_match_index = matches.index(True)
    #     name = image_labels[first_match_index]

    # Or instead, use the known face with the smallest distance to the new face
    face_distances = face_recognition.face_distance(face_encodings, face_encoding)
    best_match_index = np.argmin(face_distances)
    if matches[best_match_index]:
        name = image_labels[best_match_index]
    # Draw a box around the face using the Pillow module
    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))

    # Draw a label with a name below the face
    text_width, text_height = draw.textsize(name)
    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))
    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))


# Remove the drawing library from memory as per the Pillow docs
del draw

# Display the resulting image
pil_image.show()
</code></pre>
<p>/tmp/ipykernel_11211/4178765491.py:25: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)
/tmp/ipykernel_11211/4178765491.py:25: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)</p>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_67_1-4c30cad6378124c03a4f69e1b4cba729.png" width="1280" height="720"></p>
<pre><code class="language-python">unknown_image2 = face_recognition.load_image_file(&#x27;faces/test/unknown_02.jpg&#x27;)

# Find all the faces and face encodings in the unknown image
found_faces2 = face_recognition.face_locations(unknown_image2)
found_face_encodings2 = face_recognition.face_encodings(unknown_image2, found_faces2)

# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library
pil_image2 = Image.fromarray(unknown_image2)
</code></pre>
<pre><code class="language-python"># Create a Pillow ImageDraw Draw instance to draw with
draw = ImageDraw.Draw(pil_image2)

# Loop through each face found in the unknown image
for (top, right, bottom, left), face_encoding in zip(found_faces2, found_face_encodings2):
    # See if the face is a match for the known face(s)
    matches = face_recognition.compare_faces(face_encodings, face_encoding)

    name = &quot;Unknown&quot;

    # If a match was found in face_encodings, just use the first one.
    # if True in matches:
    #     first_match_index = matches.index(True)
    #     name = image_labels[first_match_index]

    # Or instead, use the known face with the smallest distance to the new face
    face_distances = face_recognition.face_distance(face_encodings, face_encoding)
    best_match_index = np.argmin(face_distances)
    if matches[best_match_index]:
        name = image_labels[best_match_index]

    # Draw a box around the face using the Pillow module
    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))

    # Draw a label with a name below the face
    text_width, text_height = draw.textsize(name)
    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))
    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))


# Remove the drawing library from memory as per the Pillow docs
del draw

# Display the resulting image
pil_image2.show()
</code></pre>
<p>/tmp/ipykernel_11211/1125746434.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)
/tmp/ipykernel_11211/1125746434.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)</p>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_69_1-ddebae2f57dfecd2dd614c48db18fae5.png" width="780" height="439"></p>
<pre><code class="language-python">unknown_image3 = face_recognition.load_image_file(&#x27;faces/test/unknown_03.jpg&#x27;)

# Find all the faces and face encodings in the unknown image
found_faces3 = face_recognition.face_locations(unknown_image3)
found_face_encodings3 = face_recognition.face_encodings(unknown_image3, found_faces3)

# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library
pil_image3 = Image.fromarray(unknown_image3)
</code></pre>
<pre><code class="language-python"># Create a Pillow ImageDraw Draw instance to draw with
draw = ImageDraw.Draw(pil_image3)

# Loop through each face found in the unknown image
for (top, right, bottom, left), face_encoding in zip(found_faces3, found_face_encodings3):
    # See if the face is a match for the known face(s)
    matches = face_recognition.compare_faces(face_encodings, face_encoding)

    name = &quot;Unknown&quot;

    # If a match was found in face_encodings, just use the first one.
    # if True in matches:
    #     first_match_index = matches.index(True)
    #     name = image_labels[first_match_index]

    # Or instead, use the known face with the smallest distance to the new face
    face_distances = face_recognition.face_distance(face_encodings, face_encoding)
    best_match_index = np.argmin(face_distances)
    if matches[best_match_index]:
        name = image_labels[best_match_index]

    # Draw a box around the face using the Pillow module
    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))

    # Draw a label with a name below the face
    text_width, text_height = draw.textsize(name)
    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))
    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))


# Remove the drawing library from memory as per the Pillow docs
del draw

# Display the resulting image
pil_image3.show()
</code></pre>
<p>/tmp/ipykernel_11211/3035399979.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)
/tmp/ipykernel_11211/3035399979.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)</p>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_71_1-4074a578690c43746bfa44c511d13b1c.png" width="2400" height="1800"></p>
<pre><code class="language-python">unknown_image4 = face_recognition.load_image_file(&#x27;faces/test/unknown_04.jpg&#x27;)

# Find all the faces and face encodings in the unknown image
found_faces4 = face_recognition.face_locations(unknown_image4)
found_face_encodings4 = face_recognition.face_encodings(unknown_image4, found_faces4)

# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library
pil_image4 = Image.fromarray(unknown_image4)
</code></pre>
<pre><code class="language-python"># Create a Pillow ImageDraw Draw instance to draw with
draw = ImageDraw.Draw(pil_image4)

# Loop through each face found in the unknown image
for (top, right, bottom, left), face_encoding in zip(found_faces4, found_face_encodings4):
    # See if the face is a match for the known face(s)
    matches = face_recognition.compare_faces(face_encodings, face_encoding)

    name = &quot;Unknown&quot;

    # If a match was found in face_encodings, just use the first one.
    # if True in matches:
    #     first_match_index = matches.index(True)
    #     name = image_labels[first_match_index]

    # Or instead, use the known face with the smallest distance to the new face
    face_distances = face_recognition.face_distance(face_encodings, face_encoding)
    best_match_index = np.argmin(face_distances)
    if matches[best_match_index]:
        name = image_labels[best_match_index]

    # Draw a box around the face using the Pillow module
    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))

    # Draw a label with a name below the face
    text_width, text_height = draw.textsize(name)
    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))
    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))


# Remove the drawing library from memory as per the Pillow docs
del draw

# Display the resulting image
pil_image4.show()
</code></pre>
<p>/tmp/ipykernel_11211/329699440.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)
/tmp/ipykernel_11211/329699440.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)
/tmp/ipykernel_11211/329699440.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)</p>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_73_1-6e49aa6a5523c16699e27bb1ffab0384.png" width="3328" height="1698"></p>
<pre><code class="language-python">unknown_image5 = face_recognition.load_image_file(&#x27;faces/test/unknown_05.jpg&#x27;)

# Find all the faces and face encodings in the unknown image
found_faces5 = face_recognition.face_locations(unknown_image5)
found_face_encodings5 = face_recognition.face_encodings(unknown_image5, found_faces5)

# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library
pil_image5 = Image.fromarray(unknown_image5)
</code></pre>
<pre><code class="language-python"># Create a Pillow ImageDraw Draw instance to draw with
draw = ImageDraw.Draw(pil_image5)

# Loop through each face found in the unknown image
for (top, right, bottom, left), face_encoding in zip(found_faces5, found_face_encodings5):
    # See if the face is a match for the known face(s)
    matches = face_recognition.compare_faces(face_encodings, face_encoding)

    name = &quot;Unknown&quot;

    # If a match was found in face_encodings, just use the first one.
    # if True in matches:
    #     first_match_index = matches.index(True)
    #     name = image_labels[first_match_index]

    # Or instead, use the known face with the smallest distance to the new face
    face_distances = face_recognition.face_distance(face_encodings, face_encoding)
    best_match_index = np.argmin(face_distances)
    if matches[best_match_index]:
        name = image_labels[best_match_index]

    # Draw a box around the face using the Pillow module
    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))

    # Draw a label with a name below the face
    text_width, text_height = draw.textsize(name)
    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))
    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))


# Remove the drawing library from memory as per the Pillow docs
del draw

# Display the resulting image
pil_image5.show()
</code></pre>
<p>/tmp/ipykernel_11211/864981556.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)
/tmp/ipykernel_11211/864981556.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)
/tmp/ipykernel_11211/864981556.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)</p>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_75_1-2de8685de457822eb43a1158aa3a8e82.png" width="1920" height="1080"></p>
<pre><code class="language-python">unknown_image6 = face_recognition.load_image_file(&#x27;faces/test/unknown_06.jpg&#x27;)

# Find all the faces and face encodings in the unknown image
found_faces6 = face_recognition.face_locations(unknown_image6)
found_face_encodings6 = face_recognition.face_encodings(unknown_image6, found_faces6)

# Convert the image to a PIL-format image so that we can draw on top of it with the Pillow library
pil_image6 = Image.fromarray(unknown_image6)
</code></pre>
<pre><code class="language-python"># Create a Pillow ImageDraw Draw instance to draw with
draw = ImageDraw.Draw(pil_image6)

# Loop through each face found in the unknown image
for (top, right, bottom, left), face_encoding in zip(found_faces6, found_face_encodings6):
    # See if the face is a match for the known face(s)
    matches = face_recognition.compare_faces(face_encodings, face_encoding)

    name = &quot;Unknown&quot;

    # If a match was found in face_encodings, just use the first one.
    # if True in matches:
    #     first_match_index = matches.index(True)
    #     name = image_labels[first_match_index]

    # Or instead, use the known face with the smallest distance to the new face
    face_distances = face_recognition.face_distance(face_encodings, face_encoding)
    best_match_index = np.argmin(face_distances)
    if matches[best_match_index]:
        name = image_labels[best_match_index]

    # Draw a box around the face using the Pillow module
    draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))

    # Draw a label with a name below the face
    text_width, text_height = draw.textsize(name)
    draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))
    draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))


# Remove the drawing library from memory as per the Pillow docs
del draw

# Display the resulting image
pil_image6.show()
</code></pre>
<p>/tmp/ipykernel_11211/1615432601.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)
/tmp/ipykernel_11211/1615432601.py:26: DeprecationWarning: textsize is deprecated and will be removed in Pillow 10 (2023-07-01). Use textbbox or textlength instead.
text_width, text_height = draw.textsize(name)</p>
<p><img alt="DLIB Face Recognition" src="/assets/images/output_77_1-3809e9b204faa60015065cced483eac6.png" width="1500" height="1002"></p>
<h2 id="save-feature-vector">Save Feature Vector</h2>
<p>Export encodings and labels to use them in a Flask App -&gt; see <code>./main.py</code></p>
<pre><code class="language-python">with open(&#x27;features/face_encodings.npy&#x27;, &#x27;wb&#x27;) as f:
    np.save(f, face_encodings)

with open(&#x27;features/image_labels.npy&#x27;, &#x27;wb&#x27;) as f:
    np.save(f, image_labels)
</code></pre>
<pre><code class="language-python">with open(&#x27;features/face_encodings.npy&#x27;, &#x27;rb&#x27;) as f:
    feature_vectors = np.load(f)

with open(&#x27;features/image_labels.npy&#x27;, &#x27;rb&#x27;) as f:
    feature_labels = np.load(f)
</code></pre>
<pre><code class="language-python">np.unique(feature_labels, return_counts=True)
</code></pre>
<pre><code class="language-bash">    (array(amos_burton, bobbie_w_draper, camina_drummer,
            chrisjen_avasarala, jim_holden, naomi_nagata, dtype=&lt;U18),
     array(10, 10, 10, 10, 10, 10))
</code></pre>
<pre><code class="language-python">feature_vectors.shape
</code></pre>
<p>(60, 128)</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/python">Python</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/machine-learning">Machine Learning</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/category/machine-learning"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Machine Learning</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/IoT-and-Machine-Learning/ML/2023-09-23--yolo8-listen/2023-09-23"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Audio Classification with Computer Vision</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#detect-face-location-cpu" class="table-of-contents__link toc-highlight">Detect Face Location (CPU)</a><ul><li><a href="#crop-location" class="table-of-contents__link toc-highlight">Crop Location</a></li><li><a href="#get-all-the-training-images" class="table-of-contents__link toc-highlight">Get all the Training Images</a></li></ul></li><li><a href="#face-recognition" class="table-of-contents__link toc-highlight">Face Recognition</a><ul><li><a href="#compare-faces" class="table-of-contents__link toc-highlight">Compare Faces</a></li></ul></li><li><a href="#detect-face-location-gpu--batch-processing" class="table-of-contents__link toc-highlight">Detect Face Location (GPU + Batch Processing)</a></li><li><a href="#draw-bounding-boxes" class="table-of-contents__link toc-highlight">Draw Bounding Boxes</a></li><li><a href="#save-feature-vector" class="table-of-contents__link toc-highlight">Save Feature Vector</a></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Research</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Notebook</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tags">Tags</a></li><li class="footer__item"><a class="footer__link-item" href="/Curriculum-Vitae">CV</a></li></ul></div><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/mike-polinowski-6396ba121/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/MikePolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.flickr.com/people/149680084@N06/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Flickr<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Mike Polinowski, INSTAR Deutschland GmbH, Shenzhen - China.</div></div></div></footer></div>
</body>
</html>