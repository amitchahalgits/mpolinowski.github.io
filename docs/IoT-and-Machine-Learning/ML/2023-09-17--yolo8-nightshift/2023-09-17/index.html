<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.0.0">
<title data-rh="true">YOLOv8 Nightshift | Mike Polinowski</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/2023-09-17"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="YOLOv8 Nightshift | Mike Polinowski"><meta data-rh="true" name="description" content="Training an YOLOv8 Object Tracker for Day/Night Cameras"><meta data-rh="true" property="og:description" content="Training an YOLOv8 Object Tracker for Day/Night Cameras"><link data-rh="true" rel="icon" href="/img/icons/favicon-32x32.png"><link data-rh="true" rel="canonical" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/2023-09-17"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/2023-09-17" hreflang="en"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/2023-09-17" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Mike Polinowski RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Mike Polinowski Atom Feed">




<link rel="icon" href="/img/angular_momentum.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37,194,160)">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#000">
<link rel="apple-touch-icon" href="/img/angular_momentum.png">
<link rel="mask-icon" href="/img/angular_momentum.png" color="rgb(33,33,33)">
<meta name="msapplication-TileImage" content="/img/angular_momentum.png">
<meta name="msapplication-TileColor" content="#000">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-P74BDWF0C6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-P74BDWF0C6",{})</script><link rel="stylesheet" href="/assets/css/styles.dcca9435.css">
<script src="/assets/js/runtime~main.9a0cc3b5.js" defer="defer"></script>
<script src="/assets/js/main.6d14a3ae.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_gu5v" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_ZRzL themedComponent--light_dGsa"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_ZRzL themedComponent--dark_pzCA"></div><b class="navbar__title text--truncate">Mike Polinowski</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/docs/tags">Tags</a><a class="navbar__item navbar__link" href="/Search">Search</a><a href="https://mpolinowski.github.io/Personal" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_T11m"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_T11m"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_kWbt colorModeToggle_GwZs"><button class="clean-btn toggleButton_fOL9 toggleButtonDisabled_STpu" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_DCeJ"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_DFgp"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_IP3a"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_IbdI"><div class="docsWrapper_JGIH"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_SdI4" type="button"></button><div class="docRoot_eRbX"><aside class="theme-doc-sidebar-container docSidebarContainer_Ta75"><div class="sidebarViewport_fgog"><div class="sidebar_oDHW"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_vPEQ"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/development">Development</a><button aria-label="Expand sidebar category &#x27;Development&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/devops">DevOps</a><button aria-label="Expand sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/machine-learning-ai-and-computer-vision">Machine Learning, AI and Computer Vision</a><button aria-label="Collapse sidebar category &#x27;Machine Learning, AI and Computer Vision&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/category/machine-learning">Machine Learning</a><button aria-label="Collapse sidebar category &#x27;Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/2023-10-01">DLIB Face Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-23--yolo8-listen/2023-09-23">Audio Classification with Computer Vision</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/2023-09-21">CVAT Semi-automatic and Automatic Annotation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-19--cvat-computer-vision-annotation-tool/2023-09-19">Computer Vision Annotation Tool (CVAT) Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/2023-09-17">YOLOv8 Nightshift</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/2023-09-15">YOLOv8 License Plate Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-10--model-explainability-shap/2023-09-11">Scikit-Learn ML Model Explainability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-05--semantic-segmentation-in-opencv/2023-09-05">Using Tensorflow Models in OpenCV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-01--yolo-i-know-flowers/2023-09-01">YOLOv8 Image Classifier</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/2023-08-31">Detectron Object Detection with OpenImages Dataset (WIP)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-30--instance_segmentation_detectron2_model_zoo_mask_rcnn/2023-08-30">Instance Segmentation with PyTorch (Mask RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-29--semantic-segmentation-detectron2-model-zoo-faster-rcnn/2023-08-29">Image Segmentation with PyTorch (Faster RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-28--semantic-segmentation-detectron2-model-zoo/2023-08-28">Image Segmentation with PyTorch (RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-27--image-segmentation-with-pytorch/2023-08-27">Image Segmentation with PyTorch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/2023-08-21">Containerized PyTorch Dev Workflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-13-tensorflow-i-know-flowers-model-eval/2023-08-13">Tensorflow Image Classifier - Model Evaluation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-12-tensorflow-i-know-flowers-xception/2023-08-12">Tensorflow Image Classifier - Xception</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-11-tensorflow-i-know-flowers-vit/2023-08-11">Tensorflow Image Classifier - ViT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-10-tensorflow-i-know-flowers-nasnetmobile/2023-08-10">Tensorflow Image Classifier - NASNetMobile</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-09-tensorflow-i-know-flowers-mobilenetv3small/2023-08-09">Tensorflow Image Classifier - MobileNetV3Small</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-08-tensorflow-i-know-flowers-mobilenetv3large/2023-08-08">Tensorflow Image Classifier - MobileNetV3Large</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-07-tensorflow-i-know-flowers-mobilenetv2/2023-08-07">Tensorflow Image Classifier - MobileNetV2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/2023-08-06">Tensorflow Image Classifier - InceptionV3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-05-tensorflow-i-know-flowers-efficientnetv2s/2023-08-05">Tensorflow Image Classifier - EfficientNetV2S</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-04-tensorflow-i-know-flowers-efficientnetv2b0/2023-08-04">Tensorflow Image Classifier - EfficientNetV2B0</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit/2023-08-03">Tensorflow Image Classifier - Data-efficient Image Transformers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-02-tensorflow-i-know-flowers-preprocessing/2023-08-02">Tensorflow Image Classifier - Data Pre-processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-01-tensorflow-i-know-flowers-intro/2023-08-01">Tensorflow Image Classifier - Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-27-tensorflow-vision-transformer/2023-07-27">Tensorflow VITs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/2023-07-26">Human Emotion Detection with Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/2023-07-25">Working with ONNX Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-21-introduction-to-pytorch-caffe2/2023-07-21">Introduction to Caffe2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-02-sql-in-data-science-ml/2023-07-02">SQL in Data Science - Machine Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-30-sql-in-data-science-advanced/2023-06-30">SQL in Data Science - Slightly more Advanced Queries</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-27-sql-in-data-science-basics/2023-06-27">SQL in Data Science - The Basics using Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-26-autogluon-transit-photometry-dataset/2023-06-26">Detection of Exoplanets using Transit Photometry</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-19-tensorflow-natural-language-processing/2023-04-19">(Re) Introduction to Tensorflow Natural Language Processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-16-deep-3d-image-segmentation/2023-04-16">3D Image Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-14-manifold-learning-for-image-segmentation/2023-04-14">Dimensionality Reduction for Image Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-fisher-discriminant-analysis/2023-04-13">Fisher Linear Discriminant Analysis (LDA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-isometric-mapping/2023-04-13">Isometric Mapping (ISOMAP)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-multi-dimensional-scaling/2023-04-13">Multidimensional Scaling (MDS)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-12-tstochastic-neighbor-embedding/2023-04-12">tStochastic Neighbor Embedding (t-SNE)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-11-locally-linear-embedding/2023-04-11">Locally Linear Embedding (LLE)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-09-principal-component-analysis/2023-04-09">Principal Component Analysis (PCA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-generative-adversial-networks/2023-03-26">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05">Tensorflow 2 - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03">Tensorflow 2 - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02">Tensorflow 2 - Neural Network Classifications</a><button aria-label="Expand sidebar category &#x27;Tensorflow 2 - Neural Network Classifications&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28">Tensorflow 2 - Neural Network Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27">Tensorflow 2 - Neural Network Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22">Tensorflow 2 - An (Re)Introduction 2023 (3)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21">Tensorflow 2 - An (Re)Introduction 2023 (2)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19">Tensorflow 2 - An (Re)Introduction 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-vgg16/2023-02-18">Keras for Tensorflow - VGG16 Network Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-rnn/2023-02-18">Keras for Tensorflow - Recurrent Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/2023-02-17">Keras for Tensorflow - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-16-keras-introduction-ann/2023-02-16">Keras for Tensorflow - Artificial Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-15-as-one-yolo-object-tracking/2023-02-15">YOLOv8 with AS-One</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-14-keras-introduction/2023-02-14">Keras for Tensorflow - An (Re)Introduction 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-30-predicting-wine-quality/2023-01-30">SciKit Wine Quality</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-28-opencv-coin-counter/2023-01-28">OpenCV Count My Money</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-14-yolov7_to_tensorflow/2023-01-14">YOLOv7 to Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-13-yolov7_data_conversion/2023-01-13">YOLOv7 Label Conversion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-10-yolov7_custom_data/2023-01-10">YOLOv7 Training with Custom Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-08-depth-vision-midas/2023-01-08">MiDaS Depth Vision</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-05-yolov7/2023-01-05">YOLOv7 Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-31-tf-rnn-text-generation/2022-12-31">Recurrent Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/2022-12-28">Deep Convolutional Generative Adversarial Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21">Tensorflow Downsampling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-deepdream/2022-12-21">Tensorflow Deep Dream</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-20-tf-representation/2022-12-19">Tensorflow Representation Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-19-tf-hub/2022-12-19">Tensorflow Hub</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/2022-12-18">Tensorflow Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-16-tf-cifar/2022-12-16">Tensorflow Image Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part6/2022-12-12">Breast Histopathology Image Segmentation Part 6</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part5/2022-12-12">Breast Histopathology Image Segmentation Part 5</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part4/2022-12-11">Breast Histopathology Image Segmentation Part 4</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part3/2022-12-11">Breast Histopathology Image Segmentation Part 3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part2/2022-12-11">Breast Histopathology Image Segmentation Part 2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/2022-12-10">Breast Histopathology Image Segmentation Part 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27">Deep Docker on Arch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/2022-04-04">Face Restoration with GFPGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-03-pytorch-real-super-resolution/2022-04-03">Super Resolution with Real-ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-02-pytorch-super-resolution/2022-04-02">Super Resolution with ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01">Deep Audio</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20">Yolo App - YOLOv5 Data Preparation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19">Yolo App - Flask Web Application</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18">Yolo App - Tesseract Optical Character Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-17--yolo-app-prediction-pipeline/2022-02-17">Yolo App - Pipeline Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16">Yolo App - Train a Model with Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15">Yolo App - Data Collection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-10--opencv-optical-flow-tracking/2021-12-10">OpenCV Optical Flow Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-09--opencv-camshift-tracking/2021-12-09">OpenCV CAMshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-08--opencv-meanshift-tracking/2021-12-08">OpenCV Meanshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/2021-12-07">OpenCV Object Detection and Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/2021-12-06">OpenCV Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-05--opencv-face-detection/2021-12-05">OpenCV Face Detection and Privacy</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/2021-12-04">OpenCV Image Objects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-03--opencv-image-operations/2021-12-03">OpenCV Image Operations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-02--opencv-with-videos/2021-12-02">OpenCV, Streams and Video Files</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-01--opencv-with-images/2021-12-01">OpenCV and Images</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-15--facebook-prophet-introduction/2021-11-15">Introduction into FB Prophet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-14--tensorflow-model-for-tfjs/2021-11-14">Tensorflow.js React App</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/2021-11-13">Tensorflow2 Model Zoo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-12--tensorflow-crash-course-part-v/2021-11-12">Tensorflow2 Crash Course - Part V</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-11--tensorflow-crash-course-part-iv/2021-11-11">Tensorflow2 Crash Course - Part IV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-10--tensorflow-crash-course-part-iii/2021-11-10">Tensorflow2 Crash Course - Part III</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-09--tensorflow-crash-course-part-ii/2021-11-09">Tensorflow2 Crash Course - Part II</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-08--tensorflow-crash-course-part-i/2021-11-08">Tensorflow Crash Course - Part I</a><button aria-label="Expand sidebar category &#x27;Tensorflow Crash Course - Part I&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-07--opencv-crash-course-part-ii/2021-11-07">OpenCV Crash Course Part II</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-06--opencv-crash-course-part-i/2021-11-06">OpenCV Crash Course Part I</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-05--license-plates-yolov4-opencv-tesseract/2021-11-05">License Plate Recognition with YOLOv4, OpenCV and Tesseract</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-04--installing-yolov4/2021-11-04">Installing YOLOv4 with Anaconda</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/2021-11-03">Streamlit user interface for openCV/Mediapipe face mesh app</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-02--spacy_ner_predictions/2021-11-02">spaCy NER Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-01--spacy_natural_language_processing/2021-11-01">spaCy NER on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-04-01--introduction-to-keras/2019-04-01">Introduction to Keras</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/2021-10-31">Tesseract OCR on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-03-31--introduction-to-tensorflow-2-beta/2019-03-31">Introduction to TensorFlow 2 Beta</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/2018-01-02">Machine Learning with SciKit Learn</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/aiops">AIOps</a><button aria-label="Expand sidebar category &#x27;AIOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/automation-deep-vision-and-robotics">Automation, Deep Vision and Robotics</a><button aria-label="Expand sidebar category &#x27;Automation, Deep Vision and Robotics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_lg0V"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_nDJs"><div class="docItemContainer_OGiL"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_k3Z9" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_JACu"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/machine-learning-ai-and-computer-vision"><span itemprop="name">Machine Learning, AI and Computer Vision</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/machine-learning"><span itemprop="name">Machine Learning</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">YOLOv8 Nightshift</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_QCOD theme-doc-toc-mobile tocMobile_N0YI"><button type="button" class="clean-btn tocCollapsibleButton_pHwF">On this page</button></div><div class="theme-doc-markdown markdown"><p><img alt="Guangzhou, China" src="/assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-864be48f76a28ed6a3e155f7ab51bc74.jpg" width="1500" height="871"></p>
<ul>
<li><a href="#yolov8-nightshift">YOLOv8 Nightshift</a>
<ul>
<li><a href="#dataset">Dataset</a>
<ul>
<li><a href="#dataset-exploration">Dataset Exploration</a></li>
<li><a href="#label-conversion-json2yolo">Label Conversion JSON2YOLO</a>
<ul>
<li><a href="#video-rgb-test-dataset">Video RGB Test Dataset</a></li>
<li><a href="#video-thermal-test-dataset">Video Thermal Test Dataset</a></li>
<li><a href="#images-rgb-train-dataset">Images RGB Train Dataset</a></li>
<li><a href="#images-thermal-train-dataset">Images Thermal Train Dataset</a></li>
<li><a href="#images-rgb-val-dataset">Images RGB Val Dataset</a></li>
<li><a href="#images-thermal-val-dataset">Images Thermal Val Dataset</a></li>
</ul>
</li>
<li><a href="#dataset-configuration">Dataset Configuration</a></li>
</ul>
</li>
<li><a href="#training-the-yolov8-model-rgb--ir">Training the YOLOv8 Model (RGB / IR)</a>
<ul>
<li><a href="#yolov8-nano-rgb">YOLOv8 Nano (RGB)</a>
<ul>
<li><a href="#model-training">Model Training</a></li>
<li><a href="#model-evaluation">Model Evaluation</a></li>
</ul>
</li>
<li><a href="#yolov8-small-rgb">YOLOv8 Small (RGB)</a>
<ul>
<li><a href="#model-training-1">Model Training</a></li>
<li><a href="#model-evaluation-1">Model Evaluation</a></li>
</ul>
</li>
<li><a href="#yolov8-nano-ir">YOLOv8 Nano (IR)</a>
<ul>
<li><a href="#model-training-2">Model Training</a></li>
<li><a href="#model-evaluation-2">Model Evaluation</a></li>
</ul>
</li>
<li><a href="#yolov8-small-ir">YOLOv8 Small (IR)</a></li>
<li><a href="#model-training-3">Model Training</a>
<ul>
<li><a href="#model-evaluation-3">Model Evaluation</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#training-the-yolov8-mixed-model-rgb--ir">Training the YOLOv8 Mixed Model (RGB + IR)</a>
<ul>
<li><a href="#yolov8-nano-rgbir">YOLOv8 Nano (RGB+IR)</a>
<ul>
<li><a href="#model-training-4">Model Training</a></li>
<li><a href="#model-evaluation-4">Model Evaluation</a></li>
</ul>
</li>
<li><a href="#yolov8-small-rgb--ir">YOLOv8 Small (RGB + IR)</a>
<ul>
<li><a href="#model-training-5">Model Training</a></li>
<li><a href="#model-evaluation-5">Model Evaluation</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#model-evaluation-6">Model Evaluation</a>
<ul>
<li><a href="#yolov8n--rgb-dataset">YOLOv8n &amp; RGB Dataset</a></li>
<li><a href="#yolov8s--rgb-dataset">YOLOv8s &amp; RGB Dataset</a></li>
<li><a href="#yolov8n--ir-dataset">YOLOv8n &amp; IR Dataset</a></li>
<li><a href="#yolov8s--rgb-dataset-1">YOLOv8s &amp; RGB Dataset</a></li>
<li><a href="#yolov8n--combined-dataset">YOLOv8n &amp; Combined Dataset</a></li>
<li><a href="#yolov8s--combined-dataset">YOLOv8s &amp; Combined Dataset</a></li>
<li><a href="#combining-results">Combining Results</a></li>
</ul>
</li>
<li><a href="#evaluate-bounding-boxes">Evaluate Bounding Boxes</a>
<ul>
<li><a href="#show-labels">Show Labels</a></li>
<li><a href="#show-predictions">Show Predictions</a></li>
<li><a href="#show-labels-1">Show Labels</a></li>
<li><a href="#show-predictions-1">Show Predictions</a></li>
<li><a href="#show-labels-2">Show Labels</a></li>
<li><a href="#show-predictions-2">Show Predictions</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="yolov8-nightshift">YOLOv8 Nightshift</h1>
<h2 id="dataset">Dataset</h2>
<blockquote>
<p><a href="https://adas-dataset-v2.flirconservator.com/#multipartdownloadsection">Teledyne FLIR Free ADAS Thermal Dataset v2</a>:
The Teledyne FLIR free starter thermal dataset provides fully annotated thermal and visible spectrum frames for development of object detection neural networks. This data was constructed to encourage research on visible + thermal spectrum sensor fusion algorithms (&quot;RGBT&quot;) in order to advance the safety of autonomous vehicles. A total of 26,442 fully-annotated frames are included with 15 different object classes.</p>
</blockquote>
<blockquote>
<p><strong>Baseline Model</strong>: Baseline accuracy for object detection was established using the YOLOX-m neural network designed for 640 X 640 images. Both the RGB and thermal detectors were pre-trained on MSCOCO data (<a href="https://arxiv.org/abs/2107.08430">YOLOX: Exceeding YOLO Series in 2021</a> and <a href="https://github.com/Megvii-BaseDetection/YOLOX">YOLOX</a>). The base neural networks were trained on the training set data provided in this dataset and tested on the video test data also provided in this dataset.</p>
</blockquote>
<pre><code class="language-python">from glob import glob
import json
import matplotlib.pyplot as plt
import numpy as np
import os
import shutil
from tqdm import tqdm
</code></pre>
<h3 id="dataset-exploration">Dataset Exploration</h3>
<pre><code class="language-python"># read in dataset
images_themal = glob(&#x27;./datasets/video_thermal_test/images/*.jpg&#x27;)
images_rgb = glob(&#x27;./datasets/video_rgb_test/images/*.jpg&#x27;)
</code></pre>
<pre><code class="language-python">print(len(images_themal), len(images_rgb))
</code></pre>
<p>3749 3749</p>
<pre><code class="language-python"># plot multiple random thermal images
ran_gen = np.random.default_rng()

plt.figure(figsize=(16, 14))
plt.suptitle(&#x27;Thermal Images&#x27;)
for i in range(12):
    ax = plt.subplot(4, 4, i+1)
    random_index = ran_gen.integers(low=0, high=3748, size=1)
    i = random_index[0]
    img_loc = images_themal[i]
    img_title = &#x27;video: &#x27; + images_themal[i][-52:-35]+&#x27;\n&#x27;+ &#x27;frame: &#x27; + images_themal[i][-28:-22]+&#x27;\n&#x27;+ &#x27;id: &#x27; + images_themal[i][-21:-4]
    image = plt.imread(img_loc)
    plt.imshow(image, cmap=plt.cm.binary)
    plt.title(img_title, fontsize=&#x27;small&#x27;)
    plt.axis(False)
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_5_0-81cd34f42a0d8751d1dc52567fab774e.png" width="1260" height="947"></p>
<pre><code class="language-python"># plot multiple random rgb images
ran_gen = np.random.default_rng()

plt.figure(figsize=(16, 14))
plt.suptitle(&#x27;RGB Images&#x27;)
for i in range(12):
    ax = plt.subplot(4, 4, i+1)
    random_index = ran_gen.integers(low=0, high=3748, size=1)
    i = random_index[0]
    img_loc = images_rgb[i]
    img_title = &#x27;video: &#x27; + images_rgb[i][-52:-35]+&#x27;\n&#x27;+ &#x27;frame: &#x27; + images_rgb[i][-28:-22]+&#x27;\n&#x27;+ &#x27;id: &#x27; + images_rgb[i][-21:-4]
    image = plt.imread(img_loc)
    plt.imshow(image, cmap=plt.cm.binary)
    plt.title(img_title, fontsize=&#x27;small&#x27;)
    plt.axis(False)
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_6_0-5ff5758fd447e6cf2087b8830ac02bd9.png" width="1260" height="952"></p>
<h3 id="label-conversion-json2yolo">Label Conversion JSON2YOLO</h3>
<ul>
<li><code>&quot;file_name&quot;: &quot;data/video-BzZspxAweF8AnKhWK-frame-000745-SSCRtAHcFjphNPczJ.jpg&quot;,</code> -&gt; <code>&quot;file_name&quot;: &quot;video-BzZspxAweF8AnKhWK-frame-000745-SSCRtAHcFjphNPczJ.jpg&quot;,</code></li>
</ul>
<p>YOLOv8 expects all images to be located in an <code>images</code> dir and the txt format annotation in a <code>labels</code> folder next to it. The dataset was using a dirname of <code>data</code> for all images and had COCO JSON annotations. I renamed the folder, created the missing one and removed the &quot;data/&quot; from all the filenames in the JSON file. Now I am able to run a conversion:</p>
<pre><code class="language-python">def make_folders(output_path):
    if os.path.exists(output_path):
        shutil.rmtree(output_path)
    os.makedirs(output_path)
    return output_path


def convert_bbox_coco2yolo(img_width, img_height, bbox):
    &quot;&quot;&quot;
    Convert bounding box from COCO  format to YOLO format

    Parameters
    ----------
    img_width : int
        width of image
    img_height : int
        height of image
    bbox : list[int]
        bounding box annotation in COCO format: 
        [top left x position, top left y position, width, height]

    Returns
    -------
    list[float]
        bounding box annotation in YOLO format: 
        [x_center_rel, y_center_rel, width_rel, height_rel]
    &quot;&quot;&quot;
    
    # YOLO bounding box format: [x_center, y_center, width, height]
    # (float values relative to width and height of image)
    x_tl, y_tl, w, h = bbox

    dw = 1.0 / img_width
    dh = 1.0 / img_height

    x_center = x_tl + w / 2.0
    y_center = y_tl + h / 2.0

    x = x_center * dw
    y = y_center * dh
    w = w * dw
    h = h * dh

    return [x, y, w, h]
</code></pre>
<pre><code class="language-python">def convert_coco_json_to_yolo_txt(output_path, json_file):

    path = make_folders(output_path)

    with open(json_file) as f:
        json_data = json.load(f)

    # write _darknet.labels, which holds names of all classes (one class per line)
    label_file = os.path.join(output_path, &quot;_darknet.labels&quot;)
    with open(label_file, &quot;w&quot;) as f:
        for category in tqdm(json_data[&quot;categories&quot;], desc=&quot;Categories&quot;):
            category_name = category[&quot;name&quot;]
            f.write(f&quot;{category_name}\n&quot;)

    for image in tqdm(json_data[&quot;images&quot;], desc=&quot;Annotation txt for each iamge&quot;):
        img_id = image[&quot;id&quot;]
        img_name = image[&quot;file_name&quot;]
        img_width = image[&quot;width&quot;]
        img_height = image[&quot;height&quot;]

        anno_in_image = [anno for anno in json_data[&quot;annotations&quot;] if anno[&quot;image_id&quot;] == img_id]
        anno_txt = os.path.join(output_path, img_name.split(&quot;.&quot;)[0] + &quot;.txt&quot;)
        with open(anno_txt, &quot;w&quot;) as f:
            for anno in anno_in_image:
                category = anno[&quot;category_id&quot;]
                bbox_COCO = anno[&quot;bbox&quot;]
                x, y, w, h = convert_bbox_coco2yolo(img_width, img_height, bbox_COCO)
                f.write(f&quot;{category} {x:.6f} {y:.6f} {w:.6f} {h:.6f}\n&quot;)

    print(&quot;Converting COCO Json to YOLO txt finished!&quot;)
</code></pre>
<h4 id="video-rgb-test-dataset">Video RGB Test Dataset</h4>
<pre><code class="language-python">convert_coco_json_to_yolo_txt(&quot;./datasets/video_rgb_test/labels&quot;, &quot;./datasets/video_rgb_test/coco.json&quot;)
</code></pre>
<p>Categories: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00, 253241.00it/s]
Annotation txt for each iamge: 100%|███████████████████████████████████████████████████████████████████████████████| 3749/3749 [00:38, 98.23it/s]</p>
<p>Converting COCO Json to YOLO txt finished!</p>
<h4 id="video-thermal-test-dataset">Video Thermal Test Dataset</h4>
<pre><code class="language-python">convert_coco_json_to_yolo_txt(&quot;./datasets/video_thermal_test/labels&quot;, &quot;./datasets/video_thermal_test/coco.json&quot;)
</code></pre>
<p>Categories: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00, 430185.03it/s]
Annotation txt for each iamge: 100%|██████████████████████████████████████████████████████████████████████████████| 3749/3749 [00:25, 145.99it/s]</p>
<p>Converting COCO Json to YOLO txt finished!</p>
<h4 id="images-rgb-train-dataset">Images RGB Train Dataset</h4>
<pre><code class="language-python">convert_coco_json_to_yolo_txt(&quot;./datasets/images_rgb_train/labels&quot;, &quot;./datasets/images_rgb_train/coco.json&quot;)
</code></pre>
<p>Categories: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00, 175218.97it/s]1060
Annotation txt for each iamge: 100%|█████████████████████████████████████████████████████████████████████████████| 10318/10318 [03:18, 51.86it/s]</p>
<p>Converting COCO Json to YOLO txt finished!</p>
<h4 id="images-thermal-train-dataset">Images Thermal Train Dataset</h4>
<pre><code class="language-python">convert_coco_json_to_yolo_txt(&quot;./datasets/images_thermal_train/labels&quot;, &quot;./datasets/images_thermal_train/coco.json&quot;)
</code></pre>
<p>Categories: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00, 394758.02it/s]
Annotation txt for each iamge: 100%|█████████████████████████████████████████████████████████████████████████████| 10742/10742 [03:07, 57.44it/s]</p>
<p>Converting COCO Json to YOLO txt finished!</p>
<h4 id="images-rgb-val-dataset">Images RGB Val Dataset</h4>
<pre><code class="language-python">convert_coco_json_to_yolo_txt(&quot;./datasets/images_rgb_val/labels&quot;, &quot;./datasets/images_rgb_val/coco.json&quot;)
</code></pre>
<p>Categories: 100%|████████████  ██████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00, 281970.02it/s]
Annotation txt for each iamge: 100%|██████████████████████████████████████████████████████████████████████████████| 1085/1085 [00:02, 452.60it/s]</p>
<p>Converting COCO Json to YOLO txt finished!</p>
<h4 id="images-thermal-val-dataset">Images Thermal Val Dataset</h4>
<pre><code class="language-python">convert_coco_json_to_yolo_txt(&quot;./datasets/images_thermal_val/labels&quot;, &quot;./datasets/images_thermal_val/coco.json&quot;)
</code></pre>
<p>Categories: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████| 16/16 [00:00, 377016.09it/s]
Annotation txt for each iamge: 100%|██████████████████████████████████████████████████████████████████████████████| 1144/1144 [00:02, 472.82it/s]</p>
<p>Converting COCO Json to YOLO txt finished!</p>
<h3 id="dataset-configuration">Dataset Configuration</h3>
<p>The <code>coco.yaml</code> file that came with the dataset contained all 80 COCO classes - I removed all classes that were not part of the annotation and assigned new <code>category_id</code>&#x27;s from <code>0</code>-<code>15</code> for the 16 categories. If you want to use the configuration files below to train your YOLO model you need to replace the annotations accordingly - check the <code>./config</code> folder.</p>
<ul>
<li><code>config/data_thermal.yaml</code></li>
</ul>
<pre><code class="language-yaml">train: ../images_thermal_train/images
val: ../images_thermal_val/images
test: ../video_thermal_test/images

nc: 16
names: [
  &#x27;person&#x27;,
  &#x27;bike&#x27;,
  &#x27;car&#x27;,
  &#x27;motor&#x27;,
  &#x27;bus&#x27;,
  &#x27;train&#x27;,
  &#x27;truck&#x27;,
  &#x27;light&#x27;,
  &#x27;hydrant&#x27;,
  &#x27;sign&#x27;,
  &#x27;dog&#x27;,
  &#x27;deer&#x27;,
  &#x27;skateboard&#x27;,
  &#x27;stroller&#x27;,
  &#x27;scooter&#x27;,
  &#x27;other vehicle&#x27;
  ]
</code></pre>
<ul>
<li><code>config/data_rgb.yaml</code></li>
</ul>
<pre><code class="language-yaml">train: /opt/app/datasets/images_rgb_train/images
val: /opt/app/datasets/images_rgb_val/images
test: /opt/app/datasets/video_rgb_test/images

nc: 16
names: [
  &#x27;person&#x27;,
  &#x27;bike&#x27;,
  &#x27;car&#x27;,
  &#x27;motor&#x27;,
  &#x27;bus&#x27;,
  &#x27;train&#x27;,
  &#x27;truck&#x27;,
  &#x27;light&#x27;,
  &#x27;hydrant&#x27;,
  &#x27;sign&#x27;,
  &#x27;dog&#x27;,
  &#x27;deer&#x27;,
  &#x27;skateboard&#x27;,
  &#x27;stroller&#x27;,
  &#x27;scooter&#x27;,
  &#x27;other vehicle&#x27;
  ]
</code></pre>
<pre><code class="language-python">f_rgb = open(&#x27;./config/images_rgb_val_coco.json&#x27;) # =&gt;&#x27;./datasets/images_rgb_val/coco.json&#x27;
f_thermal = open(&#x27;./config/images_thermal_val_coco.json&#x27;) # =&gt; &#x27;./datasets/images_thermal_val/coco.json&#x27;
# returns JSON object as a dictionary
data_rgb_val = json.load(f_rgb)
data_thermal_val = json.load(f_thermal)
# closing files
f_rgb.close()
f_thermal.close()
</code></pre>
<pre><code class="language-python">f_rgb = open(&#x27;./config/images_rgb_train_coco.json&#x27;) # =&gt; &#x27;./datasets/images_rgb_train/coco.json&#x27;
f_thermal = open(&#x27;./config/images_thermal_train_coco.json&#x27;) # =&gt; &#x27;./datasets/images_thermal_train/coco.json&#x27;
# returns JSON object as a dictionary
data_rgb_train = json.load(f_rgb)
data_thermal_train = json.load(f_thermal)
# closing files
f_rgb.close()
f_thermal.close()
</code></pre>
<pre><code class="language-python">f_rgb = open(&#x27;./config/video_rgb_test_coco.json&#x27;) # =&gt; &#x27;./datasets/video_rgb_test/coco.json&#x27;
f_thermal = open(&#x27;./config/video_thermal_test_coco.json&#x27;) # =&gt; &#x27;./datasets/video_thermal_test/coco.json&#x27;
# returns JSON object as a dictionary
data_rgb_test = json.load(f_rgb)
data_thermal_test = json.load(f_thermal)
# closing files
f_rgb.close()
f_thermal.close()
</code></pre>
<pre><code class="language-python"># Iterating through the json list - check that all annotations are between 0 and 15

categories = []

for detection in data_rgb_val[&#x27;annotations&#x27;]:
    categories.append(detection[&#x27;category_id&#x27;])

print(np.unique(categories))
</code></pre>
<p>[ 0  1  2  3  5  6  8  9 12 13 15]</p>
<pre><code class="language-python">categories = []

for detection in data_thermal_val[&#x27;annotations&#x27;]:
    categories.append(detection[&#x27;category_id&#x27;])

print(np.unique(categories))
</code></pre>
<p>[ 0  1  2  3  5  6  8  9 12 13 15]</p>
<pre><code class="language-python">categories = []

for detection in data_rgb_train[&#x27;annotations&#x27;]:
    categories.append(detection[&#x27;category_id&#x27;])

print(np.unique(categories))
</code></pre>
<p>[ 0  1  2  3  5  6  8  9 12 13 14 15]</p>
<pre><code class="language-python">categories = []

for detection in data_thermal_train[&#x27;annotations&#x27;]:
    categories.append(detection[&#x27;category_id&#x27;])

print(np.unique(categories))
</code></pre>
<p>[ 0  1  2  3  5  6  8  9 10 11 12 13 14 15]</p>
<pre><code class="language-python">categories = []

for detection in data_rgb_test[&#x27;annotations&#x27;]:
    categories.append(detection[&#x27;category_id&#x27;])

print(np.unique(categories))
</code></pre>
<p>[ 0  1  2  3  6  7  8  9 10 15]</p>
<pre><code class="language-python">categories = []

for detection in data_thermal_test[&#x27;annotations&#x27;]:
    categories.append(detection[&#x27;category_id&#x27;])

print(np.unique(categories))
</code></pre>
<p>[ 0  1  2  3  6  8  9 10 15]</p>
<h2 id="training-the-yolov8-model-rgb--ir">Training the YOLOv8 Model (RGB / IR)</h2>
<pre><code class="language-python"># missing yolo dep
!pip install lapx&gt;=0.5.2
</code></pre>
<p>[33mWARNING: Running pip as the &#x27;root&#x27; user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: <a href="https://pip.pypa.io/warnings/venv%1B%5B0m%1B%5B33m">https://pip.pypa.io/warnings/venv[0m[33m</a>
[0m</p>
<pre><code class="language-python">import cv2 as cv
from glob import glob
import matplotlib.pyplot as plt
import os
import random
from ultralytics import YOLO
</code></pre>
<h3 id="yolov8-nano-rgb">YOLOv8 Nano (RGB)</h3>
<pre><code class="language-python"># unzip downloaded dataset to `./datasets`
dataset_rgb = &#x27;datasets/data_rgb.yaml&#x27;

# load a model
backbone_nano = YOLO(&quot;yolov8n.yaml&quot;)  # build a new model from scratch
</code></pre>
<h4 id="model-training">Model Training</h4>
<pre><code class="language-python">import json
 
# Opening JSON file
f = open(&#x27;./datasets/images_rgb_train/coco.json&#x27;)
 
# returns JSON object as
# a dictionary
data = json.load(f)
</code></pre>
<pre><code class="language-python"># Iterating through the json
list = []
for i in data[&#x27;annotations&#x27;]:
    list.append(i[&#x27;category_id&#x27;])
</code></pre>
<pre><code class="language-python">len(list)
</code></pre>
<p>169174</p>
<pre><code class="language-python">import numpy as np

print(np.unique(list))

# Closing file
f.close()
</code></pre>
<p>[ 0  1  2  3  5  6  8  9 12 13 14 15]</p>
<pre><code class="language-python"># Train the model
results_n = backbone_nano.train(data=dataset_rgb, epochs=20)
</code></pre>
<blockquote>
<p>20 epochs completed in 1.521 hours.</p>
</blockquote>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th><th>Size</th></tr></thead><tbody><tr><td>10/20</td><td>3.07G</td><td>1.829</td><td>1.375</td><td>1.254</td><td>328</td><td></td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td><td>mAP50-95</td></tr><tr><td>all</td><td>1085</td><td>16909</td><td>0.525</td><td>0.16</td><td>0.156</td><td>0.077</td></tr></tbody></table>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th><th>Size</th></tr></thead><tbody><tr><td>20/20</td><td>2.63G</td><td>1.595</td><td>1.117</td><td>1.146</td><td>223</td><td></td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td><td>mAP50-95</td></tr><tr><td>all</td><td>1085</td><td>16909</td><td>0.579</td><td>0.185</td><td>0.196</td><td>0.102</td></tr></tbody></table>
<blockquote>
<p>YOLOv8n summary (fused): 168 layers, 3008768 parameters, 0 gradients</p>
</blockquote>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>1085</td><td>16909</td><td>0.578</td><td>0.186</td><td>0.196</td><td>0.102</td></tr><tr><td>person</td><td>1085</td><td>3223</td><td>0.501</td><td>0.375</td><td>0.389</td><td>0.167</td></tr><tr><td>bike</td><td>1085</td><td>193</td><td>0.201</td><td>0.197</td><td>0.101</td><td>0.0438</td></tr><tr><td>car</td><td>1085</td><td>7285</td><td>0.662</td><td>0.575</td><td>0.621</td><td>0.397</td></tr><tr><td>motor</td><td>1085</td><td>77</td><td>0.418</td><td>0.26</td><td>0.298</td><td>0.164</td></tr><tr><td>train</td><td>1085</td><td>183</td><td>0.458</td><td>0.246</td><td>0.253</td><td>0.153</td></tr><tr><td>truck</td><td>1085</td><td>2190</td><td>0.458</td><td>0.198</td><td>0.206</td><td>0.0686</td></tr><tr><td>hydrant</td><td>1085</td><td>126</td><td>0.744</td><td>0.0232</td><td>0.0797</td><td>0.0265</td></tr><tr><td>sign</td><td>1085</td><td>3581</td><td>0.564</td><td>0.143</td><td>0.171</td><td>0.0824</td></tr><tr><td>skateboard</td><td>1085</td><td>4</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>1085</td><td>7</td><td>1</td><td>0</td><td>0.018</td><td>0.0144</td></tr><tr><td>other vehicle</td><td>1085</td><td>40</td><td>0.348</td><td>0.025</td><td>0.0231</td><td>0.00793</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.2ms preprocess, 4.2ms inference, 0.0ms loss, 0.6ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_rgb_nano_results-5a600015b86f5eff87e279b83fef0a57.webp" width="2400" height="1200"></p>
<pre><code class="language-python">plt.figure(figsize=(24, 14))

im_batch0_labels = plt.imread(&#x27;./assets/backbone_rgb_nano_val_batch0_labels.webp&#x27;)
im_batch0_pred = plt.imread(&#x27;./assets/backbone_rgb_nano_val_batch0_pred.webp&#x27;)
im_batch1_labels = plt.imread(&#x27;./assets/backbone_rgb_nano_val_batch1_labels.webp&#x27;)
im_batch1_pred = plt.imread(&#x27;./assets/backbone_rgb_nano_val_batch1_pred.webp&#x27;)
im_batch2_labels = plt.imread(&#x27;./assets/backbone_rgb_nano_val_batch2_labels.webp&#x27;)
im_batch2_pred = plt.imread(&#x27;./assets/backbone_rgb_nano_val_batch2_pred.webp&#x27;)

ax = plt.subplot(2, 3, 1)
plt.title(&#x27;batch0_labels&#x27;)
plt.imshow(im_batch0_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 2)
plt.title(&#x27;batch1_labels&#x27;)
plt.imshow(im_batch1_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 3)
plt.title(&#x27;batch2_labels&#x27;)
plt.imshow(im_batch2_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 4)
plt.title(&#x27;batch0_pred&#x27;)
plt.imshow(im_batch0_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 5)
plt.title(&#x27;batch1_pred&#x27;)
plt.imshow(im_batch1_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 6)
plt.title(&#x27;batch2_pred&#x27;)
plt.imshow(im_batch2_pred)
plt.axis(&quot;off&quot;)
</code></pre>
<p>(-0.5, 1919.5, 1647.5, -0.5)</p>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_13_1-b41dc7141bbde3c5a528a32b5859383d.png" width="1880" height="1099"></p>
<h4 id="model-evaluation">Model Evaluation</h4>
<pre><code class="language-python"># Evaluate the model&#x27;s performance on the validation set
results_n = backbone_nano.val()
</code></pre>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>1085</td><td>16909</td><td>0.578</td><td>0.185</td><td>0.198</td><td>0.104</td></tr><tr><td>person</td><td>1085</td><td>3223</td><td>0.505</td><td>0.375</td><td>0.391</td><td>0.167</td></tr><tr><td>bike</td><td>1085</td><td>193</td><td>0.2</td><td>0.197</td><td>0.102</td><td>0.044</td></tr><tr><td>car</td><td>1085</td><td>7285</td><td>0.663</td><td>0.574</td><td>0.621</td><td>0.398</td></tr><tr><td>motor</td><td>1085</td><td>77</td><td>0.419</td><td>0.26</td><td>0.3</td><td>0.166</td></tr><tr><td>train</td><td>1085</td><td>183</td><td>0.455</td><td>0.246</td><td>0.252</td><td>0.155</td></tr><tr><td>truck</td><td>1085</td><td>2190</td><td>0.458</td><td>0.197</td><td>0.205</td><td>0.0686</td></tr><tr><td>hydrant</td><td>1085</td><td>126</td><td>0.741</td><td>0.023</td><td>0.0801</td><td>0.0274</td></tr><tr><td>sign</td><td>1085</td><td>3581</td><td>0.563</td><td>0.142</td><td>0.17</td><td>0.0824</td></tr><tr><td>skateboard</td><td>1085</td><td>4</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>1085</td><td>7</td><td>1</td><td>0</td><td>0.0353</td><td>0.023</td></tr><tr><td>other vehicle</td><td>1085</td><td>40</td><td>0.355</td><td>0.025</td><td>0.0231</td><td>0.00793</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.3ms preprocess, 5.0ms inference, 0.0ms loss, 0.7ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_rgb_nano_confusion_matrix_normalized-66158e0304362dc36a3144b4f7181871.webp" width="3000" height="2250"></p>
<pre><code class="language-python"># Export the model to ONNX format
# success = backbone_nano.export(imgsz=(640, 480), format=&#x27;onnx&#x27;, opset=12, optimize=False, half=False)
# Export to PyTorch format
success = backbone_nano.export(imgsz=640, format=&#x27;torchscript&#x27;, optimize=False, half=False, int8=False)
# TorchScript: export success ✅ 1.3s, saved as &#x27;runs/detect/train4/weights/best.torchscript&#x27; (11.9 MB)
</code></pre>
<pre><code class="language-python"># pick pre-trained model
n_model = YOLO(&#x27;runs/detect/train6/weights/best.torchscript&#x27;)
</code></pre>
<pre><code class="language-python"># read video by index
video = cv.VideoCapture(videos[1])
ret, frame = video.read()

# get video dims
frame_width = int(video.get(3))
frame_height = int(video.get(4))
size = (frame_width, frame_height)

# Define the codec and create VideoWriter object
fourcc = cv.VideoWriter_fourcc(*&#x27;DIVX&#x27;)
out = cv.VideoWriter(&#x27;./outputs/backbone_nano_rgb.avi&#x27;, fourcc, 20.0, size)

# read frames
ret = True

while ret:
    ret, frame = video.read()

    if ret:
        # detect &amp; track objects
        results = np_model.track(frame, persist=True)

        # plot results
        composed = results[0].plot()

        # save video
        out.write(composed)

out.release()
video.release()
</code></pre>
<h3 id="yolov8-small-rgb">YOLOv8 Small (RGB)</h3>
<pre><code class="language-python"># unzip downloaded dataset to `./datasets`
dataset_rgb = &#x27;datasets/data_rgb.yaml&#x27;

# load a model
backbone_small = YOLO(&quot;yolov8s.yaml&quot;)  # build a new model from scratch
</code></pre>
<h4 id="model-training-1">Model Training</h4>
<pre><code class="language-python"># Train the model
results_s = backbone_small.train(data=dataset_rgb, epochs=20)
</code></pre>
<blockquote>
<p>20 epochs completed in 2.438 hours.</p>
</blockquote>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th><th>Size</th></tr></thead><tbody><tr><td>10/20</td><td>4.84G</td><td>1.569</td><td>1.098</td><td>1.195</td><td>328</td><td></td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td><td>mAP50-95</td></tr><tr><td>all</td><td>1085</td><td>16909</td><td>0.596</td><td>0.211</td><td>0.245</td><td>0.128</td></tr></tbody></table>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th><th>Size</th></tr></thead><tbody><tr><td>20/20</td><td>4.67G</td><td>1.367</td><td>0.8879</td><td>1.083</td><td>223</td><td></td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td><td>mAP50-95</td></tr><tr><td>all</td><td>1085</td><td>16909</td><td>0.608</td><td>0.25</td><td>0.291</td><td>0.158</td></tr></tbody></table>
<blockquote>
<p>YOLOv8s summary (fused): 168 layers, 11131776 parameters, 0 gradients</p>
</blockquote>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>1085</td><td>16909</td><td>0.523</td><td>0.255</td><td>0.291</td><td>0.159</td></tr><tr><td>person</td><td>1085</td><td>3223</td><td>0.618</td><td>0.428</td><td>0.481</td><td>0.225</td></tr><tr><td>bike</td><td>1085</td><td>193</td><td>0.248</td><td>0.326</td><td>0.239</td><td>0.121</td></tr><tr><td>car</td><td>1085</td><td>7285</td><td>0.718</td><td>0.63</td><td>0.683</td><td>0.454</td></tr><tr><td>motor</td><td>1085</td><td>77</td><td>0.566</td><td>0.338</td><td>0.382</td><td>0.22</td></tr><tr><td>train</td><td>1085</td><td>183</td><td>0.577</td><td>0.344</td><td>0.409</td><td>0.276</td></tr><tr><td>truck</td><td>1085</td><td>2190</td><td>0.593</td><td>0.318</td><td>0.336</td><td>0.119</td></tr><tr><td>hydrant</td><td>1085</td><td>126</td><td>0.8</td><td>0.175</td><td>0.293</td><td>0.129</td></tr><tr><td>sign</td><td>1085</td><td>3581</td><td>0.632</td><td>0.243</td><td>0.291</td><td>0.149</td></tr><tr><td>skateboard</td><td>1085</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>1085</td><td>7</td><td>1</td><td>0</td><td>0.0687</td><td>0.0477</td></tr><tr><td>other vehicle</td><td>1085</td><td>40</td><td>0</td><td>0</td><td>0.0135</td><td>0.00526</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.3ms preprocess, 9.6ms inference, 0.0ms loss, 0.5ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_rgb_small_results-0e8772ea24bb3db6367d29dce44d586e.webp" width="2400" height="1200"></p>
<pre><code class="language-python">plt.figure(figsize=(24, 14))

im_batch0_labels = plt.imread(&#x27;./assets/backbone_rgb_small_val_batch0_labels.webp&#x27;)
im_batch0_pred = plt.imread(&#x27;./assets/backbone_rgb_small_val_batch0_pred.webp&#x27;)
im_batch1_labels = plt.imread(&#x27;./assets/backbone_rgb_small_val_batch1_labels.webp&#x27;)
im_batch1_pred = plt.imread(&#x27;./assets/backbone_rgb_small_val_batch1_pred.webp&#x27;)
im_batch2_labels = plt.imread(&#x27;./assets/backbone_rgb_small_val_batch2_labels.webp&#x27;)
im_batch2_pred = plt.imread(&#x27;./assets/backbone_rgb_small_val_batch2_pred.webp&#x27;)

ax = plt.subplot(2, 3, 1)
plt.title(&#x27;batch0_labels&#x27;)
plt.imshow(im_batch0_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 2)
plt.title(&#x27;batch1_labels&#x27;)
plt.imshow(im_batch1_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 3)
plt.title(&#x27;batch2_labels&#x27;)
plt.imshow(im_batch2_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 4)
plt.title(&#x27;batch0_pred&#x27;)
plt.imshow(im_batch0_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 5)
plt.title(&#x27;batch1_pred&#x27;)
plt.imshow(im_batch1_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 6)
plt.title(&#x27;batch2_pred&#x27;)
plt.imshow(im_batch2_pred)
plt.axis(&quot;off&quot;)
</code></pre>
<p>(-0.5, 1919.5, 1647.5, -0.5)</p>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_27_1-fae7eb8b7c2230cd414effc8d546bf6f.png" width="1880" height="1099"></p>
<h4 id="model-evaluation-1">Model Evaluation</h4>
<pre><code class="language-python"># Evaluate the model&#x27;s performance on the validation set
results_s = backbone_small.val()
</code></pre>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>1085</td><td>16909</td><td>0.524</td><td>0.253</td><td>0.29</td><td>0.159</td></tr><tr><td>person</td><td>1085</td><td>3223</td><td>0.622</td><td>0.428</td><td>0.481</td><td>0.225</td></tr><tr><td>bike</td><td>1085</td><td>193</td><td>0.247</td><td>0.321</td><td>0.239</td><td>0.121</td></tr><tr><td>car</td><td>1085</td><td>7285</td><td>0.722</td><td>0.629</td><td>0.683</td><td>0.454</td></tr><tr><td>motor</td><td>1085</td><td>77</td><td>0.563</td><td>0.338</td><td>0.382</td><td>0.219</td></tr><tr><td>train</td><td>1085</td><td>183</td><td>0.575</td><td>0.339</td><td>0.41</td><td>0.276</td></tr><tr><td>truck</td><td>1085</td><td>2190</td><td>0.6</td><td>0.315</td><td>0.333</td><td>0.12</td></tr><tr><td>hydrant</td><td>1085</td><td>126</td><td>0.8</td><td>0.175</td><td>0.292</td><td>0.129</td></tr><tr><td>sign</td><td>1085</td><td>3581</td><td>0.635</td><td>0.243</td><td>0.292</td><td>0.149</td></tr><tr><td>skateboard</td><td>1085</td><td>4</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>1085</td><td>7</td><td>1</td><td>0</td><td>0.069</td><td>0.0479</td></tr><tr><td>other vehicle</td><td>1085</td><td>40</td><td>0</td><td>0</td><td>0.0136</td><td>0.00526</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.4ms preprocess, 10.9ms inference, 0.0ms loss, 0.6ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_rgb_small_confusion_matrix_normalized-c670483f5fd5c4d59bef626befe426b4.webp" width="3000" height="2250"></p>
<pre><code class="language-python"># Export the model to ONNX format
# success = backbone_nano.export(imgsz=(640, 480), format=&#x27;onnx&#x27;, opset=12, optimize=False, half=False)
# Export to PyTorch format
success = backbone_small.export(imgsz=640, format=&#x27;torchscript&#x27;, optimize=False, half=False, int8=False)
TorchScript: export success ✅ 2.1s, saved as &#x27;runs/detect/train5/weights/best.torchscript&#x27; (42.9 MB)
</code></pre>
<h3 id="yolov8-nano-ir">YOLOv8 Nano (IR)</h3>
<pre><code class="language-python"># unzip downloaded dataset to `./datasets`
dataset_ir = &#x27;datasets/data_thermal.yaml&#x27;

# load a model
backbone_ir_nano = YOLO(&quot;yolov8n.yaml&quot;)  # build a new model from scratch
</code></pre>
<h4 id="model-training-2">Model Training</h4>
<pre><code class="language-python"># Train the model
results_ir_n = backbone_ir_nano.train(data=dataset_ir, epochs=20)
</code></pre>
<blockquote>
<p>20 epochs completed in 1.337 hours.</p>
</blockquote>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th><th>Size</th></tr></thead><tbody><tr><td>10/20</td><td>3.33G</td><td>1.746</td><td>1.263</td><td>1.211</td><td>104</td><td></td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td><td>mAP50-95</td></tr><tr><td>all</td><td>1144</td><td>16688</td><td>0.466</td><td>0.186</td><td>0.226</td><td>0.112</td></tr></tbody></table>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th><th>Size</th></tr></thead><tbody><tr><td>20/20</td><td>2.5G</td><td>1.518</td><td>1.016</td><td>1.111</td><td>102</td><td></td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td><td>mAP50-95</td></tr><tr><td>all</td><td>1144</td><td>16688</td><td>0.513</td><td>0.249</td><td>0.276</td><td>0.146</td></tr></tbody></table>
<blockquote>
<p>YOLOv8n summary (fused): 168 layers, 3008768 parameters, 0 gradients</p>
</blockquote>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>1144</td><td>16688</td><td>0.514</td><td>0.249</td><td>0.276</td><td>0.146</td></tr><tr><td>person</td><td>1144</td><td>4470</td><td>0.628</td><td>0.555</td><td>0.594</td><td>0.276</td></tr><tr><td>bike</td><td>1144</td><td>170</td><td>0.278</td><td>0.25</td><td>0.219</td><td>0.11</td></tr><tr><td>car</td><td>1144</td><td>7128</td><td>0.691</td><td>0.65</td><td>0.71</td><td>0.449</td></tr><tr><td>motor</td><td>1144</td><td>55</td><td>0.569</td><td>0.364</td><td>0.39</td><td>0.19</td></tr><tr><td>train</td><td>1144</td><td>179</td><td>0.741</td><td>0.383</td><td>0.455</td><td>0.284</td></tr><tr><td>truck</td><td>1144</td><td>2048</td><td>0.467</td><td>0.259</td><td>0.274</td><td>0.105</td></tr><tr><td>hydrant</td><td>1144</td><td>94</td><td>0.678</td><td>0.0638</td><td>0.12</td><td>0.0535</td></tr><tr><td>sign</td><td>1144</td><td>2472</td><td>0.557</td><td>0.2</td><td>0.255</td><td>0.132</td></tr><tr><td>skateboard</td><td>1144</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>1144</td><td>6</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>other vehicle</td><td>1144</td><td>63</td><td>0.0423</td><td>0.0159</td><td>0.0194</td><td>0.00652</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.3ms preprocess, 3.8ms inference, 0.0ms loss, 0.6ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_ir_nano_results-d3d699d2e623e64eee71d0e86cf8ff6e.webp" width="2400" height="1200"></p>
<pre><code class="language-python">plt.figure(figsize=(24, 14))

im_batch0_labels = plt.imread(&#x27;./assets/backbone_ir_nano_val_batch0_labels.webp&#x27;)
im_batch0_pred = plt.imread(&#x27;./assets/backbone_ir_nano_val_batch0_pred.webp&#x27;)
im_batch1_labels = plt.imread(&#x27;./assets/backbone_ir_nano_val_batch1_labels.webp&#x27;)
im_batch1_pred = plt.imread(&#x27;./assets/backbone_ir_nano_val_batch1_pred.webp&#x27;)
im_batch2_labels = plt.imread(&#x27;./assets/backbone_ir_nano_val_batch2_labels.webp&#x27;)
im_batch2_pred = plt.imread(&#x27;./assets/backbone_ir_nano_val_batch2_pred.webp&#x27;)

ax = plt.subplot(2, 3, 1)
plt.title(&#x27;batch0_labels&#x27;)
plt.imshow(im_batch0_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 2)
plt.title(&#x27;batch1_labels&#x27;)
plt.imshow(im_batch1_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 3)
plt.title(&#x27;batch2_labels&#x27;)
plt.imshow(im_batch2_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 4)
plt.title(&#x27;batch0_pred&#x27;)
plt.imshow(im_batch0_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 5)
plt.title(&#x27;batch1_pred&#x27;)
plt.imshow(im_batch1_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 6)
plt.title(&#x27;batch2_pred&#x27;)
plt.imshow(im_batch2_pred)
plt.axis(&quot;off&quot;)
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_39_1-0e53db06a791206dcb886c9108d00645.png" width="1880" height="1073"></p>
<h4 id="model-evaluation-2">Model Evaluation</h4>
<pre><code class="language-python"># Evaluate the model&#x27;s performance on the validation set
results_ir_n = backbone_ir_nano.val()
</code></pre>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>1144</td><td>16688</td><td>0.516</td><td>0.249</td><td>0.276</td><td>0.146</td></tr><tr><td>person</td><td>1144</td><td>4470</td><td>0.631</td><td>0.556</td><td>0.595</td><td>0.276</td></tr><tr><td>bike</td><td>1144</td><td>170</td><td>0.288</td><td>0.253</td><td>0.222</td><td>0.111</td></tr><tr><td>car</td><td>1144</td><td>7128</td><td>0.696</td><td>0.65</td><td>0.711</td><td>0.449</td></tr><tr><td>motor</td><td>1144</td><td>55</td><td>0.57</td><td>0.364</td><td>0.39</td><td>0.189</td></tr><tr><td>train</td><td>1144</td><td>179</td><td>0.746</td><td>0.378</td><td>0.455</td><td>0.283</td></tr><tr><td>truck</td><td>1144</td><td>2048</td><td>0.462</td><td>0.256</td><td>0.271</td><td>0.104</td></tr><tr><td>hydrant</td><td>1144</td><td>94</td><td>0.679</td><td>0.0638</td><td>0.12</td><td>0.0526</td></tr><tr><td>sign</td><td>1144</td><td>2472</td><td>0.557</td><td>0.199</td><td>0.256</td><td>0.132</td></tr><tr><td>skateboard</td><td>1144</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>1144</td><td>6</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>other vehicle</td><td>1144</td><td>63</td><td>0.0425</td><td>0.0159</td><td>0.0193</td><td>0.00637</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.3ms preprocess, 4.5ms inference, 0.0ms loss, 0.7ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_ir_nano_confusion_matrix_normalized-5cc4000782c524957dc7d362ed4c8dd1.webp" width="3000" height="2250"></p>
<pre><code class="language-python"># Export the model to ONNX format
# success = backbone_nano.export(imgsz=(640, 480), format=&#x27;onnx&#x27;, opset=12, optimize=False, half=False)
# Export to PyTorch format
success = backbone_ir_nano.export(imgsz=640, format=&#x27;torchscript&#x27;, optimize=False, half=False, int8=False)
# TorchScript: export success ✅ 1.6s, saved as &#x27;runs/detect/train6/weights/best.torchscript&#x27; (12.4 MB)
</code></pre>
<h3 id="yolov8-small-ir">YOLOv8 Small (IR)</h3>
<pre><code class="language-python"># unzip downloaded dataset to `./datasets`
dataset_ir = &#x27;datasets/data_thermal.yaml&#x27;

# load a model
backbone_ir_small = YOLO(&quot;yolov8s.yaml&quot;)  # build a new model from scratch
</code></pre>
<h3 id="model-training-3">Model Training</h3>
<pre><code class="language-python"># Train the model
results_ir_s = backbone_ir_small.train(data=dataset_ir, epochs=20)
</code></pre>
<blockquote>
<p>20 epochs completed in 2.827 hours.</p>
</blockquote>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th><th>Size</th></tr></thead><tbody><tr><td>10/20</td><td>4.83G</td><td>1.508</td><td>1.018</td><td>1.16</td><td>104</td><td></td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td><td>mAP50-95</td></tr><tr><td>all</td><td>1144</td><td>16688</td><td>0.489</td><td>0.286</td><td>0.313</td><td>0.168</td></tr></tbody></table>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th><th>Size</th></tr></thead><tbody><tr><td>20/20</td><td>4.67G</td><td>1.317</td><td>0.8207</td><td>1.064</td><td>102</td><td></td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td><td>mAP50-95</td></tr><tr><td>all</td><td>1144</td><td>16688</td><td>0.554</td><td>0.322</td><td>0.358</td><td>0.2</td></tr></tbody></table>
<blockquote>
<p>YOLOv8s summary (fused): 168 layers, 11131776 parameters, 0 gradients</p>
</blockquote>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>1144</td><td>16688</td><td>0.554</td><td>0.322</td><td>0.358</td><td>0.2</td></tr><tr><td>person</td><td>1144</td><td>4470</td><td>0.687</td><td>0.634</td><td>0.688</td><td>0.355</td></tr><tr><td>bike</td><td>1144</td><td>170</td><td>0.364</td><td>0.347</td><td>0.308</td><td>0.174</td></tr><tr><td>car</td><td>1144</td><td>7128</td><td>0.74</td><td>0.725</td><td>0.781</td><td>0.527</td></tr><tr><td>motor</td><td>1144</td><td>55</td><td>0.608</td><td>0.509</td><td>0.552</td><td>0.25</td></tr><tr><td>train</td><td>1144</td><td>179</td><td>0.683</td><td>0.419</td><td>0.526</td><td>0.358</td></tr><tr><td>truck</td><td>1144</td><td>2048</td><td>0.601</td><td>0.385</td><td>0.415</td><td>0.178</td></tr><tr><td>hydrant</td><td>1144</td><td>94</td><td>0.687</td><td>0.149</td><td>0.274</td><td>0.147</td></tr><tr><td>sign</td><td>1144</td><td>2472</td><td>0.608</td><td>0.313</td><td>0.362</td><td>0.195</td></tr><tr><td>skateboard</td><td>1144</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>1144</td><td>6</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>other vehicle</td><td>1144</td><td>63</td><td>0.112</td><td>0.0635</td><td>0.0254</td><td>0.0151</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.3ms preprocess, 9.6ms inference, 0.0ms loss, 0.6ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_ir_small_results-141a8c53c4cbf26545b5e4a8549b1b79.webp" width="2400" height="1200"></p>
<pre><code class="language-python">plt.figure(figsize=(24, 14))

im_batch0_labels = plt.imread(&#x27;./assets/backbone_ir_small_val_batch0_labels.webp&#x27;)
im_batch0_pred = plt.imread(&#x27;./assets/backbone_ir_small_val_batch0_pred.webp&#x27;)
im_batch1_labels = plt.imread(&#x27;./assets/backbone_ir_small_val_batch1_labels.webp&#x27;)
im_batch1_pred = plt.imread(&#x27;./assets/backbone_ir_small_val_batch1_pred.webp&#x27;)
im_batch2_labels = plt.imread(&#x27;./assets/backbone_ir_small_val_batch2_labels.webp&#x27;)
im_batch2_pred = plt.imread(&#x27;./assets/backbone_ir_small_val_batch2_pred.webp&#x27;)

ax = plt.subplot(2, 3, 1)
plt.title(&#x27;batch0_labels&#x27;)
plt.imshow(im_batch0_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 2)
plt.title(&#x27;batch1_labels&#x27;)
plt.imshow(im_batch1_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 3)
plt.title(&#x27;batch2_labels&#x27;)
plt.imshow(im_batch2_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 4)
plt.title(&#x27;batch0_pred&#x27;)
plt.imshow(im_batch0_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 5)
plt.title(&#x27;batch1_pred&#x27;)
plt.imshow(im_batch1_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 6)
plt.title(&#x27;batch2_pred&#x27;)
plt.imshow(im_batch2_pred)
plt.axis(&quot;off&quot;)
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_51_1-721f0f3f3ed8da31951fac7b88c3af15.png" width="1880" height="1073"></p>
<h4 id="model-evaluation-3">Model Evaluation</h4>
<pre><code class="language-python"># Evaluate the model&#x27;s performance on the validation set
results_ir_s = backbone_ir_small.val()
</code></pre>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>1144</td><td>16688</td><td>0.555</td><td>0.322</td><td>0.358</td><td>0.2</td></tr><tr><td>person</td><td>1144</td><td>4470</td><td>0.691</td><td>0.632</td><td>0.687</td><td>0.356</td></tr><tr><td>bike</td><td>1144</td><td>170</td><td>0.369</td><td>0.353</td><td>0.309</td><td>0.174</td></tr><tr><td>car</td><td>1144</td><td>7128</td><td>0.743</td><td>0.725</td><td>0.781</td><td>0.527</td></tr><tr><td>motor</td><td>1144</td><td>55</td><td>0.593</td><td>0.504</td><td>0.551</td><td>0.251</td></tr><tr><td>train</td><td>1144</td><td>179</td><td>0.683</td><td>0.419</td><td>0.527</td><td>0.361</td></tr><tr><td>truck</td><td>1144</td><td>2048</td><td>0.608</td><td>0.386</td><td>0.418</td><td>0.178</td></tr><tr><td>hydrant</td><td>1144</td><td>94</td><td>0.695</td><td>0.149</td><td>0.274</td><td>0.148</td></tr><tr><td>sign</td><td>1144</td><td>2472</td><td>0.614</td><td>0.313</td><td>0.362</td><td>0.195</td></tr><tr><td>skateboard</td><td>1144</td><td>3</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>1144</td><td>6</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>other vehicle</td><td>1144</td><td>63</td><td>0.112</td><td>0.0635</td><td>0.0254</td><td>0.0151</td></tr></tbody></table>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_ir_small_confusion_matrix_normalized-251435cb3ccf708191c5e23799d205aa.webp" width="3000" height="2250"></p>
<pre><code class="language-python"># Export the model to ONNX format
# success = backbone_nano.export(imgsz=(640, 480), format=&#x27;onnx&#x27;, opset=12, optimize=False, half=False)
# Export to PyTorch format
success = backbone_ir_small.export(imgsz=640, format=&#x27;torchscript&#x27;, optimize=False, half=False, int8=False)
# TorchScript: export success ✅ 1.6s, saved as &#x27;runs/detect/train6/weights/best.torchscript&#x27; (12.4 MB)
</code></pre>
<h2 id="training-the-yolov8-mixed-model-rgb--ir">Training the YOLOv8 Mixed Model (RGB + IR)</h2>
<pre><code class="language-python"># missing yolo dep
!pip install lapx&gt;=0.5.2
</code></pre>
<pre><code class="language-python">import cv2 as cv
from glob import glob
import matplotlib.pyplot as plt
import os
import random
from ultralytics import YOLO
</code></pre>
<h3 id="yolov8-nano-rgbir">YOLOv8 Nano (RGB+IR)</h3>
<pre><code class="language-python"># unzip downloaded dataset to `./datasets`
dataset_combined = &#x27;datasets/data_combined.yaml&#x27;

# load a model
backbone_nano = YOLO(&quot;yolov8n.yaml&quot;)  # build a new model from scratch
</code></pre>
<h4 id="model-training-4">Model Training</h4>
<pre><code class="language-python"># Train the model
results_n = backbone_nano.train(data=dataset_combined, epochs=20)
</code></pre>
<blockquote>
<p>20 epochs completed in 2.531 hours.</p>
</blockquote>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th></tr></thead><tbody><tr><td>10/20</td><td>3.18G</td><td>1.655</td><td>1.208</td><td>1.154</td><td>179</td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td></tr><tr><td>all</td><td>2229</td><td>33597</td><td>0.545</td><td>0.208</td><td>0.226</td></tr></tbody></table>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th></tr></thead><tbody><tr><td>20/20</td><td>2.6G</td><td>1.458</td><td>0.9884</td><td>1.073</td><td>52</td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td></tr><tr><td>all</td><td>2229</td><td>33597</td><td>0.52</td><td>0.242</td><td>0.272</td></tr></tbody></table>
<blockquote>
<p>YOLOv8n summary (fused): 168 layers, 3008768 parameters, 0 gradients</p>
</blockquote>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>2229</td><td>33597</td><td>0.522</td><td>0.241</td><td>0.272</td><td>0.147</td></tr><tr><td>person</td><td>2229</td><td>7693</td><td>0.624</td><td>0.48</td><td>0.526</td><td>0.253</td></tr><tr><td>bike</td><td>2229</td><td>363</td><td>0.288</td><td>0.27</td><td>0.239</td><td>0.128</td></tr><tr><td>car</td><td>2229</td><td>14413</td><td>0.689</td><td>0.644</td><td>0.696</td><td>0.46</td></tr><tr><td>motor</td><td>2229</td><td>132</td><td>0.611</td><td>0.364</td><td>0.419</td><td>0.193</td></tr><tr><td>train</td><td>2229</td><td>362</td><td>0.675</td><td>0.344</td><td>0.425</td><td>0.281</td></tr><tr><td>truck</td><td>2229</td><td>4238</td><td>0.492</td><td>0.235</td><td>0.255</td><td>0.0951</td></tr><tr><td>hydrant</td><td>2229</td><td>220</td><td>0.688</td><td>0.0955</td><td>0.162</td><td>0.0659</td></tr><tr><td>sign</td><td>2229</td><td>6053</td><td>0.592</td><td>0.205</td><td>0.252</td><td>0.13</td></tr><tr><td>skateboard</td><td>2229</td><td>7</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>2229</td><td>13</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>other vehicle</td><td>2229</td><td>103</td><td>0.0798</td><td>0.0194</td><td>0.0232</td><td>0.00977</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.2ms preprocess, 4.0ms inference, 0.0ms loss, 0.6ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_combined_nano_results-0dbf1b3bbf1ada0f2465babc80ee476c.webp" width="2400" height="1200"></p>
<pre><code class="language-python">plt.figure(figsize=(24, 14))

im_batch0_labels = plt.imread(&#x27;./assets/backbone_combined_nano_val_batch0_labels.webp&#x27;)
im_batch0_pred = plt.imread(&#x27;./assets/backbone_combined_nano_val_batch0_pred.webp&#x27;)
im_batch1_labels = plt.imread(&#x27;./assets/backbone_combined_nano_val_batch1_labels.webp&#x27;)
im_batch1_pred = plt.imread(&#x27;./assets/backbone_combined_nano_val_batch1_pred.webp&#x27;)
im_batch2_labels = plt.imread(&#x27;./assets/backbone_combined_nano_val_batch2_labels.webp&#x27;)
im_batch2_pred = plt.imread(&#x27;./assets/backbone_combined_nano_val_batch2_pred.webp&#x27;)

ax = plt.subplot(2, 3, 1)
plt.title(&#x27;batch0_labels&#x27;)
plt.imshow(im_batch0_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 2)
plt.title(&#x27;batch1_labels&#x27;)
plt.imshow(im_batch1_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 3)
plt.title(&#x27;batch2_labels&#x27;)
plt.imshow(im_batch2_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 4)
plt.title(&#x27;batch0_pred&#x27;)
plt.imshow(im_batch0_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 5)
plt.title(&#x27;batch1_pred&#x27;)
plt.imshow(im_batch1_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 6)
plt.title(&#x27;batch2_pred&#x27;)
plt.imshow(im_batch2_pred)
plt.axis(&quot;off&quot;)
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_9_1-2acdb1047c3c0dc07ae51a341d34c4f8.png" width="1880" height="1073"></p>
<h4 id="model-evaluation-4">Model Evaluation</h4>
<pre><code class="language-python"># Evaluate the model&#x27;s performance on the validation set
results_n = backbone_nano.val()
</code></pre>
<p>Ultralytics YOLOv8.0.173 🚀 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6070MiB)
YOLOv8n summary (fused): 168 layers, 3008768 parameters, 0 gradients
[34m[1mval: [0mScanning /opt/app/datasets/images_combined_val/labels.cache... 2229 images, 32 backgrounds, 0 corrupt: 100%|██████████| 2229/2229 , ?it/s][0m
Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 140/140 [00:31,  4.47it/s]
all       2229      33597      0.519      0.242      0.272      0.147
person       2229       7693      0.623      0.482      0.527      0.253
bike       2229        363      0.281      0.267      0.239       0.13
car       2229      14413      0.686      0.646      0.697      0.461
motor       2229        132      0.607      0.364      0.417      0.193
train       2229        362      0.666      0.348      0.424      0.279
truck       2229       4238      0.493      0.237      0.256      0.096
hydrant       2229        220      0.685     0.0955      0.162     0.0676
sign       2229       6053      0.588      0.205      0.251      0.131
skateboard       2229          7          0          0          0          0
stroller       2229         13          1          0          0          0
other vehicle       2229        103     0.0795     0.0194      0.023    0.00967
Speed: 0.3ms preprocess, 4.5ms inference, 0.0ms loss, 0.6ms postprocess per image
Results saved to [1mruns/detect/val5[0m</p>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>2229</td><td>33597</td><td>0.519</td><td>0.242</td><td>0.272</td><td>0.147</td></tr><tr><td>person</td><td>2229</td><td>7693</td><td>0.623</td><td>0.482</td><td>0.527</td><td>0.253</td></tr><tr><td>bike</td><td>2229</td><td>363</td><td>0.281</td><td>0.267</td><td>0.239</td><td>0.13</td></tr><tr><td>car</td><td>2229</td><td>14413</td><td>0.686</td><td>0.646</td><td>0.697</td><td>0.461</td></tr><tr><td>motor</td><td>2229</td><td>132</td><td>0.607</td><td>0.364</td><td>0.417</td><td>0.193</td></tr><tr><td>train</td><td>2229</td><td>362</td><td>0.666</td><td>0.348</td><td>0.424</td><td>0.279</td></tr><tr><td>truck</td><td>2229</td><td>4238</td><td>0.493</td><td>0.237</td><td>0.256</td><td>0.096</td></tr><tr><td>hydrant</td><td>2229</td><td>220</td><td>0.685</td><td>0.0955</td><td>0.162</td><td>0.0676</td></tr><tr><td>sign</td><td>2229</td><td>6053</td><td>0.588</td><td>0.205</td><td>0.251</td><td>0.131</td></tr><tr><td>skateboard</td><td>2229</td><td>7</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>2229</td><td>13</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>other vehicle</td><td>2229</td><td>103</td><td>0.0795</td><td>0.0194</td><td>0.023</td><td>0.00967</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.3ms preprocess, 4.5ms inference, 0.0ms loss, 0.6ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_combined_nano_confusion_matrix_normalized-862d07c8f16e8239a12003d8042c7ffb.webp" width="3000" height="2250"></p>
<pre><code class="language-python"># Export the model to ONNX format
# success = backbone_nano.export(imgsz=(640, 480), format=&#x27;onnx&#x27;, opset=12, optimize=False, half=False)
# Export to PyTorch format
success = backbone_nano.export(imgsz=640, format=&#x27;torchscript&#x27;, optimize=False, half=False, int8=False)
# TorchScript: export success ✅ 1.2s, saved as &#x27;runs/detect/train10/weights/best.torchscript&#x27; (11.9 MB)
</code></pre>
<p>Ultralytics YOLOv8.0.173 🚀 Python-3.10.11 torch-2.0.1 CPU (Intel Core(TM) i7-7700 3.60GHz)</p>
<p>[34m[1mPyTorch:[0m starting from &#x27;runs/detect/train10/weights/best.pt&#x27; with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 20, 8400) (6.0 MB)</p>
<p>[34m[1mTorchScript:[0m starting export with torch 2.0.1...
[34m[1mTorchScript:[0m export success ✅ 1.2s, saved as &#x27;runs/detect/train10/weights/best.torchscript&#x27; (11.9 MB)</p>
<p>Export complete (2.5s)
Results saved to [1m/opt/app/runs/detect/train10/weights[0m
Predict:         yolo predict task=detect model=runs/detect/train10/weights/best.torchscript imgsz=640<br>
<!-- -->Validate:        yolo val task=detect model=runs/detect/train10/weights/best.torchscript imgsz=640 data=datasets/data_combined.yaml<br>
<!-- -->Visualize:       <a href="https://netron.app">https://netron.app</a></p>
<h3 id="yolov8-small-rgb--ir">YOLOv8 Small (RGB + IR)</h3>
<pre><code class="language-python"># unzip downloaded dataset to `./datasets`
dataset_combined = &#x27;datasets/data_combined.yaml&#x27;

# load a model
backbone_small = YOLO(&quot;yolov8s.yaml&quot;)  # build a new model from scratch
</code></pre>
<h4 id="model-training-5">Model Training</h4>
<pre><code class="language-python"># Train the model
results_s = backbone_small.train(data=dataset_combined, epochs=20)
</code></pre>
<blockquote>
<p>20 epochs completed in 4.965 hours.</p>
</blockquote>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th></tr></thead><tbody><tr><td>10/20</td><td>4.88G</td><td>1.445</td><td>0.9915</td><td>1.085</td><td>179</td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td></tr><tr><td>all</td><td>2229</td><td>33597</td><td>0.548</td><td>0.277</td><td>0.314</td></tr></tbody></table>
<table><thead><tr><th>Epoch</th><th>GPU_mem</th><th>box_loss</th><th>cls_loss</th><th>dfl_loss</th><th>Instances</th></tr></thead><tbody><tr><td>20/20</td><td>4.86G</td><td>1.265</td><td>0.7992</td><td>1.011</td><td>52</td></tr><tr><td>Class</td><td>Images</td><td>Instances</td><td>P</td><td>R</td><td>mAP50</td></tr><tr><td>all</td><td>2229</td><td>33597</td><td>0.651</td><td>0.324</td><td>0.36</td></tr></tbody></table>
<blockquote>
<p>YOLOv8s summary (fused): 168 layers, 11131776 parameters, 0 gradients</p>
</blockquote>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>2229</td><td>33597</td><td>0.652</td><td>0.323</td><td>0.36</td><td>0.204</td></tr><tr><td>person</td><td>2229</td><td>7693</td><td>0.687</td><td>0.566</td><td>0.628</td><td>0.325</td></tr><tr><td>bike</td><td>2229</td><td>363</td><td>0.35</td><td>0.383</td><td>0.353</td><td>0.199</td></tr><tr><td>car</td><td>2229</td><td>14413</td><td>0.735</td><td>0.712</td><td>0.764</td><td>0.528</td></tr><tr><td>motor</td><td>2229</td><td>132</td><td>0.645</td><td>0.439</td><td>0.513</td><td>0.268</td></tr><tr><td>train</td><td>2229</td><td>362</td><td>0.703</td><td>0.478</td><td>0.555</td><td>0.383</td></tr><tr><td>truck</td><td>2229</td><td>4238</td><td>0.589</td><td>0.389</td><td>0.404</td><td>0.167</td></tr><tr><td>hydrant</td><td>2229</td><td>220</td><td>0.696</td><td>0.177</td><td>0.266</td><td>0.121</td></tr><tr><td>sign</td><td>2229</td><td>6053</td><td>0.62</td><td>0.329</td><td>0.372</td><td>0.205</td></tr><tr><td>skateboard</td><td>2229</td><td>7</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>2229</td><td>13</td><td>1</td><td>0</td><td>0.0386</td><td>0.0297</td></tr><tr><td>other vehicle</td><td>2229</td><td>103</td><td>0.15</td><td>0.0777</td><td>0.0616</td><td>0.0202</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.2ms preprocess, 9.1ms inference, 0.0ms loss, 0.5ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_combined_small_results-d72b565cfcbd4a09f9bd034957fe98e5.webp" width="2400" height="1200"></p>
<pre><code class="language-python">plt.figure(figsize=(24, 14))

im_batch0_labels = plt.imread(&#x27;./assets/backbone_combined_small_val_batch0_labels.webp&#x27;)
im_batch0_pred = plt.imread(&#x27;./assets/backbone_combined_small_val_batch0_pred.webp&#x27;)
im_batch1_labels = plt.imread(&#x27;./assets/backbone_combined_small_val_batch1_labels.webp&#x27;)
im_batch1_pred = plt.imread(&#x27;./assets/backbone_combined_small_val_batch1_pred.webp&#x27;)
im_batch2_labels = plt.imread(&#x27;./assets/backbone_combined_small_val_batch2_labels.webp&#x27;)
im_batch2_pred = plt.imread(&#x27;./assets/backbone_combined_small_val_batch2_pred.webp&#x27;)

ax = plt.subplot(2, 3, 1)
plt.title(&#x27;batch0_labels&#x27;)
plt.imshow(im_batch0_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 2)
plt.title(&#x27;batch1_labels&#x27;)
plt.imshow(im_batch1_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 3)
plt.title(&#x27;batch2_labels&#x27;)
plt.imshow(im_batch2_labels)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 4)
plt.title(&#x27;batch0_pred&#x27;)
plt.imshow(im_batch0_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 5)
plt.title(&#x27;batch1_pred&#x27;)
plt.imshow(im_batch1_pred)
plt.axis(&quot;off&quot;)

ax = plt.subplot(2, 3, 6)
plt.title(&#x27;batch2_pred&#x27;)
plt.imshow(im_batch2_pred)
plt.axis(&quot;off&quot;)
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_21_1-085e50c2b12dccd7d72d2b781d75311b.png" width="1880" height="1073"></p>
<h4 id="model-evaluation-5">Model Evaluation</h4>
<pre><code class="language-python"># Evaluate the model&#x27;s performance on the validation set
results_s = backbone_small.val()
</code></pre>
<p>Ultralytics YOLOv8.0.173 🚀 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6070MiB)
YOLOv8s summary (fused): 168 layers, 11131776 parameters, 0 gradients
[34m[1mval: [0mScanning /opt/app/datasets/images_combined_val/labels.cache... 2229 images, 32 backgrounds, 0 corrupt: 100%|██████████| 2229/2229 , ?it/s][0m
Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 140/140 [00:42,  3.28it/s]
all       2229      33597      0.651      0.324      0.359      0.204
person       2229       7693      0.687      0.569       0.63      0.326
bike       2229        363      0.346      0.383      0.351      0.198
car       2229      14413      0.734      0.713      0.764      0.529
motor       2229        132      0.633      0.439      0.514      0.267
train       2229        362      0.707      0.481      0.556      0.384
truck       2229       4238       0.59      0.391      0.407      0.167
hydrant       2229        220      0.697      0.178      0.266      0.122
sign       2229       6053      0.617      0.329      0.371      0.205
skateboard       2229          7          1          0          0          0
stroller       2229         13          1          0     0.0323      0.024
other vehicle       2229        103      0.148     0.0777     0.0618     0.0193
Speed: 0.3ms preprocess, 10.3ms inference, 0.0ms loss, 0.7ms postprocess per image
Results saved to [1mruns/detect/val6[0m</p>
<table><thead><tr><th>Class</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><td>all</td><td>2229</td><td>33597</td><td>0.651</td><td>0.324</td><td>0.359</td><td>0.204</td></tr><tr><td>person</td><td>2229</td><td>7693</td><td>0.687</td><td>0.569</td><td>0.63</td><td>0.326</td></tr><tr><td>bike</td><td>2229</td><td>363</td><td>0.346</td><td>0.383</td><td>0.351</td><td>0.198</td></tr><tr><td>car</td><td>2229</td><td>14413</td><td>0.734</td><td>0.713</td><td>0.764</td><td>0.529</td></tr><tr><td>motor</td><td>2229</td><td>132</td><td>0.633</td><td>0.439</td><td>0.514</td><td>0.267</td></tr><tr><td>train</td><td>2229</td><td>362</td><td>0.707</td><td>0.481</td><td>0.556</td><td>0.384</td></tr><tr><td>truck</td><td>2229</td><td>4238</td><td>0.59</td><td>0.391</td><td>0.407</td><td>0.167</td></tr><tr><td>hydrant</td><td>2229</td><td>220</td><td>0.697</td><td>0.178</td><td>0.266</td><td>0.122</td></tr><tr><td>sign</td><td>2229</td><td>6053</td><td>0.617</td><td>0.329</td><td>0.371</td><td>0.205</td></tr><tr><td>skateboard</td><td>2229</td><td>7</td><td>1</td><td>0</td><td>0</td><td>0</td></tr><tr><td>stroller</td><td>2229</td><td>13</td><td>1</td><td>0</td><td>0.0323</td><td>0.024</td></tr><tr><td>other vehicle</td><td>2229</td><td>103</td><td>0.148</td><td>0.0777</td><td>0.0618</td><td>0.0193</td></tr></tbody></table>
<blockquote>
<p><em>Speed: 0.3ms preprocess, 10.3ms inference, 0.0ms loss, 0.7ms postprocess per image</em></p>
</blockquote>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/backbone_combined_small_confusion_matrix_normalized-8ff40073ea9895f907c2c149dd816aaf.webp" width="3000" height="2250"></p>
<pre><code class="language-python"># Export the model to ONNX format
# success = backbone_nano.export(imgsz=(640, 480), format=&#x27;onnx&#x27;, opset=12, optimize=False, half=False)
# Export to PyTorch format
success = backbone_small.export(imgsz=640, format=&#x27;torchscript&#x27;, optimize=False, half=False, int8=False)
# TorchScript: export success ✅ 1.7s, saved as &#x27;runs/detect/train11/weights/best.torchscript&#x27; (42.9 MB)
</code></pre>
<h2 id="model-evaluation-6">Model Evaluation</h2>
<pre><code class="language-python">import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns
</code></pre>
<h3 id="yolov8n--rgb-dataset">YOLOv8n &amp; RGB Dataset</h3>
<pre><code class="language-python">data_index = [&#x27;all&#x27;, &#x27;person&#x27;, &#x27;bike&#x27;, &#x27;car&#x27;, &#x27;motor&#x27;, &#x27;train&#x27;, &#x27;truck&#x27;, &#x27;hydrant&#x27;, &#x27;sign&#x27;, &#x27;skateboard&#x27;, &#x27;stroller&#x27;, &#x27;other vehicle&#x27;]
data_columns = [&#x27;Model&#x27;, &#x27;Images&#x27;, &#x27;Instances&#x27;, &#x27;P&#x27;, &#x27;R&#x27;, &#x27;mAP50&#x27;, &#x27;mAP50-95&#x27;]
</code></pre>
<pre><code class="language-python">rgb_nano = [
    [&#x27;rgb_nano&#x27;, 1085, 16909, 0.578, 0.185, 0.198, 0.104],
    [&#x27;rgb_nano&#x27;, 1085, 3223, 0.505, 0.375, 0.391, 0.167],
    [&#x27;rgb_nano&#x27;, 1085, 193, 0.2, 0.197, 0.102, 0.044],
    [&#x27;rgb_nano&#x27;, 1085, 7285, 0.663, 0.574, 0.621, 0.398],
    [&#x27;rgb_nano&#x27;, 1085, 77, 0.419, 0.26, 0.3, 0.166],
    [&#x27;rgb_nano&#x27;, 1085, 183, 0.455, 0.246, 0.252, 0.155],
    [&#x27;rgb_nano&#x27;, 1085, 2190, 0.458, 0.197, 0.205, 0.0686],
    [&#x27;rgb_nano&#x27;, 1085, 126, 0.741, 0.023, 0.0801, 0.0274],
    [&#x27;rgb_nano&#x27;, 1085, 3581, 0.563, 0.142, 0.17, 0.0824],
    [&#x27;rgb_nano&#x27;, 1085, 4, 1, 0, 0, 0],
    [&#x27;rgb_nano&#x27;, 1085, 7, 1, 0, 0.0353, 0.023],
    [&#x27;rgb_nano&#x27;, 1085, 40, 0.355, 0.025, 0.0231, 0.00793]
]
</code></pre>
<pre><code class="language-python">rgb_nano_df = pd.DataFrame(rgb_nano, data_index, data_columns)
rgb_nano_df
</code></pre>
<table><thead><tr><th></th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>all</th><td>rgb_nano</td><td>1085</td><td>16909</td><td>0.578</td><td>0.185</td><td>0.1980</td><td>0.10400</td></tr><tr><th>person</th><td>rgb_nano</td><td>1085</td><td>3223</td><td>0.505</td><td>0.375</td><td>0.3910</td><td>0.16700</td></tr><tr><th>bike</th><td>rgb_nano</td><td>1085</td><td>193</td><td>0.200</td><td>0.197</td><td>0.1020</td><td>0.04400</td></tr><tr><th>car</th><td>rgb_nano</td><td>1085</td><td>7285</td><td>0.663</td><td>0.574</td><td>0.6210</td><td>0.39800</td></tr><tr><th>motor</th><td>rgb_nano</td><td>1085</td><td>77</td><td>0.419</td><td>0.260</td><td>0.3000</td><td>0.16600</td></tr><tr><th>train</th><td>rgb_nano</td><td>1085</td><td>183</td><td>0.455</td><td>0.246</td><td>0.2520</td><td>0.15500</td></tr><tr><th>truck</th><td>rgb_nano</td><td>1085</td><td>2190</td><td>0.458</td><td>0.197</td><td>0.2050</td><td>0.06860</td></tr><tr><th>hydrant</th><td>rgb_nano</td><td>1085</td><td>126</td><td>0.741</td><td>0.023</td><td>0.0801</td><td>0.02740</td></tr><tr><th>sign</th><td>rgb_nano</td><td>1085</td><td>3581</td><td>0.563</td><td>0.142</td><td>0.1700</td><td>0.08240</td></tr><tr><th>skateboard</th><td>rgb_nano</td><td>1085</td><td>4</td><td>1.000</td><td>0.000</td><td>0.0000</td><td>0.00000</td></tr><tr><th>stroller</th><td>rgb_nano</td><td>1085</td><td>7</td><td>1.000</td><td>0.000</td><td>0.0353</td><td>0.02300</td></tr><tr><th>other vehicle</th><td>rgb_nano</td><td>1085</td><td>40</td><td>0.355</td><td>0.025</td><td>0.0231</td><td>0.00793</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(16, 5))
plt.title(&#x27;Average Precision by Class &amp; Instances&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=rgb_nano_df.reset_index(),
    x=&#x27;Instances&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;index&#x27;,
    palette=&#x27;nipy_spectral&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_6_2-bac58363175530630108cd09187807ea.png" width="1486" height="470"></p>
<h3 id="yolov8s--rgb-dataset">YOLOv8s &amp; RGB Dataset</h3>
<pre><code class="language-python">rgb_small = [
    [&#x27;rgb_small&#x27;, 1085, 16909, 0.524, 0.253, 0.29, 0.159],
    [&#x27;rgb_small&#x27;, 1085, 3223, 0.622, 0.428, 0.481, 0.225],
    [&#x27;rgb_small&#x27;, 1085, 193, 0.247, 0.321, 0.239, 0.121],
    [&#x27;rgb_small&#x27;, 1085, 7285, 0.722, 0.629, 0.683, 0.454],
    [&#x27;rgb_small&#x27;, 1085, 77, 0.563, 0.338, 0.382, 0.219],
    [&#x27;rgb_small&#x27;, 1085, 183, 0.575, 0.339, 0.41, 0.276],
    [&#x27;rgb_small&#x27;, 1085, 2190, 0.6, 0.315, 0.333, 0.12],
    [&#x27;rgb_small&#x27;, 1085, 126, 0.8, 0.175, 0.292, 0.129],
    [&#x27;rgb_small&#x27;, 1085, 3581, 0.635, 0.243, 0.292, 0.149],
    [&#x27;rgb_small&#x27;, 1085, 4, 0, 0, 0, 0],
    [&#x27;rgb_small&#x27;, 1085, 7, 1, 0, 0.069, 0.0479],
    [&#x27;rgb_small&#x27;, 1085, 40, 0, 0, 0.0136, 0.00526]
]
</code></pre>
<pre><code class="language-python">rgb_small_df = pd.DataFrame(rgb_small, data_index, data_columns)
rgb_small_df
</code></pre>
<table><thead><tr><th></th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>all</th><td>rgb_small</td><td>1085</td><td>16909</td><td>0.524</td><td>0.253</td><td>0.2900</td><td>0.15900</td></tr><tr><th>person</th><td>rgb_small</td><td>1085</td><td>3223</td><td>0.622</td><td>0.428</td><td>0.4810</td><td>0.22500</td></tr><tr><th>bike</th><td>rgb_small</td><td>1085</td><td>193</td><td>0.247</td><td>0.321</td><td>0.2390</td><td>0.12100</td></tr><tr><th>car</th><td>rgb_small</td><td>1085</td><td>7285</td><td>0.722</td><td>0.629</td><td>0.6830</td><td>0.45400</td></tr><tr><th>motor</th><td>rgb_small</td><td>1085</td><td>77</td><td>0.563</td><td>0.338</td><td>0.3820</td><td>0.21900</td></tr><tr><th>train</th><td>rgb_small</td><td>1085</td><td>183</td><td>0.575</td><td>0.339</td><td>0.4100</td><td>0.27600</td></tr><tr><th>truck</th><td>rgb_small</td><td>1085</td><td>2190</td><td>0.600</td><td>0.315</td><td>0.3330</td><td>0.12000</td></tr><tr><th>hydrant</th><td>rgb_small</td><td>1085</td><td>126</td><td>0.800</td><td>0.175</td><td>0.2920</td><td>0.12900</td></tr><tr><th>sign</th><td>rgb_small</td><td>1085</td><td>3581</td><td>0.635</td><td>0.243</td><td>0.2920</td><td>0.14900</td></tr><tr><th>skateboard</th><td>rgb_small</td><td>1085</td><td>4</td><td>0.000</td><td>0.000</td><td>0.0000</td><td>0.00000</td></tr><tr><th>stroller</th><td>rgb_small</td><td>1085</td><td>7</td><td>1.000</td><td>0.000</td><td>0.0690</td><td>0.04790</td></tr><tr><th>other vehicle</th><td>rgb_small</td><td>1085</td><td>40</td><td>0.000</td><td>0.000</td><td>0.0136</td><td>0.00526</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(16, 5))
plt.title(&#x27;Average Precision by Class &amp; Instances&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=rgb_small_df.reset_index(),
    x=&#x27;Instances&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;index&#x27;,
    palette=&#x27;nipy_spectral&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_10_2-286c1cae4daaff250e32b136ea305b8a.png" width="1496" height="479"></p>
<h3 id="yolov8n--ir-dataset">YOLOv8n &amp; IR Dataset</h3>
<pre><code class="language-python">ir_nano = [
    [&#x27;ir_nano&#x27;, 1144, 16688, 0.516, 0.249, 0.276, 0.146],
    [&#x27;ir_nano&#x27;, 1144, 4470, 0.631, 0.556, 0.595, 0.276],
    [&#x27;ir_nano&#x27;, 1144, 170, 0.288, 0.253, 0.222, 0.111],
    [&#x27;ir_nano&#x27;, 1144, 7128, 0.696, 0.65, 0.711, 0.449],
    [&#x27;ir_nano&#x27;, 1144, 55, 0.57, 0.364, 0.39, 0.189],
    [&#x27;ir_nano&#x27;, 1144, 179, 0.746, 0.378, 0.455, 0.283],
    [&#x27;ir_nano&#x27;, 1144, 2048, 0.462, 0.256, 0.271, 0.104],
    [&#x27;ir_nano&#x27;, 1144, 94, 0.679, 0.0638, 0.12, 0.0526],
    [&#x27;ir_nano&#x27;, 1144, 2472, 0.557, 0.199, 0.256, 0.132],
    [&#x27;ir_nano&#x27;, 1144, 3, 0, 0, 0, 0],
    [&#x27;ir_nano&#x27;, 1144, 6, 1, 0, 0, 0],
    [&#x27;ir_nano&#x27;, 1144, 63, 0.0425, 0.0159, 0.0193, 0.00637]
]
</code></pre>
<pre><code class="language-python">ir_nano_df = pd.DataFrame(ir_nano, data_index, data_columns)
ir_nano_df
</code></pre>
<table><thead><tr><th></th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>all</th><td>ir_nano</td><td>1144</td><td>16688</td><td>0.5160</td><td>0.2490</td><td>0.2760</td><td>0.14600</td></tr><tr><th>person</th><td>ir_nano</td><td>1144</td><td>4470</td><td>0.6310</td><td>0.5560</td><td>0.5950</td><td>0.27600</td></tr><tr><th>bike</th><td>ir_nano</td><td>1144</td><td>170</td><td>0.2880</td><td>0.2530</td><td>0.2220</td><td>0.11100</td></tr><tr><th>car</th><td>ir_nano</td><td>1144</td><td>7128</td><td>0.6960</td><td>0.6500</td><td>0.7110</td><td>0.44900</td></tr><tr><th>motor</th><td>ir_nano</td><td>1144</td><td>55</td><td>0.5700</td><td>0.3640</td><td>0.3900</td><td>0.18900</td></tr><tr><th>train</th><td>ir_nano</td><td>1144</td><td>179</td><td>0.7460</td><td>0.3780</td><td>0.4550</td><td>0.28300</td></tr><tr><th>truck</th><td>ir_nano</td><td>1144</td><td>2048</td><td>0.4620</td><td>0.2560</td><td>0.2710</td><td>0.10400</td></tr><tr><th>hydrant</th><td>ir_nano</td><td>1144</td><td>94</td><td>0.6790</td><td>0.0638</td><td>0.1200</td><td>0.05260</td></tr><tr><th>sign</th><td>ir_nano</td><td>1144</td><td>2472</td><td>0.5570</td><td>0.1990</td><td>0.2560</td><td>0.13200</td></tr><tr><th>skateboard</th><td>ir_nano</td><td>1144</td><td>3</td><td>0.0000</td><td>0.0000</td><td>0.0000</td><td>0.00000</td></tr><tr><th>stroller</th><td>ir_nano</td><td>1144</td><td>6</td><td>1.0000</td><td>0.0000</td><td>0.0000</td><td>0.00000</td></tr><tr><th>other vehicle</th><td>ir_nano</td><td>1144</td><td>63</td><td>0.0425</td><td>0.0159</td><td>0.0193</td><td>0.00637</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(16, 5))
plt.title(&#x27;Average Precision by Class &amp; Instances&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=ir_nano_df.reset_index(),
    x=&#x27;Instances&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;index&#x27;,
    palette=&#x27;nipy_spectral&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_14_2-28221bf851c599903186f00281bb9df1.png" width="1496" height="479"></p>
<h3 id="yolov8s--rgb-dataset-1">YOLOv8s &amp; RGB Dataset</h3>
<pre><code class="language-python">ir_small = [
    [&#x27;ir_small&#x27;, 1144, 16688, 0.555, 0.322, 0.358, 0.2],
    [&#x27;ir_small&#x27;, 1144, 4470, 0.691, 0.632, 0.687, 0.356],
    [&#x27;ir_small&#x27;, 1144, 170, 0.369, 0.353, 0.309, 0.174],
    [&#x27;ir_small&#x27;, 1144, 7128, 0.743, 0.725, 0.781, 0.527],
    [&#x27;ir_small&#x27;, 1144, 55, 0.593, 0.504, 0.551, 0.251],
    [&#x27;ir_small&#x27;, 1144, 179, 0.683, 0.419, 0.527, 0.361],
    [&#x27;ir_small&#x27;, 1144, 2048, 0.608, 0.386, 0.418, 0.178],
    [&#x27;ir_small&#x27;, 1144, 94, 0.695, 0.149, 0.274, 0.148],
    [&#x27;ir_small&#x27;, 1144, 2472, 0.614, 0.313, 0.362, 0.195],
    [&#x27;ir_small&#x27;, 1144, 3, 0, 0, 0, 0],
    [&#x27;ir_small&#x27;, 1144, 6, 1, 0, 0, 0],
    [&#x27;ir_small&#x27;, 1144, 63, 0.112, 0.0635, 0.0254, 0.0151]
]
</code></pre>
<pre><code class="language-python">ir_small_df = pd.DataFrame(ir_small, data_index, data_columns)
ir_small_df
</code></pre>
<table><thead><tr><th></th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>all</th><td>ir_small</td><td>1144</td><td>16688</td><td>0.555</td><td>0.3220</td><td>0.3580</td><td>0.2000</td></tr><tr><th>person</th><td>ir_small</td><td>1144</td><td>4470</td><td>0.691</td><td>0.6320</td><td>0.6870</td><td>0.3560</td></tr><tr><th>bike</th><td>ir_small</td><td>1144</td><td>170</td><td>0.369</td><td>0.3530</td><td>0.3090</td><td>0.1740</td></tr><tr><th>car</th><td>ir_small</td><td>1144</td><td>7128</td><td>0.743</td><td>0.7250</td><td>0.7810</td><td>0.5270</td></tr><tr><th>motor</th><td>ir_small</td><td>1144</td><td>55</td><td>0.593</td><td>0.5040</td><td>0.5510</td><td>0.2510</td></tr><tr><th>train</th><td>ir_small</td><td>1144</td><td>179</td><td>0.683</td><td>0.4190</td><td>0.5270</td><td>0.3610</td></tr><tr><th>truck</th><td>ir_small</td><td>1144</td><td>2048</td><td>0.608</td><td>0.3860</td><td>0.4180</td><td>0.1780</td></tr><tr><th>hydrant</th><td>ir_small</td><td>1144</td><td>94</td><td>0.695</td><td>0.1490</td><td>0.2740</td><td>0.1480</td></tr><tr><th>sign</th><td>ir_small</td><td>1144</td><td>2472</td><td>0.614</td><td>0.3130</td><td>0.3620</td><td>0.1950</td></tr><tr><th>skateboard</th><td>ir_small</td><td>1144</td><td>3</td><td>0.000</td><td>0.0000</td><td>0.0000</td><td>0.0000</td></tr><tr><th>stroller</th><td>ir_small</td><td>1144</td><td>6</td><td>1.000</td><td>0.0000</td><td>0.0000</td><td>0.0000</td></tr><tr><th>other vehicle</th><td>ir_small</td><td>1144</td><td>63</td><td>0.112</td><td>0.0635</td><td>0.0254</td><td>0.0151</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(16, 5))
plt.title(&#x27;Average Precision by Class &amp; Instances&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=ir_small_df.reset_index(),
    x=&#x27;Instances&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;index&#x27;,
    palette=&#x27;nipy_spectral&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_18_2-ecdcc39cee71e1d5e0dd396f6c16b86d.png" width="1496" height="479"></p>
<h3 id="yolov8n--combined-dataset">YOLOv8n &amp; Combined Dataset</h3>
<pre><code class="language-python">combined_nano = [
    [&#x27;combined_nano&#x27;, 2229, 33597, 0.519, 0.242, 0.272, 0.147],
    [&#x27;combined_nano&#x27;, 2229, 7693, 0.623, 0.482, 0.527, 0.253],
    [&#x27;combined_nano&#x27;, 2229, 363, 0.281, 0.267, 0.239, 0.13],
    [&#x27;combined_nano&#x27;, 2229, 14413, 0.686, 0.646, 0.697, 0.461],
    [&#x27;combined_nano&#x27;, 2229, 132, 0.607, 0.364, 0.417, 0.193],
    [&#x27;combined_nano&#x27;, 2229, 362, 0.666, 0.348, 0.424, 0.279],
    [&#x27;combined_nano&#x27;, 2229, 4238, 0.493, 0.237, 0.256, 0.096],
    [&#x27;combined_nano&#x27;, 2229, 220, 0.685, 0.0955, 0.162, 0.0676],
    [&#x27;combined_nano&#x27;, 2229, 6053, 0.588, 0.205, 0.251, 0.131],
    [&#x27;combined_nano&#x27;, 2229, 7, 0, 0, 0, 0],
    [&#x27;combined_nano&#x27;, 2229, 13, 1, 0, 0, 0],
    [&#x27;combined_nano&#x27;, 2229, 103, 0.0795, 0.0194, 0.023, 0.00967]
]
</code></pre>
<pre><code class="language-python">combined_nano_df = pd.DataFrame(combined_nano, data_index, data_columns)
combined_nano_df
</code></pre>
<table><thead><tr><th></th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>all</th><td>combined_nano</td><td>2229</td><td>33597</td><td>0.5190</td><td>0.2420</td><td>0.272</td><td>0.14700</td></tr><tr><th>person</th><td>combined_nano</td><td>2229</td><td>7693</td><td>0.6230</td><td>0.4820</td><td>0.527</td><td>0.25300</td></tr><tr><th>bike</th><td>combined_nano</td><td>2229</td><td>363</td><td>0.2810</td><td>0.2670</td><td>0.239</td><td>0.13000</td></tr><tr><th>car</th><td>combined_nano</td><td>2229</td><td>14413</td><td>0.6860</td><td>0.6460</td><td>0.697</td><td>0.46100</td></tr><tr><th>motor</th><td>combined_nano</td><td>2229</td><td>132</td><td>0.6070</td><td>0.3640</td><td>0.417</td><td>0.19300</td></tr><tr><th>train</th><td>combined_nano</td><td>2229</td><td>362</td><td>0.6660</td><td>0.3480</td><td>0.424</td><td>0.27900</td></tr><tr><th>truck</th><td>combined_nano</td><td>2229</td><td>4238</td><td>0.4930</td><td>0.2370</td><td>0.256</td><td>0.09600</td></tr><tr><th>hydrant</th><td>combined_nano</td><td>2229</td><td>220</td><td>0.6850</td><td>0.0955</td><td>0.162</td><td>0.06760</td></tr><tr><th>sign</th><td>combined_nano</td><td>2229</td><td>6053</td><td>0.5880</td><td>0.2050</td><td>0.251</td><td>0.13100</td></tr><tr><th>skateboard</th><td>combined_nano</td><td>2229</td><td>7</td><td>0.0000</td><td>0.0000</td><td>0.000</td><td>0.00000</td></tr><tr><th>stroller</th><td>combined_nano</td><td>2229</td><td>13</td><td>1.0000</td><td>0.0000</td><td>0.000</td><td>0.00000</td></tr><tr><th>other vehicle</th><td>combined_nano</td><td>2229</td><td>103</td><td>0.0795</td><td>0.0194</td><td>0.023</td><td>0.00967</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(16, 5))
plt.title(&#x27;Average Precision by Class &amp; Instances&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=combined_nano_df.reset_index(),
    x=&#x27;Instances&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;index&#x27;,
    palette=&#x27;nipy_spectral&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_22_2-f6232706f61634b580200645afd51bb2.png" width="1496" height="479"></p>
<h3 id="yolov8s--combined-dataset">YOLOv8s &amp; Combined Dataset</h3>
<pre><code class="language-python">combined_small = [
    [&#x27;combined_small&#x27;, 2229, 33597, 0.651, 0.324, 0.359, 0.204],
    [&#x27;combined_small&#x27;, 2229, 7693, 0.687, 0.569, 0.63, 0.326],
    [&#x27;combined_small&#x27;, 2229, 363, 0.346, 0.383, 0.351, 0.198],
    [&#x27;combined_small&#x27;, 2229, 14413, 0.734, 0.713, 0.764, 0.529],
    [&#x27;combined_small&#x27;, 2229, 132, 0.633, 0.439, 0.514, 0.267],
    [&#x27;combined_small&#x27;, 2229, 362, 0.707, 0.481, 0.556, 0.384],
    [&#x27;combined_small&#x27;, 2229, 4238, 0.59, 0.391, 0.407, 0.167],
    [&#x27;combined_small&#x27;, 2229, 220, 0.697, 0.178, 0.266, 0.122],
    [&#x27;combined_small&#x27;, 2229, 6053, 0.617, 0.329, 0.371, 0.205],
    [&#x27;combined_small&#x27;, 2229, 7, 1, 0, 0, 0],
    [&#x27;combined_small&#x27;, 2229, 13, 1, 0, 0.0323, 0.024],
    [&#x27;combined_small&#x27;, 2229, 103, 0.148, 0.0777, 0.0618, 0.0193]
]
</code></pre>
<pre><code class="language-python">combined_small_df = pd.DataFrame(combined_small, data_index, data_columns)
combined_small_df
</code></pre>
<table><thead><tr><th></th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>all</th><td>combined_small</td><td>2229</td><td>33597</td><td>0.651</td><td>0.3240</td><td>0.3590</td><td>0.2040</td></tr><tr><th>person</th><td>combined_small</td><td>2229</td><td>7693</td><td>0.687</td><td>0.5690</td><td>0.6300</td><td>0.3260</td></tr><tr><th>bike</th><td>combined_small</td><td>2229</td><td>363</td><td>0.346</td><td>0.3830</td><td>0.3510</td><td>0.1980</td></tr><tr><th>car</th><td>combined_small</td><td>2229</td><td>14413</td><td>0.734</td><td>0.7130</td><td>0.7640</td><td>0.5290</td></tr><tr><th>motor</th><td>combined_small</td><td>2229</td><td>132</td><td>0.633</td><td>0.4390</td><td>0.5140</td><td>0.2670</td></tr><tr><th>train</th><td>combined_small</td><td>2229</td><td>362</td><td>0.707</td><td>0.4810</td><td>0.5560</td><td>0.3840</td></tr><tr><th>truck</th><td>combined_small</td><td>2229</td><td>4238</td><td>0.590</td><td>0.3910</td><td>0.4070</td><td>0.1670</td></tr><tr><th>hydrant</th><td>combined_small</td><td>2229</td><td>220</td><td>0.697</td><td>0.1780</td><td>0.2660</td><td>0.1220</td></tr><tr><th>sign</th><td>combined_small</td><td>2229</td><td>6053</td><td>0.617</td><td>0.3290</td><td>0.3710</td><td>0.2050</td></tr><tr><th>skateboard</th><td>combined_small</td><td>2229</td><td>7</td><td>1.000</td><td>0.0000</td><td>0.0000</td><td>0.0000</td></tr><tr><th>stroller</th><td>combined_small</td><td>2229</td><td>13</td><td>1.000</td><td>0.0000</td><td>0.0323</td><td>0.0240</td></tr><tr><th>other vehicle</th><td>combined_small</td><td>2229</td><td>103</td><td>0.148</td><td>0.0777</td><td>0.0618</td><td>0.0193</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(16, 5))
plt.title(&#x27;Average Precision by Class &amp; Instances&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=combined_small_df.reset_index(),
    x=&#x27;Instances&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;index&#x27;,
    palette=&#x27;nipy_spectral&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_26_2-2053b766a5d9dae785d58237ba40216e.png" width="1496" height="479"></p>
<h3 id="combining-results">Combining Results</h3>
<pre><code class="language-python">combined_df = pd.concat([rgb_nano_df, rgb_small_df, ir_nano_df, ir_small_df, combined_nano_df, combined_small_df], axis=0)
combined_df = combined_df.reset_index()
</code></pre>
<pre><code class="language-python">plt.figure(figsize=(16, 5))
plt.title(&#x27;Average Precision by Class&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=combined_df.reset_index(),
    x=&#x27;index&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;Model&#x27;,
    palette=&#x27;seismic&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_29_2-3a65b249d1b903a3750bb28b996eec20.png" width="1325" height="479"></p>
<pre><code class="language-python">plt.figure(figsize=(24, 10))

sns.set(style=&#x27;darkgrid&#x27;)

sns.scatterplot(
    data=combined_df.reset_index(),
    x=&#x27;R&#x27;,
    y=&#x27;P&#x27;,
    s=300,
    alpha=0.8,
    hue=&#x27;Model&#x27;,
    palette=&#x27;nipy_spectral&#x27;,
    style=&#x27;index&#x27;
).set_title(&#x27;Precision Recall&#x27;)
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_30_2-63612818c43f62f6fb22db9d6572696c.png" width="1941" height="864"></p>
<pre><code class="language-python">combined_df[combined_df[&#x27;index&#x27;] == &#x27;car&#x27;]
</code></pre>
<table><thead><tr><th></th><th>index</th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>3</th><td>car</td><td>rgb_nano</td><td>1085</td><td>7285</td><td>0.663</td><td>0.574</td><td>0.621</td><td>0.398</td></tr><tr><th>15</th><td>car</td><td>rgb_small</td><td>1085</td><td>7285</td><td>0.722</td><td>0.629</td><td>0.683</td><td>0.454</td></tr><tr><th>27</th><td>car</td><td>ir_nano</td><td>1144</td><td>7128</td><td>0.696</td><td>0.650</td><td>0.711</td><td>0.449</td></tr><tr><th>39</th><td>car</td><td>ir_small</td><td>1144</td><td>7128</td><td>0.743</td><td>0.725</td><td>0.781</td><td>0.527</td></tr><tr><th>51</th><td>car</td><td>combined_nano</td><td>2229</td><td>14413</td><td>0.686</td><td>0.646</td><td>0.697</td><td>0.461</td></tr><tr><th>63</th><td>car</td><td>combined_small</td><td>2229</td><td>14413</td><td>0.734</td><td>0.713</td><td>0.764</td><td>0.529</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(8, 5))
plt.title(&#x27;Average Precision by Class&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=combined_df[combined_df[&#x27;index&#x27;] == &#x27;car&#x27;],
    x=&#x27;index&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;Model&#x27;,
    palette=&#x27;seismic&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_32_2-d0bcdc2a1caf347772c0ef83671fefe3.png" width="893" height="479"></p>
<pre><code class="language-python">combined_df[combined_df[&#x27;index&#x27;] == &#x27;person&#x27;]
</code></pre>
<table><thead><tr><th></th><th>index</th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>1</th><td>person</td><td>rgb_nano</td><td>1085</td><td>3223</td><td>0.505</td><td>0.375</td><td>0.391</td><td>0.167</td></tr><tr><th>13</th><td>person</td><td>rgb_small</td><td>1085</td><td>3223</td><td>0.622</td><td>0.428</td><td>0.481</td><td>0.225</td></tr><tr><th>25</th><td>person</td><td>ir_nano</td><td>1144</td><td>4470</td><td>0.631</td><td>0.556</td><td>0.595</td><td>0.276</td></tr><tr><th>37</th><td>person</td><td>ir_small</td><td>1144</td><td>4470</td><td>0.691</td><td>0.632</td><td>0.687</td><td>0.356</td></tr><tr><th>49</th><td>person</td><td>combined_nano</td><td>2229</td><td>7693</td><td>0.623</td><td>0.482</td><td>0.527</td><td>0.253</td></tr><tr><th>61</th><td>person</td><td>combined_small</td><td>2229</td><td>7693</td><td>0.687</td><td>0.569</td><td>0.630</td><td>0.326</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(8, 5))
plt.title(&#x27;Average Precision by Class&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=combined_df[combined_df[&#x27;index&#x27;] == &#x27;person&#x27;],
    x=&#x27;index&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;Model&#x27;,
    palette=&#x27;seismic&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_34_2-12faf5d89984aa436eea1d530626a719.png" width="893" height="479"></p>
<pre><code class="language-python">combined_df[combined_df[&#x27;index&#x27;] == &#x27;motor&#x27;]
</code></pre>
<table><thead><tr><th></th><th>index</th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>4</th><td>motor</td><td>rgb_nano</td><td>1085</td><td>77</td><td>0.419</td><td>0.260</td><td>0.300</td><td>0.166</td></tr><tr><th>16</th><td>motor</td><td>rgb_small</td><td>1085</td><td>77</td><td>0.563</td><td>0.338</td><td>0.382</td><td>0.219</td></tr><tr><th>28</th><td>motor</td><td>ir_nano</td><td>1144</td><td>55</td><td>0.570</td><td>0.364</td><td>0.390</td><td>0.189</td></tr><tr><th>40</th><td>motor</td><td>ir_small</td><td>1144</td><td>55</td><td>0.593</td><td>0.504</td><td>0.551</td><td>0.251</td></tr><tr><th>52</th><td>motor</td><td>combined_nano</td><td>2229</td><td>132</td><td>0.607</td><td>0.364</td><td>0.417</td><td>0.193</td></tr><tr><th>64</th><td>motor</td><td>combined_small</td><td>2229</td><td>132</td><td>0.633</td><td>0.439</td><td>0.514</td><td>0.267</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(8, 5))
plt.title(&#x27;Average Precision by Class&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=combined_df[combined_df[&#x27;index&#x27;] == &#x27;motor&#x27;],
    x=&#x27;index&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;Model&#x27;,
    palette=&#x27;seismic&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_36_2-2c642b8ef818c5d36896dd237b567d8d.png" width="893" height="479"></p>
<pre><code class="language-python">combined_df[combined_df[&#x27;index&#x27;] == &#x27;bike&#x27;]
</code></pre>
<table><thead><tr><th></th><th>index</th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>2</th><td>bike</td><td>rgb_nano</td><td>1085</td><td>193</td><td>0.200</td><td>0.197</td><td>0.102</td><td>0.044</td></tr><tr><th>14</th><td>bike</td><td>rgb_small</td><td>1085</td><td>193</td><td>0.247</td><td>0.321</td><td>0.239</td><td>0.121</td></tr><tr><th>26</th><td>bike</td><td>ir_nano</td><td>1144</td><td>170</td><td>0.288</td><td>0.253</td><td>0.222</td><td>0.111</td></tr><tr><th>38</th><td>bike</td><td>ir_small</td><td>1144</td><td>170</td><td>0.369</td><td>0.353</td><td>0.309</td><td>0.174</td></tr><tr><th>50</th><td>bike</td><td>combined_nano</td><td>2229</td><td>363</td><td>0.281</td><td>0.267</td><td>0.239</td><td>0.130</td></tr><tr><th>62</th><td>bike</td><td>combined_small</td><td>2229</td><td>363</td><td>0.346</td><td>0.383</td><td>0.351</td><td>0.198</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(8, 5))
plt.title(&#x27;Average Precision by Class&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=combined_df[combined_df[&#x27;index&#x27;] == &#x27;bike&#x27;],
    x=&#x27;index&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;Model&#x27;,
    palette=&#x27;seismic&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_38_2-e676685e058d3dd23571d5b0289d1112.png" width="903" height="479"></p>
<pre><code class="language-python">combined_df[combined_df[&#x27;index&#x27;] == &#x27;truck&#x27;]
</code></pre>
<table><thead><tr><th></th><th>index</th><th>Model</th><th>Images</th><th>Instances</th><th>P</th><th>R</th><th>mAP50</th><th>mAP50-95</th></tr></thead><tbody><tr><th>6</th><td>truck</td><td>rgb_nano</td><td>1085</td><td>2190</td><td>0.458</td><td>0.197</td><td>0.205</td><td>0.0686</td></tr><tr><th>18</th><td>truck</td><td>rgb_small</td><td>1085</td><td>2190</td><td>0.600</td><td>0.315</td><td>0.333</td><td>0.1200</td></tr><tr><th>30</th><td>truck</td><td>ir_nano</td><td>1144</td><td>2048</td><td>0.462</td><td>0.256</td><td>0.271</td><td>0.1040</td></tr><tr><th>42</th><td>truck</td><td>ir_small</td><td>1144</td><td>2048</td><td>0.608</td><td>0.386</td><td>0.418</td><td>0.1780</td></tr><tr><th>54</th><td>truck</td><td>combined_nano</td><td>2229</td><td>4238</td><td>0.493</td><td>0.237</td><td>0.256</td><td>0.0960</td></tr><tr><th>66</th><td>truck</td><td>combined_small</td><td>2229</td><td>4238</td><td>0.590</td><td>0.391</td><td>0.407</td><td>0.1670</td></tr></tbody></table>
<pre><code class="language-python">plt.figure(figsize=(8, 5))
plt.title(&#x27;Average Precision by Class&#x27;)
sns.set(style=&#x27;darkgrid&#x27;)
sns.barplot(
    data=combined_df[combined_df[&#x27;index&#x27;] == &#x27;truck&#x27;],
    x=&#x27;index&#x27;,
    y=&#x27;mAP50&#x27;,
    errorbar=&#x27;sd&#x27;,
    hue=&#x27;Model&#x27;,
    palette=&#x27;seismic&#x27;
)
plt.legend(bbox_to_anchor=(1.01,1.01))
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_40_2-5388475efa60719c9ca27031043762ba.png" width="903" height="479"></p>
<h2 id="evaluate-bounding-boxes">Evaluate Bounding Boxes</h2>
<pre><code class="language-python"># read images
images = glob(&#x27;./datasets/images_combined_val/images/\*.jpg&#x27;)
print(len(images))
</code></pre>
<p>2229</p>
<pre><code class="language-python"># select image
img = cv.imread(images[0])
height, width, _ = img.shape

print(images[0][38:-4], height, width)
</code></pre>
<p>video-57kWWRyeqqHs3Byei-frame-000816-b6tuLjNco8MfoBs3d 512 640</p>
<pre><code class="language-python"># select label file
path = &#x27;./datasets/images_combined_val/labels/&#x27; + images[0][38:-4] + &#x27;.txt&#x27;
labels = open(path, &#x27;r&#x27;)

data = labels.readlines()
labels.close()

print(data)
</code></pre>
<p>[&#x27;9 0.696875 0.375000 0.025000 0.039062\n&#x27;, &#x27;9 0.696094 0.314453 0.032813 0.082031\n&#x27;, &#x27;9 0.168750 0.395508 0.040625 0.013672\n&#x27;, &#x27;0 0.464063 0.457031 0.009375 0.027344\n&#x27;, &#x27;0 0.004688 0.491211 0.009375 0.041016\n&#x27;, &#x27;0 0.165625 0.489258 0.009375 0.033203\n&#x27;, &#x27;1 0.316406 0.500000 0.014063 0.035156\n&#x27;, &#x27;2 0.600781 0.511719 0.117188 0.113281\n&#x27;, &#x27;2 0.524219 0.481445 0.060938 0.064453\n&#x27;, &#x27;2 0.481250 0.469727 0.037500 0.033203\n&#x27;, &#x27;2 0.426563 0.454102 0.015625 0.017578\n&#x27;, &#x27;2 0.412500 0.463867 0.015625 0.025391\n&#x27;, &#x27;2 0.376563 0.474609 0.018750 0.023438\n&#x27;, &#x27;2 0.364063 0.477539 0.021875 0.033203\n&#x27;, &#x27;2 0.342188 0.477539 0.034375 0.041016\n&#x27;, &#x27;0 0.315625 0.483398 0.021875 0.044922\n&#x27;, &#x27;8 0.105469 0.500977 0.007812 0.021484\n&#x27;]</p>
<pre><code class="language-python"># create one colour for every COCO class
colours = []
number_colours=80

for j in range(number_colours):
    colour = np.random.randint(0,255),np.random.randint(0,255),np.random.randint(0,255)
    colours.append(colour)

print(len(colours),colours)
</code></pre>
<p>80 [(129, 83, 161), (220, 116, 220), (47, 113, 141), (185, 137, 77), (212, 208, 251), (36, 83, 204), (4, 40, 112), (61, 18, 39), (25, 132, 21), (239, 67, 234), (140, 253, 52), (207, 196, 72), (144, 32, 112), (138, 29, 227), (101, 17, 45), (102, 118, 7), (210, 51, 160), (59, 158, 131), (37, 145, 69), (68, 56, 71), (28, 96, 25), (72, 189, 118), (190, 67, 118), (152, 48, 33), (153, 138, 248), (218, 94, 242), (236, 229, 215), (133, 186, 102), (33, 198, 167), (223, 32, 103), (16, 209, 160), (83, 89, 91), (194, 46, 110), (243, 47, 47), (187, 11, 41), (193, 188, 6), (107, 119, 230), (116, 118, 109), (65, 155, 110), (12, 151, 145), (135, 138, 197), (43, 19, 174), (52, 203, 214), (72, 178, 172), (10, 247, 17), (108, 90, 185), (134, 29, 207), (217, 96, 179), (2, 38, 161), (245, 175, 254), (254, 57, 175), (84, 184, 46), (249, 195, 60), (246, 67, 127), (51, 89, 138), (12, 162, 182), (176, 89, 187), (165, 40, 110), (141, 76, 226), (245, 187, 119), (47, 237, 138), (173, 176, 50), (49, 101, 36), (171, 235, 78), (125, 105, 250), (123, 83, 13), (18, 47, 133), (196, 102, 109), (234, 204, 106), (55, 110, 131), (116, 209, 240), (147, 203, 253), (115, 246, 60), (17, 245, 112), (50, 250, 19), (254, 233, 18), (122, 211, 221), (229, 12, 236), (86, 169, 186), (13, 189, 38)]</p>
<h3 id="show-labels">Show Labels</h3>
<pre><code class="language-python">index = 0

for line in data:

    # Split string to float
    _, x, y, w, h = map(float, line.split(&#x27; &#x27;))
    
    l = int((x - w / 2) * width)
    r = int((x + w / 2) * width)
    t = int((y - h / 2) * height)
    b = int((y + h / 2) * height)
    
    if l &lt; 0:
        l = 0
    if r &gt; width - 1:
        r = width - 1
    if t &lt; 0:
        t = 0
    if b &gt; height - 1:
        b = height - 1

    image = cv.rectangle(img, (l, t), (r, b), colours[index], thickness=2)
    index += 1

plt.title(&#x27;Image with original Labels&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(image)
plt.show()
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_47_0-c0a83047cb90928efb8dc283e804a5e6.png" width="481" height="411"></p>
<h3 id="show-predictions">Show Predictions</h3>
<pre><code class="language-python"># Load the best model
backbone_combined_small = YOLO(&#x27;./runs/detect/backbone_combined_small.torchscript&#x27;)
</code></pre>
<pre><code class="language-python"># Run batched inference on a list of images
results = backbone_combined_small(img)  # return a list of Results objects

for r in results:
    im_array = r.plot()  # plot a BGR numpy array of predictions
    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image
    im.show()  # show image
    im.save(&#x27;results.jpg&#x27;)  # save image
</code></pre>
<p>0: 640x640 5 persons, 1 bike, 11 cars, 3 signs, 16.8ms
Speed: 8.9ms preprocess, 16.8ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)</p>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_50_1-9cce9463bb811c8453377702306e0fd7.png" width="640" height="512"></p>
<h3 id="show-labels-1">Show Labels</h3>
<pre><code class="language-python"># get another image
img = cv.imread(images[1337])
height, width, _ = img.shape

# get labels
path = &#x27;./datasets/images_combined_val/labels/&#x27; + images[1337][38:-4] + &#x27;.txt&#x27;
labels = open(path, &#x27;r&#x27;)

data = labels.readlines()
labels.close()
</code></pre>
<pre><code class="language-python">index = 0

for line in data:

    # Split string to float
    _, x, y, w, h = map(float, line.split(&#x27; &#x27;))
    
    l = int((x - w / 2) * width)
    r = int((x + w / 2) * width)
    t = int((y - h / 2) * height)
    b = int((y + h / 2) * height)
    
    if l &lt; 0:
        l = 0
    if r &gt; width - 1:
        r = width - 1
    if t &lt; 0:
        t = 0
    if b &gt; height - 1:
        b = height - 1

    image = cv.rectangle(img, (l, t), (r, b), colours[index], thickness=2)
    index += 1

plt.title(&#x27;Image with original Labels&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(image)
plt.show()
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_53_0-79b8a8889221f283c30381b798ae4c5a.png" width="435" height="411"></p>
<h3 id="show-predictions-1">Show Predictions</h3>
<pre><code class="language-python"># Run batched inference on a list of images
results = backbone_combined_small(img)  # return a list of Results objects

for r in results:
    im_array = r.plot()  # plot a BGR numpy array of predictions
    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image
    im.show()  # show image
    im.save(&#x27;results.jpg&#x27;)  # save image
</code></pre>
<p>0: 640x640 2 persons, 1 car, 7 trucks, 2 signs, 17.7ms
Speed: 12.7ms preprocess, 17.7ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)</p>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_55_1-1069c6045570d2e9a9b0415dd4f08f43.png" width="1800" height="1600"></p>
<h3 id="show-labels-2">Show Labels</h3>
<pre><code class="language-python"># get another image
img = cv.imread(images[666])
height, width, _ = img.shape

# get labels
path = &#x27;./datasets/images_combined_val/labels/&#x27; + images[666][38:-4] + &#x27;.txt&#x27;
labels = open(path, &#x27;r&#x27;)

data = labels.readlines()
labels.close()
</code></pre>
<pre><code class="language-python">index = 0

for line in data:

    # Split string to float
    _, x, y, w, h = map(float, line.split(&#x27; &#x27;))
    
    l = int((x - w / 2) * width)
    r = int((x + w / 2) * width)
    t = int((y - h / 2) * height)
    b = int((y + h / 2) * height)
    
    if l &lt; 0:
        l = 0
    if r &gt; width - 1:
        r = width - 1
    if t &lt; 0:
        t = 0
    if b &gt; height - 1:
        b = height - 1

    image = cv.rectangle(img, (l, t), (r, b), colours[index], thickness=2)
    index += 1

plt.title(&#x27;Image with original Labels&#x27;)
plt.axis(&#x27;off&#x27;)
plt.imshow(image)
plt.show()
</code></pre>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_58_0-198e50df39cd289729136a12ec07e51f.png" width="435" height="411"></p>
<h3 id="show-predictions-2">Show Predictions</h3>
<pre><code class="language-python"># Run batched inference on a list of images
results = backbone_combined_small(img)  # return a list of Results objects

for r in results:
    im_array = r.plot()  # plot a BGR numpy array of predictions
    im = Image.fromarray(im_array[..., ::-1])  # RGB PIL image
    im.show()  # show image
    im.save(&#x27;results.jpg&#x27;)  # save image
</code></pre>
<p>0: 640x640 2 persons, 3 bikes, 7 cars, 1 sign, 16.9ms
Speed: 13.9ms preprocess, 16.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 640)</p>
<p><img alt="Training the YOLOv8 Model (RGB)" src="/assets/images/output_60_1-c8b7f1f7075ac8f7f254ea2c858006e6.png" width="1800" height="1600"></p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_aHIs padding--none margin-left--sm"><li class="tag_nwHU"><a class="tag_QDqo tagRegular_RTiO" href="/docs/tags/python">Python</a></li><li class="tag_nwHU"><a class="tag_QDqo tagRegular_RTiO" href="/docs/tags/machine-learning">Machine Learning</a></li><li class="tag_nwHU"><a class="tag_QDqo tagRegular_RTiO" href="/docs/tags/py-torch">PyTorch</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_NulP" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated__GQF"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/IoT-and-Machine-Learning/ML/2023-09-19--cvat-computer-vision-annotation-tool/2023-09-19"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Computer Vision Annotation Tool (CVAT) Introduction</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/2023-09-15"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">YOLOv8 License Plate Detection</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_IS5x thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#dataset" class="table-of-contents__link toc-highlight">Dataset</a><ul><li><a href="#dataset-exploration" class="table-of-contents__link toc-highlight">Dataset Exploration</a></li><li><a href="#label-conversion-json2yolo" class="table-of-contents__link toc-highlight">Label Conversion JSON2YOLO</a></li><li><a href="#dataset-configuration" class="table-of-contents__link toc-highlight">Dataset Configuration</a></li></ul></li><li><a href="#training-the-yolov8-model-rgb--ir" class="table-of-contents__link toc-highlight">Training the YOLOv8 Model (RGB / IR)</a><ul><li><a href="#yolov8-nano-rgb" class="table-of-contents__link toc-highlight">YOLOv8 Nano (RGB)</a></li><li><a href="#yolov8-small-rgb" class="table-of-contents__link toc-highlight">YOLOv8 Small (RGB)</a></li><li><a href="#yolov8-nano-ir" class="table-of-contents__link toc-highlight">YOLOv8 Nano (IR)</a></li><li><a href="#yolov8-small-ir" class="table-of-contents__link toc-highlight">YOLOv8 Small (IR)</a></li><li><a href="#model-training-3" class="table-of-contents__link toc-highlight">Model Training</a></li></ul></li><li><a href="#training-the-yolov8-mixed-model-rgb--ir" class="table-of-contents__link toc-highlight">Training the YOLOv8 Mixed Model (RGB + IR)</a><ul><li><a href="#yolov8-nano-rgbir" class="table-of-contents__link toc-highlight">YOLOv8 Nano (RGB+IR)</a></li><li><a href="#yolov8-small-rgb--ir" class="table-of-contents__link toc-highlight">YOLOv8 Small (RGB + IR)</a></li></ul></li><li><a href="#model-evaluation-6" class="table-of-contents__link toc-highlight">Model Evaluation</a><ul><li><a href="#yolov8n--rgb-dataset" class="table-of-contents__link toc-highlight">YOLOv8n &amp; RGB Dataset</a></li><li><a href="#yolov8s--rgb-dataset" class="table-of-contents__link toc-highlight">YOLOv8s &amp; RGB Dataset</a></li><li><a href="#yolov8n--ir-dataset" class="table-of-contents__link toc-highlight">YOLOv8n &amp; IR Dataset</a></li><li><a href="#yolov8s--rgb-dataset-1" class="table-of-contents__link toc-highlight">YOLOv8s &amp; RGB Dataset</a></li><li><a href="#yolov8n--combined-dataset" class="table-of-contents__link toc-highlight">YOLOv8n &amp; Combined Dataset</a></li><li><a href="#yolov8s--combined-dataset" class="table-of-contents__link toc-highlight">YOLOv8s &amp; Combined Dataset</a></li><li><a href="#combining-results" class="table-of-contents__link toc-highlight">Combining Results</a></li></ul></li><li><a href="#evaluate-bounding-boxes" class="table-of-contents__link toc-highlight">Evaluate Bounding Boxes</a><ul><li><a href="#show-labels" class="table-of-contents__link toc-highlight">Show Labels</a></li><li><a href="#show-predictions" class="table-of-contents__link toc-highlight">Show Predictions</a></li><li><a href="#show-labels-1" class="table-of-contents__link toc-highlight">Show Labels</a></li><li><a href="#show-predictions-1" class="table-of-contents__link toc-highlight">Show Predictions</a></li><li><a href="#show-labels-2" class="table-of-contents__link toc-highlight">Show Labels</a></li><li><a href="#show-predictions-2" class="table-of-contents__link toc-highlight">Show Predictions</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Research</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Notebook</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tags">Tags</a></li><li class="footer__item"><a class="footer__link-item" href="/Curriculum-Vitae">CV</a></li></ul></div><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/mike-polinowski-6396ba121/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_T11m"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/MikePolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_T11m"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.flickr.com/people/149680084@N06/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Flickr<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_T11m"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_T11m"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2023 Mike Polinowski, INSTAR Deutschland GmbH, Shenzhen - China.</div></div></div></footer></div>
</body>
</html>