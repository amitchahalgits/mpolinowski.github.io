<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/index" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.0">
<title data-rh="true">Deep Audio | Mike Polinowski</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Deep Audio | Mike Polinowski"><meta data-rh="true" name="description" content="Deep Audio Classifier with Tensorflow"><meta data-rh="true" property="og:description" content="Deep Audio Classifier with Tensorflow"><link data-rh="true" rel="icon" href="/img/icons/favicon-32x32.png"><link data-rh="true" rel="canonical" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01" hreflang="en"><link data-rh="true" rel="alternate" href="https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Mike Polinowski RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Mike Polinowski Atom Feed">




<link rel="icon" href="/img/angular_momentum.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37,194,160)">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#000">
<link rel="apple-touch-icon" href="/img/angular_momentum.png">
<link rel="mask-icon" href="/img/angular_momentum.png" color="rgb(33,33,33)">
<meta name="msapplication-TileImage" content="/img/angular_momentum.png">
<meta name="msapplication-TileColor" content="#000">

<link rel="preconnect" href="https://www.google-analytics.com">
<link rel="preconnect" href="https://www.googletagmanager.com">
<script async src="https://www.googletagmanager.com/gtag/js?id=G-P74BDWF0C6"></script>
<script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-P74BDWF0C6",{})</script><link rel="stylesheet" href="/assets/css/styles.08c8c484.css">
<script src="/assets/js/runtime~main.839e810d.js" defer="defer"></script>
<script src="/assets/js/main.9aa3fe7c.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/angular_momentum.png" alt="Mike Polinowski :: Dev Notebook" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">Mike Polinowski</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/docs/tags">Tags</a><a class="navbar__item navbar__link" href="/Search">Search</a><a href="https://mpolinowski.github.io/Personal" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">About<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Introduction</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/development">Development</a><button aria-label="Expand sidebar category &#x27;Development&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/devops">DevOps</a><button aria-label="Expand sidebar category &#x27;DevOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/docs/category/machine-learning-ai-and-computer-vision">Machine Learning, AI and Computer Vision</a><button aria-label="Collapse sidebar category &#x27;Machine Learning, AI and Computer Vision&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/docs/category/machine-learning">Machine Learning</a><button aria-label="Collapse sidebar category &#x27;Machine Learning&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-10-01--delib-face-detection/2023-10-01">DLIB Face Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-23--yolo8-listen/2023-09-23">Audio Classification with Computer Vision</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/2023-09-21">CVAT Semi-automatic and Automatic Annotation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-19--cvat-computer-vision-annotation-tool/2023-09-19">Computer Vision Annotation Tool (CVAT) Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/2023-09-17">YOLOv8 Nightshift</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/2023-09-15">YOLOv8 License Plate Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-10--model-explainability-shap/2023-09-11">Scikit-Learn ML Model Explainability</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-05--semantic-segmentation-in-opencv/2023-09-05">Using Tensorflow Models in OpenCV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-09-01--yolo-i-know-flowers/2023-09-01">YOLOv8 Image Classifier</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-31--semantic_segmentation_detectron2_openimages_dataset/2023-08-31">Detectron Object Detection with OpenImages Dataset (WIP)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-30--instance_segmentation_detectron2_model_zoo_mask_rcnn/2023-08-30">Instance Segmentation with PyTorch (Mask RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-29--semantic-segmentation-detectron2-model-zoo-faster-rcnn/2023-08-29">Image Segmentation with PyTorch (Faster RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-28--semantic-segmentation-detectron2-model-zoo/2023-08-28">Image Segmentation with PyTorch (RCNN)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-27--image-segmentation-with-pytorch/2023-08-27">Image Segmentation with PyTorch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/2023-08-21">Containerized PyTorch Dev Workflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-13-tensorflow-i-know-flowers-model-eval/2023-08-13">Tensorflow Image Classifier - Model Evaluation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-12-tensorflow-i-know-flowers-xception/2023-08-12">Tensorflow Image Classifier - Xception</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-11-tensorflow-i-know-flowers-vit/2023-08-11">Tensorflow Image Classifier - ViT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-10-tensorflow-i-know-flowers-nasnetmobile/2023-08-10">Tensorflow Image Classifier - NASNetMobile</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-09-tensorflow-i-know-flowers-mobilenetv3small/2023-08-09">Tensorflow Image Classifier - MobileNetV3Small</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-08-tensorflow-i-know-flowers-mobilenetv3large/2023-08-08">Tensorflow Image Classifier - MobileNetV3Large</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-07-tensorflow-i-know-flowers-mobilenetv2/2023-08-07">Tensorflow Image Classifier - MobileNetV2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/2023-08-06">Tensorflow Image Classifier - InceptionV3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-05-tensorflow-i-know-flowers-efficientnetv2s/2023-08-05">Tensorflow Image Classifier - EfficientNetV2S</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-04-tensorflow-i-know-flowers-efficientnetv2b0/2023-08-04">Tensorflow Image Classifier - EfficientNetV2B0</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit/2023-08-03">Tensorflow Image Classifier - Data-efficient Image Transformers</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-02-tensorflow-i-know-flowers-preprocessing/2023-08-02">Tensorflow Image Classifier - Data Pre-processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-08-01-tensorflow-i-know-flowers-intro/2023-08-01">Tensorflow Image Classifier - Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-27-tensorflow-vision-transformer/2023-07-27">Tensorflow VITs</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/2023-07-26">Human Emotion Detection with Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/2023-07-25">Working with ONNX Models</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-21-introduction-to-pytorch-caffe2/2023-07-21">Introduction to Caffe2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-07-02-sql-in-data-science-ml/2023-07-02">SQL in Data Science - Machine Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-30-sql-in-data-science-advanced/2023-06-30">SQL in Data Science - Slightly more Advanced Queries</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-27-sql-in-data-science-basics/2023-06-27">SQL in Data Science - The Basics using Python</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-06-26-autogluon-transit-photometry-dataset/2023-06-26">Detection of Exoplanets using Transit Photometry</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-19-tensorflow-natural-language-processing/2023-04-19">(Re) Introduction to Tensorflow Natural Language Processing</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-16-deep-3d-image-segmentation/2023-04-16">3D Image Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-14-manifold-learning-for-image-segmentation/2023-04-14">Dimensionality Reduction for Image Segmentation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-fisher-discriminant-analysis/2023-04-13">Fisher Linear Discriminant Analysis (LDA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-isometric-mapping/2023-04-13">Isometric Mapping (ISOMAP)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-13-multi-dimensional-scaling/2023-04-13">Multidimensional Scaling (MDS)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-12-tstochastic-neighbor-embedding/2023-04-12">tStochastic Neighbor Embedding (t-SNE)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-11-locally-linear-embedding/2023-04-11">Locally Linear Embedding (LLE)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-04-09-principal-component-analysis/2023-04-09">Principal Component Analysis (PCA)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-generative-adversial-networks/2023-03-26">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24">Tensorflow 2 - Unsupervised Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06">Tensorflow 2 - Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05">Tensorflow 2 - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03">Tensorflow 2 - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02">Tensorflow 2 - Neural Network Classifications</a><button aria-label="Expand sidebar category &#x27;Tensorflow 2 - Neural Network Classifications&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28">Tensorflow 2 - Neural Network Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27">Tensorflow 2 - Neural Network Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23">Tensorflow 2 - Neural Network Regression</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22">Tensorflow 2 - An (Re)Introduction 2023 (3)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21">Tensorflow 2 - An (Re)Introduction 2023 (2)</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19">Tensorflow 2 - An (Re)Introduction 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-vgg16/2023-02-18">Keras for Tensorflow - VGG16 Network Architecture</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-rnn/2023-02-18">Keras for Tensorflow - Recurrent Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/2023-02-17">Keras for Tensorflow - Convolutional Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-16-keras-introduction-ann/2023-02-16">Keras for Tensorflow - Artificial Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-15-as-one-yolo-object-tracking/2023-02-15">YOLOv8 with AS-One</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-02-14-keras-introduction/2023-02-14">Keras for Tensorflow - An (Re)Introduction 2023</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-30-predicting-wine-quality/2023-01-30">SciKit Wine Quality</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-28-opencv-coin-counter/2023-01-28">OpenCV Count My Money</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-14-yolov7_to_tensorflow/2023-01-14">YOLOv7 to Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-13-yolov7_data_conversion/2023-01-13">YOLOv7 Label Conversion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-10-yolov7_custom_data/2023-01-10">YOLOv7 Training with Custom Data</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-08-depth-vision-midas/2023-01-08">MiDaS Depth Vision</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2023-01-05-yolov7/2023-01-05">YOLOv7 Introduction</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-31-tf-rnn-text-generation/2022-12-31">Recurrent Neural Networks</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/2022-12-28">Deep Convolutional Generative Adversarial Network</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21">Tensorflow Downsampling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-deepdream/2022-12-21">Tensorflow Deep Dream</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-20-tf-representation/2022-12-19">Tensorflow Representation Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-19-tf-hub/2022-12-19">Tensorflow Hub</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/2022-12-18">Tensorflow Transfer Learning</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-16-tf-cifar/2022-12-16">Tensorflow Image Classification</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part6/2022-12-12">Breast Histopathology Image Segmentation Part 6</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-12-tf-breast-cancer-classification-part5/2022-12-12">Breast Histopathology Image Segmentation Part 5</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part4/2022-12-11">Breast Histopathology Image Segmentation Part 4</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part3/2022-12-11">Breast Histopathology Image Segmentation Part 3</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-11-tf-breast-cancer-classification-part2/2022-12-11">Breast Histopathology Image Segmentation Part 2</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/2022-12-10">Breast Histopathology Image Segmentation Part 1</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27">Deep Docker on Arch</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/2022-04-04">Face Restoration with GFPGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-03-pytorch-real-super-resolution/2022-04-03">Super Resolution with Real-ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-02-pytorch-super-resolution/2022-04-02">Super Resolution with ESRGAN</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01">Deep Audio</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20">Yolo App - YOLOv5 Data Preparation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19">Yolo App - Flask Web Application</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18">Yolo App - Tesseract Optical Character Recognition</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-17--yolo-app-prediction-pipeline/2022-02-17">Yolo App - Pipeline Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16">Yolo App - Train a Model with Tensorflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15">Yolo App - Data Collection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-10--opencv-optical-flow-tracking/2021-12-10">OpenCV Optical Flow Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-09--opencv-camshift-tracking/2021-12-09">OpenCV CAMshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-08--opencv-meanshift-tracking/2021-12-08">OpenCV Meanshift Algorithm for Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-07--opencv-detection-and-tracking/2021-12-07">OpenCV Object Detection and Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-06--opencv-object-tracking/2021-12-06">OpenCV Object Tracking</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-05--opencv-face-detection/2021-12-05">OpenCV Face Detection and Privacy</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/2021-12-04">OpenCV Image Objects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-03--opencv-image-operations/2021-12-03">OpenCV Image Operations</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-02--opencv-with-videos/2021-12-02">OpenCV, Streams and Video Files</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-12-01--opencv-with-images/2021-12-01">OpenCV and Images</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-15--facebook-prophet-introduction/2021-11-15">Introduction into FB Prophet</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-14--tensorflow-model-for-tfjs/2021-11-14">Tensorflow.js React App</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-13--tensorflow-model-zoo/2021-11-13">Tensorflow2 Model Zoo</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-12--tensorflow-crash-course-part-v/2021-11-12">Tensorflow2 Crash Course - Part V</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-11--tensorflow-crash-course-part-iv/2021-11-11">Tensorflow2 Crash Course - Part IV</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-10--tensorflow-crash-course-part-iii/2021-11-10">Tensorflow2 Crash Course - Part III</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-09--tensorflow-crash-course-part-ii/2021-11-09">Tensorflow2 Crash Course - Part II</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-08--tensorflow-crash-course-part-i/2021-11-08">Tensorflow Crash Course - Part I</a><button aria-label="Expand sidebar category &#x27;Tensorflow Crash Course - Part I&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-07--opencv-crash-course-part-ii/2021-11-07">OpenCV Crash Course Part II</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-06--opencv-crash-course-part-i/2021-11-06">OpenCV Crash Course Part I</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-05--license-plates-yolov4-opencv-tesseract/2021-11-05">License Plate Recognition with YOLOv4, OpenCV and Tesseract</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-04--installing-yolov4/2021-11-04">Installing YOLOv4 with Anaconda</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/2021-11-03">Streamlit user interface for openCV/Mediapipe face mesh app</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-02--spacy_ner_predictions/2021-11-02">spaCy NER Predictions</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-11-01--spacy_natural_language_processing/2021-11-01">spaCy NER on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-04-01--introduction-to-keras/2019-04-01">Introduction to Keras</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2021-10-31--tesseract_ocr_arch_linux/2021-10-31">Tesseract OCR on Arch Linux</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2019-03-31--introduction-to-tensorflow-2-beta/2019-03-31">Introduction to TensorFlow 2 Beta</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-3 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/IoT-and-Machine-Learning/ML/2018-01-02--machine-learning-with-python/2018-01-02">Machine Learning with SciKit Learn</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/docs/category/aiops">AIOps</a><button aria-label="Expand sidebar category &#x27;AIOps&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/docs/category/automation-deep-vision-and-robotics">Automation, Deep Vision and Robotics</a><button aria-label="Expand sidebar category &#x27;Automation, Deep Vision and Robotics&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/machine-learning-ai-and-computer-vision"><span itemprop="name">Machine Learning, AI and Computer Vision</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/docs/category/machine-learning"><span itemprop="name">Machine Learning</span></a><meta itemprop="position" content="2"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Deep Audio</span><meta itemprop="position" content="3"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Deep Audio</h1></header><p><img alt="Victoria Harbour, Hongkong" src="/assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-23d027067cc9016279f834178a642545.jpg" width="1500" height="565"></p>
<ul>
<li><a href="#signal-processing-with-tensorflow">Signal Processing with Tensorflow</a></li>
<li><a href="#project-setup">Project Setup</a></li>
<li><a href="#data-loading">Data Loading</a></li>
<li><a href="#creating-the-dataset">Creating the Dataset</a></li>
<li><a href="#calculating-average-length-of-a-birdcall">Calculating Average Length of a Birdcall</a></li>
<li><a href="#converting-data-into-a-spectrogram">Converting Data into a Spectrogram</a>
<ul>
<li><a href="#test-function">Test Function</a></li>
</ul>
</li>
<li><a href="#preparing-a-testing--training-dataset">Preparing a Testing &amp; Training Dataset</a>
<ul>
<li><a href="#training-set">Training Set</a></li>
<li><a href="#testing-set">Testing Set</a></li>
</ul>
</li>
<li><a href="#build-the-deep-learning-model">Build the Deep Learning Model</a>
<ul>
<li><a href="#sequential-model">Sequential Model</a></li>
</ul>
</li>
<li><a href="#training-the-model">Training the Model</a></li>
<li><a href="#making-predictions">Making Predictions</a></li>
<li><a href="#putting-the-model-to-work">Putting the Model to Work</a>
<ul>
<li><a href="#test-function-1">Test Function</a></li>
<li><a href="#data-preprocessing">Data Preprocessing</a></li>
<li><a href="#running-a-prediction">Running a Prediction</a></li>
<li><a href="#grouping-consecutive-hits">Grouping Consecutive Hits</a></li>
</ul>
</li>
<li><a href="#processing-the-raw-data">Processing the RAW Data</a>
<ul>
<li><a href="#export-the-results">Export the Results</a></li>
</ul>
</li>
</ul>
<p><a href="https://github.com/mpolinowski/signal-processing-tensorflow">Github Repository</a></p>
<h2 id="signal-processing-with-tensorflow">Signal Processing with Tensorflow</h2>
<p>The Challenge is to build a Machine Learning model and <a href="https://www.kaggle.com/datasets/kenjee/z-by-hp-unlocked-challenge-3-signal-processing">code to count the number of Capuchinbird calls within a given clip</a>. This can be done in a variety of ways and we would recommend that you do some research into <a href="https://www.kaggle.com/datasets/kenjee/z-by-hp-unlocked-challenge-3-signal-processing#where-to-start">various methods of audio recognition</a>.</p>
<h2 id="project-setup">Project Setup</h2>
<p>The Dataset is provided on <a href="https://www.kaggle.com/datasets/kenjee/z-by-hp-unlocked-challenge-3-signal-processing">kaggle.com</a> and contains of three sets of bird call recordings:</p>
<ul>
<li>raw (RAW Data)</li>
<li>positives (Cut out positive bird calls)</li>
<li>negatives (Cut out negatives)</li>
</ul>
<p>Copy them into your <code>data</code> folder. Open a Jupyter Notebook and create a notebook called <code>signal-processing</code>:</p>
<pre><code class="language-bash">jupyter notebook
</code></pre>
<p>Now we can install the Python dependencies from inside the notebook:</p>
<pre><code class="language-bash">!pip install tensorflow tensorflow-gpu tensorflow-io matplotlib
</code></pre>
<p>Once installed import them into your notebook:</p>
<pre><code class="language-python">import os
from matplotlib import pyplot as plt
import tensorflow as tf 
import tensorflow_io as tfio
</code></pre>
<h2 id="data-loading">Data Loading</h2>
<p>To work with the recorded audio files we can select the corresponding data paths - in the example below we pick both an example file that contains the signal we are looking for and one that only comes with background noise:</p>
<pre><code class="language-python">CAPUCHIN_FILE = os.path.join(&#x27;data&#x27;, &#x27;positives&#x27;, &#x27;XC3776-3.wav&#x27;)
NOT_CAPUCHIN_FILE = os.path.join(&#x27;data&#x27;, &#x27;negatives&#x27;, &#x27;afternoon-birds-song-in-forest-0.wav&#x27;)
</code></pre>
<p>And read a single audio stream (mono) resampled to 16kHz from those files by feeding the <code>filepath</code>  into the following function:</p>
<ul>
<li><a href="https://www.tensorflow.org/api_docs/python/tf/audio/decode_wav">decode_wav</a> : Read single channel from stereo file</li>
<li><a href="https://www.tensorflow.org/tutorials/audio/simple_audio">squeeze</a> : Since all the data is single channel (mono), drop the <code>channels</code> axis from array</li>
<li><a href="https://www.tensorflow.org/io/api_docs/python/tfio/audio/resample">resample</a> : Reduce audio data to 16kHz</li>
</ul>
<pre><code class="language-python">def load_wav_16k_mono(filename):
    # Load encoded wav file
    file_contents = tf.io.read_file(filename)
    # Decode wav (tensors by channels) 
    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)
    # Removes trailing axis
    wav = tf.squeeze(wav, axis=-1)
    sample_rate = tf.cast(sample_rate, dtype=tf.int64)
    # Goes from 44100Hz to 16000hz - amplitude of the audio signal
    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)
    return wav
</code></pre>
<p>We can run the function over both the positive and negative file:</p>
<pre><code class="language-python">wave = load_wav_16k_mono(CAPUCHIN_FILE)
nwave = load_wav_16k_mono(NOT_CAPUCHIN_FILE)
</code></pre>
<p>And overlay both waves in a plot:</p>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_01-9099cae18ea318d913deb288536936c2.png" width="978" height="396"></p>
<p>The blue plot represents the positive signal - the correct bird call. While the orange plot is a negative representing our baseline background noise. This now gives us a image representation of our audio that we can use to train our neural network with.</p>
<h2 id="creating-the-dataset">Creating the Dataset</h2>
<p>First we need to define the path to all our positive and negative audio files:</p>
<pre><code class="language-python">POS = os.path.join(&#x27;data&#x27;, &#x27;positives&#x27;)
NEG = os.path.join(&#x27;data&#x27;, &#x27;negatives&#x27;)
</code></pre>
<p>Now we can store all the data paths inside <a href="https://www.tensorflow.org/api_docs/python/tf/data/Dataset">Tensorflow Datasets</a>:</p>
<pre><code class="language-Python">pos = tf.data.Dataset.list_files(POS+&#x27;/*.wav&#x27;)
neg = tf.data.Dataset.list_files(NEG+&#x27;/*.wav&#x27;)
</code></pre>
<p>We can now label our data by adding ones and zeros to each filepath inside the dataset depending on whether it is a positive or negative sample:</p>
<pre><code class="language-python">positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))

negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))
</code></pre>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_02-38f5644096c17c03dd63c34e9e7d20c6.png" width="980" height="205"></p>
<p>After successfully labelling our data we can now merge everything into a single dataset:</p>
<pre><code class="language-python">data = positives.concatenate(negatives)
</code></pre>
<h2 id="calculating-average-length-of-a-birdcall">Calculating Average Length of a Birdcall</h2>
<p>To be able to count bird calls in our RAW data we first have to know the average length of a single call. We can do this by taking all our parsed positive recordings and load them into their waveform:</p>
<pre><code class="language-python">lengths = []
for file in os.listdir(os.path.join(&#x27;data&#x27;, &#x27;positives&#x27;)):
    tensor_wave = load_wav_16k_mono(os.path.join(&#x27;data&#x27;, &#x27;positives&#x27;, file))
    lengths.append(len(tensor_wave))
</code></pre>
<p>By appending each file length to the <code>lengths</code> array we can now do some basic maths to calculate the <strong>Min</strong>, <strong>Max</strong> and <strong>AVG</strong> length of a positive birdcall:</p>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_03-3d5becd95368c543379396673698f8fa.png" width="981" height="473"></p>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_04-24d83d821ae7c9435921faca625b02a0.png" width="981" height="304"></p>
<p>This means that the average birdcall ist <code>54156 / 16000 Hz = 3.38s</code>. And the calls are in between <strong>Min</strong> <code>2s</code> and <strong>Max</strong> <code>5s</code> in length.</p>
<h2 id="converting-data-into-a-spectrogram">Converting Data into a Spectrogram</h2>
<p>The following function takes an audio file and converts it to 16 kHz Mono. Since we know that the average call is about 3s in length we can limit our data to the first 48000 units of each parsed audio file.</p>
<p>Since our minimum file length was 32000 we need to make sure that every file is padded up with zeros to a length of 48000 using the <code>tf.zeros</code> function:</p>
<pre><code class="language-python">def preprocess(file_path, label):
	# Load files into 16kHz mono
    wav = load_wav_16k_mono(file_path)
    # Only read the first 3 secs
    wav = wav[:48000]
    # If file &lt; 3s add zeros
    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)
    wav = tf.concat([zero_padding, wav],0)
    # Use Short-time Fourier Transform
    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)
    # Convert to absolut values (no negatives)
    spectrogram = tf.abs(spectrogram)
    # Add channel dimension (needed by CNN later)
    spectrogram = tf.expand_dims(spectrogram, axis=2)
    return spectrogram, label
</code></pre>
<p>To create the spectrogram we can use the <a href="https://www.tensorflow.org/api_docs/python/tf/signal/stft">Short-time Fourier Transformation</a> provided by Tensorflow.</p>
<p>_<strong>Note</strong>: the dimensions of each spectrogram are <code>1491,257,1</code> - which represents the height and width of the image representation + an additional channel that was added with the <code>tf.expand_dims</code> function. This channel does not hold any information here but is expected to exists by the Tensorflow model we are going to use later.</p>
<h3 id="test-function">Test Function</h3>
<p>Pick a random audio file from the <code>positives</code> dataset:</p>
<pre><code class="language-python">filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()
</code></pre>
<p>And run it through the pre-processing function:</p>
<pre><code class="language-python">spectrogram, label = preprocess(filepath, label)
</code></pre>
<p>Let&#x27;s see what the spectrum actually looks like:</p>
<pre><code class="language-python">plt.figure(figsize=(30,20))
plt.imshow(tf.transpose(spectrogram)[0])
plt.show()
</code></pre>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_05-0793a83ec3cb42c4e99b53d967f27d5c.png" width="985" height="304"></p>
<p>For comparison, this is the spectrogram of a negative sample:</p>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_06-7b30d9ce088cdf7c33271b021e2e7553.png" width="982" height="304"></p>
<p>Now all we have to do, is to train a Tensorflow model that is able to distinguish between those two image representation of our audio data.</p>
<h2 id="preparing-a-testing--training-dataset">Preparing a Testing &amp; Training Dataset</h2>
<p>We already wrapped all of our data - positives and negatives - into the <code>data</code> variable. So now we can map through this data and feed each file to the <code>preprocessing</code> function.</p>
<pre><code class="language-python">data = data.map(preprocess)
data = data.cache()
data = data.shuffle(buffer_size=1000)
data = data.batch(16)
data = data.prefetch(8)
</code></pre>
<p>To optimize the training we will first shuffle the data and limit the amount of simultaneous files being processed to <code>16</code> and the pre-fetch to <code>8</code> files. This can be increased if your CPU/GPU can handle it.</p>
<p>To split our data into training and testing data we can run:</p>
<pre><code class="language-python">train = data.take(36)
test = data.skip(36).take(15)
</code></pre>
<p>With <code>len(data) = 51</code> the split ration is close to <strong>70:30</strong>. We can verify the content of each array by:</p>
<h3 id="training-set">Training Set</h3>
<pre><code class="language-python">samples, labels = train.as_numpy_iterator().next
labels

array([0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.],
      dtype=float32)
</code></pre>
<h3 id="testing-set">Testing Set</h3>
<pre><code class="language-python">samples, labels = test.as_numpy_iterator().next()
labels

array([0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0.],
      dtype=float32)
</code></pre>
<h2 id="build-the-deep-learning-model">Build the Deep Learning Model</h2>
<pre><code class="language-python">from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Dense, Flatten
</code></pre>
<h3 id="sequential-model">Sequential Model</h3>
<pre><code class="language-python">model = Sequential()
model.add(Conv2D(8, (3,3), activation=&#x27;relu&#x27;, input_shape=(1491,257,1)))
model.add(Conv2D(8, (3,3), activation=&#x27;relu&#x27;))
model.add(Flatten())
model.add(Dense(32, activation=&#x27;relu&#x27;))
model.add(Dense(1, activation=&#x27;sigmoid&#x27;))
</code></pre>
<pre><code class="language-python">model.compile(&#x27;Adam&#x27;, loss=&#x27;BinaryCrossentropy&#x27;, metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])
</code></pre>
<p><em>model.summary()</em></p>
<pre><code class="language-bash">Model: &quot;sequential&quot;
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 conv2d (Conv2D)             (None, 1489, 255, 8)      80        
                                                                 
 conv2d_1 (Conv2D)           (None, 1487, 253, 8)      584       
                                                                 
 flatten (Flatten)           (None, 3009688)           0         
                                                                 
 dense (Dense)               (None, 32)                96310048  
                                                                 
 dense_1 (Dense)             (None, 1)                 33        
                                                                 
=================================================================
Total params: 96,310,745
Trainable params: 96,310,745
Non-trainable params: 0
_________________________________________________________________
</code></pre>
<h2 id="training-the-model">Training the Model</h2>
<pre><code class="language-python">hist = model.fit(train, epochs=4, validation_data=test)
</code></pre>
<p>Already after 4 epochs we are starting to get getting a precision and recall value around 100%:</p>
<pre><code class="language-bash">Epoch 4/4
36/36 [==============================] - 6s 177ms/step - loss: 0.0091 - recall: 0.9870 - precision: 1.0000 - val_loss: 0.0157 - val_recall: 0.9844 - val_precision: 1.0000
</code></pre>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_07-637f322258cd342f7752ff6a15b2b8fa.png" width="980" height="436"></p>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_08-d226b68924dddb2fa409188b2b389c32.png" width="984" height="437"></p>
<h2 id="making-predictions">Making Predictions</h2>
<p>We can now use our testing data - the 16 files we excluded from the training dataset - and use them to run a prediction against:</p>
<pre><code class="language-python">X_test, y_test = test.as_numpy_iterator().next()
</code></pre>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_09-273cc1be5ce851dc0821d7994bad2089.png" width="980" height="251"></p>
<p>The <code>yhat</code> parameter gives us the probabilities of a file being the recording of a birdcall:</p>
<pre><code class="language-bash">yhat = model.predict(X_test)
</code></pre>
<p>Every value that is close to <code>1.00000000e+00</code> is a recording that, with a very high probability, contains the birdcall we are looking for:</p>
<pre><code class="language-python">array([[9.99920249e-01],
       [3.07901189e-08],
       [1.00000000e+00],
       [2.84484369e-25],
       [9.62874225e-09],
       [9.99707282e-01],
       [1.53503152e-05],
       [2.34340667e-03],
       [8.77155067e-28],
       [1.00000000e+00],
       [1.14530545e-08],
       [5.61734714e-06],
       [3.27430301e-20],
       [1.99461836e-11],
       [0.00000000e+00],
       [0.00000000e+00]], dtype=float32)
</code></pre>
<p>To make this more readable we can make this - within a selected range of confidence - binary:</p>
<pre><code class="language-python">yhat = [1 if prediction &gt; 0.5 else 0 for prediction in yhat]
</code></pre>
<p>Which looks like this:</p>
<pre><code class="language-python">[1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]
</code></pre>
<p>We can verify that this result is correct by calculating the sum of <code>yhat</code> and comparing it with the sum of <code>y_test</code> - which are our labels that we set to <code>1</code> for positives and <code>0</code> for negatives:</p>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_10-109f59222cc37bb53ab05515e1ae9b96.png" width="982" height="252"></p>
<p>And it seems that we were able to identify all 4 of them! But we should also rule out false-positives/negatives by comparing both arrays:</p>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_11-3af10ccca631fc66050260fc7b2ce559.png" width="982" height="228"></p>
<p>And we have a match - all the zeros and ones are where they belong.</p>
<h2 id="putting-the-model-to-work">Putting the Model to Work</h2>
<p>We now have a well performing model that is able to recognize bird calls. So we can now let it loose on the RAW forest recordings in the <code>data/raw</code> directory. First we need a function that loads the recordings - that are this time in <code>mp3</code> containers. So instead of the <code>tf.io.read_file</code> function we now need to use <code>tfio.audio.AudioIOTensor</code>. We will handle the stereo recording by adding both channels into a single channel and divide every value by <code>2</code>:</p>
<pre><code class="language-python">def load_mp3_16k_mono(filename):
    # Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio.
    res = tfio.audio.AudioIOTensor(filename)
    # Convert to tensor and combine channels 
    tensor = res.to_tensor()
    tensor = tf.math.reduce_sum(tensor, axis=1) / 2 
    # Extract sample rate and cast
    sample_rate = res.rate
    sample_rate = tf.cast(sample_rate, dtype=tf.int64)
    # Resample to 16 kHz
    wav = tfio.audio.resample(tensor, rate_in=sample_rate, rate_out=16000)
    return wav
</code></pre>
<h3 id="test-function-1">Test Function</h3>
<p>We can test the loading function by loading a single file:</p>
<pre><code class="language-python">mp3 = os.path.join(&#x27;data&#x27;, &#x27;Forest Recordings&#x27;, &#x27;recording_00.mp3&#x27;)
wav = load_mp3_16k_mono(mp3)
</code></pre>
<p>Since the RAW recordings are much longer than the neatly parsed training recordings that were already cut down to the length of a typical bird call we can now slice up the file into short sequences of the same length <code>48000</code>:</p>
<pre><code class="language-python">audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)
</code></pre>
<p>We can check the amount of slices that were generated with <code>len(audio_slices)</code> - and in case of the file <code>recording_00.mp3</code> we end up with <strong>60</strong> sequences.</p>
<h3 id="data-preprocessing">Data Preprocessing</h3>
<p>The pre-processing step is identical to before. We can pick the first sequence out of the 60 slices that were generated, make sure that it is the correct length (which of course in case of the first slice - it will be). And then continue generating the spectrogram:</p>
<pre><code class="language-python">def preprocess_mp3(sample, index):
    sample = sample[0]
    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)
    wav = tf.concat([zero_padding, sample],0)
    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)
    spectrogram = tf.abs(spectrogram)
    spectrogram = tf.expand_dims(spectrogram, axis=2)
    return spectrogram
</code></pre>
<p>Now we can create the audio slices and run them through the preprocessing function:</p>
<pre><code class="language-python">audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)
audio_slices = audio_slices.map(preprocess_mp3)
audio_slices = audio_slices.batch(64)
</code></pre>
<h3 id="running-a-prediction">Running a Prediction</h3>
<p>With the 60 slices in place we can now run our prediction model against them - this time I will bump up the confidence to 90% to make sure we don&#x27;t catch any background noise:</p>
<pre><code class="language-python">yhat = model.predict(audio_slices)
yhat = [1 if prediction &gt; 0.9 else 0 for prediction in yhat]
</code></pre>
<p>The <code>yhat</code> variable now returns 60 zeros and ones depending on wether the tested sequence contained a bird call or not:</p>
<pre><code class="language-python">len(yhat)
60

yhat
[0,0,0,1,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0]
</code></pre>
<p>But we can see that there are consecutive detections that are most likely caused by us slicing a single bird call into two. Currently we would count&#x27;t 8 bird calls:</p>
<pre><code class="language-python">tf.math.reduce_sum(yhat)
&lt;tf.Tensor: shape=(), dtype=int32, numpy=8&gt;
</code></pre>
<h3 id="grouping-consecutive-hits">Grouping Consecutive Hits</h3>
<pre><code class="language-python">from itertools import groupby

yhat = [key for key, group in groupby(yhat)]
calls = tf.math.reduce_sum(yhat).numpy()
</code></pre>
<p>This reduces the number of detections to 5 - which we can confirm by listening to the <code>recording_00.mp3</code> file and counting using finger technology:</p>
<pre><code class="language-python">calls
5
</code></pre>
<h2 id="processing-the-raw-data">Processing the RAW Data</h2>
<p>Now with everything in place we can loop through every file in the <code>raw</code> directory and count our detections:</p>
<pre><code class="language-python">results = {}
for file in os.listdir(os.path.join(&#x27;data&#x27;, &#x27;raw&#x27;)):
    FILEPATH = os.path.join(&#x27;data&#x27;,&#x27;raw&#x27;, file)
    
    wav = load_mp3_16k_mono(FILEPATH)
    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)
    audio_slices = audio_slices.map(preprocess_mp3)
    audio_slices = audio_slices.batch(64)
    
    yhat = model.predict(audio_slices)
    
    results[file] = yhat
</code></pre>
<p>This returns predictions for every slice in every recording:</p>
<p><img alt="Tensorflow Audio Signal Classifier" src="/assets/images/Tensorflow_Audio_Signal_Classifier_12-65d58afdadefd9af5980968181fe5207.png" width="983" height="474"></p>
<p>Again we can make this more readable by turning everything with a 99% confidence into ones and the rest into zeros:</p>
<pre><code class="language-python">class_preds = {}
for file, logits in results.items():
    class_preds[file] = [1 if prediction &gt; 0.99 else 0 for prediction in logits]
class_preds
</code></pre>
<p>And group all consecutive detections to make sure we don&#x27;t double-count them:</p>
<pre><code class="language-python">postprocessed = {}
for file, scores in class_preds.items():
    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()
postprocessed
</code></pre>
<p>Now we end up with the sum of all calls inside each file:</p>
<pre><code class="language-python">{&#x27;recording_00.mp3&#x27;: 5,
 &#x27;recording_01.mp3&#x27;: 0,
 &#x27;recording_02.mp3&#x27;: 0,
 &#x27;recording_03.mp3&#x27;: 0,
 &#x27;recording_04.mp3&#x27;: 4,
 &#x27;recording_05.mp3&#x27;: 0,
 &#x27;recording_06.mp3&#x27;: 5,
 &#x27;recording_07.mp3&#x27;: 2,
 &#x27;recording_08.mp3&#x27;: 25,
 &#x27;recording_09.mp3&#x27;: 0,
 &#x27;recording_10.mp3&#x27;: 5,
 &#x27;recording_11.mp3&#x27;: 3,
 &#x27;recording_12.mp3&#x27;: 0,
 &#x27;recording_13.mp3&#x27;: 0,
 &#x27;recording_14.mp3&#x27;: 0,
 &#x27;recording_15.mp3&#x27;: 2,
 &#x27;recording_17.mp3&#x27;: 3,
 &#x27;recording_18.mp3&#x27;: 5,
 &#x27;recording_19.mp3&#x27;: 0,
 &#x27;recording_20.mp3&#x27;: 0,
 &#x27;recording_21.mp3&#x27;: 1,
 &#x27;recording_22.mp3&#x27;: 2,
 &#x27;recording_23.mp3&#x27;: 5,
 &#x27;recording_24.mp3&#x27;: 0,
 &#x27;recording_25.mp3&#x27;: 16,
 &#x27;recording_26.mp3&#x27;: 2,
 &#x27;recording_27.mp3&#x27;: 0,
 &#x27;recording_28.mp3&#x27;: 16,
 &#x27;recording_29.mp3&#x27;: 0,
 &#x27;recording_30.mp3&#x27;: 2,
 &#x27;recording_31.mp3&#x27;: 1,
 &#x27;recording_32.mp3&#x27;: 2,
 &#x27;recording_34.mp3&#x27;: 4,
 &#x27;recording_35.mp3&#x27;: 0,
 &#x27;recording_36.mp3&#x27;: 0,
 &#x27;recording_37.mp3&#x27;: 3,
 &#x27;recording_38.mp3&#x27;: 1,
 &#x27;recording_39.mp3&#x27;: 9,
 &#x27;recording_40.mp3&#x27;: 1,
 &#x27;recording_41.mp3&#x27;: 0,
 &#x27;recording_42.mp3&#x27;: 0,
 &#x27;recording_43.mp3&#x27;: 5,
 &#x27;recording_44.mp3&#x27;: 1,
 &#x27;recording_45.mp3&#x27;: 3,
 &#x27;recording_46.mp3&#x27;: 17,
 &#x27;recording_47.mp3&#x27;: 16,
 &#x27;recording_48.mp3&#x27;: 4,
 &#x27;recording_49.mp3&#x27;: 0,
 &#x27;recording_51.mp3&#x27;: 3,
 &#x27;recording_52.mp3&#x27;: 0,
 &#x27;recording_53.mp3&#x27;: 0,
 &#x27;recording_54.mp3&#x27;: 3,
 &#x27;recording_55.mp3&#x27;: 0,
 &#x27;recording_56.mp3&#x27;: 16,
 &#x27;recording_57.mp3&#x27;: 3,
 &#x27;recording_58.mp3&#x27;: 0,
 &#x27;recording_59.mp3&#x27;: 15,
 &#x27;recording_60.mp3&#x27;: 4,
 &#x27;recording_61.mp3&#x27;: 11,
 &#x27;recording_62.mp3&#x27;: 0,
 &#x27;recording_63.mp3&#x27;: 17,
 &#x27;recording_64.mp3&#x27;: 2,
 &#x27;recording_65.mp3&#x27;: 5,
 &#x27;recording_66.mp3&#x27;: 0,
 &#x27;recording_16.mp3&#x27;: 5,
 &#x27;recording_33.mp3&#x27;: 0,
 &#x27;recording_50.mp3&#x27;: 0,
 &#x27;recording_67.mp3&#x27;: 0,
 &#x27;recording_68.mp3&#x27;: 1,
 &#x27;recording_69.mp3&#x27;: 1,
 &#x27;recording_70.mp3&#x27;: 4,
 &#x27;recording_71.mp3&#x27;: 5,
 &#x27;recording_72.mp3&#x27;: 4,
 &#x27;recording_73.mp3&#x27;: 0,
 &#x27;recording_74.mp3&#x27;: 0,
 &#x27;recording_75.mp3&#x27;: 1,
 &#x27;recording_76.mp3&#x27;: 0,
 &#x27;recording_77.mp3&#x27;: 3,
 &#x27;recording_78.mp3&#x27;: 10,
 &#x27;recording_79.mp3&#x27;: 0,
 &#x27;recording_80.mp3&#x27;: 1,
 &#x27;recording_81.mp3&#x27;: 5,
 &#x27;recording_82.mp3&#x27;: 0,
 &#x27;recording_83.mp3&#x27;: 0,
 &#x27;recording_84.mp3&#x27;: 16,
 &#x27;recording_85.mp3&#x27;: 0,
 &#x27;recording_86.mp3&#x27;: 17,
 &#x27;recording_87.mp3&#x27;: 24,
 &#x27;recording_88.mp3&#x27;: 0,
 &#x27;recording_89.mp3&#x27;: 5,
 &#x27;recording_90.mp3&#x27;: 0,
 &#x27;recording_91.mp3&#x27;: 0,
 &#x27;recording_92.mp3&#x27;: 0,
 &#x27;recording_93.mp3&#x27;: 5,
 &#x27;recording_94.mp3&#x27;: 3,
 &#x27;recording_95.mp3&#x27;: 4,
 &#x27;recording_96.mp3&#x27;: 1,
 &#x27;recording_97.mp3&#x27;: 4,
 &#x27;recording_98.mp3&#x27;: 21,
 &#x27;recording_99.mp3&#x27;: 5}
</code></pre>
<h3 id="export-the-results">Export the Results</h3>
<pre><code class="language-python">with open(&#x27;results.csv&#x27;, &#x27;w&#x27;, newline=&#x27;&#x27;) as f:
    writer = csv.writer(f, delimiter=&#x27;,&#x27;)
    writer.writerow([&#x27;recording&#x27;, &#x27;capuchin_calls&#x27;])
    for key, value in postprocessed.items():
        writer.writerow([key, value])
</code></pre></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/tensorflow">Tensorflow</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/machine-learning">Machine Learning</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/docs/tags/python">Python</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/index.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/IoT-and-Machine-Learning/ML/2022-04-02-pytorch-super-resolution/2022-04-02"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Super Resolution with ESRGAN</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Yolo App - YOLOv5 Data Preparation</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#signal-processing-with-tensorflow" class="table-of-contents__link toc-highlight">Signal Processing with Tensorflow</a></li><li><a href="#project-setup" class="table-of-contents__link toc-highlight">Project Setup</a></li><li><a href="#data-loading" class="table-of-contents__link toc-highlight">Data Loading</a></li><li><a href="#creating-the-dataset" class="table-of-contents__link toc-highlight">Creating the Dataset</a></li><li><a href="#calculating-average-length-of-a-birdcall" class="table-of-contents__link toc-highlight">Calculating Average Length of a Birdcall</a></li><li><a href="#converting-data-into-a-spectrogram" class="table-of-contents__link toc-highlight">Converting Data into a Spectrogram</a><ul><li><a href="#test-function" class="table-of-contents__link toc-highlight">Test Function</a></li></ul></li><li><a href="#preparing-a-testing--training-dataset" class="table-of-contents__link toc-highlight">Preparing a Testing &amp; Training Dataset</a><ul><li><a href="#training-set" class="table-of-contents__link toc-highlight">Training Set</a></li><li><a href="#testing-set" class="table-of-contents__link toc-highlight">Testing Set</a></li></ul></li><li><a href="#build-the-deep-learning-model" class="table-of-contents__link toc-highlight">Build the Deep Learning Model</a><ul><li><a href="#sequential-model" class="table-of-contents__link toc-highlight">Sequential Model</a></li></ul></li><li><a href="#training-the-model" class="table-of-contents__link toc-highlight">Training the Model</a></li><li><a href="#making-predictions" class="table-of-contents__link toc-highlight">Making Predictions</a></li><li><a href="#putting-the-model-to-work" class="table-of-contents__link toc-highlight">Putting the Model to Work</a><ul><li><a href="#test-function-1" class="table-of-contents__link toc-highlight">Test Function</a></li><li><a href="#data-preprocessing" class="table-of-contents__link toc-highlight">Data Preprocessing</a></li><li><a href="#running-a-prediction" class="table-of-contents__link toc-highlight">Running a Prediction</a></li><li><a href="#grouping-consecutive-hits" class="table-of-contents__link toc-highlight">Grouping Consecutive Hits</a></li></ul></li><li><a href="#processing-the-raw-data" class="table-of-contents__link toc-highlight">Processing the RAW Data</a><ul><li><a href="#export-the-results" class="table-of-contents__link toc-highlight">Export the Results</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Research</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Notebook</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/tags">Tags</a></li><li class="footer__item"><a class="footer__link-item" href="/Curriculum-Vitae">CV</a></li></ul></div><div class="col footer__col"><div class="footer__title">Social</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.linkedin.com/in/mike-polinowski-6396ba121/" target="_blank" rel="noopener noreferrer" class="footer__link-item">LinkedIn<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://twitter.com/MikePolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">Twitter<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://www.flickr.com/people/149680084@N06/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Flickr<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li><li class="footer__item"><a href="https://github.com/mpolinowski" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Mike Polinowski, INSTAR Deutschland GmbH, Shenzhen - China.</div></div></div></footer></div>
</body>
</html>