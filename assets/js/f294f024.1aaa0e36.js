"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[62826],{3905:(e,t,n)=>{n.d(t,{Zo:()=>s,kt:()=>u});var r=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function a(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?a(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):a(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,r,o=function(e,t){if(null==e)return{};var n,r,o={},a=Object.keys(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);for(r=0;r<a.length;r++)n=a[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var l=r.createContext({}),p=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},s=function(e){var t=p(e.components);return r.createElement(l.Provider,{value:t},e.children)},d={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},h=r.forwardRef((function(e,t){var n=e.components,o=e.mdxType,a=e.originalType,l=e.parentName,s=c(e,["components","mdxType","originalType","parentName"]),h=p(n),u=o,m=h["".concat(l,".").concat(u)]||h[u]||d[u]||a;return n?r.createElement(m,i(i({ref:t},s),{},{components:n})):r.createElement(m,i({ref:t},s))}));function u(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var a=n.length,i=new Array(a);i[0]=h;var c={};for(var l in t)hasOwnProperty.call(t,l)&&(c[l]=t[l]);c.originalType=e,c.mdxType="string"==typeof e?e:o,i[1]=c;for(var p=2;p<a;p++)i[p]=n[p];return r.createElement.apply(null,i)}return r.createElement.apply(null,n)}h.displayName="MDXCreateElement"},48922:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>d,frontMatter:()=>a,metadata:()=>c,toc:()=>p});var r=n(87462),o=(n(67294),n(3905));const a={sidebar_position:4160,slug:"2023-08-21",title:"Containerized PyTorch Dev Workflow",authors:"mpolinowski",tags:["Python","Machine Learning","PyTorch","Docker"],description:"Develop your PyTorch models inside the official PyTorch container image."},i=void 0,c={unversionedId:"IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/index",id:"IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/index",title:"Containerized PyTorch Dev Workflow",description:"Develop your PyTorch models inside the official PyTorch container image.",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker",slug:"/IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/2023-08-21",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/2023-08-21",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"PyTorch",permalink:"/docs/tags/py-torch"},{label:"Docker",permalink:"/docs/tags/docker"}],version:"current",sidebarPosition:4160,frontMatter:{sidebar_position:4160,slug:"2023-08-21",title:"Containerized PyTorch Dev Workflow",authors:"mpolinowski",tags:["Python","Machine Learning","PyTorch","Docker"],description:"Develop your PyTorch models inside the official PyTorch container image."},sidebar:"tutorialSidebar",previous:{title:"Image Segmentation with PyTorch",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-27--image-segmentation-with-pytorch/2023-08-27"},next:{title:"Tensorflow Image Classifier - Model Evaluation",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-13-tensorflow-i-know-flowers-model-eval/2023-08-13"}},l={},p=[{value:"Docker Image",id:"docker-image",level:2},{value:"Running the Container",id:"running-the-container",level:3},{value:"Verify PyTorch",id:"verify-pytorch",level:3},{value:"Troubleshooting",id:"troubleshooting",level:3}],s={toc:p};function d(e){let{components:t,...a}=e;return(0,o.kt)("wrapper",(0,r.Z)({},s,a,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"TST, Hong Kong",src:n(32179).Z,width:"1500",height:"549"})),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#containerized-pytorch-dev-workflow"},"Containerized PyTorch Dev Workflow"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#docker-image"},"Docker Image"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#running-the-container"},"Running the Container")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#verify-pytorch"},"Verify PyTorch")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#troubleshooting"},"Troubleshooting"))))))),(0,o.kt)("h1",{id:"containerized-pytorch-dev-workflow"},"Containerized PyTorch Dev Workflow"),(0,o.kt)("p",null,"I recently looked into ",(0,o.kt)("em",{parentName:"p"},"dockerrizing")," my Tensorflow ",(0,o.kt)("a",{parentName:"p",href:"/docs/IoT-and-Machine-Learning/ML/2023-08-01-tensorflow-i-know-flowers-intro/2023-08-01"},"development & deployment workflow"),". I now want to see if I can do the same with my PyTorch projects."),(0,o.kt)("p",null,"First of all, you still need to prepare your system so that ",(0,o.kt)("a",{parentName:"p",href:"docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27"},"Docker has access to your Nvidia GPU"),". This seems to be identical to the Tensorflow setup."),(0,o.kt)("h2",{id:"docker-image"},"Docker Image"),(0,o.kt)("p",null,"Next, there are official ",(0,o.kt)("a",{parentName:"p",href:"https://hub.docker.com/r/pytorch/pytorch/tags"},"PyTorch Docker Images")," available for download. Good! But I really started to like using Jupyter notebooks - and there is no version of the official image that has them pre-installed. So let's fix that:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-Dockerfile"},'FROM pytorch/pytorch:latest\n\n# Set environment variables\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install system dependencies\nRUN apt-get update && \\\n    apt-get install -y \\\n        git \\\n        tini \\\n        python3-pip \\\n        python3-dev \\\n        python3-opencv \\\n        libglib2.0-0\n\n# Upgrade pip\nRUN python3 -m pip install --upgrade pip\nRUN pip3 install jupyter\n\n\n# Set the working directory\nWORKDIR /opt/app\n\n# Start the notebook\nRUN chmod +x /usr/bin/tini\nENTRYPOINT ["/usr/bin/tini", "--"]\nCMD ["jupyter", "notebook", "--port=8888", "--no-browser", "--ip=0.0.0.0", "--allow-root"]\n')),(0,o.kt)("h3",{id:"running-the-container"},"Running the Container"),(0,o.kt)("p",null,"Let's build this custom image with:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"docker build -t pytorch-jupyter . -f Dockerfile\n")),(0,o.kt)("p",null,"I can now create the container and mount my working directory into the container WORKDIR to get started:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"docker run --gpus all -ti --rm \\\n    -v $(pwd):/opt/app -p 8888:8888 \\\n    --name pytorch-jupyter \\\n    pytorch-jupyter:latest\n")),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"[C 2023-08-21 08:47:56.598 ServerApp] \n    \n    To access the server, open this file in a browser:\n        file:///root/.local/share/jupyter/runtime/jpserver-7-open.html\n    Or copy and paste one of these URLs:\n        http://e7f849cdd75e:8888/tree?token=8d72a759100e2c2971c4266bbcb8c6da5f743015eecd5255\n        http://127.0.0.1:8888/tree?token=8d72a759100e2c2971c4266bbcb8c6da5f743015eecd5255\n")),(0,o.kt)("h3",{id:"verify-pytorch"},"Verify PyTorch"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Containerized PyTorch Dev Workflow",src:n(1939).Z,width:"1042",height:"515"})),(0,o.kt)("h3",{id:"troubleshooting"},"Troubleshooting"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},(0,o.kt)("inlineCode",{parentName:"p"},"ERROR: Unexpected bus error encountered in worker. This might be caused by insufficient shared memory (shm)."))),(0,o.kt)("p",null,"Please note that PyTorch uses shared memory to share data between processes, so if torch multiprocessing is used (e.g. for multithreaded data loaders) the default shared memory segment size that container runs with is not enough, and you should ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/pytorch/pytorch#using-pre-built-images"},"increase shared memory size")," either with --ipc=host or --shm-size command line options to nvidia-docker run."),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"docker run --ipc=host --gpus all -ti --rm \\\n    -v $(pwd):/opt/app -p 8888:8888 \\\n    --name pytorch-jupyter \\\n    pytorch-jupyter:latest\n")))}d.isMDXComponent=!0},1939:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/PyTorch_Jupyter_Notebook_in_Docker_01-edea53276b343317772136f8496cab9a.png"},32179:(e,t,n)=>{n.d(t,{Z:()=>r});const r=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-19827635eae5b5cb12f68c531f406341.jpg"}}]);