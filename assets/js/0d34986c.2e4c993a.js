"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[11448],{463574:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>h,frontMatter:()=>s,metadata:()=>t,toc:()=>l});var a=i(474848),r=i(28453);const s={sidebar_position:5e3,slug:"2022-11-27",title:"Deep Docker on Arch",authors:"mpolinowski",tags:["Python","Machine Learning","Docker"],description:"The NVIDIA Container Toolkit run GPU accelerated Docker containers"},o=void 0,t={id:"IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/index",title:"Deep Docker on Arch",description:"The NVIDIA Container Toolkit run GPU accelerated Docker containers",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning",slug:"/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Docker",permalink:"/docs/tags/docker"}],version:"current",sidebarPosition:5e3,frontMatter:{sidebar_position:5e3,slug:"2022-11-27",title:"Deep Docker on Arch",authors:"mpolinowski",tags:["Python","Machine Learning","Docker"],description:"The NVIDIA Container Toolkit run GPU accelerated Docker containers"},sidebar:"tutorialSidebar",previous:{title:"Breast Histopathology Image Segmentation Part 1",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-10-tf-breast-cancer-classification-part1/2022-12-10"},next:{title:"Face Restoration with GFPGAN",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/2022-04-04"}},c={},l=[{value:"Preparations",id:"preparations",level:2},{value:"Installation in Arch Linux",id:"installation-in-arch-linux",level:3},{value:"YAY",id:"yay",level:4},{value:"Manually",id:"manually",level:4},{value:"Testing",id:"testing",level:3},{value:"Docker Images",id:"docker-images",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Guangzhou, China",src:i(103892).A+"",width:"1500",height:"383"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"#preparations",children:"Preparations"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"#installation-in-arch-linux",children:"Installation in Arch Linux"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#yay",children:"YAY"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#manually",children:"Manually"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#testing",children:"Testing"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#docker-images",children:"Docker Images"})}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["The ",(0,a.jsx)(n.a,{href:"https://github.com/NVIDIA/nvidia-docker",children:"NVIDIA Container Toolkit"})," allows users to build and run GPU accelerated Docker containers. The toolkit includes a container runtime library and utilities to automatically configure containers to leverage NVIDIA GPUs."]}),"\n",(0,a.jsx)(n.h2,{id:"preparations",children:"Preparations"}),"\n",(0,a.jsxs)(n.p,{children:["Make sure you have installed the ",(0,a.jsx)(n.a,{href:"https://docs.nvidia.com/datacenter/tesla/tesla-installation-notes/index.html",children:"NVIDIA driver"})," and Docker engine for your Linux distribution. Note that you do not need to install the CUDA Toolkit on the host system."]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"sudo pacman -Syu\nsudo pacman -S base-devel linux-headers git nano --needed\n"})}),"\n",(0,a.jsx)(n.p,{children:"Verify what version of the nVidia driver you need:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'lspci -k | grep -A 2 -E "(VGA|3D)"\n\n00:02.0 VGA compatible controller: Intel Corporation HD Graphics 630 (rev 04)\n\tDeviceName:  Onboard IGD\n\tSubsystem: Dell HD Graphics 630\n--\n01:00.0 VGA compatible controller: NVIDIA Corporation GP106M [GeForce GTX 1060 Mobile] (rev a1)\n\tSubsystem: Dell GP106M [GeForce GTX 1060 Mobile]\n\tKernel driver in use: nouveau\n'})}),"\n",(0,a.jsx)(n.p,{children:"Install a suitable version:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"sudo pacman -S nvidia nvidia-utils nvidia-settings opencl-nvidia xorg-server-devel\nreboot\n"})}),"\n",(0,a.jsx)(n.p,{children:"Verify that the installation worked:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"sudo nvidia-smi\n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA GeForce GTX 1060        Off |   00000000:01:00.0 Off |                  N/A |\n| N/A   50C    P8              4W /   78W |       6MiB /   6144MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|    0   N/A  N/A       709      G   /usr/lib/Xorg                                   4MiB |\n+-----------------------------------------------------------------------------------------+\n"})}),"\n",(0,a.jsx)(n.h3,{id:"installation-in-arch-linux",children:"Installation in Arch Linux"}),"\n",(0,a.jsxs)(n.p,{children:["Starting from Docker version 19.03, NVIDIA GPUs are natively supported as Docker devices. ",(0,a.jsx)(n.a,{href:"https://github.com/NVIDIA/nvidia-docker",children:"NVIDIA Container Toolkit"})," is the recommended way of running containers that leverage NVIDIA GPUs."]}),"\n",(0,a.jsxs)(n.p,{children:["Install the ",(0,a.jsx)(n.a,{href:"https://aur.archlinux.org/packages/nvidia-container-toolkit/",children:"nvidia-container-toolkit"})," package. Next, restart docker. You can now run containers that make use of NVIDIA GPUs using the ",(0,a.jsx)(n.code,{children:"--gpus"})," option."]}),"\n",(0,a.jsx)(n.h4,{id:"yay",children:"YAY"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"yay -Syu\nyay -S nvidia-container-toolkit\n"})}),"\n",(0,a.jsx)(n.p,{children:"And restart Docker:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"sudo systemctl restart docker\n"})}),"\n",(0,a.jsx)(n.h4,{id:"manually",children:"Manually"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"wget https://aur.archlinux.org/cgit/aur.git/snapshot/nvidia-container-toolkit.tar.gz\ntar -xf nvidia-container-toolkit.tar.gz && cd nvidia-container-toolkit/\nmakepkg\nsudo pacman -U nvidia-container-toolkit-1.11.0-1-x86_64.pkg.tar.zst\n"})}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"Missing dependencies: -> libnvidia-container-tools>=1.9.0"})," ",(0,a.jsx)(n.a,{href:"https://aur.archlinux.org/packages/libnvidia-container-tools",children:"AUR"})]}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"wget https://aur.archlinux.org/cgit/aur.git/snapshot/libnvidia-container.tar.gz\ntar -xf libnvidia-container.tar.gz && cd libnvidia-container/\nmakepkg\nsudo pacman -U libnvidia-container-1.11.0-1-x86_64.pkg.tar.zst\nsudo pacman -U libnvidia-container-tools-1.11.0-1-x86_64.pkg.tar.zst\n"})}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.code,{children:"Missing dependencies: -> bmake, -> rpcsvc-proto"})}),"\n"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"sudo pacman -S bmake rpcsvc-proto \n"})}),"\n",(0,a.jsxs)(n.p,{children:["You might also need to re-enable c-groups in ",(0,a.jsx)(n.code,{children:"/etc/nvidia-container-runtime/config.toml"})," by ensuring ",(0,a.jsx)(n.code,{children:"no-cgroups"})," is not set to true. And restart Docker:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"sudo systemctl restart docker\n"})}),"\n",(0,a.jsx)(n.h3,{id:"testing",children:"Testing"}),"\n",(0,a.jsx)(n.p,{children:"At this point, a working setup can be tested by running a base CUDA container:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker run --rm --gpus all nvidia/cuda:12.3.2-base-ubuntu22.04 nvidia-smi  \n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.54.14              Driver Version: 550.54.14      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  NVIDIA GeForce GTX 1060        Off |   00000000:01:00.0 Off |                  N/A |\n| N/A   50C    P8              6W /   78W |       6MiB /   6144MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n"})}),"\n",(0,a.jsx)(n.p,{children:":thumbsup:"}),"\n",(0,a.jsx)(n.h2,{id:"docker-images",children:"Docker Images"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker pull tensorflow/tensorflow:latest-gpu\ndocker pull pytorch/pytorch:1.13.0-cuda11.6-cudnn8-runtime\n"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:["Continued here:","\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-01-tf-model-server/2023-01-01",children:"Tensorflow Docker Model Server"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/AIOps/2023-08-19-tensorflow-serving-api/2023-08-19",children:"Tensorflow Serving API"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-08-21--pytorch-development-in-docker/2023-08-21",children:"Containerized PyTorch Dev Workflow"})}),"\n"]}),"\n"]}),"\n"]})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},103892:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-918471126c0472aad97358a725e1a399.jpg"},28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>t});var a=i(296540);const r={},s=a.createContext(r);function o(e){const n=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function t(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:o(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);