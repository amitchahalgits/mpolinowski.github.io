"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[43686],{611723:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>l});var t=r(785893),i=r(603905);const s={sidebar_position:5030,slug:"2022-04-04",title:"Face Restoration with GFPGAN",authors:"mpolinowski",tags:["Torch","Machine Learning","Python"]},a=void 0,o={id:"IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/index",title:"Face Restoration with GFPGAN",description:"Victoria Harbour, Hongkong",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration",slug:"/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/2022-04-04",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/2022-04-04",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-04-04-pytorch-face-restoration/index.md",tags:[{label:"Torch",permalink:"/docs/tags/torch"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"}],version:"current",sidebarPosition:5030,frontMatter:{sidebar_position:5030,slug:"2022-04-04",title:"Face Restoration with GFPGAN",authors:"mpolinowski",tags:["Torch","Machine Learning","Python"]},sidebar:"tutorialSidebar",previous:{title:"Deep Docker on Arch",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-11-27-containerized-deep-learning/2022-11-27"},next:{title:"Super Resolution with Real-ESRGAN",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-04-03-pytorch-real-super-resolution/2022-04-03"}},c={},l=[{value:"Project Setup",id:"project-setup",level:2},{value:"Install Dependencies",id:"install-dependencies",level:3},{value:"Run Up-Sampling",id:"run-up-sampling",level:2},{value:"Results",id:"results",level:3}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.ah)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Victoria Harbour, Hongkong",src:r(967570).Z+"",width:"1500",height:"565"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#project-setup",children:"Project Setup"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#install-dependencies",children:"Install Dependencies"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#run-up-sampling",children:"Run Up-Sampling"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#results",children:"Results"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/mpolinowski/GFPGAN",children:"Github Repository"})}),"\n",(0,t.jsx)(n.h2,{id:"project-setup",children:"Project Setup"}),"\n",(0,t.jsx)(n.p,{children:"This project uses the GFPGAN repository available on Github:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"git clone https://github.com/mpolinowski/GFPGAN\n"})}),"\n",(0,t.jsxs)(n.p,{children:["And we will be using a pre-trained model that can be downloaded from ",(0,t.jsx)(n.a,{href:"https://github.com/mpolinowski/GFPGAN#european_castle-model-zoo",children:"here"}),". There are different models available - one of them does not rely on a CUDA-Extensions (can be run on a CPU). But the following one does require an nVidia graphics card:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"cd GFPGAN\nwget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth -P experiments/pretrained_models\n"})}),"\n",(0,t.jsx)(n.h3,{id:"install-dependencies",children:"Install Dependencies"}),"\n",(0,t.jsxs)(n.p,{children:["All dependencies are listed in the ",(0,t.jsx)(n.code,{children:"requirements.txt"})," file:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"torch>=1.7\nnumpy<1.21  # numba requires numpy<1.21,>=1.17\nopencv-python\ntorchvision\nscipy\ntqdm\nbasicsr>=1.3.4.0\nfacexlib>=0.2.0.3\nlmdb\npyyaml\ntb-nightly\nyapf\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip3 install -r requirements.txt\n"})}),"\n",(0,t.jsxs)(n.p,{children:["If you want to enhance the background (non-face) regions with Real-ESRGAN, you also need to install the ",(0,t.jsx)(n.code,{children:"realesrgan"})," package:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"pip3 install realesrgan\n"})}),"\n",(0,t.jsx)(n.p,{children:"And run the setup script:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python setup.py develop\n"})}),"\n",(0,t.jsx)(n.h2,{id:"run-up-sampling",children:"Run Up-Sampling"}),"\n",(0,t.jsxs)(n.p,{children:["We can run the following script included inside the repository to feed images from the ",(0,t.jsx)(n.code,{children:"./inputs/whole_imgs"})," directory into our GAN and output the up-sampled images into the ",(0,t.jsx)(n.code,{children:"./results"})," folder:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2\n"})}),"\n",(0,t.jsx)(n.h3,{id:"results",children:"Results"}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"ESRGAN Super Resolution",src:r(792343).Z+"",width:"1791",height:"587"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"ESRGAN Super Resolution",src:r(312918).Z+"",width:"1867",height:"567"})})]})}function h(e={}){const{wrapper:n}={...(0,i.ah)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},603905:(e,n,r)=>{r.d(n,{ah:()=>l});var t=r(667294);function i(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function s(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,t)}return r}function a(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?s(Object(r),!0).forEach((function(n){i(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):s(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function o(e,n){if(null==e)return{};var r,t,i=function(e,n){if(null==e)return{};var r,t,i={},s=Object.keys(e);for(t=0;t<s.length;t++)r=s[t],n.indexOf(r)>=0||(i[r]=e[r]);return i}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(t=0;t<s.length;t++)r=s[t],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(i[r]=e[r])}return i}var c=t.createContext({}),l=function(e){var n=t.useContext(c),r=n;return e&&(r="function"==typeof e?e(n):a(a({},n),e)),r},d={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},h=t.forwardRef((function(e,n){var r=e.components,i=e.mdxType,s=e.originalType,c=e.parentName,h=o(e,["components","mdxType","originalType","parentName"]),p=l(r),u=i,g=p["".concat(c,".").concat(u)]||p[u]||d[u]||s;return r?t.createElement(g,a(a({ref:n},h),{},{components:r})):t.createElement(g,a({ref:n},h))}));h.displayName="MDXCreateElement"},792343:(e,n,r)=>{r.d(n,{Z:()=>t});const t=r.p+"assets/images/Before_After-574e289d9c5ffe649f47ce9577f47215.png"},312918:(e,n,r)=>{r.d(n,{Z:()=>t});const t=r.p+"assets/images/Before_After2-c6e59bde2b550a290b3946286f09863a.png"},967570:(e,n,r)=>{r.d(n,{Z:()=>t});const t=r.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-23d027067cc9016279f834178a642545.jpg"}}]);