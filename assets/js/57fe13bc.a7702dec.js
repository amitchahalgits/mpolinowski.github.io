"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[64682],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>d});var a=n(67294);function o(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){o(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function r(e,t){if(null==e)return{};var n,a,o=function(e,t){if(null==e)return{};var n,a,o={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(o[n]=e[n]);return o}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(o[n]=e[n])}return o}var s=a.createContext({}),c=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,o=e.mdxType,i=e.originalType,s=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),m=c(n),d=o,h=m["".concat(s,".").concat(d)]||m[d]||u[d]||i;return n?a.createElement(h,l(l({ref:t},p),{},{components:n})):a.createElement(h,l({ref:t},p))}));function d(e,t){var n=arguments,o=t&&t.mdxType;if("string"==typeof e||o){var i=n.length,l=new Array(i);l[0]=m;var r={};for(var s in t)hasOwnProperty.call(t,s)&&(r[s]=t[s]);r.originalType=e,r.mdxType="string"==typeof e?e:o,l[1]=r;for(var c=2;c<i;c++)l[c]=n[c];return a.createElement.apply(null,l)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},67554:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>l,default:()=>u,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var a=n(87462),o=(n(67294),n(3905));const i={sidebar_position:4090,slug:"2023-09-21",title:"CVAT Semi-automatic and Automatic Annotation",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"CVAT supports supervised machine learning tasks pertaining to object detection, image classification, image segmentation and 3D data annotation."},l=void 0,r={unversionedId:"IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/index",id:"IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/index",title:"CVAT Semi-automatic and Automatic Annotation",description:"CVAT supports supervised machine learning tasks pertaining to object detection, image classification, image segmentation and 3D data annotation.",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation",slug:"/IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/2023-09-21",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/2023-09-21",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-09-21--cvat-automatic-annotation/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4090,frontMatter:{sidebar_position:4090,slug:"2023-09-21",title:"CVAT Semi-automatic and Automatic Annotation",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"CVAT supports supervised machine learning tasks pertaining to object detection, image classification, image segmentation and 3D data annotation."},sidebar:"tutorialSidebar",previous:{title:"Audio Classification with Computer Vision",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-09-23--yolo8-listen/2023-09-23"},next:{title:"Computer Vision Annotation Tool (CVAT) Introduction",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-09-19--cvat-computer-vision-annotation-tool/2023-09-19"}},s={},c=[{value:"Installation (Docker)",id:"installation-docker",level:2},{value:"Installing Nuclio",id:"installing-nuclio",level:3},{value:"Start CVAT",id:"start-cvat",level:3},{value:"Deploy AI Models with Nuclio",id:"deploy-ai-models-with-nuclio",level:3}],p={toc:c};function u(e){let{components:t,...i}=e;return(0,o.kt)("wrapper",(0,a.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"Guangzhou, China",src:n(87367).Z,width:"1500",height:"871"})),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#computer-vision-annotation-tool-cvat"},"Computer Vision Annotation Tool (CVAT)"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#installation-docker"},"Installation (Docker)"),(0,o.kt)("ul",{parentName:"li"},(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#installing-nuclio"},"Installing Nuclio")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#start-cvat"},"Start CVAT")),(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("a",{parentName:"li",href:"#deploy-ai-models-with-nuclio"},"Deploy AI Models with Nuclio"))))))),(0,o.kt)("h1",{id:"computer-vision-annotation-tool-cvat"},"Computer Vision Annotation Tool (CVAT)"),(0,o.kt)("p",null,(0,o.kt)("a",{parentName:"p",href:"https://opencv.github.io/cvat/about/"},"CVAT")," was designed to provide users with a set of convenient instruments for annotating digital images and videos. CVAT supports supervised machine learning tasks pertaining to object detection, image classification, image segmentation and 3D data annotation. It allows users to annotate images with multiple tools (boxes, polygons, cuboids, circles, skeletons, etc)."),(0,o.kt)("h2",{id:"installation-docker"},"Installation (Docker)"),(0,o.kt)("blockquote",null,(0,o.kt)("p",{parentName:"blockquote"},"In the previous note I already started the CVAT containers with a simple ",(0,o.kt)("inlineCode",{parentName:"p"},"docker-compose up -d")," which used the default ",(0,o.kt)("inlineCode",{parentName:"p"},"docker-compose.yml")," file to start the services. They have to be brought down first before continuing with a ",(0,o.kt)("inlineCode",{parentName:"p"},"docker-compose down")," from inside the already existing cvat directory.")),(0,o.kt)("p",null,"Otherwise start by downloading the CVAT source code as follows:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"git clone https://github.com/opencv/cvat\ncd cvat\n")),(0,o.kt)("h3",{id:"installing-nuclio"},"Installing Nuclio"),(0,o.kt)("p",null,"You have to install ",(0,o.kt)("inlineCode",{parentName:"p"},"nuctl")," command line tool to build and deploy serverless functions. Download version ",(0,o.kt)("inlineCode",{parentName:"p"},"1.8.14"),". It is important that the version you download matches the version in ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/cvat-ai/cvat/blob/develop/components/serverless/docker-compose.serverless.yml"},"docker-compose.serverless.yml"),":"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://github.com/nuclio/nuclio/releases/download/1.8.14/nuctl-1.8.14-linux-amd64\n")),(0,o.kt)("p",null,"After downloading the ",(0,o.kt)("inlineCode",{parentName:"p"},"nuclio"),", give it a proper permission and do a softlink:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"sudo chmod +x nuctl-1.8.14-linux-amd64\nsudo ln -sf $(pwd)/nuctl-1.8.14-linux-amd64 /usr/local/bin/nuctl\n")),(0,o.kt)("p",null,"Verify that the installation worked:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'nuctl version\n\nClient version:\n"Label: 1.8.14, Git commit: cbb0774230996a3eb4621c1a2079e2317578005b, OS: linux, Arch: amd64, Go version: go1.17.8 \n')),(0,o.kt)("h3",{id:"start-cvat"},"Start CVAT"),(0,o.kt)("p",null,"To bring up ",(0,o.kt)("inlineCode",{parentName:"p"},"cvat")," with auto annotation tool, from cvat root directory, you need to run:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"export CVAT_HOST=your-ip-address\ndocker-compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml up -d\n")),(0,o.kt)("p",null,"To stop the containers, simply run:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"docker-compose -f docker-compose.yml -f components/serverless/docker-compose.serverless.yml down\n")),(0,o.kt)("p",null,"The CVAT UI is now available on ",(0,o.kt)("inlineCode",{parentName:"p"},"your-ip-address")," with port ",(0,o.kt)("inlineCode",{parentName:"p"},"8080"),"."),(0,o.kt)("h3",{id:"deploy-ai-models-with-nuclio"},"Deploy AI Models with Nuclio"),(0,o.kt)("p",null,"Create ",(0,o.kt)("inlineCode",{parentName:"p"},"cvat")," project inside nuclio dashboard where you will deploy new serverless functions and deploy a couple of DL models. Commands below should be run only after CVAT has been installed using docker-compose because it runs nuclio dashboard which manages all serverless functions:"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"nuctl create project cvat\n")),(0,o.kt)("p",null,"You can verify that the ",(0,o.kt)("inlineCode",{parentName:"p"},"cvat")," project was created by visiting the Nuclio dashboard ",(0,o.kt)("inlineCode",{parentName:"p"},"localhost:8070")," on the host system:"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"CVAT Semi-automatic and Automatic Annotation",src:n(91297).Z,width:"1080",height:"395"})),(0,o.kt)("p",null,"There are a couple of models available in the ",(0,o.kt)("inlineCode",{parentName:"p"},"cvat")," repository located in the ",(0,o.kt)("a",{parentName:"p",href:"https://github.com/opencv/cvat/tree/develop/serverless"},"serverless")," directory. The official documentation gives us a few examples like:"),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"YOLOv7(CPU)"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"nuctl deploy --project-name cvat \\\n  --path serverless/onnx/WongKinYiu/yolov7/nuclio/ \\\n  --volume `pwd`/serverless/common:/opt/nuclio/common \\\n  --platform local\n")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Segment Anything (CPU)"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"nuctl deploy --project-name cvat \\\n  --path serverless/pytorch/facebookresearch/sam/nuclio \\\n  --volume `pwd`/serverless/common:/opt/nuclio/common \\\n  --platform local\n")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"YOLOv3 (CPU)"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},"nuctl deploy --project-name cvat \\\n  --path serverless/openvino/omz/public/yolo-v3-tf/nuclio \\\n  --volume `pwd`/serverless/common:/opt/nuclio/common \\\n  --platform local\n")),(0,o.kt)("ul",null,(0,o.kt)("li",{parentName:"ul"},(0,o.kt)("strong",{parentName:"li"},"Mask RCNN (GPU)"))),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre",className:"language-bash"},'nuctl deploy --project-name cvat \\\n  --path serverless/tensorflow/matterport/mask_rcnn/nuclio \\\n  --platform local --base-image tensorflow/tensorflow:1.15.5-gpu-py3 \\\n  --desc "GPU based implementation of Mask RCNN on Python 3, Keras, and TensorFlow." \\\n  --image cvat/tf.matterport.mask_rcnn_gpu \\\n  --triggers \'{"myHttpTrigger": {"maxWorkers": 1}}\' \\\n  --resource-limit nvidia.com/gpu=1\n')),(0,o.kt)("p",null,"For example running the YOLOv7 command adds the following function:"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"CVAT Semi-automatic and Automatic Annotation",src:n(68235).Z,width:"1080",height:"350"})),(0,o.kt)("p",null,"And the model is also listed in the CVAT UI with all the supported classes:"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"CVAT Semi-automatic and Automatic Annotation",src:n(82421).Z,width:"1191",height:"738"})),(0,o.kt)("p",null,"The model is now listed under ",(0,o.kt)("strong",{parentName:"p"},"AI Tools")," and I can map the classes the model was trained with to my current class labels. And clicking on ",(0,o.kt)("strong",{parentName:"p"},"Annotate")," automatically generates the bounding boxes - that might need a little bit refinement but will save you a ton of time <3:"),(0,o.kt)("p",null,(0,o.kt)("img",{alt:"CVAT Semi-automatic and Automatic Annotation",src:n(90823).Z,width:"1191",height:"648"})))}u.isMDXComponent=!0},91297:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/CVAT_Automatic_Annotation_01-b26cad237fe7c9864fbf451750dc9aa5.png"},68235:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/CVAT_Automatic_Annotation_02-932a57dcf4951d98cc81545940044834.png"},82421:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/CVAT_Automatic_Annotation_03-1ca5e07e17c724bb4dbba11b4f1c8e85.png"},90823:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/CVAT_Automatic_Annotation_04-119f12fa4739263c55faab7944ce0176.png"},87367:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-864be48f76a28ed6a3e155f7ab51bc74.jpg"}}]);