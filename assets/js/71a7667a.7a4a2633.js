"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[31528],{143039:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var t=a(785893),r=a(603905);const o={sidebar_position:4860,slug:"2022-12-21",title:"Tensorflow Downsampling",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Using Representation Learning to Downsample Images"},i=void 0,s={id:"IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/index",title:"Tensorflow Downsampling",description:"Using Representation Learning to Downsample Images",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling",slug:"/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/2022-12-21",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-downsampling/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4860,frontMatter:{sidebar_position:4860,slug:"2022-12-21",title:"Tensorflow Downsampling",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Using Representation Learning to Downsample Images"},sidebar:"tutorialSidebar",previous:{title:"Deep Convolutional Generative Adversarial Network",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-28-tf-gan-image-generator/2022-12-28"},next:{title:"Tensorflow Deep Dream",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-21-tf-deepdream/2022-12-21"}},d={},l=[{value:"Build the Autoencoder",id:"build-the-autoencoder",level:2},{value:"Train the Autoencoder",id:"train-the-autoencoder",level:2},{value:"Evaluation",id:"evaluation",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,r.ah)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Guangzhou, China",src:a(91382).Z+"",width:"1500",height:"383"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#build-the-autoencoder",children:"Build the Autoencoder"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#train-the-autoencoder",children:"Train the Autoencoder"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#evaluation",children:"Evaluation"})}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Using ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-12-20-tf-representation/2022-12-19",children:"Representation Learning"})," to downsample images."]}),"\n",(0,t.jsx)(n.h2,{id:"build-the-autoencoder",children:"Build the Autoencoder"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:'# build autoencoder model\nautoencoder = tf.keras.models.Sequential()\n\n# build the encoder CNN\nautoencoder.add(tf.keras.layers.Conv2D(64, (3,3), strides=1, padding="same", input_shape=(32, 32, 3)))\nautoencoder.add(tf.keras.layers.BatchNormalization())\nautoencoder.add(tf.keras.layers.Activation(\'relu\'))\nautoencoder.add(tf.keras.layers.AveragePooling2D((2,2), padding="same"))\n\nautoencoder.add(tf.keras.layers.Conv2D(32, (3,3), strides=1, padding="same"))\nautoencoder.add(tf.keras.layers.BatchNormalization())\nautoencoder.add(tf.keras.layers.Activation(\'relu\'))\n\n# representation layer\nautoencoder.add(tf.keras.layers.AveragePooling2D((2,2), padding="same"))\n\n# build the decoder CNN \nautoencoder.add(tf.keras.layers.BatchNormalization())\nautoencoder.add(tf.keras.layers.Activation(\'relu\'))\nautoencoder.add(tf.keras.layers.UpSampling2D((2, 2)))\n\nautoencoder.add(tf.keras.layers.Conv2D(64, (3,3), strides=1, padding="same"))\nautoencoder.add(tf.keras.layers.BatchNormalization())\nautoencoder.add(tf.keras.layers.Activation(\'relu\'))\nautoencoder.add(tf.keras.layers.UpSampling2D((2, 2)))\n\nautoencoder.add(tf.keras.layers.Conv2D(3, (3,3), strides=1, activation=\'sigmoid\', padding="same"))\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"# compile model\nautoencoder.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.01))\nautoencoder.summary()\n"})}),"\n",(0,t.jsx)(n.h2,{id:"train-the-autoencoder",children:"Train the Autoencoder"}),"\n",(0,t.jsxs)(n.p,{children:["Before I used ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-12-20-tf-representation/2022-12-19",children:"Representation Learning to remove digital noise from image files"}),". There we needed to compare the generated image from our CNN layers with a noise-free version of the image as a performance metric. For downsampling we need to compare the de-compressed image to the original image - the model first compresses features (encoding) and then de-compresses them (decoding) to try to match the original input:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"# fit model to dataset\nautoencoder.fit(X_train,          \n          X_train, \n          epochs=20, \n          batch_size=200, \n          validation_data=(X_test, X_test))\n"})}),"\n",(0,t.jsx)(n.h2,{id:"evaluation",children:"Evaluation"}),"\n",(0,t.jsx)(n.p,{children:"And we end up with a lightly compressed version of the input images:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"# test training\n# take 15 images from test set and predict compressed image\npredicted = autoencoder.predict(X_test[:10].reshape(-1, 32, 32, 3))\n# plot input vs output\nfig, axes = plt.subplots(nrows=2, ncols=10, sharex=True, sharey=True, figsize=(20,4))\nfor images, row in zip([X_test[:10], predicted], axes):\n    for img, ax in zip(images, row):\n        ax.imshow(img.reshape((32, 32, 3)))\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\nplt.show()\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Tensorflow Transfer Learning",src:a(121065).Z+"",width:"1573",height:"319"})})]})}function p(e={}){const{wrapper:n}={...(0,r.ah)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},603905:(e,n,a)=>{a.d(n,{ah:()=>l});var t=a(667294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function o(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function i(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?o(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function s(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var d=t.createContext({}),l=function(e){var n=t.useContext(d),a=n;return e&&(a="function"==typeof e?e(n):i(i({},n),e)),a},c={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},p=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,o=e.originalType,d=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=l(a),h=r,g=u["".concat(d,".").concat(h)]||u[h]||c[h]||o;return a?t.createElement(g,i(i({ref:n},p),{},{components:a})):t.createElement(g,i({ref:n},p))}));p.displayName="MDXCreateElement"},121065:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/Tensorflow_Transfer_Learning_01-bcedf01b351e75791b7d551b984abefd.png"},91382:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-918471126c0472aad97358a725e1a399.jpg"}}]);