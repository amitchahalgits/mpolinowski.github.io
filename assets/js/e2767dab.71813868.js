"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[51525],{225508:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>r,contentTitle:()=>o,default:()=>p,frontMatter:()=>s,metadata:()=>l,toc:()=>c});var i=a(474848),t=a(28453);const s={sidebar_position:4250,slug:"2023-08-06",title:"Tensorflow Image Classifier - InceptionV3",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Blue print image classifier using Tensorflow and Keras Applications pre-trained models"},o="Tf Image Classifier",l={id:"IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/index",title:"Tensorflow Image Classifier - InceptionV3",description:"Blue print image classifier using Tensorflow and Keras Applications pre-trained models",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3",slug:"/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/2023-08-06",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/2023-08-06",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4250,frontMatter:{sidebar_position:4250,slug:"2023-08-06",title:"Tensorflow Image Classifier - InceptionV3",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Blue print image classifier using Tensorflow and Keras Applications pre-trained models"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow Image Classifier - MobileNetV2",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-07-tensorflow-i-know-flowers-mobilenetv2/2023-08-07"},next:{title:"Tensorflow Image Classifier - EfficientNetV2S",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-05-tensorflow-i-know-flowers-efficientnetv2s/2023-08-05"}},r={},c=[{value:"InceptionV3",id:"inceptionv3",level:2},{value:"Dataset",id:"dataset",level:2},{value:"Building the InceptionV3 TF Model",id:"building-the-inceptionv3-tf-model",level:2},{value:"Model Training",id:"model-training",level:3},{value:"Model Evaluation",id:"model-evaluation",level:3},{value:"Model Finetuning",id:"model-finetuning",level:3},{value:"Model Evaluation",id:"model-evaluation-1",level:3},{value:"Saving the Model",id:"saving-the-model",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Angkor Wat, Cambodia",src:a(351306).A+"",width:"1500",height:"706"})}),"\n",(0,i.jsx)(n.h1,{id:"tf-image-classifier",children:"Tf Image Classifier"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-08-01-tensorflow-i-know-flowers-intro/2023-08-01",children:"Overview - Model Evaluation & Deployment"})}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"inceptionv3",children:"InceptionV3"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay)\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.io import TFRecordWriter\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.callbacks  import (\n    Callback,\n    CSVLogger,\n    EarlyStopping,\n    LearningRateScheduler,\n    ModelCheckpoint\n)\nfrom tensorflow.keras.layers import (\n    Layer,\n    GlobalAveragePooling2D,\n    Conv2D,\n    MaxPool2D,\n    Dense,\n    Flatten,\n    InputLayer,\n    BatchNormalization,\n    Input,\n    Dropout,\n    RandomFlip,\n    RandomRotation,\n    RandomContrast,\n    RandomBrightness,\n    Resizing,\n    Rescaling\n)\nfrom tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy, SparseCategoricalAccuracy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import L2, L1\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow.train import Feature, Features, Example, BytesList, Int64List\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"BATCH = 32\nSIZE = 224\nSEED = 42\n\nEPOCHS = 20\nLR = 0.001\nFILTERS = 6\nKERNEL = 3\nSTRIDES = 1\nREGRATE = 0.0\nPOOL = 2\nDORATE = 0.05\nLABELS = ['Gladiolus', 'Adenium', 'Alpinia_Purpurata', 'Alstroemeria', 'Amaryllis', 'Anthurium_Andraeanum', 'Antirrhinum', 'Aquilegia', 'Billbergia_Pyramidalis', 'Cattleya', 'Cirsium', 'Coccinia_Grandis', 'Crocus', 'Cyclamen', 'Dahlia', 'Datura_Metel', 'Dianthus_Barbatus', 'Digitalis', 'Echinacea_Purpurea', 'Echinops_Bannaticus', 'Fritillaria_Meleagris', 'Gaura', 'Gazania', 'Gerbera', 'Guzmania', 'Helianthus_Annuus', 'Iris_Pseudacorus', 'Leucanthemum', 'Malvaceae', 'Narcissus_Pseudonarcissus', 'Nerine', 'Nymphaea_Tetragona', 'Paphiopedilum', 'Passiflora', 'Pelargonium', 'Petunia', 'Platycodon_Grandiflorus', 'Plumeria', 'Poinsettia', 'Primula', 'Protea_Cynaroides', 'Rose', 'Rudbeckia', 'Strelitzia_Reginae', 'Tropaeolum_Majus', 'Tussilago', 'Viola', 'Zantedeschia_Aethiopica']\nNLABELS = len(LABELS)\nDENSE1 = 1024\nDENSE2 = 128\n"})}),"\n",(0,i.jsx)(n.h2,{id:"dataset",children:"Dataset"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"train_directory = '../dataset/Flower_Dataset/split/train'\ntest_directory = '../dataset/Flower_Dataset/split/val'\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"train_dataset = image_dataset_from_directory(\n    train_directory,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=LABELS,\n    color_mode='rgb',\n    batch_size=BATCH,\n    image_size=(SIZE, SIZE),\n    shuffle=True,\n    seed=SEED,\n    interpolation='bilinear',\n    follow_links=False,\n    crop_to_aspect_ratio=False\n)\n\n# Found 9206 files belonging to 48 classes.\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"test_dataset = image_dataset_from_directory(\n    test_directory,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=LABELS,\n    color_mode='rgb',\n    batch_size=BATCH,\n    image_size=(SIZE, SIZE),\n    shuffle=True,\n    seed=SEED\n)\n\n# Found 3090 files belonging to 48 classes.\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"data_augmentation = Sequential([\n        # Resizing(224, 224),\n        RandomRotation(factor=0.25),\n        RandomFlip(mode='horizontal'),\n        RandomContrast(factor=0.1),\n        RandomBrightness(0.1)\n    ],\n    name=\"img_augmentation\",\n)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"training_dataset = (\n    train_dataset\n    .map(lambda image, label: (data_augmentation(image), label))\n    .prefetch(tf.data.AUTOTUNE)\n)\n\n\ntesting_dataset = (\n    test_dataset.prefetch(\n        tf.data.AUTOTUNE\n    )\n)\n"})}),"\n",(0,i.jsx)(n.h2,{id:"building-the-inceptionv3-tf-model",children:"Building the InceptionV3 TF Model"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# transfer learning\n\nbackbone = tf.keras.applications.InceptionV3(\n    input_shape=(SIZE, SIZE, 3),\n    include_top=False,\n    weights="imagenet"\n)\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"backbone.trainable = False\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"input = Input(shape=(SIZE,SIZE,3))\nx = backbone(input, training=False)\n\nx = GlobalAveragePooling2D()(x)\nx = Dense(DENSE1, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dense(DENSE2, activation='relu')(x)\n\noutput = Dense(NLABELS, activation='softmax')(x)\n\ninception_model = Model(input, output)\ninception_model.summary()\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"checkpoint_callback = ModelCheckpoint(\n    '../best_weights',\n    monitor='val_accuracy',\n    mode='max',\n    verbose=1,\n    save_best_only=True\n)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"early_stopping_callback = EarlyStopping(\n    monitor='val_accuracy',\n    patience=10,\n    restore_best_weights=True\n)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"loss_function = CategoricalCrossentropy()\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"metrics = [CategoricalAccuracy(name='accuracy')]\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"inception_model.compile(\n    optimizer = Adam(learning_rate=LR),\n    loss = loss_function,\n    metrics = metrics\n)\n"})}),"\n",(0,i.jsx)(n.h3,{id:"model-training",children:"Model Training"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"inception_history = inception_model.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    verbose = 1,\n    # callbacks=[checkpoint_callback, early_stopping_callback]\n)\n\n# loss: 2.6270\n# accuracy: 0.2870\n# val_loss: 2.8781\n# val_accuracy: 0.2502\n"})}),"\n",(0,i.jsx)(n.h3,{id:"model-evaluation",children:"Model Evaluation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"inception_model.evaluate(testing_dataset)\n# loss: 2.8781 - accuracy: 0.2502\n"})}),"\n",(0,i.jsx)(n.h3,{id:"model-finetuning",children:"Model Finetuning"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"for i, layer in enumerate(backbone.layers):\n   print(i, layer.name)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 249 layers and unfreeze the rest:\nfor layer in backbone.layers[:249]:\n   layer.trainable = False\nfor layer in backbone.layers[249:]:\n   layer.trainable = True\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"inception_model.compile(\n    optimizer=SGD(learning_rate=0.0001, momentum=0.9),\n    loss = loss_function,\n    metrics = metrics\n)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"inception_history = inception_model.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    shuffle=True,\n    verbose = 1,\n    # callbacks=[checkpoint_callback, early_stopping_callback]\n)\n\n# loss: 2.4939\n# accuracy: 0.3194\n# val_loss: 2.7004\n# val_accuracy: 0.3100\n"})}),"\n",(0,i.jsx)(n.h3,{id:"model-evaluation-1",children:"Model Evaluation"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"inception_model.evaluate(testing_dataset)\n# loss: 2.7047 - accuracy: 0.3087\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"plt.plot(inception_history.history['loss'])\nplt.plot(inception_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss', 'val_loss'])\nplt.savefig('assets/InceptionV3_FT_01.webp', bbox_inches='tight')\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"tf Emotion Detection",src:a(445934).A+"",width:"576",height:"455"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"plt.plot(inception_history.history['accuracy'])\nplt.plot(inception_history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train_accuracy', 'val_accuracy'])\nplt.savefig('assets/InceptionV3_FT_02.webp', bbox_inches='tight')\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"tf Emotion Detection",src:a(5231).A+"",width:"584",height:"455"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"test_image_bgr = cv.imread('../dataset/snapshots/Viola_Tricolor.jpg')\ntest_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\ntest_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\nimg = tf.constant(test_image_rgb, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nprobs = inception_model(img).numpy()\nlabel = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n\nprint(label, str(probs[0]))\n\nplt.imshow(test_image_rgb)\nplt.title(label)\nplt.axis('off')\n        \nplt.savefig('assets/InceptionV3_Prediction_01.webp', bbox_inches='tight')\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"tf Emotion Detection",src:a(144699).A+"",width:"389",height:"411"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"test_image_bgr = cv.imread('../dataset/snapshots/Strelitzia.jpg')\ntest_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\ntest_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\nimg = tf.constant(test_image_rgb, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nprobs = inception_model(img).numpy()\nlabel = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n\nprint(label, str(probs[0]))\n\nplt.imshow(test_image_rgb)\nplt.title(label)\nplt.axis('off')\n        \nplt.savefig('assets/InceptionV3_Prediction_02.webp', bbox_inches='tight')\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"tf Emotion Detection",src:a(465178).A+"",width:"389",height:"411"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"test_image_bgr = cv.imread('../dataset/snapshots/Water_Lilly.jpg')\ntest_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\ntest_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\nimg = tf.constant(test_image_rgb, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nprobs = inception_model(img).numpy()\nlabel = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n\nprint(label, str(probs[0]))\n\nplt.imshow(test_image_rgb)\nplt.title(label)\nplt.axis('off')\n        \nplt.savefig('assets/InceptionV3_Prediction_03.webp', bbox_inches='tight')\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"tf Emotion Detection",src:a(186277).A+"",width:"389",height:"411"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"plt.figure(figsize=(16,16))\n\nfor images, labels in testing_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n        pred = \"Predicted: \" + LABELS[\n            tf.argmax(inception_model(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n        ]\n        plt.title(\n           true  + \"\\n\" + pred\n        )\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/InceptionV3_FT_03.webp', bbox_inches='tight')\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"tf Emotion Detection",src:a(848012).A+"",width:"1281",height:"1295"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"y_pred = []\ny_test = []\n\nfor img, label in testing_dataset:\n    y_pred.append(inception_model(img))\n    y_test.append(label.numpy())\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"conf_mtx = ConfusionMatrixDisplay(\n    confusion_matrix=confusion_matrix(\n        np.argmax(y_test[:-1], axis=-1).flatten(),\n        np.argmax(y_pred[:-1], axis=-1).flatten()\n    ),\n    display_labels=LABELS\n)\n\nfig, ax = plt.subplots(figsize=(16,12))\nconf_mtx.plot(ax=ax, cmap='plasma', include_values=True, xticks_rotation='vertical')\n\nplt.savefig('assets/InceptionV3_FT_04.webp', bbox_inches='tight')\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"tf Emotion Detection",src:a(76541).A+"",width:"1296",height:"1160"})}),"\n",(0,i.jsx)(n.h3,{id:"saving-the-model",children:"Saving the Model"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"tf.keras.saving.save_model(\n    inception_model, 'saved_model/inception_model_model_ft', overwrite=True, save_format='tf'\n)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# restore the model\nrestored_model2 = tf.keras.saving.load_model('saved_model/inception_model_model_ft')\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Check its architecture\nrestored_model2.summary()\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"restored_model2.evaluate(testing_dataset)\n# loss: 2.7047 - accuracy: 0.3087\n"})})]})}function p(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},445934:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/InceptionV3_FT_01-453cbc1b1730b63b64f0d35fe0c7d6bb.webp"},5231:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/InceptionV3_FT_02-b2f8b00b9867e437c9344426c03505e2.webp"},848012:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/InceptionV3_FT_03-01be415085ace69506fa6420a151498d.webp"},76541:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/InceptionV3_FT_04-683824ef7291010195b78e09b785d88c.webp"},144699:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/InceptionV3_Prediction_01-55f51bba4706932addf74296189b10f5.webp"},465178:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/InceptionV3_Prediction_02-27f7f31dc410aabd3b056828d7eef7e1.webp"},186277:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/InceptionV3_Prediction_03-b3822b2df41cf5c12b352b10bef1b23b.webp"},351306:(e,n,a)=>{a.d(n,{A:()=>i});const i=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-4b4c922f390788acb724c3c274da1ef9.jpg"},28453:(e,n,a)=>{a.d(n,{R:()=>o,x:()=>l});var i=a(296540);const t={},s=i.createContext(t);function o(e){const n=i.useContext(s);return i.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),i.createElement(s.Provider,{value:n},e.children)}}}]);