"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[75351],{136651:(e,r,s)=>{s.r(r),s.d(r,{assets:()=>a,contentTitle:()=>d,default:()=>h,frontMatter:()=>t,metadata:()=>l,toc:()=>o});var n=s(474848),i=s(28453);const t={sidebar_position:4710,slug:"2023-02-01",title:"Apache Airflow Introduction",authors:"mpolinowski",tags:["Python","Machine Learning","Airflow"],description:"Airflow is a platform to author, schedule and monitor workflows."},d=void 0,l={id:"IoT-and-Machine-Learning/AIOps/2023-02-01-apache-airflow-introduction/index",title:"Apache Airflow Introduction",description:"Airflow is a platform to author, schedule and monitor workflows.",source:"@site/docs/IoT-and-Machine-Learning/AIOps/2023-02-01-apache-airflow-introduction/index.md",sourceDirName:"IoT-and-Machine-Learning/AIOps/2023-02-01-apache-airflow-introduction",slug:"/IoT-and-Machine-Learning/AIOps/2023-02-01-apache-airflow-introduction/2023-02-01",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-02-01-apache-airflow-introduction/2023-02-01",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/AIOps/2023-02-01-apache-airflow-introduction/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Airflow",permalink:"/docs/tags/airflow"}],version:"current",sidebarPosition:4710,frontMatter:{sidebar_position:4710,slug:"2023-02-01",title:"Apache Airflow Introduction",authors:"mpolinowski",tags:["Python","Machine Learning","Airflow"],description:"Airflow is a platform to author, schedule and monitor workflows."},sidebar:"tutorialSidebar",previous:{title:"Apache Airflow Data Pipelines",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-02-04-apache-airflow-data-pipelines/2023-02-04"},next:{title:"Python Ray Model Serving",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-31-python-ray-model-serving/2023-01-31"}},a={},o=[{value:"Introduction",id:"introduction",level:2},{value:"Installation with Docker",id:"installation-with-docker",level:2},{value:"Command Line Interface",id:"command-line-interface",level:3},{value:"CLI Cheat Sheet",id:"cli-cheat-sheet",level:4},{value:"Common Commands",id:"common-commands",level:4}];function c(e){const r={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(r.p,{children:(0,n.jsx)(r.img,{alt:"Guangzhou, China",src:s(825993).A+"",width:"1061",height:"405"})}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsx)(r.li,{children:(0,n.jsx)(r.a,{href:"#introduction",children:"Introduction"})}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"#installation-with-docker",children:"Installation with Docker"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.a,{href:"#command-line-interface",children:"Command Line Interface"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsx)(r.li,{children:(0,n.jsx)(r.a,{href:"#cli-cheat-sheet",children:"CLI Cheat Sheet"})}),"\n",(0,n.jsx)(r.li,{children:(0,n.jsx)(r.a,{href:"#common-commands",children:"Common Commands"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsx)(r.p,{children:(0,n.jsx)(r.a,{href:"/docs/IoT-and-Machine-Learning/AIOps/2023-02-04-apache-airflow-data-pipelines/2023-02-04",children:"Apache Airflow Data Pipelines"})}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsx)(r.p,{children:(0,n.jsx)(r.a,{href:"/docs/IoT-and-Machine-Learning/AIOps/2023-02-05-apache-airflow-scheduler/2023-02-05",children:"Apache Airflow DAG Scheduling"})}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsx)(r.p,{children:(0,n.jsx)(r.a,{href:"/docs/IoT-and-Machine-Learning/AIOps/2023-02-06-apache-airflow-dynamic-dags/2023-02-06",children:"Apache Airflow Dynamic DAGs"})}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsx)(r.p,{children:(0,n.jsx)(r.a,{href:"https://github.com/mpolinowski/apache-airflow-intro",children:"Github Repository"})}),"\n"]}),"\n"]}),"\n",(0,n.jsxs)(r.p,{children:["I have been ",(0,n.jsx)(r.a,{href:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-22-python-ray-introduction/2023-01-22",children:"looking into Python Ray"})," to provision / update ML models for prediction API. In my research I have been hearing about two alternative platforms that supposedly offer the same or similar benefits to MLOps workflows. So before diving into the nitty, gritty details of Ray let's take a look at the alternatives - ",(0,n.jsx)(r.a,{href:"https://airflow.apache.org/",children:"Apache Airflow"})," and the Kubernetes native ",(0,n.jsx)(r.a,{href:"https://www.kubeflow.org/",children:"Kubeflow"}),". So let's start with Airflow."]}),"\n",(0,n.jsx)(r.h2,{id:"introduction",children:"Introduction"}),"\n",(0,n.jsx)(r.p,{children:"Apache Airflow is an open-source platform for developing, scheduling, and monitoring batch-oriented workflows. Airflow\u2019s extensible Python framework enables you to build workflows connecting with virtually any technology. A web interface helps manage the state of your workflows. Airflow is deployable in many ways, varying from a single process on your laptop to a distributed setup to support even the biggest workflows."}),"\n",(0,n.jsxs)(r.p,{children:["The main characteristic of Airflow workflows is that all workflows are defined in Python code allowing us to write dynamic ",(0,n.jsx)(r.em,{children:"Data Pipelines"})," called ",(0,n.jsx)(r.strong,{children:"DAG"}),"'s (",(0,n.jsx)(r.a,{href:"https://medium.com/hashmapinc/building-ml-pipelines-8e27344a42d2",children:"Directed Acyclic Graph"}),") \u2014 a mathematical abstraction of a pipeline. \u201cWorkflows as code\u201d serves several purposes:"]}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Dynamic"}),": Airflow pipelines are configured as Python code, allowing for dynamic pipeline generation."]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Extensible"}),": The Airflow framework contains operators to connect with numerous technologies. All Airflow components are extensible to easily adjust to your environment."]}),"\n"]}),"\n",(0,n.jsxs)(r.li,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Flexible"}),": Workflow parameterization is built-in leveraging the Jinja templating engine."]}),"\n"]}),"\n"]}),"\n",(0,n.jsx)(r.h2,{id:"installation-with-docker",children:"Installation with Docker"}),"\n",(0,n.jsxs)(r.p,{children:["Clone the Github Repository (linked above) and enter the ",(0,n.jsx)(r.code,{children:"docker"})," directory. Here you find a ",(0,n.jsx)(r.strong,{children:"Dockerfile"})," and shell script we will need to start Airflow inside a Docker container."]}),"\n",(0,n.jsxs)(r.blockquote,{children:["\n",(0,n.jsxs)(r.p,{children:[(0,n.jsx)(r.strong,{children:"Note"})," that the shell script contains instructions to create the default admin user. You can change the login credentials there - the ",(0,n.jsx)(r.strong,{children:"default login"})," is set to ",(0,n.jsx)(r.code,{children:"admin"}),"/",(0,n.jsx)(r.code,{children:"admin"}),"."]}),"\n"]}),"\n",(0,n.jsx)(r.p,{children:"We can build the Docker image by running the following command inside the directory:"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-bash",children:"docker build -t airflow-postgres .\n"})}),"\n",(0,n.jsxs)(r.p,{children:["This will download the official Python Docker image as base and installs the latest version of Airflow (currently ",(0,n.jsx)(r.code,{children:"v2.5.1"})," with support for Python ",(0,n.jsx)(r.code,{children:"v3.10"}),")."]}),"\n",(0,n.jsx)(r.p,{children:"You can now run the container exposing the WebUI port using:"}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-bash",children:"docker run --rm -d -p 8080:8080 --name airflow airflow-postgres\n"})}),"\n",(0,n.jsxs)(r.p,{children:["You can visit the WebUI on ",(0,n.jsx)(r.code,{children:"http://localhost:8080"})," and login with the user that was created by the shell script:"]}),"\n",(0,n.jsx)(r.p,{children:(0,n.jsx)(r.img,{alt:"Apache Airflow Introduction",src:s(954293).A+"",width:"953",height:"441"})}),"\n",(0,n.jsx)(r.p,{children:"We now have access to the user interface and can take control over workflows:"}),"\n",(0,n.jsx)(r.p,{children:(0,n.jsx)(r.img,{alt:"Apache Airflow Introduction",src:s(352190).A+"",width:"1395",height:"618"})}),"\n",(0,n.jsx)(r.h3,{id:"command-line-interface",children:"Command Line Interface"}),"\n",(0,n.jsxs)(r.p,{children:["Besides the web interface we can also interact with Airflow through it's CLI interface. Since Airflow is running inside the ",(0,n.jsx)(r.code,{children:"airflow"})," Docker container we first have to access this environment:"]}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-bash",children:"docker exec -ti airflow /bin/bash\n"})}),"\n",(0,n.jsx)(r.pre,{children:(0,n.jsx)(r.code,{className:"language-bash",children:"usage: airflow [-h] GROUP_OR_COMMAND ...\n\npositional arguments:\n  GROUP_OR_COMMAND\n\n    Groups:\n      celery         Celery components\n      config         View configuration\n      connections    Manage connections\n      dags           Manage DAGs\n      db             Database operations\n      jobs           Manage jobs\n      kubernetes     Tools to help run the KubernetesExecutor\n      pools          Manage pools\n      providers      Display providers\n      roles          Manage roles\n      tasks          Manage tasks\n      users          Manage users\n      variables      Manage variables\n\n    Commands:\n      cheat-sheet    Display cheat sheet\n      dag-processor  Start a standalone Dag Processor instance\n      info           Show information about current Airflow and environment\n      kerberos       Start a kerberos ticket renewer\n      plugins        Dump information about loaded plugins\n      rotate-fernet-key\n                     Rotate encrypted connection credentials and variables\n      scheduler      Start a scheduler instance\n      standalone     Run an all-in-one copy of Airflow\n      sync-perm      Update permissions for existing roles and optionally DAGs\n      triggerer      Start a triggerer instance\n      version        Show the version\n      webserver      Start a Airflow webserver instanc\n"})}),"\n",(0,n.jsx)(r.h4,{id:"cli-cheat-sheet",children:"CLI Cheat Sheet"}),"\n",(0,n.jsxs)(r.table,{children:[(0,n.jsx)(r.thead,{children:(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.th,{children:"Commands"}),(0,n.jsx)(r.th,{children:"Description"})]})}),(0,n.jsxs)(r.tbody,{children:[(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Miscellaneous commands"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow cheat-sheet"}),(0,n.jsx)(r.td,{children:"Display cheat sheet"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dag-processor"}),(0,n.jsx)(r.td,{children:"Start a standalone Dag Processor instance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow info"}),(0,n.jsx)(r.td,{children:"Show information about current Airflow and environment"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow kerberos"}),(0,n.jsx)(r.td,{children:"Start a kerberos ticket renewer"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow plugins"}),(0,n.jsx)(r.td,{children:"Dump information about loaded plugins"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow rotate-fernet-key"}),(0,n.jsx)(r.td,{children:"Rotate encrypted connection credentials and variables"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow scheduler"}),(0,n.jsx)(r.td,{children:"Start a scheduler instance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow standalone"}),(0,n.jsx)(r.td,{children:"Run an all-in-one copy of Airflow"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow sync-perm"}),(0,n.jsx)(r.td,{children:"Update permissions for existing roles and optionally DAGs"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow triggerer"}),(0,n.jsx)(r.td,{children:"Start a triggerer instance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow version"}),(0,n.jsx)(r.td,{children:"Show the version"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow webserver"}),(0,n.jsx)(r.td,{children:"Start a Airflow webserver instance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Celery components"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow celery flower"}),(0,n.jsx)(r.td,{children:"Start a Celery Flower"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow celery stop"}),(0,n.jsx)(r.td,{children:"Stop the Celery worker gracefully"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow celery worker"}),(0,n.jsx)(r.td,{children:"Start a Celery worker node"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"View configuration"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow config get-value"}),(0,n.jsx)(r.td,{children:"Print the value of the configuration"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow config list"}),(0,n.jsx)(r.td,{children:"List options for the configuration"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Manage connections"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow connections add"}),(0,n.jsx)(r.td,{children:"Add a connection"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow connections delete"}),(0,n.jsx)(r.td,{children:"Delete a connection"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow connections export"}),(0,n.jsx)(r.td,{children:"Export all connections"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow connections get"}),(0,n.jsx)(r.td,{children:"Get a connection"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow connections import"}),(0,n.jsx)(r.td,{children:"Import connections from a file"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow connections list"}),(0,n.jsx)(r.td,{children:"List connections"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Manage DAGs"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags backfill"}),(0,n.jsx)(r.td,{children:"Run subsections of a DAG for a specified date range"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags delete"}),(0,n.jsx)(r.td,{children:"Delete all DB records related to the specified DAG"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags list"}),(0,n.jsx)(r.td,{children:"List all the DAGs"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags list-import-errors"}),(0,n.jsx)(r.td,{children:"List all the DAGs that have import errors"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags list-jobs"}),(0,n.jsx)(r.td,{children:"List the jobs"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags list-runs"}),(0,n.jsx)(r.td,{children:"List DAG runs given a DAG id"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags next-execution"}),(0,n.jsx)(r.td,{children:"Get the next execution datetimes of a DAG"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags pause"}),(0,n.jsx)(r.td,{children:"Pause a DAG"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags report"}),(0,n.jsx)(r.td,{children:"Show DagBag loading report"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags reserialize"}),(0,n.jsx)(r.td,{children:"Reserialize all DAGs by parsing the DagBag files"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags show"}),(0,n.jsx)(r.td,{children:"Displays DAG's tasks with their dependencies"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags show-dependencies"}),(0,n.jsx)(r.td,{children:"Displays DAGs with their dependencies"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags state"}),(0,n.jsx)(r.td,{children:"Get the status of a dag run"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags test"}),(0,n.jsx)(r.td,{children:"Execute one single DagRun"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags trigger"}),(0,n.jsx)(r.td,{children:"Trigger a DAG run"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow dags unpause"}),(0,n.jsx)(r.td,{children:"Resume a paused DAG"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Database operations"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow db check"}),(0,n.jsx)(r.td,{children:"Check if the database can be reached"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow db check-migrations"}),(0,n.jsx)(r.td,{children:"Check if migration have finished"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow db clean"}),(0,n.jsx)(r.td,{children:"Purge old records in metastore tables"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow db downgrade"}),(0,n.jsx)(r.td,{children:"Downgrade the schema of the metadata database."})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow db init"}),(0,n.jsx)(r.td,{children:"Initialize the metadata database"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow db reset"}),(0,n.jsx)(r.td,{children:"Burn down and rebuild the metadata database"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow db shell"}),(0,n.jsx)(r.td,{children:"Runs a shell to access the database"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow db upgrade"}),(0,n.jsx)(r.td,{children:"Upgrade the metadata database to latest version"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Manage jobs"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow jobs check"}),(0,n.jsx)(r.td,{children:"Checks if job(s) are still alive"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Tools to help run the KubernetesExecutor"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow kubernetes cleanup-pods"}),(0,n.jsx)(r.td,{children:"Clean up Kubernetes pods (created by KubernetesExecutor/KubernetesPodOperator) in evicted/failed/succeeded/pending states"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow kubernetes generate-dag-yaml"}),(0,n.jsx)(r.td,{children:"Generate YAML files for all tasks in DAG. Useful for debugging tasks without launching into a cluster"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Manage pools"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow pools delete"}),(0,n.jsx)(r.td,{children:"Delete pool"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow pools export"}),(0,n.jsx)(r.td,{children:"Export all pools"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow pools get"}),(0,n.jsx)(r.td,{children:"Get pool size"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow pools import"}),(0,n.jsx)(r.td,{children:"Import pools"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow pools list"}),(0,n.jsx)(r.td,{children:"List pools"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow pools set"}),(0,n.jsx)(r.td,{children:"Configure pool"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Display providers"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow providers auth"}),(0,n.jsx)(r.td,{children:"Get information about API auth backends provided"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow providers behaviours"}),(0,n.jsx)(r.td,{children:"Get information about registered connection types with custom behaviours"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow providers get"}),(0,n.jsx)(r.td,{children:"Get detailed information about a provider"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow providers hooks"}),(0,n.jsx)(r.td,{children:"List registered provider hooks"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow providers links"}),(0,n.jsx)(r.td,{children:"List extra links registered by the providers"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow providers list"}),(0,n.jsx)(r.td,{children:"List installed providers"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow providers logging"}),(0,n.jsx)(r.td,{children:"Get information about task logging handlers provided"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow providers secrets"}),(0,n.jsx)(r.td,{children:"Get information about secrets backends provided"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow providers widgets"}),(0,n.jsx)(r.td,{children:"Get information about registered connection form widgets"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Manage roles"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow roles add-perms"}),(0,n.jsx)(r.td,{children:"Add roles permissions"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow roles create"}),(0,n.jsx)(r.td,{children:"Create role"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow roles del-perms"}),(0,n.jsx)(r.td,{children:"Delete roles permissions"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow roles delete"}),(0,n.jsx)(r.td,{children:"Delete role"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow roles export"}),(0,n.jsx)(r.td,{children:"Export roles (without permissions) from db to JSON file"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow roles import"}),(0,n.jsx)(r.td,{children:"Import roles (without permissions) from JSON file to db"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow roles list"}),(0,n.jsx)(r.td,{children:"List roles"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Manage tasks"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow tasks clear"}),(0,n.jsx)(r.td,{children:"Clear a set of task instance, as if they never ran"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow tasks failed-deps"}),(0,n.jsx)(r.td,{children:"Returns the unmet dependencies for a task instance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow tasks list"}),(0,n.jsx)(r.td,{children:"List the tasks within a DAG"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow tasks render"}),(0,n.jsx)(r.td,{children:"Render a task instance's template(s)"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow tasks run"}),(0,n.jsx)(r.td,{children:"Run a single task instance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow tasks state"}),(0,n.jsx)(r.td,{children:"Get the status of a task instance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow tasks states-for-dag-run"}),(0,n.jsx)(r.td,{children:"Get the status of all task instances in a dag run"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow tasks test"}),(0,n.jsx)(r.td,{children:"Test a task instance"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Manage users"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow users add-role"}),(0,n.jsx)(r.td,{children:"Add role to a user"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow users create"}),(0,n.jsx)(r.td,{children:"Create a user"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow users delete"}),(0,n.jsx)(r.td,{children:"Delete a user"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow users export"}),(0,n.jsx)(r.td,{children:"Export all users"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow users import"}),(0,n.jsx)(r.td,{children:"Import users"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow users list"}),(0,n.jsx)(r.td,{children:"List users"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow users remove-role"}),(0,n.jsx)(r.td,{children:"Remove role from a user"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:(0,n.jsx)(r.strong,{children:"Manage variables"})}),(0,n.jsx)(r.td,{})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow variables delete"}),(0,n.jsx)(r.td,{children:"Delete variable"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow variables export"}),(0,n.jsx)(r.td,{children:"Export all variables"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow variables get"}),(0,n.jsx)(r.td,{children:"Get variable"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow variables import"}),(0,n.jsx)(r.td,{children:"Import variables"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow variables list"}),(0,n.jsx)(r.td,{children:"List variables"})]}),(0,n.jsxs)(r.tr,{children:[(0,n.jsx)(r.td,{children:"airflow variables set"}),(0,n.jsx)(r.td,{children:"Set variable"})]})]})]}),"\n",(0,n.jsx)(r.h4,{id:"common-commands",children:"Common Commands"}),"\n",(0,n.jsxs)(r.ul,{children:["\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow db init"}),": Initialise the metadatabase"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow db reset"}),":  Reinitialize the metadatabase (Drop everything)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow db upgrade"}),": Upgrade the metadatabase (Latest schemas, values, ...)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow webserver"}),": Start Airflow\u2019s webserver"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow scheduler"}),": Start Airflow\u2019s scheduler"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow celery worker"}),": Start a Celery worker (Useful in distributed mode to spread tasks among nodes - machines)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow dags list"}),": Give the list of known dags (either those in the examples folder or in dags folder)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow dags trigger example_python_operator"}),": Trigger the dag example_python_operator with the current date as execution date"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow dags trigger example_python_operator -e 2023-01-01"}),": Trigger the dag example_python_operator with a date in the past as execution date (This won\u2019t trigger the tasks of that dag unless you set the option catchup=True in the DAG definition)"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow dags trigger example_python_operator -e '2023-01-01 19:04:00+00:00'"}),": Trigger the dag example_python_operator with a date in the future (change the date here with one having +2 minutes later than the current date displayed in the Airflow UI). The dag will be scheduled at that date."]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow dags list-runs -d example_python_operator"}),": Display the history of example_python_operator\u2019s dag runs"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow tasks list example_python_operator"}),": List the tasks contained into the example_python_operator dag"]}),"\n",(0,n.jsxs)(r.li,{children:[(0,n.jsx)(r.code,{children:"airflow tasks test example_python_operator print_the_context 2023-01-01"}),": Allow to test a task (print_the_context) from a given dag (example_python_operator here) without taking care of dependencies and past runs. Useful for debugging."]}),"\n"]})]})}function h(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,n.jsx)(r,{...e,children:(0,n.jsx)(c,{...e})}):c(e)}},954293:(e,r,s)=>{s.d(r,{A:()=>n});const n=s.p+"assets/images/Apache_Airflow_Introduction_01-0c89fe239c5aa7f66548c4d24672fbef.png"},352190:(e,r,s)=>{s.d(r,{A:()=>n});const n=s.p+"assets/images/Apache_Airflow_Introduction_02-05e263b42615920b39834d761b43d5cd.png"},825993:(e,r,s)=>{s.d(r,{A:()=>n});const n=s.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-fe9bbb57ea8da08fea2f3fef2bf2515b.jpg"},28453:(e,r,s)=>{s.d(r,{R:()=>d,x:()=>l});var n=s(296540);const i={},t=n.createContext(i);function d(e){const r=n.useContext(t);return n.useMemo((function(){return"function"==typeof e?e(r):{...r,...e}}),[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:d(e.components),n.createElement(t.Provider,{value:r},e.children)}}}]);