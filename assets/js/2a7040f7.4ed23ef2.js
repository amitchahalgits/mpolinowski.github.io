"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[10601],{3905:(e,n,a)=>{a.d(n,{Zo:()=>m,kt:()=>_});var t=a(67294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function o(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function s(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?o(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function i(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},o=Object.keys(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(t=0;t<o.length;t++)a=o[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var l=t.createContext({}),c=function(e){var n=t.useContext(l),a=n;return e&&(a="function"==typeof e?e(n):s(s({},n),e)),a},m=function(e){var n=c(e.components);return t.createElement(l.Provider,{value:n},e.children)},d={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},p=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,m=i(e,["components","mdxType","originalType","parentName"]),p=c(a),_=r,u=p["".concat(l,".").concat(_)]||p[_]||d[_]||o;return a?t.createElement(u,s(s({ref:n},m),{},{components:a})):t.createElement(u,s({ref:n},m))}));function _(e,n){var a=arguments,r=n&&n.mdxType;if("string"==typeof e||r){var o=a.length,s=new Array(o);s[0]=p;var i={};for(var l in n)hasOwnProperty.call(n,l)&&(i[l]=n[l]);i.originalType=e,i.mdxType="string"==typeof e?e:r,s[1]=i;for(var c=2;c<o;c++)s[c]=a[c];return t.createElement.apply(null,s)}return t.createElement.apply(null,a)}p.displayName="MDXCreateElement"},14645:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>d,frontMatter:()=>o,metadata:()=>i,toc:()=>c});var t=a(87462),r=(a(67294),a(3905));const o={sidebar_position:4620,slug:"2023-02-26",title:"Tensorflow 2 - Neural Network Regression",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Working with the medical cost dataset"},s=void 0,i={unversionedId:"IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/index",id:"IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/index",title:"Tensorflow 2 - Neural Network Regression",description:"Working with the medical cost dataset",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset",slug:"/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4620,frontMatter:{sidebar_position:4620,slug:"2023-02-26",title:"Tensorflow 2 - Neural Network Regression",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Working with the medical cost dataset"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow 2 - Neural Network Regression",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26"},next:{title:"Tensorflow 2 - Neural Network Regression",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25"}},l={},c=[{value:"Medical Cost Dataset",id:"medical-cost-dataset",level:2},{value:"Model Building",id:"model-building",level:3},{value:"Improving the Model",id:"improving-the-model",level:3},{value:"When to stop training?",id:"when-to-stop-training",level:3}],m={toc:c};function d(e){let{components:n,...o}=e;return(0,r.kt)("wrapper",(0,t.Z)({},m,o,{components:n,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Mong Kok, Hong Kong",src:a(60248).Z,width:"2830",height:"1272"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#tensorflow-neural-network-regression"},"Tensorflow Neural Network Regression"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#medical-cost-dataset"},"Medical Cost Dataset"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#model-building"},"Model Building")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#improving-the-model"},"Improving the Model")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#when-to-stop-training"},"When to stop training?"))))))),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"See also:")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Fun, fun, tensors: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19"},"Tensor Constants, Variables and Attributes"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21"},"Tensor Indexing, Expanding and Manipulations"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22"},"Matrix multiplications, Squeeze, One-hot and Numpy")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Neural Network Regression: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23"},"Building a Regression Model"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24"},"Model Evaluation"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25"},"Model Optimization"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26"},'Working with a "Real" Dataset'),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26"},"Feature Scaling")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Neural Network Classification: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27"},"Non-linear Data and Activation Functions"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28"},"Model Evaluation and Performance Improvement"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02"},"Multiclass Classification Problems"))),(0,r.kt)("h1",{id:"tensorflow-neural-network-regression"},"Tensorflow Neural Network Regression"),(0,r.kt)("h2",{id:"medical-cost-dataset"},"Medical Cost Dataset"),(0,r.kt)("p",null,"The ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/Machine-Learning-with-R-datasets"},"Medical Cost Dataset")," investigates if you can accurately predict insurance costs based on:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"age"),": age of primary beneficiary"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"sex"),": insurance contractor gender, female, male"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"bmi"),": Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (",(0,r.kt)("inlineCode",{parentName:"li"},"kg / m ^ 2"),") using the ratio of height to weight, ideally ",(0,r.kt)("inlineCode",{parentName:"li"},"18.5")," to ",(0,r.kt)("inlineCode",{parentName:"li"},"24.9")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"children"),": Number of children covered by health insurance / Number of dependents"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"smoker"),": Smoking"),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"region"),": the beneficiary's residential area in the US, northeast, southeast, southwest, northwest."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"charges"),": Individual medical costs billed by health insurance")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# get insurance dataset\ninsurance_data = pd.read_csv('https://raw.githubusercontent.com/mpolinowski/Machine-Learning-with-R-datasets/master/insurance.csv')\ninsurance_data\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Neural Network Regression",src:a(66064).Z,width:"465",height:"351"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# shuffle dataframe to prevent bias\ninsurance_data_random = insurance_data.sample(frac=1)\ninsurance_data_random\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Neural Network Regression",src:a(799).Z,width:"456",height:"349"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# creating numerical labels for strings\n# convert categorical variables into indicator variables with pandas get_dummies\ninsurance_one_hot = pd.get_dummies(insurance_data_random)\ninsurance_one_hot.head()\n")),(0,r.kt)("p",null,(0,r.kt)("img",{src:a(96182).Z,width:"982",height:"154"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# create features and labels\n# we need to predict "charges" - so drop this column from features\nX = insurance_one_hot.drop("charges", axis=1)\ny = insurance_one_hot["charges"]\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# training and testing data split using scikit-learn\n# this function actually randomizes the dataset for us\n# we did not need to shuffle the dataframe before - doesn't hurt, though\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.20, random_state=42)\n\nX_train\n# 80% => 1070 rows \xd7 11 columns\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Neural Network Regression",src:a(67234).Z,width:"938",height:"350"})),(0,r.kt)("h3",{id:"model-building"},"Model Building"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'tf.random.set_seed(42)\n\n# building the model (based on the "best model" above)\ninsurance_model = tf.keras.Sequential([\n    layers.Dense(10, input_shape=[11], name="input_layer"),\n    layers.Dense(16, activation="relu", name="dense_layer1"),\n    layers.Dense(8, activation="relu", name="dense_layer2"),\n    layers.Dense(1, name="output_layer")\n], name="insurance_model")\n\ninsurance_model.compile(\n    loss=tf.keras.losses.mae,\n    optimizer=optimizers.Adam(learning_rate=0.001),\n    metrics="mae")\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# model training\ninsurance_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500)\n# Epoch 500/500\n# 34/34 [==============================] - 0s 3ms/step - loss: 2702.7041 - mae: 2702.7041 - val_loss: 2433.1829 - val_mae: 2433.1829\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# we have an average absolute validation error of val_mae: `2433.1829`\ny_train.median(), y_train.mean()\n# (9373.744050000001, 13240.898205242056)\n\n# the arithmetic average is of medical charges is `13240.898` => 18.4% off\n")),(0,r.kt)("h3",{id:"improving-the-model"},"Improving the Model"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# since the model was still improving I will extend the training\ninsurance_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5000)\n# I am still seeing improvements after 5000 epochs\n\n# Epoch 5000/5000\n# 34/34 [==============================] - 0s 3ms/step - loss: 1498.0355 - mae: 1498.0355 - val_loss: 1543.5344 - val_mae: 1543.5344\n\n# the error is now down to 11% from 18% before\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# since before removing complexity actually improved the model\n# removing one dense layer\ninsurance_model_1 = tf.keras.Sequential([\n    layers.Dense(10, input_shape=[11], name="input_layer"),\n    layers.Dense(8, activation="relu", name="dense_layer"),\n    layers.Dense(1, name="output_layer")\n], name="insurance_model_1")\n\ninsurance_model_1.compile(\n    loss=tf.keras.losses.mae,\n    optimizer=optimizers.Adam(learning_rate=0.001),\n    metrics="mae")\n\ninsurance_model_1.summary()\n\n# Model: "insurance_model_1"\n# _________________________________________________________________\n#  Layer (type)                Output Shape              Param #   \n# =================================================================\n#  input_layer (Dense)         (None, 10)                120       \n                                                                 \n#  dense_layer (Dense)         (None, 8)                 88        \n                                                                 \n#  output_layer (Dense)        (None, 1)                 9         \n                                                                 \n# =================================================================\n# Total params: 217\n# Trainable params: 217\n# Non-trainable params: 0\n# _________________________________________________________________\n\ninsurance_model_1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500)\n\n# this decreased the performance with the error after 500 cycles\n# Epoch 500/500\n# 34/34 [==============================] - 0s 3ms/step - loss: 3530.7039 - mae: 3530.7039 - val_loss: 3634.2502 - val_mae: 3634.2502\n\n# mae `2433.1829`  => mae `3634.2502`\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'tf.random.set_seed(42)\n\n# back to the initial model but with a larger learning rate\ninsurance_model_2 = tf.keras.Sequential([\n    layers.Dense(8, input_shape=[11], name="input_layer"),\n    layers.Dense(16, activation="relu", name="dense_layer1"),\n    layers.Dense(8, activation="relu", name="dense_layer2"),\n    layers.Dense(1, name="output_layer")\n], name="insurance_model_2")\n\ninsurance_model_2.compile(\n    loss=tf.keras.losses.mae,\n    optimizer=optimizers.Adam(learning_rate=0.01),\n    metrics="mae")\n\ninsurance_model_2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500)\n# Epoch 500/500\n# 34/34 [==============================] - 0s 3ms/step - loss: 2059.1406 - mae: 2059.1406 - val_loss: 2059.2986 - val_mae: 2059.2986\n\n# mae `2433.1829`  => mae `2059.2986`\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'tf.random.set_seed(42)\n\n# increase number of units\ninsurance_model_3 = tf.keras.Sequential([\n    layers.Dense(8, input_shape=[11], name="input_layer"),\n    layers.Dense(32, activation="relu", name="dense_layer1"),\n    layers.Dense(8, activation="relu", name="dense_layer2"),\n    layers.Dense(1, name="output_layer")\n], name="insurance_model_3")\n\ninsurance_model_3.compile(\n    loss=tf.keras.losses.mae,\n    optimizer=optimizers.Adam(learning_rate=0.01),\n    metrics="mae")\n\nhistory = insurance_model_3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500)\n\n# Epoch 500/500\n# 34/34 [==============================] - 0s 3ms/step - loss: 2110.4812 - mae: 2110.4812 - val_loss: 1937.2085 - val_mae: 1937.2085\n\n# even better\n# mae `2433.1829`  => mae `1937.2085`\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# history plot\npd.DataFrame(history.history).plot()\nplt.ylabel("loss")\nplt.xlabel("epochs")\n\n# the improvements keep creeping in slowly.\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow Neural Network Regression",src:a(9105).Z,width:"589",height:"432"})),(0,r.kt)("h3",{id:"when-to-stop-training"},"When to stop training?"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# a way to keep training until a minimum of\n# improvement is reached you can use the \n# `EarlyStopping()` callback\n\n# stop when loss stops improving min 0.0001\n# over 10 cycles\nearlystop_callback = tf.keras.callbacks.EarlyStopping(\n  monitor='val_loss', min_delta=0.0001,\n  patience=10, restore_best_weights=True)\n\nhistory = insurance_model_3.fit(X_train, y_train,\n                                validation_data=(X_test, y_test),\n                                epochs=5000, callbacks=[earlystop_callback])\n\n# since the model is already trained it won't run for long now before the callback is triggered:\n# Epoch 21/5000\n# 34/34 [==============================] - 0s 3ms/step - loss: 1843.7740 - mae: 1843.7740 - val_loss: 1802.4473 - val_mae: 1802.4473\n")))}d.isMDXComponent=!0},66064:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/01a_Tensorflow_Regressions_15-43febb02670ff5c9c452a9730c829c9f.png"},799:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/01a_Tensorflow_Regressions_16-8b901ecaf9c64fe4216d3f94446c45f2.png"},96182:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/01a_Tensorflow_Regressions_17-2ea88e362a91f5ecbc03ac60bcaeea39.png"},67234:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/01a_Tensorflow_Regressions_18-043c9bd6e68ab1294e7b870309566af0.png"},9105:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/01a_Tensorflow_Regressions_19-7a8889645efbc4dc0bb8fa750af9f674.png"},60248:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-f80e63ee872dae25129198058ac93b4e.jpg"}}]);