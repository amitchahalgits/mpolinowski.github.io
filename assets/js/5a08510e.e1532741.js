"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[51262],{205529:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>o,contentTitle:()=>s,default:()=>m,frontMatter:()=>t,metadata:()=>d,toc:()=>c});var a=r(474848),i=r(28453);const t={sidebar_position:9050,slug:"2021-11-03",title:"Streamlit user interface for openCV/Mediapipe face mesh app",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},s=void 0,d={id:"IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/index",title:"Streamlit user interface for openCV/Mediapipe face mesh app",description:"Victoria Harbour, Hongkong",source:"@site/docs/IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe",slug:"/IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/2021-11-03",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/2021-11-03",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2021-11-03--streamlit-opencv-mediapipe/index.md",tags:[{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"OpenCV",permalink:"/docs/tags/open-cv"}],version:"current",sidebarPosition:9050,frontMatter:{sidebar_position:9050,slug:"2021-11-03",title:"Streamlit user interface for openCV/Mediapipe face mesh app",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},sidebar:"tutorialSidebar",previous:{title:"Installing YOLOv4 with Anaconda",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-11-04--installing-yolov4/2021-11-04"},next:{title:"spaCy NER Predictions",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-11-02--spacy_ner_predictions/2021-11-02"}},o={},c=[{value:"Face Landmark Detection",id:"face-landmark-detection",level:2},{value:"Basic Setup",id:"basic-setup",level:3},{value:"StreamLit",id:"streamlit",level:3},{value:"Create About Page",id:"create-about-page",level:2},{value:"Create Image Page",id:"create-image-page",level:2},{value:"Create Video Page",id:"create-video-page",level:2}];function l(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Victoria Harbour, Hongkong",src:r(932943).A+"",width:"1500",height:"663"})}),"\n",(0,a.jsxs)(n.p,{children:["This code is based on a free tutorial by Agumented Startups. All free tutorials available on ",(0,a.jsx)(n.a,{href:"https://www.augmentedstartups.com/visionstore",children:"augmentedstartups.com"}),". Changes made:"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Updated all dependencies to latest version"}),"\n",(0,a.jsx)(n.li,{children:"Removed deprecation errors"}),"\n",(0,a.jsx)(n.li,{children:"Added new demo files"}),"\n"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"#face-landmark-detection",children:"Face Landmark Detection"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#basic-setup",children:"Basic Setup"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#streamlit",children:"StreamLit"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#create-about-page",children:"Create About Page"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#create-image-page",children:"Create Image Page"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#create-video-page",children:"Create Video Page"})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"face-landmark-detection",children:"Face Landmark Detection"}),"\n",(0,a.jsx)(n.h3,{id:"basic-setup",children:"Basic Setup"}),"\n",(0,a.jsxs)(n.p,{children:["Go to Augmented Startups and open the ",(0,a.jsx)(n.a,{href:"https://www.augmentedstartups.com/face-mesh-Stream-Lit-UI",children:"Face Landmark Detection StreamLit User Interface"})," project page. Scroll down and download the project setup files:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"mkdir /opt/Python/streamLit/ cd /opt/Python/streamLit/ \r\nwget https://www.augmentedstartups.com/resource_redirect/downloads/sites/104576/themes/2148177103/downloads/yWtJ2GTTUmbdL4paud0M_Face-Mesh-MediaPipe-StreamLit.zip\r\nunzip yWtJ2GTTUmbdL4paud0M_Face-Mesh-MediaPipe-StreamLit.zip\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The project contains a ",(0,a.jsx)(n.code,{children:"requirements.txt"})," file that we can use to install the following dependencies into your\r\nvirtual environment:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"opencv_python_headless==4.5.2.54\r\nstreamlit==0.82.0\r\nmediapipe==0.8.4.2\r\nnumpy==1.18.5\r\nPillow==8.2.0\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"pip install -r requirements.txt\n"})}),"\n",(0,a.jsx)(n.h3,{id:"streamlit",children:"StreamLit"}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://docs.streamlit.io",children:"Streamlit"})," is an open-source Python library that makes it easy to create and share beautiful, custom web apps for\r\nmachine learning and data science. In just a few minutes you can build and deploy powerful data apps."]}),"\n",(0,a.jsxs)(n.p,{children:["Create a new Python file ",(0,a.jsx)(n.code,{children:"face_mesh_app.py"})," and import the dependencies:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import streamlit as st\r\nimport mediapipe as mp\r\nimport cv2 as cv\r\nimport numpy as np\r\nimport tempfile\r\nimport time\r\nfrom PIL import Image\n"})}),"\n",(0,a.jsxs)(n.p,{children:["Test your installation by running the following and opening your browser on ",(0,a.jsx)(n.code,{children:"localhost:8501"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"st.title('Face Mesh App using Mediapipe')\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"streamlit run face_mesh_app.py\n"})}),"\n",(0,a.jsx)(n.p,{children:"You should see the title displayed on the Top of your page. Ok now we can continue building the rest of the page:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Basic App Scaffolding\r\nst.title('Face Mesh App using Streamlit')\r\n\r\nst.markdown(\r\n    \"\"\"\r\n    <style>\r\n    [data-testid=\"stSidebar\"][aria-expanded=\"true\"] > div:first-child{\r\n        width: 350px\r\n    }\r\n    [data-testid=\"stSidebar\"][aria-expanded=\"false\"] > div:first-child{\r\n        width: 350px\r\n        margin-left: -350px\r\n    }\r\n    </style>\r\n    \"\"\",\r\n    unsafe_allow_html=True,\r\n)\r\n\r\n# Create Sidebar\r\nst.sidebar.title('FaceMesh Sidebar')\r\nst.sidebar.subheader('Parameter')\r\n\r\n# Define available pages in selection box\r\napp_mode = st.sidebar.selectbox(\r\n    'App Mode',\r\n    ['About','Image','Video']\r\n)\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"StreamLit",src:r(936110).A+"",width:"1229",height:"421"})}),"\n",(0,a.jsx)(n.p,{children:"Make sure that the image dimensions do not exceed the dimensions of the page - else resize:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Resize Images to fit Container\r\n@st.cache()\r\n# Get Image Dimensions\r\ndef image_resize(image, width=None, height=None, inter=cv.INSTER_AREA):\r\n    dim = None\r\n    (h,w) = image.shape[:2]\r\n\r\n    if width is None and height is None:\r\n        return image\r\n\r\n    if width is None:\r\n        r = width/float(w)\r\n        dim = (int(w*r),height)\r\n\r\n    else:\r\n        r = width/float(w)\r\n        dim = width, int(h*r)\r\n\r\n    # Resize image\r\n    resized = cv.resize(image,dim,interpolation=inter)\r\n\r\n    return resized\n"})}),"\n",(0,a.jsx)(n.h2,{id:"create-about-page",children:"Create About Page"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# About Page\r\n\r\nif app_mode == \'About\':\r\n    st.markdown(\'\'\'\r\n                ## Face Mesh \\n\r\n                In this application we are using **MediaPipe** for creating a Face Mesh. **StreamLit** is used to create the Web Graphical User Interface (GUI) \\n\r\n                \r\n                - [Github](https://github.com/mpolinowski/streamLit-cv-mediapipe) \\n\r\n    \'\'\')\r\n\r\n## Add Sidebar and Window style\r\nst.markdown(\r\n    """\r\n    <style>\r\n    [data-testid="stSidebar"][aria-expanded="true"] > div:first-child{\r\n        width: 350px\r\n    }\r\n    [data-testid="stSidebar"][aria-expanded="false"] > div:first-child{\r\n        width: 350px\r\n        margin-left: -350px\r\n    }\r\n    </style>\r\n    """,\r\n    unsafe_allow_html=True,\r\n)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"create-image-page",children:"Create Image Page"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"StreamLit",src:r(706469).A+"",width:"1227",height:"908"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'elif app_mode == \'Image\':\r\n    drawing_spec = mp.solutions.drawing_utils.DrawingSpec(thickness=2, circle_radius=1)\r\n\r\n    st.sidebar.markdown(\'---\')\r\n\r\n    ## Add Sidebar and Window style\r\n    st.markdown(\r\n        """\r\n        <style>\r\n        [data-testid="stSidebar"][aria-expanded="true"] > div:first-child{\r\n            width: 350px\r\n        }\r\n        [data-testid="stSidebar"][aria-expanded="false"] > div:first-child{\r\n            width: 350px\r\n            margin-left: -350px\r\n        }\r\n        </style>\r\n        """,\r\n        unsafe_allow_html=True,\r\n    )\r\n\r\n    st.markdown("**Detected Faces**")\r\n    kpil_text = st.markdown(\'0\')\r\n\r\n    max_faces = st.sidebar.number_input(\'Maximum Number of Faces\', value=2, min_value=1)\r\n    st.sidebar.markdown(\'---\')\r\n\r\n    detection_confidence = st.sidebar.slider(\'Min Detection Confidence\', min_value=0.0,max_value=1.0,value=0.5)\r\n    st.sidebar.markdown(\'---\')\r\n\r\n    img_file_buffer = st.sidebar.file_uploader("Upload an Image", type=["jpg","jpeg","png"])\r\n    if img_file_buffer is not None:\r\n        image = np.array(Image.open(img_file_buffer))\r\n\r\n    else:\r\n        demo_image = DEMO_IMAGE\r\n        image = np.array(Image.open(demo_image))\r\n\r\n    st.sidebar.text(\'Original Image\')\r\n    st.sidebar.image(image)\r\n\r\n    face_count=0\r\n\r\n    ## Dashboard\r\n    with mp.solutions.face_mesh.FaceMesh(\r\n        static_image_mode=True, #Set of unrelated images\r\n        max_num_faces=max_faces,\r\n        min_detection_confidence=detection_confidence\r\n    ) as face_mesh:\r\n\r\n            results = face_mesh.process(image)\r\n            out_image=image.copy()\r\n\r\n            #Face Landmark Drawing\r\n            for face_landmarks in results.multi_face_landmarks:\r\n                face_count += 1\r\n\r\n                mp.solutions.drawing_utils.draw_landmarks(\r\n                    image=out_image,\r\n                    landmark_list=face_landmarks,\r\n                    connections=mp.solutions.face_mesh.FACE_CONNECTIONS,\r\n                    landmark_drawing_spec=drawing_spec\r\n                )\r\n\r\n                kpil_text.write(f"<h1 style=\'text-align: center; color:red;\'>{face_count}</h1>", unsafe_allow_html=True)\r\n\r\n            st.subheader(\'Output Image\')\r\n            st.image(out_image, use_column_width=True)\n'})}),"\n",(0,a.jsx)(n.h2,{id:"create-video-page",children:"Create Video Page"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"StreamLit",src:r(623580).A+"",width:"1227",height:"848"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"elif app_mode == 'Video':\r\n\r\n    st.set_option('deprecation.showfileUploaderEncoding', False)\r\n\r\n    use_webcam = st.sidebar.button('Use Webcam')\r\n    record = st.sidebar.checkbox(\"Record Video\")\r\n\r\n    if record:\r\n        st.checkbox('Recording', True)\r\n\r\n    drawing_spec = mp.solutions.drawing_utils.DrawingSpec(thickness=2, circle_radius=1)\r\n\r\n    st.sidebar.markdown('---')\r\n\r\n    ## Add Sidebar and Window style\r\n    st.markdown(\r\n        \"\"\"\r\n        <style>\r\n        [data-testid=\"stSidebar\"][aria-expanded=\"true\"] > div:first-child{\r\n            width: 350px\r\n        }\r\n        [data-testid=\"stSidebar\"][aria-expanded=\"false\"] > div:first-child{\r\n            width: 350px\r\n            margin-left: -350px\r\n        }\r\n        </style>\r\n        \"\"\",\r\n        unsafe_allow_html=True,\r\n    )\r\n\r\n    max_faces = st.sidebar.number_input('Maximum Number of Faces', value=5, min_value=1)\r\n    st.sidebar.markdown('---')\r\n    detection_confidence = st.sidebar.slider('Min Detection Confidence', min_value=0.0,max_value=1.0,value=0.5)\r\n    tracking_confidence = st.sidebar.slider('Min Tracking Confidence', min_value=0.0,max_value=1.0,value=0.5)\r\n    st.sidebar.markdown('---')\r\n\r\n    ## Get Video\r\n    stframe = st.empty()\r\n    video_file_buffer = st.sidebar.file_uploader(\"Upload a Video\", type=['mp4', 'mov', 'avi', 'asf', 'm4v'])\r\n    temp_file = tempfile.NamedTemporaryFile(delete=False)\r\n\r\n    if not video_file_buffer:\r\n        if use_webcam:\r\n            video = cv.VideoCapture(0)\r\n        else:\r\n            video = cv.VideoCapture(DEMO_VIDEO)\r\n            temp_file.name = DEMO_VIDEO\r\n\r\n    else:\r\n        temp_file.write(video_file_buffer.read())\r\n        video = cv.VideoCapture(temp_file.name)\r\n\r\n    width = int(video.get(cv.CAP_PROP_FRAME_WIDTH))\r\n    height = int(video.get(cv.CAP_PROP_FRAME_HEIGHT))\r\n    fps_input = int(video.get(cv.CAP_PROP_FPS))\r\n\r\n    ## Recording\r\n    codec = cv.VideoWriter_fourcc('a','v','c','1')\r\n    out = cv.VideoWriter('output1.mp4', codec, fps_input, (width,height))\r\n\r\n    st.sidebar.text('Input Video')\r\n    st.sidebar.video(temp_file.name)\r\n\r\n    fps = 0\r\n    i = 0\r\n\r\n    drawing_spec = mp.solutions.drawing_utils.DrawingSpec(thickness=2, circle_radius=1)\r\n\r\n    kpil, kpil2, kpil3 = st.columns(3)\r\n\r\n    with kpil:\r\n        st.markdown('**Frame Rate**')\r\n        kpil_text = st.markdown('0')\r\n\r\n    with kpil2:\r\n        st.markdown('**Detected Faces**')\r\n        kpil2_text = st.markdown('0')\r\n\r\n    with kpil3:\r\n        st.markdown('**Image Resolution**')\r\n        kpil3_text = st.markdown('0')\r\n\r\n    st.markdown('<hr/>', unsafe_allow_html=True)\r\n\r\n\r\n    ## Face Mesh\r\n    with mp.solutions.face_mesh.FaceMesh(\r\n        max_num_faces=max_faces,\r\n        min_detection_confidence=detection_confidence,\r\n        min_tracking_confidence=tracking_confidence\r\n\r\n    ) as face_mesh:\r\n\r\n            prevTime = 0\r\n\r\n            while video.isOpened():\r\n                i +=1\r\n                ret, frame = video.read()\r\n                if not ret:\r\n                    continue\r\n\r\n                results = face_mesh.process(frame)\r\n                frame.flags.writeable = True\r\n\r\n                face_count = 0\r\n                if results.multi_face_landmarks:\r\n\r\n                    #Face Landmark Drawing\r\n                    for face_landmarks in results.multi_face_landmarks:\r\n                        face_count += 1\r\n\r\n                        mp.solutions.drawing_utils.draw_landmarks(\r\n                            image=frame,\r\n                            landmark_list=face_landmarks,\r\n                            connections=mp.solutions.face_mesh.FACEMESH_CONTOURS,\r\n                            landmark_drawing_spec=drawing_spec,\r\n                            connection_drawing_spec=drawing_spec\r\n                        )\r\n\r\n                # FPS Counter\r\n                currTime = time.time()\r\n                fps = 1/(currTime - prevTime)\r\n                prevTime = currTime\r\n\r\n                if record:\r\n                    out.write(frame)\r\n\r\n                # Dashboard\r\n                kpil_text.write(f\"<h1 style='text-align: center; color:red;'>{int(fps)}</h1>\", unsafe_allow_html=True)\r\n                kpil2_text.write(f\"<h1 style='text-align: center; color:red;'>{face_count}</h1>\", unsafe_allow_html=True)\r\n                kpil3_text.write(f\"<h1 style='text-align: center; color:red;'>{width*height}</h1>\",\r\n                                 unsafe_allow_html=True)\r\n\r\n                frame = cv.resize(frame,(0,0), fx=0.8, fy=0.8)\r\n                frame = image_resize(image=frame, width=640)\r\n                stframe.image(frame,channels='BGR', use_column_width=True)\n"})})]})}function m(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(l,{...e})}):l(e)}},936110:(e,n,r)=>{r.d(n,{A:()=>a});const a=r.p+"assets/images/face_mesh_app_01-968ee4a1f7faf9eb21034937f7692520.png"},706469:(e,n,r)=>{r.d(n,{A:()=>a});const a=r.p+"assets/images/face_mesh_app_02-d72131fae56911c5ba8a8a5980ae9dc4.png"},623580:(e,n,r)=>{r.d(n,{A:()=>a});const a=r.p+"assets/images/face_mesh_app_03-63758b9c883cd6c0335eace5ee9a1440.png"},932943:(e,n,r)=>{r.d(n,{A:()=>a});const a=r.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-4f747fa38245d3c618169ab90d8c3f77.jpg"},28453:(e,n,r)=>{r.d(n,{R:()=>s,x:()=>d});var a=r(296540);const i={},t=a.createContext(i);function s(e){const n=a.useContext(t);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function d(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:s(e.components),a.createElement(t.Provider,{value:n},e.children)}}}]);