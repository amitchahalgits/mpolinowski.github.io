"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[89579],{414417:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>s,contentTitle:()=>o,default:()=>p,frontMatter:()=>i,metadata:()=>l,toc:()=>d});var r=a(785893),t=a(603905);const i={sidebar_position:6020,slug:"2022-02-15",title:"Yolo App - Data Collection",authors:"mpolinowski",tags:["Machine Learning","Python","YOLO"]},o=void 0,l={id:"IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/index",title:"Yolo App - Data Collection",description:"Shenzhen, China",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data",slug:"/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/index.md",tags:[{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"YOLO",permalink:"/docs/tags/yolo"}],version:"current",sidebarPosition:6020,frontMatter:{sidebar_position:6020,slug:"2022-02-15",title:"Yolo App - Data Collection",authors:"mpolinowski",tags:["Machine Learning","Python","YOLO"]},sidebar:"tutorialSidebar",previous:{title:"Yolo App - Train a Model with Tensorflow",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16"},next:{title:"OpenCV Optical Flow Algorithm for Object Tracking",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-10--opencv-optical-flow-tracking/2021-12-10"}},s={},d=[{value:"Project Setup",id:"project-setup",level:2},{value:"Data Collection",id:"data-collection",level:2},{value:"Image Labeling",id:"image-labeling",level:3},{value:"Get Bounding Boxes Coordinates",id:"get-bounding-boxes-coordinates",level:3},{value:"Get Image Files for Each Bounding Box",id:"get-image-files-for-each-bounding-box",level:3},{value:"Draw Bounding Box on Images",id:"draw-bounding-box-on-images",level:3},{value:"Normalize Data",id:"normalize-data",level:3},{value:"Divide into Training and Testing Data Set",id:"divide-into-training-and-testing-data-set",level:3}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.ah)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Shenzhen, China",src:a(11738).Z+"",width:"1500",height:"688"})}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15",children:"Prepare your Images and get Data"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16",children:"Train your Tensorflow Model"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-17--yolo-app-prediction-pipeline/2022-02-17",children:"Use your Model to do Predictions"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18",children:"Use Tesseract to Read Number Plates"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19",children:"Flask Web Application"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20",children:"Yolo v5 - Data Prep"})}),"\n"]}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#project-setup",children:"Project Setup"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#data-collection",children:"Data Collection"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#image-labeling",children:"Image Labeling"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#get-bounding-boxes-coordinates",children:"Get Bounding Boxes Coordinates"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#get-image-files-for-each-bounding-box",children:"Get Image Files for Each Bounding Box"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#draw-bounding-box-on-images",children:"Draw Bounding Box on Images"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#normalize-data",children:"Normalize Data"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#divide-into-training-and-testing-data-set",children:"Divide into Training and Testing Data Set"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"project-setup",children:"Project Setup"}),"\n",(0,r.jsxs)(n.p,{children:["Create a ",(0,r.jsx)(n.code,{children:"dependencies.txt"})," file and install all dependencies:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"opencv-python==4.5.5.62\r\ntensorflow-gpu==2.8.0\r\nnotebook\r\npandas\r\nnumpy\r\nmatplotlib\r\nsklearn\r\npytesseract\n"})}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Note"}),": that I am using GPU accelerated version of Tensorflow for Nvidia GPUs. Replace ",(0,r.jsx)(n.code,{children:"tensorflow-gpu"})," with ",(0,r.jsx)(n.code,{children:"tensorflow"})," if you don't have a compatible graphic card in your PC."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pip install -r dependencies.txt\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Verify that OpenCV and Tensorflow was installed by creating and executing ",(0,r.jsx)(n.code,{children:"test.py"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"import cv2\r\nimport tensorflow as tf\r\n\r\nprint('Tensorflow Version: ' + tf.__version__)\r\nprint('OpenCV Version: ' + cv2.__version__)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"python test.py \r\nTensorflow Version: 2.8.0\r\nOpenCV Version: 4.5.4\n"})}),"\n",(0,r.jsx)(n.h2,{id:"data-collection",children:"Data Collection"}),"\n",(0,r.jsx)(n.h3,{id:"image-labeling",children:"Image Labeling"}),"\n",(0,r.jsxs)(n.p,{children:["I can use Google to collect photos of cars with visible license plates. I have to label those images so that they can be used for the Tensorflow training. To lable the images we are going to use ",(0,r.jsx)(n.a,{href:"https://github.com/tzutalin/labelImg",children:"labelImg"}),", which is a graphical image annotation tool."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"pip3 install labelImg\r\n\r\nSuccessfully installed PyQt5-Qt5-5.15.2 PyQt5-sip-12.9.0 labelImg-1.8.3 pyqt5-5.15.6\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Start the Software from your console with ",(0,r.jsx)(n.code,{children:"labelImg"})," and label all your trainings images:"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Yolo App Data Collection",src:a(999163).Z+"",width:"1016",height:"608"})}),"\n",(0,r.jsx)(n.p,{children:"An example XML label generated by this process looks like:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-xml",children:"<annotation>\r\n\t<folder>d</folder>\r\n\t<filename>N3.jpeg</filename>\r\n\t<path>./resources/car.jpg</path>\r\n\t<source>\r\n\t\t<database>Unknown</database>\r\n\t</source>\r\n\t<size>\r\n\t\t<width>932</width>\r\n\t\t<height>699</height>\r\n\t\t<depth>3</depth>\r\n\t</size>\r\n\t<segmented>0</segmented>\r\n\t<object>\r\n\t\t<name>num_plate</name>\r\n\t\t<pose>Unspecified</pose>\r\n\t\t<truncated>0</truncated>\r\n\t\t<difficult>0</difficult>\r\n\t\t<bndbox>\r\n\t\t\t<xmin>73</xmin>\r\n\t\t\t<ymin>381</ymin>\r\n\t\t\t<xmax>260</xmax>\r\n\t\t\t<ymax>462</ymax>\r\n\t\t</bndbox>\r\n\t</object>\r\n</annotation>\n"})}),"\n",(0,r.jsx)(n.h3,{id:"get-bounding-boxes-coordinates",children:"Get Bounding Boxes Coordinates"}),"\n",(0,r.jsxs)(n.p,{children:["I now need to extract the ",(0,r.jsx)(n.strong,{children:"Bounding Box"})," coordinates ",(0,r.jsx)(n.code,{children:"xmin"}),", ",(0,r.jsx)(n.code,{children:"ymin"}),", ",(0,r.jsx)(n.code,{children:"xmax"})," and ",(0,r.jsx)(n.code,{children:"ymax"})," from the ",(0,r.jsx)(n.strong,{children:"XML"})," files and write them into ",(0,r.jsx)(n.strong,{children:"CSV"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"jupyter notebook\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"import pandas as pd\r\nimport xml.etree.ElementTree as xet\r\nfrom glob import glob\r\n\r\n# Get all generated image XML labels\r\npath = glob('../labels/*.xml')\r\n\r\n# Create empty label dictionary\r\nlabels = dict(filepath=[], xmin=[], ymin=[], xmax=[], ymax=[])\r\n# Extract bounding box coordinates for all labels\r\nfor filename in path:\r\n    info = xet.parse(filename)\r\n    root = info.getroot()\r\n    member_object = root.find('object')\r\n    labels_info = member_object.find('bndbox')\r\n    xmin = int(labels_info.find('xmin').text)\r\n    ymin = int(labels_info.find('ymin').text)\r\n    xmax = int(labels_info.find('xmax').text)\r\n    ymax = int(labels_info.find('ymax').text)\r\n    # Append values to dictionary\r\n    labels['filepath'].append(filename)\r\n    labels['xmin'].append(xmin)\r\n    labels['ymin'].append(ymin)\r\n    labels['xmax'].append(xmax)\r\n    labels['ymax'].append(ymax)\r\n\r\n# Create data frame from dictionary\r\ndf = pd.DataFrame(labels)\r\n\r\n# Write data frame to CSV\r\ndf.to_csv('../labels/labels.csv')\n"})}),"\n",(0,r.jsx)(n.h3,{id:"get-image-files-for-each-bounding-box",children:"Get Image Files for Each Bounding Box"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"import numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport xml.etree.ElementTree as xet\r\nimport os\r\nimport cv2\r\n\r\ndf = pd.read_csv('../labels/labels.csv')\r\n\r\n# Find image file path for a given label\r\ndef getImagePath(filename):\r\n    image = xet.parse(filename).getroot().find('filename').text\r\n    image_filepath = os.path.join('../resources', image)\r\n    return image_filepath\r\n\r\n# Select labels and find corresponding images\r\nimage_paths = list(df['filepath'].apply(getImagePath))\n"})}),"\n",(0,r.jsx)(n.h3,{id:"draw-bounding-box-on-images",children:"Draw Bounding Box on Images"}),"\n",(0,r.jsx)(n.p,{children:"To verify that everything is working we can use the bounding box coordinates to draw a rectangle onto the corresponding image:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# Get image path by index\r\npath = image_paths[0]\r\nimg = cv2.imread(path)\r\n\r\n# Draw bounding box onto image\r\n# Coordinates copied from generated label\r\ncv2.rectangle(img,(1093,645),(1396,727),(0,255,128),3)\r\n\r\n# Make window with name Test resizeable\r\ncv2.namedWindow('Test', cv2.WINDOW_NORMAL)\r\n\r\n# Display selected image in Test window\r\ncv2.imshow('Test', img)\r\ncv2.waitKey(0)\r\ncv2.destroyAllWindows()\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Yolo App Data Collection",src:a(32286).Z+"",width:"985",height:"264"})}),"\n",(0,r.jsx)(n.h3,{id:"normalize-data",children:"Normalize Data"}),"\n",(0,r.jsxs)(n.p,{children:["The models I am going to use later have been trained on a specific image size. I have to normalize all images and the generated bounding boxes to fit this requirement - e.g. an file size of ",(0,r.jsx)(n.strong,{children:"224x224 pixels"}),":"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"from tensorflow.keras.preprocessing.image import load_img, img_to_array\r\n\r\n# Get array coordinates from labels \r\nlabels = df.iloc[:,2:].values\r\n\r\ndata = []\r\noutput = []\r\n\r\n# Loop over all images and normalize\r\nfor i in range(len(image_paths)):\r\n\r\n    # Get image path by index\r\n    image = image_paths[i]\r\n\r\n    # Get image dimensions from it' s shape\r\n    image_array = cv2.imread(image)\r\n    h,w,d = image_array.shape\r\n\r\n    # Normalize image size to fit tf model (input)\r\n    load_image = load_img(image,target_size=(224,224))\r\n    load_image_array = img_to_array(load_image)\r\n    norm_load_image_array = load_image_array/255\r\n\r\n    # Normalize coordinates from labels (output)\r\n    xmin, xmax, ymin, ymax = labels[i]\r\n    nxmin, nxmax = xmin/w, xmax/w\r\n    nymin, nymax = ymin/h, ymax/h\r\n    label_norm = (nxmin,nxmax,nymin,nymax)\r\n    \r\n    # Append results to output arrays\r\n    data.append(norm_load_image_array)\r\n    output.append(label_norm)\r\n\r\nX = np.array(data, dtype=np.float32)\r\nY = np.array(output, dtype=np.float32)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"divide-into-training-and-testing-data-set",children:"Divide into Training and Testing Data Set"}),"\n",(0,r.jsx)(n.p,{children:"Divide the training images and labels by a 80:20 split:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"from sklearn.model_selection import train_test_split\r\n\r\nX = np.array(data, dtype=np.float32)\r\nY = np.array(output, dtype=np.float32)\r\n\r\nx_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, random_state=0)\n"})}),"\n",(0,r.jsx)(n.p,{children:"Now I am ready to continue training my Tensorflow model to be able to detect license plates!"})]})}function p(e={}){const{wrapper:n}={...(0,t.ah)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},603905:(e,n,a)=>{a.d(n,{ah:()=>d});var r=a(667294);function t(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function i(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,r)}return a}function o(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?i(Object(a),!0).forEach((function(n){t(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function l(e,n){if(null==e)return{};var a,r,t=function(e,n){if(null==e)return{};var a,r,t={},i=Object.keys(e);for(r=0;r<i.length;r++)a=i[r],n.indexOf(a)>=0||(t[a]=e[a]);return t}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)a=i[r],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(t[a]=e[a])}return t}var s=r.createContext({}),d=function(e){var n=r.useContext(s),a=n;return e&&(a="function"==typeof e?e(n):o(o({},n),e)),a},c={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},p=r.forwardRef((function(e,n){var a=e.components,t=e.mdxType,i=e.originalType,s=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),m=d(a),h=t,g=m["".concat(s,".").concat(h)]||m[h]||c[h]||i;return a?r.createElement(g,o(o({ref:n},p),{},{components:a})):r.createElement(g,o({ref:n},p))}));p.displayName="MDXCreateElement"},999163:(e,n,a)=>{a.d(n,{Z:()=>r});const r=a.p+"assets/images/Yolo_App_Data_Collection_01-e3097a2b90610e2a985d708c794db6d8.png"},32286:(e,n,a)=>{a.d(n,{Z:()=>r});const r=a.p+"assets/images/Yolo_App_Data_Collection_02-b32c7b79866fdb49928eecae6a61d98e.png"},11738:(e,n,a)=>{a.d(n,{Z:()=>r});const r=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-ffe80356d19fb4b090a3bef79b45aab3.jpg"}}]);