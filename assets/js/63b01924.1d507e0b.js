"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[28207],{974492:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>r,contentTitle:()=>l,default:()=>g,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var i=a(785893),t=a(603905);const s={sidebar_position:4560,slug:"2023-03-05",title:"Tensorflow 2 - Convolutional Neural Networks",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Computer Vision for Multiclass Image Classifications"},l="Tensorflow Convolutional Neural Networks",o={id:"IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/index",title:"Tensorflow 2 - Convolutional Neural Networks",description:"Computer Vision for Multiclass Image Classifications",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications",slug:"/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4560,frontMatter:{sidebar_position:4560,slug:"2023-03-05",title:"Tensorflow 2 - Convolutional Neural Networks",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Computer Vision for Multiclass Image Classifications"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow 2 - Transfer Learning",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06"},next:{title:"Tensorflow 2 - Convolutional Neural Networks",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03"}},r={},c=[{value:"Multiclass Image Classification",id:"multiclass-image-classification",level:2},{value:"Visualizing the Data",id:"visualizing-the-data",level:3},{value:"Preprocessing the Data",id:"preprocessing-the-data",level:3},{value:"Building the Model",id:"building-the-model",level:3},{value:"Reduce Overfitting",id:"reduce-overfitting",level:4},{value:"Making Predictions",id:"making-predictions",level:3},{value:"Saving &amp; Loading the Model",id:"saving--loading-the-model",level:3}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.ah)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"TST, Hongkong",src:a(137151).Z+"",width:"1500",height:"626"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#tensorflow-convolutional-neural-networks",children:"Tensorflow Convolutional Neural Networks"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#multiclass-image-classification",children:"Multiclass Image Classification"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#visualizing-the-data",children:"Visualizing the Data"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#preprocessing-the-data",children:"Preprocessing the Data"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#building-the-model",children:"Building the Model"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#reduce-overfitting",children:"Reduce Overfitting"})}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#making-predictions",children:"Making Predictions"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#saving--loading-the-model",children:"Saving & Loading the Model"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://github.com/mpolinowski/tf-2023",children:"Github Repository"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.em,{children:"See also:"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Fun, fun, tensors: ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19",children:"Tensor Constants, Variables and Attributes"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21",children:"Tensor Indexing, Expanding and Manipulations"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22",children:"Matrix multiplications, Squeeze, One-hot and Numpy"})]}),"\n",(0,i.jsxs)(n.li,{children:["Tensorflow 2 - Neural Network Regression: ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23",children:"Building a Regression Model"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24",children:"Model Evaluation"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25",children:"Model Optimization"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26",children:'Working with a "Real" Dataset'}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26",children:"Feature Scaling"})]}),"\n",(0,i.jsxs)(n.li,{children:["Tensorflow 2 - Neural Network Classification: ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27",children:"Non-linear Data and Activation Functions"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28",children:"Model Evaluation and Performance Improvement"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02",children:"Multiclass Classification Problems"})]}),"\n",(0,i.jsxs)(n.li,{children:["Tensorflow 2 - Convolutional Neural Networks: ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03",children:"Binary Image Classification"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05",children:"Multiclass Image Classification"})]}),"\n",(0,i.jsxs)(n.li,{children:["Tensorflow 2 - Transfer Learning: ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06",children:"Feature Extraction"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11",children:"Fine-Tuning"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16",children:"Scaling"})]}),"\n",(0,i.jsxs)(n.li,{children:["Tensorflow 2 - Unsupervised Learning: ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24",children:"Autoencoder Feature Detection"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26",children:"Autoencoder Super-Resolution"}),", ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-generative-adversial-networks/2023-03-26",children:"Generative Adverserial Networks"})]}),"\n"]}),"\n",(0,i.jsx)(n.h1,{id:"tensorflow-convolutional-neural-networks",children:"Tensorflow Convolutional Neural Networks"}),"\n",(0,i.jsx)(n.h2,{id:"multiclass-image-classification",children:"Multiclass Image Classification"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"cd datasets"}),"\n",(0,i.jsxs)(n.li,{children:["wget ",(0,i.jsx)(n.a,{href:"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip",children:"https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip"})]}),"\n",(0,i.jsx)(n.li,{children:"unzip 10_food_classes_all_data.zip && rm 10_food_classes_all_data.zip"}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"10_food_classes_all_data\n\u251c\u2500\u2500 test\n\u2502\xa0\xa0 \u251c\u2500\u2500 chicken_curry\n\u2502\xa0\xa0 \u251c\u2500\u2500 chicken_wings\n\u2502\xa0\xa0 \u251c\u2500\u2500 fried_rice\n\u2502\xa0\xa0 \u251c\u2500\u2500 grilled_salmon\n\u2502\xa0\xa0 \u251c\u2500\u2500 hamburger\n\u2502\xa0\xa0 \u251c\u2500\u2500 ice_cream\n\u2502\xa0\xa0 \u251c\u2500\u2500 pizza\n\u2502\xa0\xa0 \u251c\u2500\u2500 ramen\n\u2502\xa0\xa0 \u251c\u2500\u2500 steak\n\u2502\xa0\xa0 \u2514\u2500\u2500 sushi\n\u2514\u2500\u2500 train\n    \u251c\u2500\u2500 chicken_curry\n    \u251c\u2500\u2500 chicken_wings\n    \u251c\u2500\u2500 fried_rice\n    \u251c\u2500\u2500 grilled_salmon\n    \u251c\u2500\u2500 hamburger\n    \u251c\u2500\u2500 ice_cream\n    \u251c\u2500\u2500 pizza\n    \u251c\u2500\u2500 ramen\n    \u251c\u2500\u2500 steak\n    \u2514\u2500\u2500 sushi\n\n23 directories, 0 files\n"})}),"\n",(0,i.jsx)(n.h3,{id:"visualizing-the-data",children:"Visualizing the Data"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# set directories\ntraining_directory = \"../datasets/10_food_classes_all_data/train/\"\ntesting_directory = \"../datasets/10_food_classes_all_data/test/\"\n\n# get class names\ndata_dir = pathlib.Path(training_directory)\nclass_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\nlen(class_names), class_names \n\n# the data set has 10 classes:\n# (10,\n# array(['chicken_curry', 'chicken_wings', 'fried_rice', 'grilled_salmon',\n#        'hamburger', 'ice_cream', 'pizza', 'ramen', 'steak', 'sushi'],\n#       dtype='<U14'))\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# visualizing the dataset\n## display random images\ndef view_random_image(target_dir, target_class):\n    target_folder = str(target_dir) + \"/\" + target_class\n    random_image = random.sample(os.listdir(target_folder), 1)\n    \n    img = mpimg.imread(target_folder + \"/\" + random_image[0])\n    plt.imshow(img)\n    plt.title(str(target_class) + str(img.shape))\n    plt.axis(\"off\")\n    \n    return tf.constant(img)\n\nfig = plt.figure(figsize=(12, 6))\nplot1 = fig.add_subplot(1, 2, 1)\nplot1.title.set_text(f'Class: {class_names[0]}')\npizza_image = view_random_image(target_dir = training_directory, target_class=class_names[0])\nplot2 = fig.add_subplot(1, 2, 2)\nplot2.title.set_text(f'Class: {class_names[1]}')\nsteak_image = view_random_image(target_dir = training_directory, target_class=class_names[1])\n\nfig = plt.figure(figsize=(12, 6))\nplot3 = fig.add_subplot(1, 2, 1)\nplot3.title.set_text(f'Class: {class_names[2]}')\npizza_image = view_random_image(target_dir = training_directory, target_class=class_names[2])\nplot4 = fig.add_subplot(1, 2, 2)\nplot4.title.set_text(f'Class: {class_names[3]}')\nsteak_image = view_random_image(target_dir = training_directory, target_class=class_names[3])\n\nfig = plt.figure(figsize=(12, 6))\nplot5 = fig.add_subplot(1, 2, 1)\nplot5.title.set_text(f'Class: {class_names[4]}')\npizza_image = view_random_image(target_dir = training_directory, target_class=class_names[4])\nplot6 = fig.add_subplot(1, 2, 2)\nplot6.title.set_text(f'Class: {class_names[5]}')\nsteak_image = view_random_image(target_dir = training_directory, target_class=class_names[5])\n\nfig = plt.figure(figsize=(12, 6))\nplot7 = fig.add_subplot(1, 2, 1)\nplot7.title.set_text(f'Class: {class_names[6]}')\npizza_image = view_random_image(target_dir = training_directory, target_class=class_names[6])\nplot8 = fig.add_subplot(1, 2, 2)\nplot8.title.set_text(f'Class: {class_names[7]}')\nsteak_image = view_random_image(target_dir = training_directory, target_class=class_names[7])\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(746044).Z+"",width:"950",height:"465"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(536870).Z+"",width:"910",height:"504"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(198036).Z+"",width:"950",height:"465"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(762910).Z+"",width:"950",height:"465"})}),"\n",(0,i.jsx)(n.h3,{id:"preprocessing-the-data",children:"Preprocessing the Data"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"seed = 42\nbatch_size = 32\nimg_height = 224\nimg_width = 224\n\ntf.random.set_seed(seed)\n\ntraining_data_multi = image_dataset_from_directory(training_directory,\n                                              labels='inferred',\n                                              label_mode='categorical',\n                                              seed=seed,\n                                              shuffle=True,\n                                              image_size=(img_height, img_width),\n                                              batch_size=batch_size)\n\ntesting_data_multi = image_dataset_from_directory(testing_directory,\n                                              labels='inferred',\n                                              label_mode='categorical',\n                                              seed=seed,\n                                              shuffle=True,\n                                              image_size=(img_height, img_width),\n                                              batch_size=batch_size)\n\n# Found 7500 files belonging to 10 classes.\n# Found 2500 files belonging to 10 classes.\n"})}),"\n",(0,i.jsx)(n.h3,{id:"building-the-model",children:"Building the Model"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'tf.random.set_seed(seed)\n# building the model based on the tiny vgg architecture\nvgg_model_multiclass = Sequential([\n  Rescaling(1./255),\n  Conv2D(filters=10, \n         kernel_size=3,\n         activation="relu", \n         input_shape=(img_height, img_width, 3)),\n  Conv2D(10, 3, activation="relu"),\n  MaxPool2D(pool_size=2, padding="valid"),\n  Conv2D(10, 3, activation="relu"),\n  Conv2D(10, 3, activation="relu"),\n  MaxPool2D(2, padding="valid"),\n  Flatten(),\n  Dense(len(class_names), activation="softmax")\n])\n\n# compile the model\nvgg_model_multiclass.compile(loss="categorical_crossentropy",\n                 optimizer=Adam(learning_rate=1e-3),\n                 metrics=["accuracy"])\n\n# fitting the model\nhistory_vgg_model_multiclass = vgg_model_multiclass.fit(training_data_multi, epochs=5,\n                            steps_per_epoch=len(training_data_multi),\n                            validation_data=testing_data_multi,\n                            validation_steps=len(testing_data_multi))\n\n# Epoch 5/5\n# 235/235 [==============================] - 12s 52ms/step - loss: 0.2465 - accuracy: 0.9251 - val_loss: 4.0673 - val_accuracy: 0.2760\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'pd.DataFrame(history_vgg_model_multiclass.history).plot(title="Tiny VGG (Multiclass)")\n\n# The training loss and accuracy are getting close to being perfect\n# while the validation loss is running away => overfitting\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(34158).Z+"",width:"547",height:"435"})}),"\n",(0,i.jsx)(n.h4,{id:"reduce-overfitting",children:"Reduce Overfitting"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'tf.random.set_seed(seed)\n# reduce the complexity of our model to minimize the overfit\nvgg_model_multiclass_simplified = Sequential([\n  Rescaling(1./255),\n  Conv2D(filters=10, \n         kernel_size=3,\n         activation="relu", \n         input_shape=(img_height, img_width, 3)),\n  MaxPool2D(pool_size=2, padding="valid"),\n  Conv2D(10, 3, activation="relu"),\n  MaxPool2D(2, padding="valid"),\n  Flatten(),\n  Dense(len(class_names), activation="softmax")\n])\n\n# compile the model\nvgg_model_multiclass_simplified.compile(loss="categorical_crossentropy",\n                 optimizer=Adam(learning_rate=1e-3),\n                 metrics=["accuracy"])\n\n# fitting the model\nhistory_vgg_model_multiclass_simplified = vgg_model_multiclass_simplified.fit(\n                            training_data_multi, epochs=5,\n                            steps_per_epoch=len(training_data_multi),\n                            validation_data=testing_data_multi,\n                            validation_steps=len(testing_data_multi))\n\n# Epoch 5/5\n# 235/235 [==============================] - 12s 52ms/step - loss: 0.2465 - accuracy: 0.9251 - val_loss: 4.0673 - val_accuracy: 0.2760\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\npd.DataFrame(history_vgg_model_multiclass.history).plot(ax=axes[0], title="Tiny VGG (Multiclass)")\npd.DataFrame(history_vgg_model_multiclass_simplified.history).plot(ax=axes[1], title="Simple Tiny VGG (Multiclass)")\n# that did not help at all...\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(584326).Z+"",width:"981",height:"528"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'tf.random.set_seed(seed)\n# adding data augmentations\n# i experimented a little bit with this\n# things can go horrible wrong if you\n# add too much :)\ndata_augmentation = Sequential([\n    RandomFlip("horizontal_and_vertical"),\n    RandomRotation(0.2),\n#     RandomZoom(0.1),\n#     RandomContrast(0.2),\n#     RandomBrightness(0.2)\n])\n\n# building the model\nvgg_model_multiclass_augmentation = Sequential([\n  data_augmentation,\n  Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n  Conv2D(16, 3, activation="relu"),\n  Conv2D(10, 3, activation="relu"),\n  MaxPool2D(pool_size=2, padding="same"),\n  Conv2D(16, 3, activation="relu"),\n  Conv2D(10, 3, activation="relu"),\n  MaxPool2D(2, padding="same"),\n  Flatten(),\n  Dense(len(class_names), activation="softmax")\n])\n\n# compile the model\nvgg_model_multiclass_augmentation.compile(loss="categorical_crossentropy",\n                 optimizer=Adam(learning_rate=1e-3),\n                 metrics=["accuracy"])\n\n# fitting the model\nhistory_vgg_model_multiclass_augmentation = vgg_model_multiclass_augmentation.fit(\n                            training_data_multi, epochs=25,\n                            steps_per_epoch=len(training_data_multi),\n                            validation_data=testing_data_multi,\n                            validation_steps=len(testing_data_multi))\n\n# Epoch 10/10\n# 235/235 [==============================] - 23s 99ms/step - loss: 1.6899 - accuracy: 0.4245 - val_loss: 1.8349 - val_accuracy: 0.3736\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\npd.DataFrame(history_vgg_model_multiclass.history).plot(ax=axes[0], title="Tiny VGG (Multiclass)")\npd.DataFrame(history_vgg_model_multiclass_augmentation.history).plot(ax=axes[1], title="Augmented Tiny VGG (Multiclass)")\n# this looks already alot better - but the improvement is very slow...\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(531729).Z+"",width:"981",height:"528"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# try adding a few more epochs to get those curves closer\nhistory_vgg_model_multiclass_augmentation = vgg_model_multiclass_augmentation.fit(\n                            training_data_multi, epochs=25,\n                            steps_per_epoch=len(training_data_multi),\n                            validation_data=testing_data_multi,\n                            validation_steps=len(testing_data_multi))\n\n# as expected - running the training for longer - slowly - improves the accuracy\n# as well as validation accuracy for the model. The validation loss, however, remains\n# stubbornly high:\n# Epoch 25/25\n# 235/235 [==============================] - 23s 97ms/step - loss: 1.3810 - accuracy: 0.5397 - val_loss: 1.7875 - val_accuracy: 0.4048\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\npd.DataFrame(history_vgg_model_multiclass.history).plot(ax=axes[0], title="Tiny VGG (Multiclass)")\npd.DataFrame(history_vgg_model_multiclass_augmentation.history).plot(ax=axes[1], title="Augmented Tiny VGG (Multiclass)")\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(216185).Z+"",width:"987",height:"528"})}),"\n",(0,i.jsx)(n.h3,{id:"making-predictions",children:"Making Predictions"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'img_height = 224\nimg_width = 224\n\n# helper function to pre-process images for predictions\ndef prepare_image(file_name, img_height=img_height, img_width=img_width):\n    # read in image\n    img = tf.io.read_file(file_name)\n    # image array => tensor\n    img = tf.image.decode_image(img)\n    # reshape to training size\n    img = tf.image.resize(img, size=[img_height, img_width])\n    # we don\'t need to normalize the image this is done by the model itself\n    # img = img/255\n    # add a dimension in front for batch size => shape=(1, 224, 224, 3)\n    img = tf.expand_dims(img, axis=0)\n    return img\n\n# adapt plot function for multiclass predictions\ndef predict_and_plot_multi(model, file_name, class_names):\n    # load the image and preprocess\n    img = prepare_image(file_name)\n    # run prediction\n    prediction = model.predict(img)\n    # check for multiclass\n    if len(prediction[0]) > 1:\n        # pick class with highest probability\n        pred_class = class_names[tf.argmax(prediction[0])]\n    else:\n        # binary classifications only return 1 probability value\n        pred_class = class_names[int(tf.round(prediction))]\n    # plot image & prediction\n    plt.imshow(mpimg.imread(file_name))\n    plt.title(f"Prediction: {pred_class}")\n    plt.axis(False)\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"fig = plt.figure(figsize=(12, 6))\nplot7 = fig.add_subplot(1, 2, 1)\npizza_image = predict_and_plot_multi(model=vgg_model_multiclass_augmentation, file_name=pizza_path, class_names=class_names)\nplot8 = fig.add_subplot(1, 2, 2)\nsteak_image = predict_and_plot_multi(model=vgg_model_multiclass_augmentation, file_name=steak_path, class_names=class_names)\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(761336).Z+"",width:"950",height:"323"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# a few more images to test with\nice_cream_path = "../assets/ice_cream.jpg"\nhamburger_path = "../assets/hamburger.jpg"\n\nfig = plt.figure(figsize=(12, 6))\nplot7 = fig.add_subplot(1, 2, 1)\npizza_image = predict_and_plot_multi(model=vgg_model_multiclass_augmentation, file_name=ice_cream_path, class_names=class_names)\nplot8 = fig.add_subplot(1, 2, 2)\nsteak_image = predict_and_plot_multi(model=vgg_model_multiclass_augmentation, file_name=hamburger_path, class_names=class_names)\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(740730).Z+"",width:"950",height:"359"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(324671).Z+"",width:"200",height:"200"})}),"\n",(0,i.jsxs)(n.p,{children:["This pretty much sums up the ",(0,i.jsx)(n.code,{children:"val_accuracy: 0.4048"})," value I gut during the training. With 10 I would get an ~ accuracy of ",(0,i.jsx)(n.code,{children:"10%"})," if the model was guessing randomly. The training got us factor 4 improvement. But it is far from perfect."]}),"\n",(0,i.jsx)(n.p,{children:"The validation accuracy was still increasing - so if I kept training the model I would get better results. But the increase was very slow - it might take a long time. The validation loss was running away in the beginning. But adding image augmentations pulled it back down nicely. I have been experimenting with different augmentations and their effect ranged from good to terrible :) - there is still some room for improvement adding or adjusting augmentations."}),"\n",(0,i.jsx)(n.p,{children:"The next thing - or maybe the first - would be to consolidate the dataset. Some of the images in it are terrible. They have plenty of clutter in the background. There is grilled salmon that looks like sushi. Or close-up chicken curry that could be a pizza. Removing some of those images, or preferably replacing them with higher quality images, will improve our model performance."}),"\n",(0,i.jsxs)(n.p,{children:["We could also check out the confuion matrix to see if there are classes that perform particularly bad. If there are we can concentrate our efforts on them. (see below - ",(0,i.jsx)(n.code,{children:"sushi"})," and ",(0,i.jsx)(n.code,{children:"ramen"})," seems to perform ",(0,i.jsx)(n.em,{children:"OK"}),")"]}),"\n",(0,i.jsx)(n.h3,{id:"saving--loading-the-model",children:"Saving & Loading the Model"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# save a model\nvgg_model_multiclass_augmentation.save("../saved_models/vgg_model_multiclass_augmentation")\n\n# INFO:tensorflow:Assets written to: ../saved_models/vgg_model_multiclass_augmentation/assets\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# load a trained model\nloaded_model = tf.keras.models.load_model("../saved_models/vgg_model_multiclass_augmentation")\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# test if the model was loaded successful\nsushi_path = "../assets/sushi.jpg"\nramen_path = "../assets/ramen.jpg"\n\nfig = plt.figure(figsize=(12, 6))\nplot7 = fig.add_subplot(1, 2, 1)\npizza_image = predict_and_plot_multi(model=loaded_model, file_name=sushi_path, class_names=class_names)\nplot8 = fig.add_subplot(1, 2, 2)\nsteak_image = predict_and_plot_multi(model=loaded_model, file_name=ramen_path, class_names=class_names)\n'})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Convolutional Neural Networks",src:a(573220).Z+"",width:"950",height:"458"})}),"\n",(0,i.jsxs)(n.p,{children:["To fast forward -> Next step ",(0,i.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06",children:"Transfer Learning"})]})]})}function g(e={}){const{wrapper:n}={...(0,t.ah)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(d,{...e})}):d(e)}},603905:(e,n,a)=>{a.d(n,{ah:()=>c});var i=a(667294);function t(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function s(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,i)}return a}function l(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?s(Object(a),!0).forEach((function(n){t(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function o(e,n){if(null==e)return{};var a,i,t=function(e,n){if(null==e)return{};var a,i,t={},s=Object.keys(e);for(i=0;i<s.length;i++)a=s[i],n.indexOf(a)>=0||(t[a]=e[a]);return t}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(i=0;i<s.length;i++)a=s[i],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(t[a]=e[a])}return t}var r=i.createContext({}),c=function(e){var n=i.useContext(r),a=n;return e&&(a="function"==typeof e?e(n):l(l({},n),e)),a},d={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},g=i.forwardRef((function(e,n){var a=e.components,t=e.mdxType,s=e.originalType,r=e.parentName,g=o(e,["components","mdxType","originalType","parentName"]),m=c(a),h=t,_=m["".concat(r,".").concat(h)]||m[h]||d[h]||s;return a?i.createElement(_,l(l({ref:n},g),{},{components:a})):i.createElement(_,l({ref:n},g))}));g.displayName="MDXCreateElement"},746044:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_09-1352e1349407f735f0e2191ae26c45f3.png"},536870:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_10-2a118657821ad192f6398df000a920b0.png"},198036:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_11-a442b086d6f2f305f49cdb9e0e313e25.png"},762910:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_12-e7e9f4c03f74ba6b642906f9a7469fff.png"},34158:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_13-0a766446a5b0084e830a9f65eca3fe1a.png"},584326:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_14-26bf4f147471d9896a2889deed93009a.png"},531729:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_15-582bf5b2a2b901bafee7614101908f9a.png"},216185:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_16-b5bc2d6629772e625c139c057756578c.png"},761336:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_17-63f2703cb543c8df55bbb8b4de0b4bcc.png"},740730:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_18-af2be271e7738975734a60dcc2c43bad.png"},573220:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/03_Tensorflow_Convolutional_Neural_Networks_19-30824550113d807f2806e93ff862e095.png"},324671:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/hmmmm-0aa854f42905bbb37952c1b5e1e14729.gif"},137151:(e,n,a)=>{a.d(n,{Z:()=>i});const i=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-cd27afc91b9ae79990579bad65920e0c.jpg"}}]);