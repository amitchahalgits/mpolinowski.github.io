"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[28850],{352772:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>g,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var a=r(785893),t=r(603905);const s={sidebar_position:4810,slug:"2023-01-03",title:"Tensorflow Tensorboard",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Tensorflow dashboard that allows you to track the network performance by accuracy and loss statistics."},i=void 0,o={id:"IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/index",title:"Tensorflow Tensorboard",description:"Tensorflow dashboard that allows you to track the network performance by accuracy and loss statistics.",source:"@site/docs/IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/index.md",sourceDirName:"IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard",slug:"/IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/2023-01-03",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/2023-01-03",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4810,frontMatter:{sidebar_position:4810,slug:"2023-01-03",title:"Tensorflow Tensorboard",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Tensorflow dashboard that allows you to track the network performance by accuracy and loss statistics."},sidebar:"tutorialSidebar",previous:{title:"Distributed training with TensorFlow",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-04-tf-distributed-strategy/2023-01-04"},next:{title:"Tensorflow Serving REST API",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models/2023-01-02"}},l={},c=[{value:"Adding Tensorboard",id:"adding-tensorboard",level:2},{value:"Starting Tensorboard",id:"starting-tensorboard",level:2},{value:"Tracking Progress",id:"tracking-progress",level:2},{value:"Displaying Image Datasets",id:"displaying-image-datasets",level:2},{value:"Logging arbitrary Image Data",id:"logging-arbitrary-image-data",level:3},{value:"Confusion Matrix",id:"confusion-matrix",level:3}];function d(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.ah)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Guangzhou, China",src:r(684027).Z+"",width:"1500",height:"662"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#adding-tensorboard",children:"Adding Tensorboard"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#starting-tensorboard",children:"Starting Tensorboard"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#tracking-progress",children:"Tracking Progress"})}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"#displaying-image-datasets",children:"Displaying Image Datasets"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#logging-arbitrary-image-data",children:"Logging arbitrary Image Data"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#confusion-matrix",children:"Confusion Matrix"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://github.com/mpolinowski/tf-serving",children:"Github Repository"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.a,{href:"https://www.tensorflow.org/tensorboard",children:"Tensorboard"})," is - since Tensorflow 2.0 - a build-in model learning dashboard that we can use to track the network performance by accuracy and loss statistics. I want to take my previous project ",(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models/2023-01-02",children:"Feature Detection based on the MNIST Fashion Dataset"})," and add Tensorboard to optimize my neural network."]}),"\n",(0,a.jsx)(n.h2,{id:"adding-tensorboard",children:"Adding Tensorboard"}),"\n",(0,a.jsxs)(n.p,{children:["I will start with the simple network layout that is used by the ",(0,a.jsx)(n.a,{href:"https://www.tensorflow.org/tfx/tutorials/serving/rest_simple",children:"official Tensorflow tutorial"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"classifier = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(input_shape=(28,28,1), filters=8, kernel_size=3, strides=2, activation='relu', name='Conv1'),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(10, name='Dense')\n])\n\nclassifier.compile(optimizer='adam', \n  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n"})}),"\n",(0,a.jsx)(n.p,{children:"Now before starting the training we have to add two lines to initialize Tensorboard and insert this callback into our training:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:'# configuring tensorboard\nlog_dir="tensorboard/logs/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n\n# model training\nclassifier.fit(X_train, y_train, epochs=EPOCHS, callbacks=[tensorboard_callback])\n'})}),"\n",(0,a.jsx)(n.h2,{id:"starting-tensorboard",children:"Starting Tensorboard"}),"\n",(0,a.jsx)(n.p,{children:"To execute Tensorboard run the following command in your terminal or add the following line to the end of your training code:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:'# execute tensorboard\nos.system("tensorboard --logdir tensorboard/logs")\n'})}),"\n",(0,a.jsxs)(n.p,{children:["This will serve Tensorboard on port ",(0,a.jsx)(n.code,{children:"6006"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\nTensorBoard 2.11.0 at http://localhost:6006/ (Press CTRL+C to quit)\n"})}),"\n",(0,a.jsx)(n.p,{children:"A brief overview of the dashboards shown (tabs in top navigation bar):"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"The Scalars dashboard"})," shows how the loss and metrics change with every epoch. You can use it to also track training speed, learning rate, and other scalar values."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"The Graphs dashboard"})," helps you visualize your model. In this case, the Keras graph of layers is shown which can help you ensure it is built correctly."]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"The Distributions and Histograms dashboards"})," show the distribution of a Tensor over time. This can be useful to visualize weights and biases and verify that they are changing in an expected way."]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Tensorflow Tensorboard",src:r(531040).Z+"",width:"1222",height:"790"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Tensorflow Tensorboard",src:r(354897).Z+"",width:"930",height:"840"})}),"\n",(0,a.jsx)(n.h2,{id:"tracking-progress",children:"Tracking Progress"}),"\n",(0,a.jsx)(n.p,{children:"Changing to a slightly more complicated network:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"## second attempt\nclassifier = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28,28,1)),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(64, activation = 'relu'),\n  tf.keras.layers.Dense(10, activation = 'softmax')\n])\n"})}),"\n",(0,a.jsx)(n.p,{children:"The first attempt in green and the second in orange it is already very obvious that the latter performs a lot better:"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Tensorflow Tensorboard",src:r(697605).Z+"",width:"1099",height:"894"})}),"\n",(0,a.jsx)(n.p,{children:"So add even more complexity and see what happens:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"## third attempt\nclassifier = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(6, (5,5), activation = 'relu', input_shape = (28,28,1)),\n  tf.keras.layers.AveragePooling2D(),\n  tf.keras.layers.Conv2D(16, (5,5), activation = 'relu'),\n  tf.keras.layers.AveragePooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(120, activation = 'relu'),\n  tf.keras.layers.Dense(84, activation = 'relu'),\n  tf.keras.layers.Dense(10, activation = 'softmax')\n])\n"})}),"\n",(0,a.jsx)(n.p,{children:"We can see that this network (blue) roughly performs as well as the first attempt network (green) - in this case I would continue working with the second network (orange) as it performs significantly better:"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Tensorflow Tensorboard",src:r(31180).Z+"",width:"1099",height:"897"})}),"\n",(0,a.jsx)(n.h2,{id:"displaying-image-datasets",children:"Displaying Image Datasets"}),"\n",(0,a.jsxs)(n.p,{children:["To be able to inspect images from our dataset in Tensorboard we need to add an ",(0,a.jsx)(n.code,{children:"file_writer"}),". The following will take the first image of the training dataset and make it available to Tensorboard:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:'# configuring tensorboard\n## set log data location\nlog_dir="tensorboard/logs/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")\n## create a file writer for the log directory\nfile_writer = tf.summary.create_file_writer(log_dir)\n## reshape the first training image\nimg = np.reshape(X_train[0], (-1, 28, 28, 1))\n## using the file writer to log the reshaped image\nwith file_writer.as_default():\n  tf.summary.image("Training data", img, step=0)\n## create Tensorboard callback\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Tensorflow Tensorboard",src:r(958562).Z+"",width:"1095",height:"682"})}),"\n",(0,a.jsx)(n.h3,{id:"logging-arbitrary-image-data",children:"Logging arbitrary Image Data"}),"\n",(0,a.jsxs)(n.p,{children:["In the code below, you'll log the first 25 images as a nice grid using matplotlib's ",(0,a.jsx)(n.code,{children:"subplot()"})," function:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:'# configuring tensorboard\n## set log data location\nlog_dir="tensorboard/logs/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")\n## create a file writer for the log directory\nfile_writer = tf.summary.create_file_writer(log_dir)\n\ndef plot_to_image(figure):\n  # Converts the matplotlib plot specified by \'figure\' to a PNG image and\n  # returns it. The supplied figure is closed and inaccessible after this call.\n  # Save the plot to a PNG in memory.\n  buf = io.BytesIO()\n  plt.savefig(buf, format=\'png\')\n  # Closing the figure prevents it from being displayed directly inside\n  # the notebook.\n  plt.close(figure)\n  buf.seek(0)\n  # Convert PNG buffer to TF image\n  image = tf.image.decode_png(buf.getvalue(), channels=4)\n  # Add the batch dimension\n  image = tf.expand_dims(image, 0)\n  return image\n\ndef image_grid():\n  # Return a 5x5 grid of the MNIST images as a matplotlib figure.\n  # Create a figure to contain the plot.\n  figure = plt.figure(figsize=(10,10))\n  for i in range(25):\n    # Start next subplot.\n    plt.subplot(5, 5, i + 1, title=class_names[y_train[i]])\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(X_train[i], cmap=plt.cm.binary)\n\n  return figure\n\n# Prepare the plot\nfigure = image_grid()\n# Convert to image and log\nwith file_writer.as_default():\n  tf.summary.image("Training data", plot_to_image(figure), step=0)\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Tensorflow Tensorboard",src:r(802086).Z+"",width:"1349",height:"886"})}),"\n",(0,a.jsx)(n.h3,{id:"confusion-matrix",children:"Confusion Matrix"}),"\n",(0,a.jsx)(n.p,{children:"When training a classifier, it's useful to see the confusion matrix. The confusion matrix gives you detailed knowledge of how your classifier is performing on test data. Define a function that calculates the confusion matrix:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:'def plot_confusion_matrix(cm, class_names):\n  """\n  Returns a matplotlib figure containing the plotted confusion matrix.\n\n  Args:\n    cm (array, shape = [n, n]): a confusion matrix of integer classes\n    class_names (array, shape = [n]): String names of the integer classes\n  """\n  figure = plt.figure(figsize=(8, 8))\n  plt.imshow(cm, interpolation=\'nearest\', cmap=plt.cm.Blues)\n  plt.title("Confusion Matrix")\n  plt.colorbar()\n  tick_marks = np.arange(len(class_names))\n  plt.xticks(tick_marks, class_names, rotation=45)\n  plt.yticks(tick_marks, class_names)\n\n  # Compute the labels from the normalized confusion matrix.\n  labels = np.around(cm.astype(\'float\') / cm.sum(axis=1)[:, np.newaxis], decimals=2)\n\n  # Use white text if squares are dark; otherwise black.\n  threshold = cm.max() / 2.\n  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n    color = "white" if cm[i, j] > threshold else "black"\n    plt.text(j, i, labels[i, j], horizontalalignment="center", color=color)\n\n  plt.tight_layout()\n  plt.ylabel(\'True label\')\n  plt.xlabel(\'Predicted label\')\n  return figure\n\nfile_writer_cm = tf.summary.create_file_writer(log_dir + \'/cm\')\n\n\ndef log_confusion_matrix(epoch, logs):\n  # Use the model to predict the values from the validation dataset.\n  test_pred_raw = classifier.predict(X_test)\n  test_pred = np.argmax(test_pred_raw, axis=1)\n\n  # Calculate the confusion matrix.\n  cm = confusion_matrix(y_test, test_pred)\n  # Log the confusion matrix as an image summary.\n  figure = plot_confusion_matrix(cm, class_names=class_names)\n  cm_image = plot_to_image(figure)\n\n  # Log the confusion matrix as an image summary.\n  with file_writer_cm.as_default():\n    tf.summary.image("Confusion Matrix", cm_image, step=epoch)\n\n# Define the per-epoch callback.\ncm_callback = tf.keras.callbacks.LambdaCallback(on_epoch_end=log_confusion_matrix)\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Tensorflow Tensorboard",src:r(278653).Z+"",width:"1386",height:"899"})})]})}function g(e={}){const{wrapper:n}={...(0,t.ah)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},603905:(e,n,r)=>{r.d(n,{ah:()=>c});var a=r(667294);function t(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function s(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,a)}return r}function i(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?s(Object(r),!0).forEach((function(n){t(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):s(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function o(e,n){if(null==e)return{};var r,a,t=function(e,n){if(null==e)return{};var r,a,t={},s=Object.keys(e);for(a=0;a<s.length;a++)r=s[a],n.indexOf(r)>=0||(t[r]=e[r]);return t}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(a=0;a<s.length;a++)r=s[a],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(t[r]=e[r])}return t}var l=a.createContext({}),c=function(e){var n=a.useContext(l),r=n;return e&&(r="function"==typeof e?e(n):i(i({},n),e)),r},d={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},g=a.forwardRef((function(e,n){var r=e.components,t=e.mdxType,s=e.originalType,l=e.parentName,g=o(e,["components","mdxType","originalType","parentName"]),h=c(r),f=t,p=h["".concat(l,".").concat(f)]||h[f]||d[f]||s;return r?a.createElement(p,i(i({ref:n},g),{},{components:r})):a.createElement(p,i({ref:n},g))}));g.displayName="MDXCreateElement"},531040:(e,n,r)=>{r.d(n,{Z:()=>a});const a=r.p+"assets/images/Tensorflow_Tensorboard_01-f30dc70840228c4f81d5d7fdca28255c.png"},354897:(e,n,r)=>{r.d(n,{Z:()=>a});const a=r.p+"assets/images/Tensorflow_Tensorboard_02-cd0a7023b00f92cec121441d89159761.png"},697605:(e,n,r)=>{r.d(n,{Z:()=>a});const a=r.p+"assets/images/Tensorflow_Tensorboard_04-e707abf628dd6f6bd6cbf9f599d60f40.png"},31180:(e,n,r)=>{r.d(n,{Z:()=>a});const a=r.p+"assets/images/Tensorflow_Tensorboard_05-7b14f5b930e23630363b1046bbab089c.png"},958562:(e,n,r)=>{r.d(n,{Z:()=>a});const a=r.p+"assets/images/Tensorflow_Tensorboard_06-ac6231616103409b859d871a0c46569e.png"},802086:(e,n,r)=>{r.d(n,{Z:()=>a});const a=r.p+"assets/images/Tensorflow_Tensorboard_07-c06122b76b3be0f47e53c8a6c0883298.png"},278653:(e,n,r)=>{r.d(n,{Z:()=>a});const a=r.p+"assets/images/Tensorflow_Tensorboard_08-2c2beb896e41d5f9665a64a869f4d900.png"},684027:(e,n,r)=>{r.d(n,{Z:()=>a});const a=r.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-296769d73822f07b0ac5dc952f56bfa1.jpg"}}]);