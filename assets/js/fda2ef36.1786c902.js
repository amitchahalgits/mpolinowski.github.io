"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[98460],{3905:(e,a,n)=>{n.d(a,{Zo:()=>c,kt:()=>p});var t=n(67294);function r(e,a,n){return a in e?Object.defineProperty(e,a,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[a]=n,e}function s(e,a){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);a&&(t=t.filter((function(a){return Object.getOwnPropertyDescriptor(e,a).enumerable}))),n.push.apply(n,t)}return n}function l(e){for(var a=1;a<arguments.length;a++){var n=null!=arguments[a]?arguments[a]:{};a%2?s(Object(n),!0).forEach((function(a){r(e,a,n[a])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):s(Object(n)).forEach((function(a){Object.defineProperty(e,a,Object.getOwnPropertyDescriptor(n,a))}))}return e}function i(e,a){if(null==e)return{};var n,t,r=function(e,a){if(null==e)return{};var n,t,r={},s=Object.keys(e);for(t=0;t<s.length;t++)n=s[t],a.indexOf(n)>=0||(r[n]=e[n]);return r}(e,a);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(t=0;t<s.length;t++)n=s[t],a.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var o=t.createContext({}),A=function(e){var a=t.useContext(o),n=a;return e&&(n="function"==typeof e?e(a):l(l({},a),e)),n},c=function(e){var a=A(e.components);return t.createElement(o.Provider,{value:a},e.children)},m={inlineCode:"code",wrapper:function(e){var a=e.children;return t.createElement(t.Fragment,{},a)}},d=t.forwardRef((function(e,a){var n=e.components,r=e.mdxType,s=e.originalType,o=e.parentName,c=i(e,["components","mdxType","originalType","parentName"]),d=A(n),p=r,u=d["".concat(o,".").concat(p)]||d[p]||m[p]||s;return n?t.createElement(u,l(l({ref:a},c),{},{components:n})):t.createElement(u,l({ref:a},c))}));function p(e,a){var n=arguments,r=a&&a.mdxType;if("string"==typeof e||r){var s=n.length,l=new Array(s);l[0]=d;var i={};for(var o in a)hasOwnProperty.call(a,o)&&(i[o]=a[o]);i.originalType=e,i.mdxType="string"==typeof e?e:r,l[1]=i;for(var A=2;A<s;A++)l[A]=n[A];return t.createElement.apply(null,l)}return t.createElement.apply(null,n)}d.displayName="MDXCreateElement"},89914:(e,a,n)=>{n.r(a),n.d(a,{assets:()=>o,contentTitle:()=>l,default:()=>m,frontMatter:()=>s,metadata:()=>i,toc:()=>A});var t=n(87462),r=(n(67294),n(3905));const s={sidebar_position:4580,slug:"2023-03-02",title:"Tensorflow 2 - Neural Network Classifications",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Multiclass Classification Problems"},l=void 0,i={unversionedId:"IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/index",id:"IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/index",title:"Tensorflow 2 - Neural Network Classifications",description:"Multiclass Classification Problems",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification",slug:"/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4580,frontMatter:{sidebar_position:4580,slug:"2023-03-02",title:"Tensorflow 2 - Neural Network Classifications",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Multiclass Classification Problems"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow 2 - Convolutional Neural Networks",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03"},next:{title:"Tensorflow 2 - Neural Network Classification",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28"}},o={},A=[{value:"Multiclass Classifications",id:"multiclass-classifications",level:2},{value:"Multiclass Classification Model",id:"multiclass-classification-model",level:2},{value:"Model Performance Improvements",id:"model-performance-improvements",level:2},{value:"Normalize Data Inputs",id:"normalize-data-inputs",level:3},{value:"Finding the Ideal Learning Rate",id:"finding-the-ideal-learning-rate",level:3},{value:"Making predictions to further evaluate the model",id:"making-predictions-to-further-evaluate-the-model",level:2},{value:"Weights &amp; Biases",id:"weights--biases",level:2}],c={toc:A};function m(e){let{components:a,...s}=e;return(0,r.kt)("wrapper",(0,t.Z)({},c,s,{components:a,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"TST, Hong Kong",src:n(18240).Z,width:"1500",height:"557"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#tensorflow-neural-network-classification"},"Tensorflow Neural Network Classification"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#multiclass-classifications"},"Multiclass Classifications")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#multiclass-classification-model"},"Multiclass Classification Model")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#model-performance-improvements"},"Model Performance Improvements"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#normalize-data-inputs"},"Normalize Data Inputs")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#finding-the-ideal-learning-rate"},"Finding the Ideal Learning Rate")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#making-predictions-to-further-evaluate-the-model"},"Making predictions to further evaluate the model")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#weights--biases"},"Weights \\& Biases"))))),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"See also:")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Fun, fun, tensors: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19"},"Tensor Constants, Variables and Attributes"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21"},"Tensor Indexing, Expanding and Manipulations"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22"},"Matrix multiplications, Squeeze, One-hot and Numpy")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Neural Network Regression: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23"},"Building a Regression Model"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24"},"Model Evaluation"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25"},"Model Optimization"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26"},'Working with a "Real" Dataset'),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26"},"Feature Scaling")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Neural Network Classification: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27"},"Non-linear Data and Activation Functions"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28"},"Model Evaluation and Performance Improvement"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02"},"Multiclass Classification Problems")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Convolutional Neural Networks: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03"},"Binary Image Classification"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05"},"Multiclass Image Classification")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Transfer Learning: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06"},"Feature Extraction"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11"},"Fine-Tuning"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16"},"Scaling")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Unsupervised Learning: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24"},"Autoencoders"))),(0,r.kt)("h1",{id:"tensorflow-neural-network-classification"},"Tensorflow Neural Network Classification"),(0,r.kt)("h2",{id:"multiclass-classifications"},"Multiclass Classifications"),(0,r.kt)("p",null,"Working with the MNIST Fashion Dataset -> 60k images / 10 classes"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# importing the mnist dataset with keras\n(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.fashion_mnist.load_data()\ntrain_data.shape, test_data.shape\n# ((60000, 28, 28), (10000, 28, 28)) => 60k training images & 10k testing images with 28x28px\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# show example data\n\n## training labels\nclass_names = ["T-shirt/Top", "Trousers", "Pullover", "Dress", "Coat", "Sandal", "Shirt", "Sneaker", "Bag", "Ankle Boot"]\n\n## print label and data for index 666\nprint(f"Training Label:\\n{class_names[train_labels[666]]}\\n")\nprint(f"Training Data:\\n{train_data[666]}")\n\nplt.imshow(train_data[666], cmap=plt.cm.binary)\nplt.title(class_names[train_labels[666]])\n\n# Training Label:\n# Sneaker\n\n# Training Data:\n# [[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   2   0   0   0  25  51   0   5   0   0   0   0   0   0   0   0  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   2  72  74 115 175   7   0   7   5   0   2   0 146 110   7  0]\n#  [  0   0   0   0   0   0   0   0   0   0   0  54  95  92 123  77 123  72  20   0   0   0   0   0 255 136  51  0]\n#  [  0   0   0   0   0   0   2   0   2  38  79  97 118  90 105 121  95 115  128  59  48   5   5  64 118 103  82 0]\n#  [  0   0   0   0   0   5   2   0  61 121 108  92 115 162 167 162 175 133  105 113 144 133 110 133 144 146 141 2]\n#  [  2   0   0   0   0   0   5  36 113 103  95 118 128 126 110 108 151 182  195 167 139 136 136 115 126 108 123 2]\n#  [  0   0   2   0   7  33  51  85 105 123 128  92  90  79 108 133 103 121  162 170 193 206 151 126 123 123 118 5]\n#  [  5  33  48  59  72  74  82  82 115 123 121 118 139 115  90 133 139 136  149 164 180 170 157 170 151 139 131 2]\n#  [ 61 136 113  90  95  92 100 108 103 103 113 126 133 164 170 146 157 149  115  87  72  82 110 123 128 131 100 0]\n#  [ 41  79 118 159 149 139 136 131 113 110 113 118 113  79  85  43  15  25  36  38  51  59  41  41  41  36  54  0]\n#  [ 46  66  30  28  28  23  28  25  23  28  30  36  38  54  56  66  92 100  97  92  82  72  77  66  69  74  85 15]\n#  [  0  20  54  69  72  72  79  82  79  82  79  82  82  72  82  87  74  72  74  64  54  54  56  51  56  54  51  7]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0]\n#  [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  0   0   0   0   0   0   0   0   0   0]]\n\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow - Classification Problems",src:n(16604).Z,width:"416",height:"435"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# plot multiple random images with labels\nran_gen = np.random.default_rng()\n\nplt.figure(figsize=(12, 12))\n\nfor i in range(12):\n    ax = plt.subplot(4, 4, i+1)\n    random_index = ran_gen.integers(low=0, high=59999, size=1)\n    plt.imshow(train_data[random_index[0]], cmap=plt.cm.binary)\n    plt.title(class_names[train_labels[random_index[0]]])\n    plt.axis(False)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow - Classification Problems",src:n(13368).Z,width:"948",height:"725"})),(0,r.kt)("h2",{id:"multiclass-classification-model"},"Multiclass Classification Model"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Input Shape"),": Shape of the input image -> train_data","[0]",".shape = ",(0,r.kt)("inlineCode",{parentName:"li"},"(28, 28)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Output Shape"),": Number of labels -> len(np.unique(train_labels)) = ",(0,r.kt)("inlineCode",{parentName:"li"},"10")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Loss Function"),": ",(0,r.kt)("inlineCode",{parentName:"li"},"tf.keras.losses.CategoricalCrossentropy")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Output Layer Activation"),": ",(0,r.kt)("inlineCode",{parentName:"li"},"softmax"))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# determin the input and output shape\ntrain_data[0].shape, len(np.unique(train_labels))\n# ((28, 28), 10)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# building the model - 1st attempt\ntf.random.set_seed(42)\n\nmodel_multiclass = tf.keras.Sequential([\n    tf.keras.layers.Dense(4, activation="relu", name="input_layer"),\n    tf.keras.layers.Dense(4, activation="relu", name="dense_layer1"),\n    tf.keras.layers.Dense(10, activation="softmax", name="output_layer")\n])\n                          \nmodel_multiclass.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                        metrics="accuracy")\n                          \nhistory_multi = model_multiclass.fit(train_data, train_labels, batch_size=32,\n                    validation_data=(test_data, test_labels),\n                    epochs=100, verbose=1)\n\n# ValueError: Shapes (32,) and (32, 28, 10) are incompatible\n# => input data needs to be flattened\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# building the model - 2nd attempt\ntf.random.set_seed(42)\n\nmodel_multiclass = tf.keras.Sequential([\n    # flatten data from `28*28` => `None, 784`\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(4, activation="relu", name="input_layer"),\n    tf.keras.layers.Dense(4, activation="relu", name="dense_layer1"),\n    tf.keras.layers.Dense(10, activation="softmax", name="output_layer")\n])\n                          \nmodel_multiclass.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                        metrics="accuracy")\n                          \nhistory_multi = model_multiclass.fit(train_data, train_labels, batch_size=32,\n                    validation_data=(test_data, test_labels),\n                    epochs=100, verbose=1)\n\n# ValueError: Shapes (32, 1) and (32, 10) are incompatible\n# => CategoricalCrossentropy() expects labels to be OneHot encoded\n# use SparseCategoricalCrossentropy() instead\n')),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Use ",(0,r.kt)("inlineCode",{parentName:"p"},"SparseCategoricalCrossentropy()"),' for "regular" labels')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# building the model - 3rd attempt (works!)\ntf.random.set_seed(42)\n\nmodel_multiclass = tf.keras.Sequential([\n    # flatten data from `28*28` to `None, 784`\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(4, activation="relu", name="input_layer"),\n    tf.keras.layers.Dense(4, activation="relu", name="dense_layer1"),\n    tf.keras.layers.Dense(10, activation="softmax", name="output_layer")\n])\n                          \nmodel_multiclass.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                        metrics="accuracy")\n                          \nhistory_multi = model_multiclass.fit(train_data, train_labels, batch_size=32,\n                    validation_data=(test_data, test_labels),\n                    epochs=100, verbose=1)\n\n# Epoch 100/100\n# 1875/1875 [==============================] - 3s 2ms/step - loss: 1.0307 - accuracy: 0.5697 - val_loss: 1.0820 - val_accuracy: 0.5568\n')),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"Use ",(0,r.kt)("inlineCode",{parentName:"p"},"CategoricalCrossentropy()")," for OneHot encoded labels")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# building the model - with OneHot encoded labels (alternative)\n## OneHot encode labels\ntrain_labels_hot = tf.one_hot(train_labels, depth=10)\ntest_labels_hot = tf.one_hot(test_labels, depth=10)\n\n## re-run model with CategoricalCrossentropy() and ecoded labels\ntf.random.set_seed(42)\n\nmodel_multiclass_OneHot = tf.keras.Sequential([\n    # flatten data from `28*28` to `None, 784`\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(4, activation="relu", name="input_layer"),\n    tf.keras.layers.Dense(4, activation="relu", name="dense_layer1"),\n    tf.keras.layers.Dense(10, activation="softmax", name="output_layer")\n])\n                          \nmodel_multiclass_OneHot.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                        metrics="accuracy")\n                          \nhistory_multi_OneHot = model_multiclass_OneHot.fit(train_data, train_labels_hot, batch_size=32,\n                    validation_data=(test_data, test_labels_hot),\n                    epochs=100, verbose=1)\n\n# Epoch 100/100\n# 1875/1875 [==============================] - 4s 2ms/step - loss: 1.3885 - accuracy: 0.3996 - val_loss: 1.4322 - val_accuracy: 0.4055\n')),(0,r.kt)("h2",{id:"model-performance-improvements"},"Model Performance Improvements"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'model_multiclass.summary()\n\n# Model: "sequential_1"\n# _________________________________________________________________\n#  Layer (type)                Output Shape              Param #   \n# =================================================================\n#  flatten_1 (Flatten)         (None, 784)               0         \n                                                                 \n#  input_layer (Dense)         (None, 4)                 3140      \n                                                                 \n#  dense_layer1 (Dense)        (None, 4)                 20        \n                                                                 \n#  output_layer (Dense)        (None, 10)                50        \n                                                                 \n# =================================================================\n# Total params: 3,210\n# Trainable params: 3,210\n# Non-trainable params: 0\n# _________________________________________________________________\n')),(0,r.kt)("h3",{id:"normalize-data-inputs"},"Normalize Data Inputs"),(0,r.kt)("p",null,'The images are in grayscale and each pixel has a "dark level" between ',(0,r.kt)("inlineCode",{parentName:"p"},"0")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"255"),". We can use normalization to rearrange this scale to be between ",(0,r.kt)("inlineCode",{parentName:"p"},"0")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"1")," instead. I do not expect there to be an advantage here. Normalization helps to make two features, that have different scales, comparable. Or in transfer learning - where the base model would, very likely, be trained on normalized data. So there should not be an effect here (?)"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# check data value scale to verify\ntrain_data.min(), train_data.max()\n# (0, 255)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# the scaling here is simple - just divide by the maximum 255\ntrain_data_norm = train_data / 255.0\ntest_data_norm = test_data / 255.0\n\n# verify\ntrain_data_norm.min(), train_data_norm.max(), test_data_norm.min(), test_data_norm.max()\n# (0.0, 1.0, 0.0, 1.0)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# rebuild the model - this time with normalized data\n\ntf.random.set_seed(42)\n\nmodel_multiclass_norm = tf.keras.Sequential([\n    # flatten data from `28*28` to `None, 784`\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(4, activation="relu", name="input_layer"),\n    tf.keras.layers.Dense(4, activation="relu", name="dense_layer1"),\n    tf.keras.layers.Dense(10, activation="softmax", name="output_layer")\n])\n                          \nmodel_multiclass_norm.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                        optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n                        metrics="accuracy")\n                          \nhistory_multi_norm = model_multiclass_norm.fit(train_data_norm, train_labels, batch_size=32,\n                    validation_data=(test_data_norm, test_labels),\n                    epochs=100, verbose=1)\n\n# oh wow - the loss is still quite high. but there is a big improvement in accuracy. unexpected...\n# Epoch 100/100\n# 1875/1875 [==============================] - 4s 2ms/step - loss: 0.4706 - accuracy: 0.8376 - val_loss: 0.5227 - val_accuracy: 0.8177\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# print loss curves\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\npd.DataFrame(history_multi.history).plot(ax=axes[0], title="Direct Data")\npd.DataFrame(history_multi_norm.history).plot(ax=axes[1], title="Normalized Data")\n\n# nomalized rules!\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow - Classification Problems",src:n(7613).Z,width:"981",height:"528"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# confusion matrix\ntest_predictions = model_multiclass_norm.predict(test_data_norm)\n\nconfusion_norm = confusion_matrix(test_labels, np.argmax(test_predictions,axis=1))\nconfusion_norm\n\n# the confusion matrix already  starts to look promising\n\n# array([[757,   1,  27, 101,   4,   4,  85,   0,  19,   2],\n#        [  3, 945,   9,  36,   5,   0,   1,   0,   1,   0],\n#        [ 31,   3, 699,  10, 147,   0, 106,   0,   4,   0],\n#        [ 49,  11,   8, 853,  28,   0,  41,   0,  10,   0],\n#        [  1,   3, 111,  36, 738,   0, 102,   0,   9,   0],\n#        [  0,   1,   0,   1,   0, 895,   0,  53,   3,  47],\n#        [188,   4, 105,  62, 101,   0, 509,   0,  29,   2],\n#        [  0,   0,   0,   0,   0,  42,   0, 926,   0,  32],\n#        [  7,   2,   2,  11,   2,   4,  39,   5, 927,   1],\n#        [  1,   0,   0,   0,   0,  18,   0,  52,   1, 928]])\n")),(0,r.kt)("h3",{id:"finding-the-ideal-learning-rate"},"Finding the Ideal Learning Rate"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# add adaptive learning rate\ntf.random.set_seed(42)\n\nmodel_multiclass_norm_lr = tf.keras.Sequential([\n    tf.keras.layers.Flatten(input_shape=(28, 28), name="input_layer"),\n    tf.keras.layers.Dense(4, activation="relu", name="dense_layer1"),\n    tf.keras.layers.Dense(4, activation="relu", name="dense_layer2"),\n    tf.keras.layers.Dense(10, activation="softmax", name="output_layer")\n])\n\nmodel_multiclass_norm_lr.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                                optimizer=tf.keras.optimizers.Adam(),\n                                metrics=["accuracy"])\n\nlearning_rate_callback = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 10**(epoch/20))\n\n\nmodel_multiclass_norm_lr_history = model_multiclass_norm_lr.fit(train_data_norm, train_labels,\n                             callbacks=[learning_rate_callback],\n                            validation_data=(test_data_norm, test_labels),\n                            epochs=100, verbose=1)\n\n# Epoch 100/100\n# 1875/1875 [==============================] - 3s 2ms/step - loss: 3.1371 - accuracy: 0.0984 - val_loss: 2.4865 - val_accuracy: 0.1000 - lr: 8.9125\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# get ideal learning rate by checking the lr decay curve\nlr = 1e-4 * (10 ** (tf.range(100)/20))\nplt.figure(figsize=(12, 7))\nplt.title("Learning Rate Decay")\nplt.xlabel("Learning Rate")\nplt.ylabel("Loss")\nplt.semilogx(lr, model_multiclass_norm_lr_history.history["loss"])\nplt.show()\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow - Classification Problems",src:n(77892).Z,width:"1001",height:"629"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# the lowest point is at 4e-3 -> divide by 10\n# the ideal learning rate is 4e-4 => model re-fit\n\ntf.random.set_seed(42)\n\nmodel_multiclass_norm = tf.keras.Sequential([\n    # flatten data from `28*28` to `None, 784`\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\n    tf.keras.layers.Dense(4, activation="relu", name="input_layer"),\n    tf.keras.layers.Dense(4, activation="relu", name="dense_layer1"),\n    tf.keras.layers.Dense(10, activation="softmax", name="output_layer")\n])\n                          \nmodel_multiclass_norm.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n                        optimizer=tf.keras.optimizers.Adam(learning_rate=4e-4),\n                        metrics="accuracy")\n                          \nhistory_multi_norm = model_multiclass_norm.fit(train_data_norm, train_labels, batch_size=32,\n                    validation_data=(test_data_norm, test_labels),\n                    epochs=100, verbose=1)\n\n# Epoch 100/100\n# 1875/1875 [==============================] - 4s 2ms/step - loss: 0.5323 - accuracy: 0.8042 - val_loss: 0.6132 - val_accuracy: 0.7862\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# plot confusion matrix\nimport itertools\n\ndef plot_confusion_matrix(y_pred, y_true, classes=None, figsize = (12, 12), text_size=7):\n\n        # create the confusion matrix\n        cm = confusion_matrix(y_pred, y_true)\n\n        # normalize\n        cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis]\n        # cm_norm\n        # array([[1., 0.],\n        #        [0., 1.]])\n\n        number_of_classes = cm.shape[0]\n        # 2\n\n        # plot matrix\n        fig, ax = plt.subplots(figsize=figsize)\n        cax = ax.matshow(cm, cmap=plt.cm.Greens)\n        fig.colorbar(cax)\n\n        if classes:\n            labels = classes\n        else:\n            labels = np.arange(cm.shape[0])\n\n        # axes lables\n        ax.set(title="Confusion Matrix",\n              xlabel="Prediction",\n              ylabel="True",\n              xticks=np.arange(number_of_classes),\n              yticks=np.arange(number_of_classes),\n              xticklabels=labels,\n              yticklabels=labels)\n\n        ax.xaxis.set_label_position("bottom")\n        ax.title.set_size(15)\n        ax.xaxis.label.set_size(15)\n        ax.yaxis.label.set_size(15)\n        ax.xaxis.tick_bottom()\n\n\n        # colour threshold\n        threshold = (cm.max() + cm.min()) / 2.\n\n        # add text to cells\n        for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n            plt.text(j, i , f"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)",\n            horizontalalignment="center",\n            color="white" if cm[i, j] > threshold else "black",\n            size=text_size)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"## start by running predictions on the test dataset\ntest_predictions_ideal = model_multiclass_norm.predict(test_data_norm)\n## set class with highest probability to 1 - rest to zero\ny_pred = tf.argmax(test_predictions_ideal,axis=1)\n## plot the confusion matrix predictions vs true labels\nplot_confusion_matrix(y_pred=y_pred, y_true=test_labels, classes=class_names)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow - Classification Problems",src:n(4109).Z,width:"1003",height:"952"})),(0,r.kt)("h2",{id:"making-predictions-to-further-evaluate-the-model"},"Making predictions to further evaluate the model"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# function to pick a random image and run prediction\ndef random_image_prediction(model, images, true_labels, classes):\n    # create random image index\n    i = random.randint(0, len(images))\n    # select label of image at index i\n    true_label = classes[true_labels[i]]\n    # pick corresponding image\n    target_image = images[i]\n    # reshape image and pass it to prediction\n    pred_probabilities = model.predict(target_image.reshape(1, 28, 28))\n    # select class with highest probability\n    pred_label = classes[pred_probabilities.argmax()]\n    \n    # plot the b&w image\n    plt.imshow(target_image, cmap=plt.cm.binary)\n    \n    if pred_label == true_label:\n        color = "green"\n    else:\n        color = "red"\n        \n    plt.xlabel("Prediction: {} {:2.0f}% (True: {})".format(pred_label,\n                                                     100*tf.reduce_max(pred_probabilities),\n                                                     true_label), color = color)\n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"random_image_prediction(model=model_multiclass_norm,\n                       images=test_data_norm,\n                       true_labels=test_labels,\n                       classes=class_names)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow - Classification Problems",src:n(63108).Z,width:"416",height:"432"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# function to pick a random image and run prediction\ndef random_image_map_prediction(model, images, true_labels, classes):\n    \n    ran_gen = np.random.default_rng()\n    \n    plt.figure(figsize=(12, 12))\n    \n    for i in range(9):\n        # select random image\n        random_index = ran_gen.integers(low=0, high=len(images), size=1)\n        target_image = images[random_index[0]]\n        true_label = classes[true_labels[random_index[0]]]\n        # reshape image and pass it to prediction\n        pred_probabilities = model.predict(target_image.reshape(1, 28, 28))\n        # select class with highest probability\n        pred_label = classes[pred_probabilities.argmax()]\n        \n        ax = plt.subplot(3, 3, i+1)\n        # plt.title(classes[train_labels[random_index[0]]])\n    \n        if pred_label == true_label:\n            colour = "green"\n            colourmap = "Greens"\n        else:\n            colour = "red"\n            colourmap = "Reds"\n\n        plt.xlabel("Prediction: {} {:2.0f}% (True: {})".format(pred_label,\n                                                         100*tf.reduce_max(pred_probabilities),\n                                                         true_label), color = colour)\n        plt.imshow(target_image, cmap=colourmap)\n        plt.axis(True)\n        \n')),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"random_image_map_prediction(model=model_multiclass_norm,\n                       images=test_data_norm,\n                       true_labels=test_labels,\n                       classes=class_names)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Tensorflow - Classification Problems",src:n(67821).Z,width:"975",height:"987"})),(0,r.kt)("h2",{id:"weights--biases"},"Weights & Biases"),(0,r.kt)("p",null,"Weights represent the pattern a particular layer of our neural network has learned during training."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"model_multiclass_norm.layers\n\n# [<keras.layers.reshaping.flatten.Flatten at 0x7f0e24157940>,\n#   <keras.layers.core.dense.Dense at 0x7f0e2423e560>,\n#   <keras.layers.core.dense.Dense at 0x7f0eedc336d0>,\n#   <keras.layers.core.dense.Dense at 0x7f0e2423e620>]\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# get weigths of a particular layer\nweights, biases = model_multiclass_norm.layers[1].get_weights()\n\nweights.shape, weights, biases.shape, biases, model_multiclass_norm.summary()\n\n# weight.shape\n#  (784, 4)) => 28x28 for the image dimensions and 4 hidden units\n\n# weights\n# (array([[-1.3565315 , -0.3214511 , -0.16312897, -0.3301181 ],\n#         [-1.8619745 ,  0.22111109, -1.3103486 ,  1.1400424 ],\n#         [ 1.9727688 , -1.762827  , -1.5388335 ,  0.39442703],\n#         ...,\n#         [ 0.5418353 ,  0.5226571 ,  0.27219778,  0.4796965 ],\n#         [-0.55814236,  0.2910452 ,  0.26502737,  2.1195614 ],\n#         [-0.5417867 , -0.16617213,  1.1190995 ,  0.3001483 ]],\n#        dtype=float32)\n# for every pixel in our sample 28x28px images we get 4 different\n# values from the 4 hidden units / neurons inspecting the image for features\n# weights\n\n# biases.shape => for every hidden unit we get a bias vector\n# (4,),\n\n# biases => dictate how much the corresponding weight should influence the next layer\n#  array([ 1.9621418 ,  0.5325201 ,  1.6395437 , -0.04142712], dtype=float32),\n#  None)\n\n# model summary\n# Model: "sequential_1"\n# _________________________________________________________________\n#  Layer (type)                Output Shape              Param #   \n# =================================================================\n#  flatten_1 (Flatten)         (None, 784)               0         \n                                                                 \n#  input_layer (Dense)         (None, 4)                 3140      \n                                                                 \n#  dense_layer1 (Dense)        (None, 4)                 20        \n                                                                 \n#  output_layer (Dense)        (None, 10)                50        \n                                                                 \n# =================================================================\n# Total params: 3,210\n# Trainable params: 3,210\n# Non-trainable params: 0\n# _________________________________________________________________\n')))}m.isMDXComponent=!0},16604:(e,a,n)=>{n.d(a,{Z:()=>t});const t="data:image/png;base64,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"},13368:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/02_Tensorflow_Multi_Classifications_02-35c2c4c90113ca02e619529bb737a02f.png"},7613:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/02_Tensorflow_Multi_Classifications_03-5f55e000b836005d2aac40fdb93d2f34.png"},77892:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/02_Tensorflow_Multi_Classifications_03a-363e8337ad7d2a5baa7d58ce5bc09733.png"},4109:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/02_Tensorflow_Multi_Classifications_04-be37a21da77bffe16310dfce154e08c6.png"},63108:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/02_Tensorflow_Multi_Classifications_05-b93db29df9fcc9b31aa8b0c19895016a.png"},67821:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/02_Tensorflow_Multi_Classifications_06-28df814534e42dbd799c0ebbaf66eefd.png"},18240:(e,a,n)=>{n.d(a,{Z:()=>t});const t=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-f22d43080f9f8a797542a918e9317e01.jpg"}}]);