"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[15896],{944359:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>d,default:()=>A,frontMatter:()=>i,metadata:()=>a,toc:()=>o});var r=s(785893),t=s(603905);const i={sidebar_position:4520,slug:"2023-03-24",title:"Tensorflow 2 - Unsupervised Learning",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Use Autoencoders to Reduce Dimensionality and Feature Discovery"},d="Tensorflow Unsupervised Learning",a={id:"IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/index",title:"Tensorflow 2 - Unsupervised Learning",description:"Use Autoencoders to Reduce Dimensionality and Feature Discovery",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders",slug:"/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4520,frontMatter:{sidebar_position:4520,slug:"2023-03-24",title:"Tensorflow 2 - Unsupervised Learning",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Use Autoencoders to Reduce Dimensionality and Feature Discovery"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow 2 - Unsupervised Learning",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26"},next:{title:"Tensorflow 2 - Transfer Learning",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16"}},l={},o=[{value:"Principle of Dimensionality Reduction",id:"principle-of-dimensionality-reduction",level:2},{value:"Build the Autoencoder",id:"build-the-autoencoder",level:3},{value:"Train the Autoencoder",id:"train-the-autoencoder",level:3},{value:"Visualize the Results",id:"visualize-the-results",level:3},{value:"Autoencoders for Image Data",id:"autoencoders-for-image-data",level:2},{value:"Building the Autoencoder",id:"building-the-autoencoder",level:3},{value:"Run Predictions",id:"run-predictions",level:3},{value:"Autoencoders for Noise Removal",id:"autoencoders-for-noise-removal",level:2},{value:"Build the Denoise Autoencoder",id:"build-the-denoise-autoencoder",level:3},{value:"Run Denoiser",id:"run-denoiser",level:3},{value:"Food",id:"food",level:2},{value:"Prepare the Dataset",id:"prepare-the-dataset",level:4},{value:"Use an Autoencoder to separate Features",id:"use-an-autoencoder-to-separate-features",level:3}];function c(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.ah)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Victoria Harbour, Hongkong",src:s(268225).Z+"",width:"2385",height:"1054"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#tensorflow-unsupervised-learning",children:"Tensorflow Unsupervised Learning"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#principle-of-dimensionality-reduction",children:"Principle of Dimensionality Reduction"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#build-the-autoencoder",children:"Build the Autoencoder"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#train-the-autoencoder",children:"Train the Autoencoder"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#visualize-the-results",children:"Visualize the Results"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#autoencoders-for-image-data",children:"Autoencoders for Image Data"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#building-the-autoencoder",children:"Building the Autoencoder"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#run-predictions",children:"Run Predictions"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#autoencoders-for-noise-removal",children:"Autoencoders for Noise Removal"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#build-the-denoise-autoencoder",children:"Build the Denoise Autoencoder"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#run-denoiser",children:"Run Denoiser"})}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#food",children:"Food"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#prepare-the-dataset",children:"Prepare the Dataset"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#use-an-autoencoder-to-separate-features",children:"Use an Autoencoder to separate Features"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://github.com/mpolinowski/tf-2023",children:"Github Repository"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"See also:"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Fun, fun, tensors: ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19",children:"Tensor Constants, Variables and Attributes"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21",children:"Tensor Indexing, Expanding and Manipulations"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22",children:"Matrix multiplications, Squeeze, One-hot and Numpy"})]}),"\n",(0,r.jsxs)(n.li,{children:["Tensorflow 2 - Neural Network Regression: ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23",children:"Building a Regression Model"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24",children:"Model Evaluation"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25",children:"Model Optimization"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26",children:'Working with a "Real" Dataset'}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26",children:"Feature Scaling"})]}),"\n",(0,r.jsxs)(n.li,{children:["Tensorflow 2 - Neural Network Classification: ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27",children:"Non-linear Data and Activation Functions"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28",children:"Model Evaluation and Performance Improvement"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02",children:"Multiclass Classification Problems"})]}),"\n",(0,r.jsxs)(n.li,{children:["Tensorflow 2 - Convolutional Neural Networks: ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03",children:"Binary Image Classification"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05",children:"Multiclass Image Classification"})]}),"\n",(0,r.jsxs)(n.li,{children:["Tensorflow 2 - Transfer Learning: ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06",children:"Feature Extraction"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11",children:"Fine-Tuning"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16",children:"Scaling"})]}),"\n",(0,r.jsxs)(n.li,{children:["Tensorflow 2 - Unsupervised Learning: ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24",children:"Autoencoder Feature Detection"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26",children:"Autoencoder Super-Resolution"}),", ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-generative-adversial-networks/2023-03-26",children:"Generative Adverserial Networks"})]}),"\n"]}),"\n",(0,r.jsx)(n.h1,{id:"tensorflow-unsupervised-learning",children:"Tensorflow Unsupervised Learning"}),"\n",(0,r.jsx)(n.h2,{id:"principle-of-dimensionality-reduction",children:"Principle of Dimensionality Reduction"}),"\n",(0,r.jsx)(n.p,{children:'Using Autoencoders to remove "noisy dimensions" in our dataset to be able to extract hidden features.'}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Dense, Flatten, Reshape, GaussianNoise\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import SGD, Adam\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# global variables\nSEED = 42\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# create random feature blobs\ndata = make_blobs(n_samples=300,\n                 n_features=2,\n                 centers=2,\n                 cluster_std=1.0,\n                 random_state=SEED)\n\nX, y = data\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# create random dataset\nnp.random.seed(seed=SEED)\nz_noise = np.random.normal(size=len(X))\nz_noise = pd.Series(z_noise)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# combine data into single dataframe\nfeatures = pd.DataFrame(X)\nfeatures = pd.concat([features,z_noise], axis=1)\nfeatures.columns = ['X1', 'X2', 'Xnoise']\n\n# this generated a dataframe with 3 colums for our data:\nprint(features.head())\n"})}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{}),(0,r.jsx)(n.th,{children:"X1"}),(0,r.jsx)(n.th,{children:"X2"}),(0,r.jsx)(n.th,{children:"Xnoise"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"-7.338988"}),(0,r.jsx)(n.td,{children:"-7.729954"}),(0,r.jsx)(n.td,{children:"0.496714"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"-7.740041"}),(0,r.jsx)(n.td,{children:"-7.264665"}),(0,r.jsx)(n.td,{children:"-0.138264"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"-1.686653"}),(0,r.jsx)(n.td,{children:"7.793442"}),(0,r.jsx)(n.td,{children:"0.647689"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"4.422198"}),(0,r.jsx)(n.td,{children:"3.071947"}),(0,r.jsx)(n.td,{children:"1.523030"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"4"}),(0,r.jsx)(n.td,{children:"-8.917752"}),(0,r.jsx)(n.td,{children:"-7.888196"}),(0,r.jsx)(n.td,{children:"-0.234153"})]})]})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# plotting Y=f(x) shows 2 distinct features\nplt.scatter(features['X1'], features['X2'], c=y)\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(58746).Z+"",width:"543",height:"413"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# add a third dimension from the noise data\n# this noisy dimension(s) are supposed to\n# make it more difficult to see the underlying\n# 2 features\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(features['X1'], features['X2'], features['Xnoise'], c=y)\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(930997).Z+"",width:"404",height:"400"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# normalize the dataset\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(features)\n\n# this generated a dataframe with 3 colums for our data:\nprint(scaled_data[:5])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"array([[0.123409  , 0.0694226 , 0.52692164],\n       [0.09881332, 0.09166767, 0.4374124 ],\n       [0.4700545 , 0.81158342, 0.54820363],\n       [0.84469708, 0.58585258, 0.67159543],\n       [0.02658684, 0.06185718, 0.42389547]])\n"})}),"\n",(0,r.jsx)(n.h3,{id:"build-the-autoencoder",children:"Build the Autoencoder"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# build an encoder that reduces dimensionality from 3 => 2\nencoder = Sequential([\n  Dense(units=2, activation='relu', input_shape=[3])\n])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# and an encoder that brings it back up from 2 => 3\ndecoder = Sequential([\n  Dense(units=3, activation='relu', input_shape=[2])\n])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# compile both layers into the autoencoder model\nautoencoder = Sequential([encoder, decoder])\n\nautoencoder.compile(loss='mse', optimizer=SGD(learning_rate=1.5))\n"})}),"\n",(0,r.jsx)(n.h3,{id:"train-the-autoencoder",children:"Train the Autoencoder"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"autoencoder.fit(scaled_data, scaled_data, epochs=5)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# The encoder now reduces the dimensions of our dataset to 2\n# when we run predictions from the encoder we will get\n# 2-dimensional results that should have stripped the \n# noisy 3rd dimension we added\nencoded_2dim = encoder.predict(scaled_data)\n# (300, 2) <= (300, 3)\nprint(encoded_2dim.shape, scaled_data.shape)\nencoded_2dim\n"})}),"\n",(0,r.jsx)(n.h3,{id:"visualize-the-results",children:"Visualize the Results"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"plt.scatter(encoded_2dim[:,0], encoded_2dim[:,1], c=y)\n# the encoder simplified our dataset and extracted 2 clearly\n# defined features that might have been obfuscated by the\n# extra dimensions in our dataset\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(482567).Z+"",width:"573",height:"413"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"decoded_2to3dim = autoencoder.predict(scaled_data)\nprint(decoded_2to3dim.shape, scaled_data.shape)\n#  (300, 3) <= (300, 2) <= (300, 3)\ndecoded_2to3dim\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"fig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(decoded_2to3dim[:,0], decoded_2to3dim[:,1], decoded_2to3dim[:,2], c=y)\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(350755).Z+"",width:"414",height:"399"})}),"\n",(0,r.jsx)(n.h2,{id:"autoencoders-for-image-data",children:"Autoencoders for Image Data"}),"\n",(0,r.jsx)(n.p,{children:"Create a noisy version of the MNIST digits dataset and train an autoencoder to generate de-noised images from this source."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"plt.imshow(X_train[88])\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(543932).Z+"",width:"416",height:"413"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# normalize images\nX_train = X_train/255\nX_test = X_test/255\n"})}),"\n",(0,r.jsx)(n.h3,{id:"building-the-autoencoder",children:"Building the Autoencoder"}),"\n",(0,r.jsx)(n.p,{children:"The dataset starts out with 28*28 px images = 784 dimensions. The Encoder should now, several times over several layers, approx. cut this number in half until a minimum of dimensions is reached in a hidden layer."}),"\n",(0,r.jsx)(n.p,{children:"The following Decoder should then take those reduced feature maps and reconstruct the original image from it. By validating the against the original, not noisy images we should be able to train the Autoencoder to denoise images."}),"\n",(0,r.jsx)(n.p,{children:"Let's get started by an autoencoder that can read the original image, reduces it to ~3% and then reconstruct the original image from this state:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"encoder = Sequential([\n    # generate (28, 28) => (784) shape\n    Flatten(input_shape=[28, 28], name='input_layer'),\n    # cut dimensions in half \n    Dense(units=392, activation='relu', name=\"reducer50\"),\n    # cut dimensions in half \n    Dense(units=196, activation='relu', name=\"reducer25\"),\n    # cut dimensions in half \n    Dense(units=98, activation='relu', name=\"reducer12\"),\n    # cut dimensions in half \n    Dense(units=49, activation='relu', name=\"reducer6\"),\n    # cut dimensions in ~ half \n    Dense(units=24, activation='relu', name='hidden_layer')\n])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"decoder = Sequential([\n    Dense(units=49, activation='relu', input_shape=[24], name='expander6'),\n    Dense(units=98, activation='relu', name='expander12'),\n    Dense(units=98, activation='relu', name='expander25'),\n    Dense(units=392, activation='relu', name='expander50'),\n    Dense(units=784, activation='sigmoid', name='expander100'),\n    Reshape([28, 28], name='output_layer')\n])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"autoencoder = Sequential([encoder, decoder])\n\nautoencoder.compile(loss='binary_crossentropy',\n#                    optimizer=SGD(learning_rate=1.5),\n                    optimizer=Adam(learning_rate=1e-3),\n                    metrics=['accuracy'])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"tf.random.set_seed(SEED)\n# fit the autoencoder to training dataset\nautoencoder.fit(X_train, X_train, epochs=25,\n               validation_data=[X_test, X_test])\n\n# Epoch 25/25\n# 6s 3ms/step - loss: 0.0898 - accuracy: 0.3063 - val_loss: 0.0923 - val_accuracy: 0.2968\n"})}),"\n",(0,r.jsx)(n.h3,{id:"run-predictions",children:"Run Predictions"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# get 10 sample predictions from testing dataset\npassed_images = autoencoder.predict(X_test[:10])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# select 3 images out of 10 samples\nn = [3, 4, 5]\n\nplt.figure(figsize=(12, 12))\n# ROW 1\nplt.subplot(3, 2, 1)\nplt.title(f"Original MNIST Image => {y_test[n[0]]}")\nplt.axis(False)\nplt.imshow(X_test[n[0]])\nplt.subplot(3, 2, 2)\nplt.title("Reconstructed Image")\nplt.axis(False)\nplt.imshow(passed_images[n[0]])\n# ROW 2\nplt.subplot(3, 2, 3)\nplt.title(f"Original MNIST Image => {y_test[n[1]]}")\nplt.axis(False)\nplt.imshow(X_test[n[1]])\nplt.subplot(3, 2, 4)\nplt.title("Reconstructed Image")\nplt.axis(False)\nplt.imshow(passed_images[n[1]])\n# ROW 3\nplt.subplot(3, 2, 5)\nplt.title(f"Original MNIST Image => {y_test[n[2]]}")\nplt.axis(False)\nplt.imshow(X_test[n[2]])\nplt.subplot(3, 2, 6)\nplt.title("Reconstructed Image")\nplt.axis(False)\nplt.imshow(passed_images[n[2]])\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(214351).Z+"",width:"799",height:"966"})}),"\n",(0,r.jsx)(n.h2,{id:"autoencoders-for-noise-removal",children:"Autoencoders for Noise Removal"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# generating noise\nsample = GaussianNoise(0.2)\nnoisy = sample(X_train[:10], training=True)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'n = 4\n\nplt.figure(figsize=(12, 12))\n# ROW 1\nplt.subplot(1, 2, 1)\nplt.title(f"Original MNIST Image => {y_train[n]}")\nplt.axis(False)\nplt.imshow(X_train[n])\nplt.subplot(1, 2, 2)\nplt.title("Noised Image")\nplt.axis(False)\nplt.imshow(noisy[n])\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(90737).Z+"",width:"950",height:"465"})}),"\n",(0,r.jsx)(n.h3,{id:"build-the-denoise-autoencoder",children:"Build the Denoise Autoencoder"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"tf.random.set_seed(SEED)\n\nencoder = Sequential([\n    # generate (28, 28) => (784) shape\n    Flatten(input_shape=[28, 28], name='input_layer'),\n    \n    # add noise to source image\n    GaussianNoise(0.2),\n    \n    # cut dimensions in half \n    Dense(units=392, activation='relu', name=\"reducer50\"),\n    # cut dimensions in half \n    Dense(units=196, activation='relu', name=\"reducer25\"),\n    # cut dimensions in half \n    Dense(units=98, activation='relu', name=\"reducer12\"),\n    # cut dimensions in half \n    Dense(units=49, activation='relu', name=\"reducer6\"),\n    # cut dimensions in ~ half \n    Dense(units=24, activation='relu', name='hidden_layer')\n])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"decoder = Sequential([\n    Dense(units=49, activation='relu', input_shape=[24], name='expander6'),\n    Dense(units=98, activation='relu', name='expander12'),\n    Dense(units=98, activation='relu', name='expander25'),\n    Dense(units=392, activation='relu', name='expander50'),\n    Dense(units=784, activation='sigmoid', name='expander100'),\n    Reshape([28, 28], name='output_layer')\n])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"noise_remover = Sequential([encoder, decoder])\n\nnoise_remover.compile(loss='binary_crossentropy',\n                     optimizer=Adam(learning_rate=1e-3),\n                     metrics=['accuracy'])\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"noise_remover.fit(X_train, X_train, epochs=25,\n               validation_data=[X_test, X_test])\n\n# Epoch 25/25\n# 6s 3ms/step - loss: 0.0946 - accuracy: 0.2949 - val_loss: 0.0913 - val_accuracy: 0.2986\n"})}),"\n",(0,r.jsx)(n.h3,{id:"run-denoiser",children:"Run Denoiser"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"noisy_samples = sample(X_test[:3], training=True)\n\ndenoised_samples = noise_remover(noisy_samples)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:'# plot results\nplt.figure(figsize=(12, 12))\n# ROW 1\nplt.subplot(3, 3, 1)\nplt.title(f"Original MNIST Image => {y_test[0]}")\nplt.axis(False)\nplt.imshow(X_test[0])\nplt.subplot(3, 3, 2)\nplt.title("Noised Image")\nplt.axis(False)\nplt.imshow(noisy_samples[0])\nplt.subplot(3, 3, 3)\nplt.title("Denoised Image")\nplt.axis(False)\nplt.imshow(denoised_samples[0])\n# ROW 2\nplt.subplot(3, 3, 4)\nplt.title(f"Original MNIST Image => {y_test[1]}")\nplt.axis(False)\nplt.imshow(X_test[1])\nplt.subplot(3, 3, 5)\nplt.title("Noised Image")\nplt.axis(False)\nplt.imshow(noisy_samples[1])\nplt.subplot(3, 3, 6)\nplt.title("Denoised Image")\nplt.axis(False)\nplt.imshow(denoised_samples[1])\n# ROW 3\nplt.subplot(3, 3, 7)\nplt.title(f"Original MNIST Image => {y_test[2]}")\nplt.axis(False)\nplt.imshow(X_test[2])\nplt.subplot(3, 3, 8)\nplt.title("Noised Image")\nplt.axis(False)\nplt.imshow(noisy_samples[2])\nplt.subplot(3, 3, 9)\nplt.title("Denoised Image")\nplt.axis(False)\nplt.imshow(denoised_samples[2])\n'})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(312226).Z+"",width:"948",height:"966"})}),"\n",(0,r.jsx)(n.h2,{id:"food",children:"Food"}),"\n",(0,r.jsx)(n.p,{children:"Variations in preference for different food types in the UK"}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:"wget https://github.com/emtrujillo-lab/bggn213/blob/3fdf3e1f373545a420de9fb45a2a8e68ee5478fa/Class09/Class9/UK_foods.csv"})}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"prepare-the-dataset",children:"Prepare the Dataset"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"df = pd.read_csv('./UK_foods.csv', index_col='Unnamed: 0')\ndf\n"})}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{}),(0,r.jsx)(n.th,{children:"England"}),(0,r.jsx)(n.th,{children:"Wales"}),(0,r.jsx)(n.th,{children:"Scotland"}),(0,r.jsx)(n.th,{children:"N.Ireland"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Cheese"}),(0,r.jsx)(n.td,{children:"105"}),(0,r.jsx)(n.td,{children:"103"}),(0,r.jsx)(n.td,{children:"103"}),(0,r.jsx)(n.td,{children:"66"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Carcass_meat"}),(0,r.jsx)(n.td,{children:"245"}),(0,r.jsx)(n.td,{children:"227"}),(0,r.jsx)(n.td,{children:"242"}),(0,r.jsx)(n.td,{children:"267"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Other_meat"}),(0,r.jsx)(n.td,{children:"685"}),(0,r.jsx)(n.td,{children:"803"}),(0,r.jsx)(n.td,{children:"750"}),(0,r.jsx)(n.td,{children:"586"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Fish"}),(0,r.jsx)(n.td,{children:"147"}),(0,r.jsx)(n.td,{children:"160"}),(0,r.jsx)(n.td,{children:"122"}),(0,r.jsx)(n.td,{children:"93"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Fats_and_oils"}),(0,r.jsx)(n.td,{children:"193"}),(0,r.jsx)(n.td,{children:"235"}),(0,r.jsx)(n.td,{children:"184"}),(0,r.jsx)(n.td,{children:"209"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Sugars"}),(0,r.jsx)(n.td,{children:"156"}),(0,r.jsx)(n.td,{children:"175"}),(0,r.jsx)(n.td,{children:"147"}),(0,r.jsx)(n.td,{children:"139"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Fresh_potatoes"}),(0,r.jsx)(n.td,{children:"720"}),(0,r.jsx)(n.td,{children:"874"}),(0,r.jsx)(n.td,{children:"566"}),(0,r.jsx)(n.td,{children:"1033"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Fresh_Veg"}),(0,r.jsx)(n.td,{children:"253"}),(0,r.jsx)(n.td,{children:"265"}),(0,r.jsx)(n.td,{children:"171"}),(0,r.jsx)(n.td,{children:"143"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Other_Veg"}),(0,r.jsx)(n.td,{children:"488"}),(0,r.jsx)(n.td,{children:"570"}),(0,r.jsx)(n.td,{children:"418"}),(0,r.jsx)(n.td,{children:"355"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Processed_potatoes"}),(0,r.jsx)(n.td,{children:"198"}),(0,r.jsx)(n.td,{children:"203"}),(0,r.jsx)(n.td,{children:"220"}),(0,r.jsx)(n.td,{children:"187"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Processed_Veg"}),(0,r.jsx)(n.td,{children:"360"}),(0,r.jsx)(n.td,{children:"365"}),(0,r.jsx)(n.td,{children:"337"}),(0,r.jsx)(n.td,{children:"334"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Fresh_fruit"}),(0,r.jsx)(n.td,{children:"1102"}),(0,r.jsx)(n.td,{children:"1137"}),(0,r.jsx)(n.td,{children:"957"}),(0,r.jsx)(n.td,{children:"674"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Cereals"}),(0,r.jsx)(n.td,{children:"1472"}),(0,r.jsx)(n.td,{children:"1582"}),(0,r.jsx)(n.td,{children:"1462"}),(0,r.jsx)(n.td,{children:"1494"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Beverages"}),(0,r.jsx)(n.td,{children:"57"}),(0,r.jsx)(n.td,{children:"73"}),(0,r.jsx)(n.td,{children:"53"}),(0,r.jsx)(n.td,{children:"47"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Soft_drinks"}),(0,r.jsx)(n.td,{children:"1374"}),(0,r.jsx)(n.td,{children:"1256"}),(0,r.jsx)(n.td,{children:"1572"}),(0,r.jsx)(n.td,{children:"1506"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Alcoholic_drinks"}),(0,r.jsx)(n.td,{children:"375"}),(0,r.jsx)(n.td,{children:"475"}),(0,r.jsx)(n.td,{children:"458"}),(0,r.jsx)(n.td,{children:"135"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Confectionery"}),(0,r.jsx)(n.td,{children:"54"}),(0,r.jsx)(n.td,{children:"64"}),(0,r.jsx)(n.td,{children:"62"}),(0,r.jsx)(n.td,{children:"41"})]})]})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# create a heatmap with pandas\nplt.figure(figsize=(12, 8))\nplt.pcolor(df)\nplt.yticks(np.arange(0.5, len(df.index), 1), df.index)\nplt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)\nplt.xticks(rotation=70, fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(443704).Z+"",width:"1130",height:"722"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"df_t = df.transpose()\ndf_t\n"})}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{}),(0,r.jsx)(n.th,{children:"Cheese"}),(0,r.jsx)(n.th,{children:"Carcass_meat"}),(0,r.jsx)(n.th,{children:"Other_meat"}),(0,r.jsx)(n.th,{children:"Fish"}),(0,r.jsx)(n.th,{children:"Fats_and_oils"}),(0,r.jsx)(n.th,{children:"Sugars"}),(0,r.jsx)(n.th,{children:"Fresh_potatoes"}),(0,r.jsx)(n.th,{children:"Fresh_Veg"}),(0,r.jsx)(n.th,{children:"Other_Veg"}),(0,r.jsx)(n.th,{children:"Processed_potatoes"}),(0,r.jsx)(n.th,{children:"Processed_Veg"}),(0,r.jsx)(n.th,{children:"Fresh_fruit"}),(0,r.jsx)(n.th,{children:"Cereals"}),(0,r.jsx)(n.th,{children:"Beverages"}),(0,r.jsx)(n.th,{children:"Soft_drinks"}),(0,r.jsx)(n.th,{children:"Alcoholic_drinks"}),(0,r.jsx)(n.th,{children:"Confectionery"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"England"}),(0,r.jsx)(n.td,{children:"105"}),(0,r.jsx)(n.td,{children:"245"}),(0,r.jsx)(n.td,{children:"685"}),(0,r.jsx)(n.td,{children:"147"}),(0,r.jsx)(n.td,{children:"193"}),(0,r.jsx)(n.td,{children:"156"}),(0,r.jsx)(n.td,{children:"720"}),(0,r.jsx)(n.td,{children:"253"}),(0,r.jsx)(n.td,{children:"488"}),(0,r.jsx)(n.td,{children:"198"}),(0,r.jsx)(n.td,{children:"360"}),(0,r.jsx)(n.td,{children:"1102"}),(0,r.jsx)(n.td,{children:"1472"}),(0,r.jsx)(n.td,{children:"57"}),(0,r.jsx)(n.td,{children:"1374"}),(0,r.jsx)(n.td,{children:"375"}),(0,r.jsx)(n.td,{children:"54"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Wales"}),(0,r.jsx)(n.td,{children:"103"}),(0,r.jsx)(n.td,{children:"227"}),(0,r.jsx)(n.td,{children:"803"}),(0,r.jsx)(n.td,{children:"160"}),(0,r.jsx)(n.td,{children:"235"}),(0,r.jsx)(n.td,{children:"175"}),(0,r.jsx)(n.td,{children:"874"}),(0,r.jsx)(n.td,{children:"265"}),(0,r.jsx)(n.td,{children:"570"}),(0,r.jsx)(n.td,{children:"203"}),(0,r.jsx)(n.td,{children:"365"}),(0,r.jsx)(n.td,{children:"1137"}),(0,r.jsx)(n.td,{children:"1582"}),(0,r.jsx)(n.td,{children:"73"}),(0,r.jsx)(n.td,{children:"1256"}),(0,r.jsx)(n.td,{children:"475"}),(0,r.jsx)(n.td,{children:"64"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Scotland"}),(0,r.jsx)(n.td,{children:"103"}),(0,r.jsx)(n.td,{children:"242"}),(0,r.jsx)(n.td,{children:"750"}),(0,r.jsx)(n.td,{children:"122"}),(0,r.jsx)(n.td,{children:"184"}),(0,r.jsx)(n.td,{children:"147"}),(0,r.jsx)(n.td,{children:"566"}),(0,r.jsx)(n.td,{children:"171"}),(0,r.jsx)(n.td,{children:"418"}),(0,r.jsx)(n.td,{children:"220"}),(0,r.jsx)(n.td,{children:"337"}),(0,r.jsx)(n.td,{children:"957"}),(0,r.jsx)(n.td,{children:"1462"}),(0,r.jsx)(n.td,{children:"53"}),(0,r.jsx)(n.td,{children:"1572"}),(0,r.jsx)(n.td,{children:"458"}),(0,r.jsx)(n.td,{children:"62"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"N.Ireland"}),(0,r.jsx)(n.td,{children:"66"}),(0,r.jsx)(n.td,{children:"267"}),(0,r.jsx)(n.td,{children:"586"}),(0,r.jsx)(n.td,{children:"93"}),(0,r.jsx)(n.td,{children:"209"}),(0,r.jsx)(n.td,{children:"139"}),(0,r.jsx)(n.td,{children:"1033"}),(0,r.jsx)(n.td,{children:"143"}),(0,r.jsx)(n.td,{children:"355"}),(0,r.jsx)(n.td,{children:"187"}),(0,r.jsx)(n.td,{children:"334"}),(0,r.jsx)(n.td,{children:"674"}),(0,r.jsx)(n.td,{children:"1494"}),(0,r.jsx)(n.td,{children:"47"}),(0,r.jsx)(n.td,{children:"1506"}),(0,r.jsx)(n.td,{children:"135"}),(0,r.jsx)(n.td,{children:"41"})]})]})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# create a heatmap with seaborn\nplt.figure(figsize=(12, 6))\nsns.heatmap(df_t, cmap='RdYlGn_r', linewidths=0.5, annot=False)\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(407412).Z+"",width:"902",height:"634"})}),"\n",(0,r.jsx)(n.h3,{id:"use-an-autoencoder-to-separate-features",children:"Use an Autoencoder to separate Features"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# build the autoencoder\nencoder = Sequential([\n    Dense(units=8, activation='relu', input_shape=[17]),\n    Dense(units=4, activation='relu'),\n    Dense(units=2, activation='relu')\n])\n\ndecoder = Sequential([\n    Dense(units=4, activation='relu', input_shape=[2]),\n    Dense(units=8, activation='relu'),\n    Dense(units=17, activation='relu')\n])\n\nautoencoder= Sequential([encoder, decoder])\n\nautoencoder.compile(loss='mse', optimizer=Adam(learning_rate=1e-3))\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# normalize input data\nscaler = MinMaxScaler()\n\nscaled_df = scaler.fit_transform(df_t.values)\nscaled_df.shape\n# (4, 17)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"autoencoder.fit(scaled_df, scaled_df, epochs=25)\n# Epoch 25/25\n# 1/1 [==============================] - 0s 5ms/step - loss: 0.2891\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"# get reduced dimensionality output from encoder\nencoded_2dim = encoder.predict(scaled_df)\nencoded_2dim\n\n# array([[0.        , 1.8262266 ],\n#        [0.        , 3.4182868 ],\n#        [0.        , 1.7019984 ],\n#        [0.20801371, 0.52220476]], dtype=float32)\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"results = pd.DataFrame(data=encoded_2dim,\n                      index=df_t.index,\n                      columns=['C1', 'C2'])\n\nresults.reset_index()\n"})}),"\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{}),(0,r.jsx)(n.th,{children:"index"}),(0,r.jsx)(n.th,{children:"C1"}),(0,r.jsx)(n.th,{children:"C2"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"0"}),(0,r.jsx)(n.td,{children:"England"}),(0,r.jsx)(n.td,{children:"0.000000"}),(0,r.jsx)(n.td,{children:"1.826227"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"1"}),(0,r.jsx)(n.td,{children:"Wales"}),(0,r.jsx)(n.td,{children:"0.000000"}),(0,r.jsx)(n.td,{children:"3.418287"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"2"}),(0,r.jsx)(n.td,{children:"Scotland"}),(0,r.jsx)(n.td,{children:"0.000000"}),(0,r.jsx)(n.td,{children:"1.701998"})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"3"}),(0,r.jsx)(n.td,{children:"N.Ireland"}),(0,r.jsx)(n.td,{children:"0.208014"}),(0,r.jsx)(n.td,{children:"0.522205"})]})]})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",children:"sns.scatterplot(x='C1', y='C2', data=results.reset_index(), hue='index')\n\n# England and Scotland are very close to each other\n# while Wales and N.Ireland \n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Unsupervised Learning with Tensorflow",src:s(737094).Z+"",width:"567",height:"432"})})]})}function A(e={}){const{wrapper:n}={...(0,t.ah)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(c,{...e})}):c(e)}},603905:(e,n,s)=>{s.d(n,{ah:()=>o});var r=s(667294);function t(e,n,s){return n in e?Object.defineProperty(e,n,{value:s,enumerable:!0,configurable:!0,writable:!0}):e[n]=s,e}function i(e,n){var s=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),s.push.apply(s,r)}return s}function d(e){for(var n=1;n<arguments.length;n++){var s=null!=arguments[n]?arguments[n]:{};n%2?i(Object(s),!0).forEach((function(n){t(e,n,s[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(s)):i(Object(s)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(s,n))}))}return e}function a(e,n){if(null==e)return{};var s,r,t=function(e,n){if(null==e)return{};var s,r,t={},i=Object.keys(e);for(r=0;r<i.length;r++)s=i[r],n.indexOf(s)>=0||(t[s]=e[s]);return t}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)s=i[r],n.indexOf(s)>=0||Object.prototype.propertyIsEnumerable.call(e,s)&&(t[s]=e[s])}return t}var l=r.createContext({}),o=function(e){var n=r.useContext(l),s=n;return e&&(s="function"==typeof e?e(n):d(d({},n),e)),s},c={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},A=r.forwardRef((function(e,n){var s=e.components,t=e.mdxType,i=e.originalType,l=e.parentName,A=a(e,["components","mdxType","originalType","parentName"]),h=o(s),u=t,p=h["".concat(l,".").concat(u)]||h[u]||c[u]||i;return s?r.createElement(p,d(d({ref:n},A),{},{components:s})):r.createElement(p,d({ref:n},A))}));A.displayName="MDXCreateElement"},58746:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_01-78966739aab366fcfef01d0fd83d385b.png"},930997:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_02-1a889fb0961d639f1cc2342df23df54e.png"},482567:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_03-ee9ff1a91a52d7bf3d9115119a84db04.png"},350755:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_04-168fef5c703a4ea32cfb4583bdd03812.png"},543932:(e,n,s)=>{s.d(n,{Z:()=>r});const r="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAc1klEQVR4nO3df3RU9f3n8dckkBEwGQwxmUQCDT+EViRtUdKsSrFkCXGXBeV48Ee/BdfFIw2uGK2e9Kio7TYtttYjpdjv2RbqrviDrUClFo8GE9aa4CFCObQ2X8KJJX4hQanJhCAhJJ/9g3XqSCLeYSbvZPJ8nHPPYe6977lvPl555c69+YzPOecEAEA/S7JuAAAwNBFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMDHMuoHP6unp0eHDh5Wamiqfz2fdDgDAI+ec2tvblZOTo6Skvq9zBlwAHT58WLm5udZtAADOU1NTk8aOHdvn9gEXQKmpqZKkq3Wdhmm4cTcAAK9Oq0tv6pXwv+d9iVsArV27Vo8//riam5uVn5+vNWvWaObMmees++Rjt2EarmE+AggABp3/P8PouW6jxOUhhBdeeEFlZWVatWqV3nnnHeXn56u4uFhHjx6Nx+EAAINQXALoiSee0LJly3TbbbfpK1/5ip5++mmNHDlSv/nNb+JxOADAIBTzADp16pTq6upUVFT0z4MkJamoqEg1NTVn7d/Z2alQKBSxAAASX8wD6MMPP1R3d7eysrIi1mdlZam5ufms/SsqKhQIBMILT8ABwNBg/ouo5eXlamtrCy9NTU3WLQEA+kHMn4LLyMhQcnKyWlpaIta3tLQoGAyetb/f75ff7491GwCAAS7mV0ApKSmaMWOGKisrw+t6enpUWVmpwsLCWB8OADBIxeX3gMrKyrRkyRJdccUVmjlzpp588kl1dHTotttui8fhAACDUFwCaPHixfrggw/08MMPq7m5WV/96le1ffv2sx5MAAAMXT7nnLNu4tNCoZACgYBmawEzIQDAIHTadalKW9XW1qa0tLQ+9zN/Cg4AMDQRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMDEMOsGgHNJGjXKc80/bpge1bFml9V4rvlR5juea5J93n/2m/72zZ5rch6N7mdM9+e/eS/q6Y7qWBi6uAICAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABggslI0a+Sx6R7rkn6nd9zzZuTf+G5Jlo90dQ47xN31l35v70faJv3EklaeNX1nmtOv3couoNhyOIKCABgggACAJiIeQA98sgj8vl8EcvUqVNjfRgAwCAXl3tAl112mV5//fV/HmQYt5oAAJHikgzDhg1TMBiMx1sDABJEXO4BHThwQDk5OZowYYJuvfVWHTrU99MxnZ2dCoVCEQsAIPHFPIAKCgq0YcMGbd++XevWrVNjY6OuueYatbe397p/RUWFAoFAeMnNzY11SwCAASjmAVRSUqIbb7xR06dPV3FxsV555RW1trbqxRdf7HX/8vJytbW1hZempqZYtwQAGIDi/nTA6NGjdemll6qhoaHX7X6/X36/9180BAAMbnH/PaDjx4/r4MGDys7OjvehAACDSMwD6L777lN1dbXee+89vfXWW7r++uuVnJysm2++OdaHAgAMYjH/CO7999/XzTffrGPHjuniiy/W1VdfrdraWl188cWxPhQAYBCLeQA9//zzsX5LDFDJUfxQ0f289/t9Wydv9VwTrbWtEz3X/HbddZ5r7l7xfzzX3Jp6xHNNtE7/2vsUq01V/8FzTe4P3vJcg8TBXHAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMxP0L6ZC4/v7fJnuu2Tt1TRw6OdtXa78TVd24x7xPwnni+8c91/TnxKLR2DbV+wSwnVO6PNdcMazMc834VUxgmii4AgIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmGA2bGjYJTlR1S379isx7iR2/K+nRVXXcLP3mr9e/QvPNXWd3o9z69ZSzzVpB6P7GfOV+1d7rslIHuG5pua//tRzTaHvXs814x+u8VyD+OMKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkmI4Xe+86XoqorHf1ybBvpw/Rf3eW5ZtyvdkV1rI/+9WtR1Xm1/Gfe/06T1r4Vh056d/v2f/Fcc+kLTZ5rHg96/+9Uc9vPPNcseGel5xpJGrHl7ajq8MVwBQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEk5EmGp/Pc8lF32yOQyOxk/fCUc813T3dUR1rzK7hnmvemH2B55qsXSHPNc5zRfS6Gxo91+z66Tc813Q97n2C1QuT/J5rbvnRHzzXSNLv3y30XNNd3xDVsYYiroAAACYIIACACc8BtHPnTs2fP185OTny+XzasmVLxHbnnB5++GFlZ2drxIgRKioq0oEDB2LVLwAgQXgOoI6ODuXn52vt2rW9bl+9erWeeuopPf3009q1a5dGjRql4uJinTx58rybBQAkDs8PIZSUlKikpKTXbc45Pfnkk3rwwQe1YMECSdIzzzyjrKwsbdmyRTfddNP5dQsASBgxvQfU2Nio5uZmFRUVhdcFAgEVFBSopqam15rOzk6FQqGIBQCQ+GIaQM3NZx7nzcrKiliflZUV3vZZFRUVCgQC4SU3NzeWLQEABijzp+DKy8vV1tYWXpqamqxbAgD0g5gGUDAYlCS1tLRErG9paQlv+yy/36+0tLSIBQCQ+GIaQHl5eQoGg6qsrAyvC4VC2rVrlwoLvf9GMQAgcXl+Cu748eNqaPjnVBONjY3au3ev0tPTNW7cOK1cuVI//OEPNXnyZOXl5emhhx5STk6OFi5cGMu+AQCDnOcA2r17t6699trw67KyMknSkiVLtGHDBt1///3q6OjQHXfcodbWVl199dXavn27LrjA+3xZAIDE5XPO9ecch+cUCoUUCAQ0Wws0zOd9YsihLumrX/Fc8/s//K84dNK7VUe/5rlmb1GG55ruY//wXIP+d+x27x/N1zz2izh00rtr/rzYc03gOiYjPe26VKWtamtr+9z7+uZPwQEAhiYCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAnPX8cAnI8//P0yzzXBY+/GoRMMBJm/+6vnmnuXf8Nzzc+yaz3XSFJwVLvnms4ovnqm5+RJzzWJgCsgAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJpiMFP1q+MujrVvAANLd2ua55uXdMz3X/Gx+dJORbpr0iuea/zLl294P9OehOeEuV0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMMBlpgvm3JWnWLXyui/7tpHULGOQmPdflvWh+7PvA+eMKCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkmI00wycGPrVsAgC+EKyAAgAkCCABgwnMA7dy5U/Pnz1dOTo58Pp+2bNkSsX3p0qXy+XwRy7x582LVLwAgQXgOoI6ODuXn52vt2rV97jNv3jwdOXIkvDz33HPn1SQAIPF4fgihpKREJSUln7uP3+9XMBiMuikAQOKLyz2gqqoqZWZmasqUKVq+fLmOHTvW576dnZ0KhUIRCwAg8cU8gObNm6dnnnlGlZWV+slPfqLq6mqVlJSou7u71/0rKioUCATCS25ubqxbAgAMQDH/PaCbbrop/OfLL79c06dP18SJE1VVVaU5c+actX95ebnKysrCr0OhECEEAENA3B/DnjBhgjIyMtTQ0NDrdr/fr7S0tIgFAJD44h5A77//vo4dO6bs7Ox4HwoAMIh4/gju+PHjEVczjY2N2rt3r9LT05Wenq5HH31UixYtUjAY1MGDB3X//fdr0qRJKi4ujmnjAIDBzXMA7d69W9dee2349Sf3b5YsWaJ169Zp3759+u1vf6vW1lbl5ORo7ty5+sEPfiC/3x+7rgEAg57nAJo9e7acc31uf/XVV8+rIZyflL2jvBfNin0ffWkuGOG5Juf/xqERAOaYCw4AYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYCLmX8kNW7mvtnov+u8xb6NPSVd/5L3op7HvAwNDclam55pvrnkrDp30bs1Hkz3XJLX8w3NNj+eKxMAVEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABNMRppgfF3dnmtauj+O6lhZySM811w00vuxfMNTPNe4rlOea9D/Tk/M9lzzvTF/jEMnvfvVX672XPOl5n1x6CQxcQUEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABJORJpjuv9R7rrnxL0uiOtbO6S96rnntst95rlkwYbHnmu76Bs81OD/JX57suWbRr1+NQydn+5f3/mNUdZPKPvRcczqqIw1NXAEBAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwwWSkGPBOTLrIc43f+5ys+JST/3mm55rvPP577zVp/+65JhqHnro0qrrUf6+NcSf4NK6AAAAmCCAAgAlPAVRRUaErr7xSqampyszM1MKFC1VfH/lZx8mTJ1VaWqoxY8bowgsv1KJFi9TS0hLTpgEAg5+nAKqurlZpaalqa2v12muvqaurS3PnzlVHR0d4n3vuuUcvv/yyNm3apOrqah0+fFg33HBDzBsHAAxunh5C2L59e8TrDRs2KDMzU3V1dZo1a5ba2tr061//Whs3btS3vvUtSdL69ev15S9/WbW1tfrGN74Ru84BAIPaed0DamtrkySlp6dLkurq6tTV1aWioqLwPlOnTtW4ceNUU1PT63t0dnYqFApFLACAxBd1APX09GjlypW66qqrNG3aNElSc3OzUlJSNHr06Ih9s7Ky1Nzc3Ov7VFRUKBAIhJfc3NxoWwIADCJRB1Bpaan279+v559//rwaKC8vV1tbW3hpamo6r/cDAAwOUf0i6ooVK7Rt2zbt3LlTY8eODa8PBoM6deqUWltbI66CWlpaFAwGe30vv98vv98fTRsAgEHM0xWQc04rVqzQ5s2btWPHDuXl5UVsnzFjhoYPH67Kysrwuvr6eh06dEiFhYWx6RgAkBA8XQGVlpZq48aN2rp1q1JTU8P3dQKBgEaMGKFAIKDbb79dZWVlSk9PV1pamu666y4VFhbyBBwAIIKnAFq3bp0kafbs2RHr169fr6VLl0qSfv7znyspKUmLFi1SZ2eniouL9ctf/jImzQIAEofPOeesm/i0UCikQCCg2VqgYb7h1u0MCR8tie7j0T/96Bcx7qR3NZ3Jnmt+cNttUR0rqXpPVHX9IXlS3rl3+oz60qyojvXOjT/3XDPSl+K5pqX7Y881/+ln93uuuWTjAc81ktT9wQdR1Q11p12XqrRVbW1tSktL63M/5oIDAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJhgNmwoadSoqOoO/Oulnmvenf0/ozqWV3tO9URVd/u6uz3XnEz3/r/QQws3ea65ZPhHnmtmXXDKc020vt9yheeaqjXevycsfX2N5xr0L2bDBgAMaAQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwMs24A9no6OqKqm/SE94ku3y70ea6Z6fc+2efXUqL72eqdu9dEVZdooplYtOZ/zPRck/47JhYdyrgCAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYILJSBE1V/cXzzWPTfh6HDpB7HmfAHaUdsWhDyQyroAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGDCUwBVVFToyiuvVGpqqjIzM7Vw4ULV19dH7DN79mz5fL6I5c4774xp0wCAwc9TAFVXV6u0tFS1tbV67bXX1NXVpblz56qjoyNiv2XLlunIkSPhZfXq1TFtGgAw+Hn6RtTt27dHvN6wYYMyMzNVV1enWbNmhdePHDlSwWAwNh0CABLSed0DamtrkySlp6dHrH/22WeVkZGhadOmqby8XCdOnOjzPTo7OxUKhSIWAEDi83QF9Gk9PT1auXKlrrrqKk2bNi28/pZbbtH48eOVk5Ojffv26YEHHlB9fb1eeumlXt+noqJCjz76aLRtAAAGKZ9zzkVTuHz5cv3xj3/Um2++qbFjx/a5344dOzRnzhw1NDRo4sSJZ23v7OxUZ2dn+HUoFFJubq5ma4GG+YZH0xoAwNBp16UqbVVbW5vS0tL63C+qK6AVK1Zo27Zt2rlz5+eGjyQVFBRIUp8B5Pf75ff7o2kDADCIeQog55zuuusubd68WVVVVcrLyztnzd69eyVJ2dnZUTUIAEhMngKotLRUGzdu1NatW5Wamqrm5mZJUiAQ0IgRI3Tw4EFt3LhR1113ncaMGaN9+/bpnnvu0axZszR9+vS4/AUAAIOTp3tAPp+v1/Xr16/X0qVL1dTUpG9/+9vav3+/Ojo6lJubq+uvv14PPvjg534O+GmhUEiBQIB7QAAwSMXlHtC5sio3N1fV1dVe3hIAMEQxFxwAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwMQw6wY+yzknSTqtLskZNwMA8Oy0uiT989/zvgy4AGpvb5ckvalXjDsBAJyP9vZ2BQKBPrf73Lkiqp/19PTo8OHDSk1Nlc/ni9gWCoWUm5urpqYmpaWlGXVoj3E4g3E4g3E4g3E4YyCMg3NO7e3tysnJUVJS33d6BtwVUFJSksaOHfu5+6SlpQ3pE+wTjMMZjMMZjMMZjMMZ1uPweVc+n+AhBACACQIIAGBiUAWQ3+/XqlWr5Pf7rVsxxTicwTicwTicwTicMZjGYcA9hAAAGBoG1RUQACBxEEAAABMEEADABAEEADAxaAJo7dq1+tKXvqQLLrhABQUFevvtt61b6nePPPKIfD5fxDJ16lTrtuJu586dmj9/vnJycuTz+bRly5aI7c45Pfzww8rOztaIESNUVFSkAwcO2DQbR+cah6VLl551fsybN8+m2TipqKjQlVdeqdTUVGVmZmrhwoWqr6+P2OfkyZMqLS3VmDFjdOGFF2rRokVqaWkx6jg+vsg4zJ49+6zz4c477zTquHeDIoBeeOEFlZWVadWqVXrnnXeUn5+v4uJiHT161Lq1fnfZZZfpyJEj4eXNN9+0binuOjo6lJ+fr7Vr1/a6ffXq1Xrqqaf09NNPa9euXRo1apSKi4t18uTJfu40vs41DpI0b968iPPjueee68cO46+6ulqlpaWqra3Va6+9pq6uLs2dO1cdHR3hfe655x69/PLL2rRpk6qrq3X48GHdcMMNhl3H3hcZB0latmxZxPmwevVqo4774AaBmTNnutLS0vDr7u5ul5OT4yoqKgy76n+rVq1y+fn51m2YkuQ2b94cft3T0+OCwaB7/PHHw+taW1ud3+93zz33nEGH/eOz4+Ccc0uWLHELFiww6cfK0aNHnSRXXV3tnDvz33748OFu06ZN4X3effddJ8nV1NRYtRl3nx0H55z75je/6e6++267pr6AAX8FdOrUKdXV1amoqCi8LikpSUVFRaqpqTHszMaBAweUk5OjCRMm6NZbb9WhQ4esWzLV2Nio5ubmiPMjEAiooKBgSJ4fVVVVyszM1JQpU7R8+XIdO3bMuqW4amtrkySlp6dLkurq6tTV1RVxPkydOlXjxo1L6PPhs+PwiWeffVYZGRmaNm2aysvLdeLECYv2+jTgJiP9rA8//FDd3d3KysqKWJ+VlaW//e1vRl3ZKCgo0IYNGzRlyhQdOXJEjz76qK655hrt379fqamp1u2ZaG5ulqRez49Ptg0V8+bN0w033KC8vDwdPHhQ3//+91VSUqKamholJydbtxdzPT09Wrlypa666ipNmzZN0pnzISUlRaNHj47YN5HPh97GQZJuueUWjR8/Xjk5Odq3b58eeOAB1dfX66WXXjLsNtKADyD8U0lJSfjP06dPV0FBgcaPH68XX3xRt99+u2FnGAhuuumm8J8vv/xyTZ8+XRMnTlRVVZXmzJlj2Fl8lJaWav/+/UPiPujn6Wsc7rjjjvCfL7/8cmVnZ2vOnDk6ePCgJk6c2N9t9mrAfwSXkZGh5OTks55iaWlpUTAYNOpqYBg9erQuvfRSNTQ0WLdi5pNzgPPjbBMmTFBGRkZCnh8rVqzQtm3b9MYbb0R8fUswGNSpU6fU2toasX+ing99jUNvCgoKJGlAnQ8DPoBSUlI0Y8YMVVZWhtf19PSosrJShYWFhp3ZO378uA4ePKjs7GzrVszk5eUpGAxGnB+hUEi7du0a8ufH+++/r2PHjiXU+eGc04oVK7R582bt2LFDeXl5EdtnzJih4cOHR5wP9fX1OnToUEKdD+cah97s3btXkgbW+WD9FMQX8fzzzzu/3+82bNjg/vrXv7o77rjDjR492jU3N1u31q/uvfdeV1VV5RobG92f/vQnV1RU5DIyMtzRo0etW4ur9vZ2t2fPHrdnzx4nyT3xxBNuz5497u9//7tzzrkf//jHbvTo0W7r1q1u3759bsGCBS4vL899/PHHxp3H1ueNQ3t7u7vvvvtcTU2Na2xsdK+//rr7+te/7iZPnuxOnjxp3XrMLF++3AUCAVdVVeWOHDkSXk6cOBHe584773Tjxo1zO3bscLt373aFhYWusLDQsOvYO9c4NDQ0uMcee8zt3r3bNTY2uq1bt7oJEya4WbNmGXceaVAEkHPOrVmzxo0bN86lpKS4mTNnutraWuuW+t3ixYtddna2S0lJcZdccolbvHixa2hosG4r7t544w0n6axlyZIlzrkzj2I/9NBDLisry/n9fjdnzhxXX19v23QcfN44nDhxws2dO9ddfPHFbvjw4W78+PFu2bJlCfdDWm9/f0lu/fr14X0+/vhj993vftdddNFFbuTIke766693R44csWs6Ds41DocOHXKzZs1y6enpzu/3u0mTJrnvfe97rq2tzbbxz+DrGAAAJgb8PSAAQGIigAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABg4v8B4KL+IRSwcCkAAAAASUVORK5CYII="},214351:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_06-fa782b76e2e5162de6a009f467911ab7.png"},90737:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_07-d9fefbb7a560bf489c7c8659f8fd33a5.png"},312226:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_08-8fb4597183fe330436e8bc52059387aa.png"},443704:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_09-b2e692fbc6c17e79001510eeaec6ec7f.png"},407412:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_10-6d6e8b69f539d23fa1912fa995335fcf.png"},737094:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/05_Tensorflow_Unsupervised_Learning_11-655cbaf7a3680f431444733200450a03.png"},268225:(e,n,s)=>{s.d(n,{Z:()=>r});const r=s.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-da0f4433cfd061cf6ed148c34ca4eb14.jpg"}}]);