"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[96437],{908923:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>g,frontMatter:()=>s,metadata:()=>r,toc:()=>d});var a=i(474848),t=i(28453);const s={sidebar_position:4280,slug:"2023-08-03",title:"Tensorflow Image Classifier - Data-efficient Image Transformers",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Blue print image classifier using Tensorflow and Keras Applications pre-trained models"},o="Tf Image Classifier",r={id:"IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit/index",title:"Tensorflow Image Classifier - Data-efficient Image Transformers",description:"Blue print image classifier using Tensorflow and Keras Applications pre-trained models",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit",slug:"/IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit/2023-08-03",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit/2023-08-03",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-08-03-tensorflow-i-know-flowers-deit/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4280,frontMatter:{sidebar_position:4280,slug:"2023-08-03",title:"Tensorflow Image Classifier - Data-efficient Image Transformers",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Blue print image classifier using Tensorflow and Keras Applications pre-trained models"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow Image Classifier - EfficientNetV2B0",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-04-tensorflow-i-know-flowers-efficientnetv2b0/2023-08-04"},next:{title:"Tensorflow Image Classifier - Data Pre-processing",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-02-tensorflow-i-know-flowers-preprocessing/2023-08-02"}},l={},d=[{value:"DeiT Vision Transformer (Transfer-Learning)",id:"deit-vision-transformer-transfer-learning",level:2},{value:"Dataset",id:"dataset",level:3},{value:"DeiT Model",id:"deit-model",level:3},{value:"Model Training",id:"model-training",level:3},{value:"Model Evaluation",id:"model-evaluation",level:3},{value:"Saving the Model",id:"saving-the-model",level:3}];function c(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,t.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Angkor Wat, Cambodia",src:i(463329).A+"",width:"1500",height:"706"})}),"\n",(0,a.jsx)(n.h1,{id:"tf-image-classifier",children:"Tf Image Classifier"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-08-01-tensorflow-i-know-flowers-intro/2023-08-01",children:"Overview - Model Evaluation & Deployment"})}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"deit-vision-transformer-transfer-learning",children:"DeiT Vision Transformer (Transfer-Learning)"}),"\n",(0,a.jsxs)(n.blockquote,{children:["\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.a,{href:"https://arxiv.org/pdf/2012.12877.pdf",children:"Training data-efficient image transformers\n& distillation through attention"})}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.code,{children:"Hugo Touvron"}),", ",(0,a.jsx)(n.code,{children:"Matthieu Cord"}),", ",(0,a.jsx)(n.code,{children:"Matthijs Douze"}),", ",(0,a.jsx)(n.code,{children:"Francisco Massa"}),", ",(0,a.jsx)(n.code,{children:"Alexandre Sablayrolles"}),", ",(0,a.jsx)(n.code,{children:"Herve J'egou"})]}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.em,{children:'"Recently, neural networks purely based on attention were shown to address image understanding tasks such as image classification. These highperforming vision transformers are pre-trained with hundreds of millions of images using a large infrastructure, thereby limiting their adoption. In this work, we produce competitive convolution-free transformers by training on Imagenet only. We train them on a single computer in less than 3 days. Our reference vision transformer (86M parameters) achieves top-1 accuracy of 83.1% (single-crop) on ImageNet with no external data. More importantly, we introduce a teacher-student strategy specific to transformers. It relies on a distillation token ensuring that the student learns from the teacher through attention. We show the interest of this token-based distillation, especially when using a convnet as a teacher. This leads us to report results competitive with convnets for both Imagenet (where we obtain up to 85.2% accuracy) and when transferring to other tasks."'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"!pip install transformers\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"import cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay)\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import (\n    Conv2D,\n    BatchNormalization,\n    LayerNormalization,\n    Dense,\n    Input,\n    Embedding,\n    MultiHeadAttention,\n    Layer,\n    Add,\n    Resizing,\n    Rescaling,\n    Permute,\n    Flatten,\n    RandomFlip,\n    RandomRotation,\n    RandomContrast,\n    RandomBrightness\n)\nfrom tensorflow.keras.losses import CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import image_dataset_from_directory\n\nfrom transformers import DeiTConfig, TFDeiTModel\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"SEED = 42\nLABELS = ['Gladiolus', 'Adenium', 'Alpinia_Purpurata', 'Alstroemeria', 'Amaryllis', 'Anthurium_Andraeanum', 'Antirrhinum', 'Aquilegia', 'Billbergia_Pyramidalis', 'Cattleya', 'Cirsium', 'Coccinia_Grandis', 'Crocus', 'Cyclamen', 'Dahlia', 'Datura_Metel', 'Dianthus_Barbatus', 'Digitalis', 'Echinacea_Purpurea', 'Echinops_Bannaticus', 'Fritillaria_Meleagris', 'Gaura', 'Gazania', 'Gerbera', 'Guzmania', 'Helianthus_Annuus', 'Iris_Pseudacorus', 'Leucanthemum', 'Malvaceae', 'Narcissus_Pseudonarcissus', 'Nerine', 'Nymphaea_Tetragona', 'Paphiopedilum', 'Passiflora', 'Pelargonium', 'Petunia', 'Platycodon_Grandiflorus', 'Plumeria', 'Poinsettia', 'Primula', 'Protea_Cynaroides', 'Rose', 'Rudbeckia', 'Strelitzia_Reginae', 'Tropaeolum_Majus', 'Tussilago', 'Viola', 'Zantedeschia_Aethiopica']\nNLABELS = len(LABELS)\nBATCH_SIZE = 32\nSIZE = 224\nEPOCHS = 40\nLR = 5e-6 # default 0.001\nHIDDEN_SIZE = 768 # default 768\nNHEADS = 8 # default 12\nNLAYERS = 4 # default 12\n"})}),"\n",(0,a.jsx)(n.h3,{id:"dataset",children:"Dataset"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"train_directory = '../dataset/Flower_Dataset/split/train'\ntest_directory = '../dataset/Flower_Dataset/split/val'\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"train_dataset = image_dataset_from_directory(\n    train_directory,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=LABELS,\n    color_mode='rgb',\n    batch_size=BATCH_SIZE,\n    image_size=(SIZE, SIZE),\n    shuffle=True,\n    seed=SEED,\n    interpolation='bilinear',\n    follow_links=False,\n    crop_to_aspect_ratio=False\n)\n\n# Found 9206 files belonging to 48 classes.\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"test_dataset = image_dataset_from_directory(\n    test_directory,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=LABELS,\n    color_mode='rgb',\n    batch_size=BATCH_SIZE,\n    image_size=(SIZE, SIZE),\n    shuffle=True,\n    seed=SEED\n)\n\n# Found 3090 files belonging to 48 classes.\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"data_augmentation = Sequential([\n        RandomRotation(factor=0.25),\n        RandomFlip(mode='horizontal'),\n        RandomContrast(factor=0.1),\n        RandomBrightness(0.1)\n    ],\n    name=\"img_augmentation\",\n)\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"resize_rescale_reshape = Sequential([\n    Resizing(SIZE, SIZE),\n    Rescaling(1./255),\n    # transformer expects image shape (3,224,224)\n    Permute((3,1,2))\n])\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"training_dataset = (\n    train_dataset\n    .map(lambda image, label: (data_augmentation(image), label))\n    .prefetch(tf.data.AUTOTUNE)\n)\n\n\ntesting_dataset = (\n    test_dataset.prefetch(\n        tf.data.AUTOTUNE\n    )\n)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"deit-model",children:"DeiT Model"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'# Initializing a ViT vit-base-patch16-224 style configuration\nconfiguration = DeiTConfig(\n    image_size=SIZE,\n    hidden_size=HIDDEN_SIZE,\n    num_attention_heads=NHEADS,\n    num_hidden_layers=NLAYERS\n)\n\n# Initializing a model with random weights from the vit-base-patch16-224 style configuration\n# base_model = TFViTModel(configuration)\n\n# use pretrained weights for the model instead\nbase_model = TFDeiTModel.from_pretrained("facebook/deit-base-distilled-patch16-224", config=configuration)\n\n# Accessing the model configuration\nconfiguration = base_model.config\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"configuration\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"input = Input(shape=(SIZE,SIZE,3))\n# random image augmentation\ndata_aug = data_augmentation(input)\nx = resize_rescale_reshape(data_aug)\nx = base_model.deit(x)[0][:,0,:]\noutput = Dense(NLABELS, activation='softmax')(x)\n\ndeit_model = Model(inputs=input, outputs=output)\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"deit_model.summary()\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# testing the pretrained model\ntest_image = cv.imread('../dataset/snapshots/Viola_Tricolor.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"deit_model(tf.expand_dims(test_image, axis = 0))\n# numpy= array([[1.0963462e-01, 4.4628163e-03, 2.7227099e-03, 3.9012067e-02,\n      #   1.2207581e-02, 3.4460202e-02, 2.3577355e-03, 3.5261197e-03,\n      #   1.7803181e-02, 1.0567555e-02, 1.5943516e-02, 4.0797489e-03,\n      #   7.1987398e-03, 9.5541059e-04, 4.2675242e-02, 1.5655500e-04,\n      #   1.1215543e-02, 1.4889235e-02, 1.8372904e-01, 7.0088580e-03,\n      #   3.1637046e-03, 1.4315472e-03, 8.3367303e-03, 1.5427665e-03,\n      #   1.9941023e-02, 9.9778855e-03, 5.6907861e-03, 1.7462631e-03,\n      #   3.6991950e-02, 1.3322993e-02, 5.4029688e-02, 4.0368687e-02,\n      #   6.1121010e-03, 7.9112053e-03, 7.2245464e-02, 8.8621033e-03,\n      #   2.1858371e-03, 3.0036021e-02, 2.7811823e-02, 7.0134280e-03,\n      #   6.1850133e-03, 1.8044524e-02, 2.3036957e-02, 1.6069075e-02,\n      #   2.3161862e-02, 2.9986592e-03, 1.0242336e-02, 1.6933089e-02]],\n      # dtype=float32)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"model-training",children:"Model Training"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"loss_function = CategoricalCrossentropy()\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"metrics = [CategoricalAccuracy(name='accuracy')]\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"deit_model.compile(\n    optimizer = Adam(learning_rate = LR),\n    loss = loss_function,\n    metrics = metrics\n)\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"deit_history = deit_model.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    verbose = 1\n)\n\n# loss: 0.3592\n# accuracy: 0.8945\n# val_loss: 0.7199\n# val_accuracy: 0.7900\n"})}),"\n",(0,a.jsx)(n.h3,{id:"model-evaluation",children:"Model Evaluation"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"deit_model.evaluate(testing_dataset)\n# loss: 0.7199 - accuracy: 0.7900\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"plt.plot(deit_history.history['loss'])\nplt.plot(deit_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss', 'val_loss'])\n\nplt.savefig('assets/DeiT_01.webp', bbox_inches='tight')\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Building a Tensorflow VIT",src:i(713606).A+"",width:"567",height:"455"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"plt.plot(deit_history.history['accuracy'])\nplt.plot(deit_history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train_accuracy', 'val_accuracy'])\n\nplt.savefig('assets/DeiT_02.webp', bbox_inches='tight')\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Building a Tensorflow VIT",src:i(77863).A+"",width:"567",height:"455"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"test_image_bgr = cv.imread('../dataset/snapshots/Viola_Tricolor.jpg')\ntest_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\ntest_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\nimg = tf.constant(test_image_rgb, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nprobs = deit_model(img).numpy()\nlabel = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n\nprint(label, str(probs[0]))\n\nplt.imshow(test_image_rgb)\nplt.title(label)\nplt.axis('off')\n        \nplt.savefig('assets/DeiT_Prediction_01.webp', bbox_inches='tight')\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Building a Tensorflow VIT",src:i(162210).A+"",width:"389",height:"411"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"test_image_bgr = cv.imread('../dataset/snapshots/Strelitzia.jpg')\ntest_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\ntest_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\nimg = tf.constant(test_image_rgb, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nprobs = deit_model(img).numpy()\nlabel = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n\nprint(label, str(probs[0]))\n\nplt.imshow(test_image_rgb)\nplt.title(label)\nplt.axis('off')\n        \nplt.savefig('assets/DeiT_Prediction_02.webp', bbox_inches='tight')\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Building a Tensorflow VIT",src:i(327107).A+"",width:"389",height:"411"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"test_image_bgr = cv.imread('../dataset/snapshots/Water_Lilly.jpg')\ntest_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\ntest_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\nimg = tf.constant(test_image_rgb, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nprobs = deit_model(img).numpy()\nlabel = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n\nprint(label, str(probs[0]))\n\nplt.imshow(test_image_rgb)\nplt.title(label)\nplt.axis('off')\n        \nplt.savefig('assets/DeiT_Prediction_03.webp', bbox_inches='tight')\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Building a Tensorflow VIT",src:i(444064).A+"",width:"389",height:"411"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"plt.figure(figsize=(16,16))\n\nfor images, labels in testing_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n        pred = \"Predicted: \" + LABELS[\n            tf.argmax(deit_model(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n        ]\n        plt.title(\n           true  + \"\\n\" + pred\n        )\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/DeiT_03.webp', bbox_inches='tight')\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Building a Tensorflow VIT",src:i(924164).A+"",width:"1261",height:"1295"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"y_pred = []\ny_test = []\n\nfor img, label in testing_dataset:\n    y_pred.append(deit_model(img))\n    y_test.append(label.numpy())\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"conf_mtx = ConfusionMatrixDisplay(\n    confusion_matrix=confusion_matrix(\n        np.argmax(y_test[:-1], axis=-1).flatten(),\n        np.argmax(y_pred[:-1], axis=-1).flatten()\n    ),\n    display_labels=LABELS\n)\n\nfig, ax = plt.subplots(figsize=(16,12))\nconf_mtx.plot(ax=ax, cmap='plasma', include_values=True, xticks_rotation='vertical')\n\nplt.savefig('assets/DeiT_04.webp', bbox_inches='tight')\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Building a Tensorflow VIT",src:i(740245).A+"",width:"1305",height:"1160"})}),"\n",(0,a.jsx)(n.h3,{id:"saving-the-model",children:"Saving the Model"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"tf.keras.saving.save_model(\n    deit_model, '../saved_model/deit_model', overwrite=True, save_format='tf'\n)\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# restore the model\nrestored_model = tf.keras.saving.load_model('../saved_model/deit_model')\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# Check its architecture\nrestored_model.summary()\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"restored_model.evaluate(testing_dataset)\n# loss: 0.5184 - accuracy: 0.7840 - topk_accuracy: 0.9394\n"})})]})}function g(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},713606:(e,n,i)=>{i.d(n,{A:()=>a});const a="data:image/webp;base64,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"},77863:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/DeiT_02-06b3a47888aa484acfb91e070c8efa30.webp"},924164:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/DeiT_03-796dd088eb339411806525911b69c483.webp"},740245:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/DeiT_04-88e5b62d111205efefc9bd54f45f0f6c.webp"},162210:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/DeiT_Prediction_01-1c4c944bd8cc6908d39588b4265bbc8e.webp"},327107:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/DeiT_Prediction_02-cb566f9e2a0ff163d5ea7feca5986887.webp"},444064:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/DeiT_Prediction_03-56940b6847fb2b6012fc7d7dfdf0d4ae.webp"},463329:(e,n,i)=>{i.d(n,{A:()=>a});const a=i.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-4b4c922f390788acb724c3c274da1ef9.jpg"},28453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>r});var a=i(296540);const t={},s=a.createContext(t);function o(e){const n=a.useContext(s);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),a.createElement(s.Provider,{value:n},e.children)}}}]);