"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[14226],{468108:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>l,contentTitle:()=>i,default:()=>h,frontMatter:()=>s,metadata:()=>o,toc:()=>c});var r=a(785893),t=a(603905);const s={sidebar_position:4910,slug:"2022-12-18",title:"Tensorflow Transfer Learning",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Transfer learning is a machine learning technique in which intelligence from a base ann is being transferred to a new network as a starting point."},i=void 0,o={id:"IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/index",title:"Tensorflow Transfer Learning",description:"Transfer learning is a machine learning technique in which intelligence from a base ann is being transferred to a new network as a starting point.",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning",slug:"/IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/2022-12-18",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/2022-12-18",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-12-18-tf-transfer-learning/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4910,frontMatter:{sidebar_position:4910,slug:"2022-12-18",title:"Tensorflow Transfer Learning",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Transfer learning is a machine learning technique in which intelligence from a base ann is being transferred to a new network as a starting point."},sidebar:"tutorialSidebar",previous:{title:"Tensorflow Hub",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-19-tf-hub/2022-12-19"},next:{title:"Tensorflow Image Classification",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-12-16-tf-cifar/2022-12-16"}},l={},c=[{value:"Sharing Inteligence",id:"sharing-inteligence",level:2},{value:"Cats and Dogs",id:"cats-and-dogs",level:2},{value:"Importing the Model",id:"importing-the-model",level:3},{value:"Testrun the unmodified ResNet50 Model",id:"testrun-the-unmodified-resnet50-model",level:3},{value:"Building the Model",id:"building-the-model",level:3},{value:"Building the Model",id:"building-the-model-1",level:3},{value:"Train the Model",id:"train-the-model",level:3},{value:"Evaluating the Model",id:"evaluating-the-model",level:3},{value:"Update :: Binary Crossentropy",id:"update--binary-crossentropy",level:2}];function d(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.ah)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Guangzhou, China",src:a(765275).Z+"",width:"1500",height:"383"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#sharing-inteligence",children:"Sharing Inteligence"})}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.a,{href:"#cats-and-dogs",children:"Cats and Dogs"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#importing-the-model",children:"Importing the Model"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#testrun-the-unmodified-resnet50-model",children:"Testrun the unmodified ResNet50 Model"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#building-the-model",children:"Building the Model"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#building-the-model-1",children:"Building the Model"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#train-the-model",children:"Train the Model"})}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#evaluating-the-model",children:"Evaluating the Model"})}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(n.li,{children:(0,r.jsx)(n.a,{href:"#update--binary-crossentropy",children:"Update :: Binary Crossentropy"})}),"\n"]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.a,{href:"https://github.com/mpolinowski/tf-cats-n-dogs",children:"Github"})}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"sharing-inteligence",children:"Sharing Inteligence"}),"\n",(0,r.jsxs)(n.p,{children:[(0,r.jsx)(n.strong,{children:"Transfer learning"})," is a machine learning technique in which intelligence (i.e.: weights) from a base artificial neural network is being transferred to a new network as a starting point to perform a specific task. This can dramatically reduce the computational time required compared to starting from scratch."]}),"\n",(0,r.jsxs)(n.p,{children:["A pre-trained ",(0,r.jsx)(n.a,{href:"https://www.kaggle.com/datasets/keras/resnet50",children:"ResNet50"})," model that has been trained on ",(0,r.jsx)(n.a,{href:"https://image-net.org/about.php",children:"ImageNet which is an open source repository of images"}),". The feature maps that has been previously trained will be augmented with a new classifier (new Dense layers)."]}),"\n",(0,r.jsx)(n.p,{children:"Fine tuning can be performed by unfreezing the top layers (base) and slowly training the entire network so an improved performance can be achieved."}),"\n",(0,r.jsx)(n.h2,{id:"cats-and-dogs",children:"Cats and Dogs"}),"\n",(0,r.jsxs)(n.p,{children:["We are going to take the ",(0,r.jsx)(n.strong,{children:"ResNet50"})," model and re-train it to help distinguishing photos of cats and dogs from the ",(0,r.jsx)(n.a,{href:"https://www.kaggle.com/datasets/tongpython/cat-and-dog",children:"Cats and Dogs"})," dataset on ",(0,r.jsx)(n.code,{children:"kaggle.com"}),". Here we have two possible strategies:"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Conservative"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Freeze the trained CNN weights from the first layer"}),"\n",(0,r.jsx)(n.li,{children:"Add a new dense layer with randomly initialized weights"}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.strong,{children:"Dynamic"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Initialize the CNN network with the pre-trained weights"}),"\n",(0,r.jsxs)(n.li,{children:["Use a ",(0,r.jsx)(n.strong,{children:"small learning rate"})," to prevent aggressive changes"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"importing-the-model",children:"Importing the Model"}),"\n",(0,r.jsxs)(n.p,{children:["Just like the ",(0,r.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-12-16-tf-cifar/2022-12-16",children:"CIFAR-10 dataset"})," we can download the ResNet50 model and pre-trained weights directly through Keras:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"model = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = True)\n"})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["Keras models and datasets will be saved to ",(0,r.jsx)(n.code,{children:"/home/myuser/.keras"})," on Linux."]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"testrun-the-unmodified-resnet50-model",children:"Testrun the unmodified ResNet50 Model"}),"\n",(0,r.jsxs)(n.p,{children:["We can directly use the model and test it on some images. ",(0,r.jsx)(n.strong,{children:"Note"})," that the model was trained on colour images with 224x224 resolution and expects your images to be exactly that:"]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.code,{children:'ValueError: Input 0 of layer "resnet50" is incompatible with the layer: expected shape=(None, 224, 224, 3), found shape=(32, 32, 3)'})}),"\n"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# eval the un-modified model\n# resnet50 expects image to be of shape (1, 224, 224, 3)\nsample_image= tf.keras.preprocessing.image.load_img(r'./test_images/cat.png', target_size = (224, 224))\nsample_image = np.expand_dims(sample_image, axis = 0)\nprint('image shape: ',np.shape(sample_image))\n# keras offers resnet50 preprocess preset we can use\n# image will be processed identically to training images\npreprocessed_image = tf.keras.applications.resnet50.preprocess_input(sample_image)\n# run prediction\npredictions = model.predict(preprocessed_image)\n# use keras resnet50 prediction decoder to return top5 predictions\nprint('predictions:', tf.keras.applications.resnet50.decode_predictions(predictions, top = 5)[0])\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Tensorflow Transfer Learning",src:a(975021).Z+"",width:"887",height:"240"})}),"\n",(0,r.jsx)(n.p,{children:"The test image return the following prediction:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"./test_images/cat.png"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"predictions: [('n02123159', 'tiger_cat', 0.39868173), ('n02123045', 'tabby', 0.32775873), ('n02124075', 'Egyptian_cat', 0.26495087), ('n02127052', 'lynx', 0.0049893092), ('n04409515', 'tennis_ball', 0.00035099618)]\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"./test_images/ship.jpg"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"predictions: [('n04147183', 'schooner', 0.5001772), ('n03947888', 'pirate', 0.35976425), ('n04612504', 'yawl', 0.12959233), ('n03662601', 'lifeboat', 0.0024379618), ('n09428293', 'seashore', 0.0018175767)]\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"./test_images/truck.jpg"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"predictions: [('n03345487', 'fire_engine', 0.8839737), ('n04461696', 'tow_truck', 0.028128117), ('n03344393', 'fireboat', 0.019656133), ('n03126707', 'crane', 0.0156197725), ('n03594945', 'jeep', 0.014000045)]\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"./test_images/bird.jpg"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"predictions: [('n01601694', 'water_ouzel', 0.37704965), ('n01795545', 'black_grouse', 0.19283505), ('n01582220', 'magpie', 0.14304504), ('n01580077', 'jay', 0.04652224), ('n01797886', 'ruffed_grouse', 0.025602208)]\n"})}),"\n",(0,r.jsx)(n.h3,{id:"building-the-model",children:"Building the Model"}),"\n",(0,r.jsx)(n.p,{children:"ResNet50 contains 1000 different classes of which we only need 2 - we want our model to be able to distinguish between cats and dogs. So we do not need all the very specific training that happened in ResNet's dense layers. We are only interested in the general feature detection capabilities of it's convolution layers. So we can cut of the \"Top\" of the model and then replace it with our own dense layers that we can initialize with random weights and then freshly train with the cats&dogs dataset:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# load only the convolution layers / general feature detection of resnet50\nbase_model = tf.keras.applications.ResNet50(weights = 'imagenet', include_top = False)\n"})}),"\n",(0,r.jsx)(n.p,{children:"Now that we extracted the general feature detection from ResNet50 we can add our own - fresh - dense top layers and build the new model:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# take base model convolution layers from resnet\nx = base_model.output\n# compress incoming feature maps from resnet layers\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n# and add fresh top of dense layers\n# each node will distinguish between 1024 or 512 features\nx = tf.keras.layers.Dense(1024, activation = 'relu')(x)\nx = tf.keras.layers.Dense(1024, activation = 'relu')(x)\nx = tf.keras.layers.Dense(1024, activation = 'relu')(x)\nx = tf.keras.layers.Dense(512, activation = 'relu')(x)\n# the final layer breaks everything down to a binary decision - cat or dog\npredictions = tf.keras.layers.Dense(2, activation = 'softmax')(x)\n# create new model from both components\nmodel = tf.keras.models.Model(inputs = base_model.input, outputs = predictions)\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Now I want to use the ",(0,r.jsx)(n.strong,{children:"Conservative"})," approach defined above and freeze all the layers that were brought in from ResNet50. If we print out the layers we see that there are ",(0,r.jsx)(n.code,{children:"174"})," layers in total that need to be conserved (set un-trainable):"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"for i, layer in enumerate(base_model.layers):\n    print(i, layer.name)\n"})}),"\n",(0,r.jsx)(n.p,{children:"This will output all layers of the ResNet50 based layers:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"0 input_2\n1 conv1_pad\n2 conv1_conv\n3 conv1_bn\n4 conv1_relu\n...\n173 conv5_block3_add\n174 conv5_block3_out\n"})}),"\n",(0,r.jsx)(n.p,{children:"Lock those layers to freeze all the weights that have been applied training against the ImageNet dataset to preserve the general feature detection:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# lock all resnet layers 1-174\nfor layer in model.layers[:175]:\n    layer.trainable = False\n# the new dense layers have to be trainable\nfor layer in model.layers[175:]:\n    layer.trainable = True\n"})}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["To make the resulting model more specific to your use-case set ",(0,r.jsx)(n.code,{children:"layer.trainable = True"})," for layer ",(0,r.jsx)(n.code,{children:"1"})," - ",(0,r.jsx)(n.code,{children:"174"})," and use a small training rate to preserve the general weight distribution."]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Now we have to point Keras to our ",(0,r.jsx)(n.a,{href:"https://www.kaggle.com/datasets/tongpython/cat-and-dog",children:"Cats and Dogs"})," dataset - specifically to the ",(0,r.jsx)(n.code,{children:"training_set"})," folder that contains two folder ",(0,r.jsx)(n.code,{children:"cats"})," and ",(0,r.jsx)(n.code,{children:"dogs"})," with corresponding images. We can use the ",(0,r.jsx)(n.strong,{children:"ImageDataGenerator"})," with a set of ResNet50 specific training preprocessing functions - all readily provided by Keras:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(preprocessing_function= tf.keras.applications.resnet50.preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory('./data/training_set/', \n                                                   target_size = (224, 224),\n                                                   color_mode = 'rgb',\n                                                   batch_size = 32,\n                                                   class_mode = 'categorical',\n                                                   shuffle = True)\n"})}),"\n",(0,r.jsx)(n.h3,{id:"building-the-model-1",children:"Building the Model"}),"\n",(0,r.jsx)(n.p,{children:"Now that we defined the mode we need to compile:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# compile the new model\nmodel.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n"})}),"\n",(0,r.jsx)(n.h3,{id:"train-the-model",children:"Train the Model"}),"\n",(0,r.jsx)(n.p,{children:'Since we let ResNet50 do most of the work and simply transferred it\'s "intelligence" we can start with a small training run of 5 epochs and see how well our new model can fit our dataset:'}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# and train it on your dataset\nhistory = model.fit(train_generator, steps_per_epoch=train_generator.n//train_generator.batch_size, epochs = 5)\n"})}),"\n",(0,r.jsxs)(n.p,{children:["After the 5th epoch I end up at an accuracy of almost ",(0,r.jsx)(n.code,{children:"100%"})," which often means that we are dealing with some overfitting:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"Epoch 5/5\n250/250 [==============================] - 38s 150ms/step - loss: 0.0134 - accuracy: 0.9950\n"})}),"\n",(0,r.jsx)(n.p,{children:"So the next step is to assess our trained models capability to work it's way through the set of test images that are provided with the dataset."}),"\n",(0,r.jsx)(n.h3,{id:"evaluating-the-model",children:"Evaluating the Model"}),"\n",(0,r.jsx)(n.p,{children:"Plotting the loss and accuracy of the training run:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Tensorflow Transfer Learning",src:a(337683).Z+"",width:"1274",height:"479"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# evaluating the model - accuracy & loss\nacc = history.history['accuracy']\nloss = history.history['loss']\n## plot accuracy\nplt.figure()\nplt.plot(acc, label='Training Accuracy')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy')\n## plot loss\nplt.figure()\nplt.plot(loss, label='Training Loss')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.xlabel('epoch')\nplt.show()\n"})}),"\n",(0,r.jsx)(n.p,{children:"And we can use a test image - that is not contained in the training set - to verify that our model is performing well:"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Tensorflow Transfer Learning",src:a(854075).Z+"",width:"1105",height:"288"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"# take a sample image for testing\nSample_Image= tf.keras.preprocessing.image.load_img(r'./test_images/cat.png', target_size = (224, 224))\nplt.imshow(Sample_Image)\nplt.show()\n## pre-process for resnet\nSample_Image = tf.keras.preprocessing.image.img_to_array(Sample_Image)\nnp.shape(Sample_Image)\nSample_Image = np.expand_dims(Sample_Image, axis = 0)\n## run prediction\nSample_Image = tf.keras.applications.resnet50.preprocess_input(Sample_Image)\npredictions = model.predict(Sample_Image)\nprint('Predictions:', predictions)\n"})}),"\n",(0,r.jsxs)(n.p,{children:["The prediction values that are printed out here are the probability that the image belongs to the classes ",(0,r.jsx)(n.code,{children:"[cat, dog]"})," - and the values I am getting here are ",(0,r.jsx)(n.em,{children:"99.99%"})," to ",(0,r.jsx)(n.em,{children:"5e-7%"})]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Predictions: [[9.9999952e-01 5.0677403e-07]\n"})}),"\n",(0,r.jsx)(n.p,{children:"So there is a chance that this is actually a dog..."}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Tensorflow Transfer Learning",src:a(194956).Z+"",width:"300",height:"160"})}),"\n",(0,r.jsx)(n.h2,{id:"update--binary-crossentropy",children:"Update :: Binary Crossentropy"}),"\n",(0,r.jsxs)(n.p,{children:["When dealing with binary problems (2 classes) you should use ",(0,r.jsx)(n.a,{href:"https://keras.io/api/losses/probabilistic_losses/#binarycrossentropy-class",children:"Binary Crossentropy"})," for the loss function. ",(0,r.jsx)(n.a,{href:"https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class",children:"Categorical Crossentropy"})," is used for multiple classes:"]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-py",children:"model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"})}),"\n",(0,r.jsx)(n.p,{children:"Since the results were already almost perfect I do not see much of a difference here (re-running with categorical crossentropy sometime also results in 100% certainties):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"Predictions: [[1.000000e+00 3.776364e-12]]\n"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{alt:"Tensorflow Transfer Learning",src:a(347705).Z+"",width:"1269",height:"461"})})]})}function h(e={}){const{wrapper:n}={...(0,t.ah)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},603905:(e,n,a)=>{a.d(n,{ah:()=>c});var r=a(667294);function t(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function s(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);n&&(r=r.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,r)}return a}function i(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?s(Object(a),!0).forEach((function(n){t(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):s(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function o(e,n){if(null==e)return{};var a,r,t=function(e,n){if(null==e)return{};var a,r,t={},s=Object.keys(e);for(r=0;r<s.length;r++)a=s[r],n.indexOf(a)>=0||(t[a]=e[a]);return t}(e,n);if(Object.getOwnPropertySymbols){var s=Object.getOwnPropertySymbols(e);for(r=0;r<s.length;r++)a=s[r],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(t[a]=e[a])}return t}var l=r.createContext({}),c=function(e){var n=r.useContext(l),a=n;return e&&(a="function"==typeof e?e(n):i(i({},n),e)),a},d={inlineCode:"code",wrapper:function(e){var n=e.children;return r.createElement(r.Fragment,{},n)}},h=r.forwardRef((function(e,n){var a=e.components,t=e.mdxType,s=e.originalType,l=e.parentName,h=o(e,["components","mdxType","originalType","parentName"]),p=c(a),g=t,m=p["".concat(l,".").concat(g)]||p[g]||d[g]||s;return a?r.createElement(m,i(i({ref:n},h),{},{components:a})):r.createElement(m,i({ref:n},h))}));h.displayName="MDXCreateElement"},975021:(e,n,a)=>{a.d(n,{Z:()=>r});const r=a.p+"assets/images/Tensorflow_Transfer_Learning_01-3b261419a755412dc0afab820eb268b4.png"},337683:(e,n,a)=>{a.d(n,{Z:()=>r});const r=a.p+"assets/images/Tensorflow_Transfer_Learning_02-cdc7c37304e4cf8c005fece416ec1a84.png"},854075:(e,n,a)=>{a.d(n,{Z:()=>r});const r=a.p+"assets/images/Tensorflow_Transfer_Learning_03-510f2cce4d4999a7a35887a406cbba52.png"},347705:(e,n,a)=>{a.d(n,{Z:()=>r});const r=a.p+"assets/images/Tensorflow_Transfer_Learning_04-f79edac5a8d5810059136f5aec367c30.png"},194956:(e,n,a)=>{a.d(n,{Z:()=>r});const r=a.p+"assets/images/nevergiveup-bf43700829e15a95505635216a1d12f8.gif"},765275:(e,n,a)=>{a.d(n,{Z:()=>r});const r=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-918471126c0472aad97358a725e1a399.jpg"}}]);