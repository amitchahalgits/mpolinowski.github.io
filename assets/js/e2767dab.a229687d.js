"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[59748],{3905:(e,n,t)=>{t.d(n,{Zo:()=>c,kt:()=>g});var a=t(67294);function i(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function o(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function r(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?o(Object(t),!0).forEach((function(n){i(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):o(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,a,i=function(e,n){if(null==e)return{};var t,a,i={},o=Object.keys(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||(i[t]=e[t]);return i}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)t=o[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(i[t]=e[t])}return i}var s=a.createContext({}),p=function(e){var n=a.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):r(r({},n),e)),t},c=function(e){var n=p(e.components);return a.createElement(s.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},d=a.forwardRef((function(e,n){var t=e.components,i=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(t),g=i,u=d["".concat(s,".").concat(g)]||d[g]||m[g]||o;return t?a.createElement(u,r(r({ref:n},c),{},{components:t})):a.createElement(u,r({ref:n},c))}));function g(e,n){var t=arguments,i=n&&n.mdxType;if("string"==typeof e||i){var o=t.length,r=new Array(o);r[0]=d;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l.mdxType="string"==typeof e?e:i,r[1]=l;for(var p=2;p<o;p++)r[p]=t[p];return a.createElement.apply(null,r)}return a.createElement.apply(null,t)}d.displayName="MDXCreateElement"},59304:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>r,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var a=t(87462),i=(t(67294),t(3905));const o={sidebar_position:4250,slug:"2023-08-06",title:"Tensorflow Image Classifier - InceptionV3",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Blue print image classifier using Tensorflow and Keras Applications pre-trained models"},r=void 0,l={unversionedId:"IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/index",id:"IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/index",title:"Tensorflow Image Classifier - InceptionV3",description:"Blue print image classifier using Tensorflow and Keras Applications pre-trained models",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3",slug:"/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/2023-08-06",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/2023-08-06",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-08-06-tensorflow-i-know-flowers-inceptionv3/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4250,frontMatter:{sidebar_position:4250,slug:"2023-08-06",title:"Tensorflow Image Classifier - InceptionV3",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Blue print image classifier using Tensorflow and Keras Applications pre-trained models"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow Image Classifier - MobileNetV2",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-07-tensorflow-i-know-flowers-mobilenetv2/2023-08-07"},next:{title:"Tensorflow Image Classifier - EfficientNetV2S",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-08-05-tensorflow-i-know-flowers-efficientnetv2s/2023-08-05"}},s={},p=[{value:"InceptionV3",id:"inceptionv3",level:2},{value:"Dataset",id:"dataset",level:2},{value:"Building the InceptionV3 TF Model",id:"building-the-inceptionv3-tf-model",level:2},{value:"Model Training",id:"model-training",level:3},{value:"Model Evaluation",id:"model-evaluation",level:3},{value:"Model Finetuning",id:"model-finetuning",level:3},{value:"Model Evaluation",id:"model-evaluation-1",level:3},{value:"Saving the Model",id:"saving-the-model",level:3}],c={toc:p};function m(e){let{components:n,...o}=e;return(0,i.kt)("wrapper",(0,a.Z)({},c,o,{components:n,mdxType:"MDXLayout"}),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"Angkor Wat, Cambodia",src:t(68611).Z,width:"1500",height:"706"})),(0,i.kt)("h1",{id:"tf-image-classifier"},"Tf Image Classifier"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://mpolinowski.github.io/docs/IoT-and-Machine-Learning/ML/2023-08-01-tensorflow-i-know-flowers-intro/2023-08-01"},"Overview - Model Evaluation & Deployment"))),(0,i.kt)("h2",{id:"inceptionv3"},"InceptionV3"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"import cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay)\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow.io import TFRecordWriter\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.callbacks  import (\n    Callback,\n    CSVLogger,\n    EarlyStopping,\n    LearningRateScheduler,\n    ModelCheckpoint\n)\nfrom tensorflow.keras.layers import (\n    Layer,\n    GlobalAveragePooling2D,\n    Conv2D,\n    MaxPool2D,\n    Dense,\n    Flatten,\n    InputLayer,\n    BatchNormalization,\n    Input,\n    Dropout,\n    RandomFlip,\n    RandomRotation,\n    RandomContrast,\n    RandomBrightness,\n    Resizing,\n    Rescaling\n)\nfrom tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy, SparseCategoricalAccuracy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam, SGD\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import L2, L1\nfrom tensorflow.keras.utils import image_dataset_from_directory\nfrom tensorflow.train import Feature, Features, Example, BytesList, Int64List\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"BATCH = 32\nSIZE = 224\nSEED = 42\n\nEPOCHS = 20\nLR = 0.001\nFILTERS = 6\nKERNEL = 3\nSTRIDES = 1\nREGRATE = 0.0\nPOOL = 2\nDORATE = 0.05\nLABELS = ['Gladiolus', 'Adenium', 'Alpinia_Purpurata', 'Alstroemeria', 'Amaryllis', 'Anthurium_Andraeanum', 'Antirrhinum', 'Aquilegia', 'Billbergia_Pyramidalis', 'Cattleya', 'Cirsium', 'Coccinia_Grandis', 'Crocus', 'Cyclamen', 'Dahlia', 'Datura_Metel', 'Dianthus_Barbatus', 'Digitalis', 'Echinacea_Purpurea', 'Echinops_Bannaticus', 'Fritillaria_Meleagris', 'Gaura', 'Gazania', 'Gerbera', 'Guzmania', 'Helianthus_Annuus', 'Iris_Pseudacorus', 'Leucanthemum', 'Malvaceae', 'Narcissus_Pseudonarcissus', 'Nerine', 'Nymphaea_Tetragona', 'Paphiopedilum', 'Passiflora', 'Pelargonium', 'Petunia', 'Platycodon_Grandiflorus', 'Plumeria', 'Poinsettia', 'Primula', 'Protea_Cynaroides', 'Rose', 'Rudbeckia', 'Strelitzia_Reginae', 'Tropaeolum_Majus', 'Tussilago', 'Viola', 'Zantedeschia_Aethiopica']\nNLABELS = len(LABELS)\nDENSE1 = 1024\nDENSE2 = 128\n")),(0,i.kt)("h2",{id:"dataset"},"Dataset"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"train_directory = '../dataset/Flower_Dataset/split/train'\ntest_directory = '../dataset/Flower_Dataset/split/val'\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"train_dataset = image_dataset_from_directory(\n    train_directory,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=LABELS,\n    color_mode='rgb',\n    batch_size=BATCH,\n    image_size=(SIZE, SIZE),\n    shuffle=True,\n    seed=SEED,\n    interpolation='bilinear',\n    follow_links=False,\n    crop_to_aspect_ratio=False\n)\n\n# Found 9206 files belonging to 48 classes.\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"test_dataset = image_dataset_from_directory(\n    test_directory,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=LABELS,\n    color_mode='rgb',\n    batch_size=BATCH,\n    image_size=(SIZE, SIZE),\n    shuffle=True,\n    seed=SEED\n)\n\n# Found 3090 files belonging to 48 classes.\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"data_augmentation = Sequential([\n        # Resizing(224, 224),\n        RandomRotation(factor=0.25),\n        RandomFlip(mode='horizontal'),\n        RandomContrast(factor=0.1),\n        RandomBrightness(0.1)\n    ],\n    name=\"img_augmentation\",\n)\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"training_dataset = (\n    train_dataset\n    .map(lambda image, label: (data_augmentation(image), label))\n    .prefetch(tf.data.AUTOTUNE)\n)\n\n\ntesting_dataset = (\n    test_dataset.prefetch(\n        tf.data.AUTOTUNE\n    )\n)\n")),(0,i.kt)("h2",{id:"building-the-inceptionv3-tf-model"},"Building the InceptionV3 TF Model"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},'# transfer learning\n\nbackbone = tf.keras.applications.InceptionV3(\n    input_shape=(SIZE, SIZE, 3),\n    include_top=False,\n    weights="imagenet"\n)\n')),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"backbone.trainable = False\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"input = Input(shape=(SIZE,SIZE,3))\nx = backbone(input, training=False)\n\nx = GlobalAveragePooling2D()(x)\nx = Dense(DENSE1, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dense(DENSE2, activation='relu')(x)\n\noutput = Dense(NLABELS, activation='softmax')(x)\n\ninception_model = Model(input, output)\ninception_model.summary()\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"checkpoint_callback = ModelCheckpoint(\n    '../best_weights',\n    monitor='val_accuracy',\n    mode='max',\n    verbose=1,\n    save_best_only=True\n)\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"early_stopping_callback = EarlyStopping(\n    monitor='val_accuracy',\n    patience=10,\n    restore_best_weights=True\n)\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"loss_function = CategoricalCrossentropy()\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"metrics = [CategoricalAccuracy(name='accuracy')]\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"inception_model.compile(\n    optimizer = Adam(learning_rate=LR),\n    loss = loss_function,\n    metrics = metrics\n)\n")),(0,i.kt)("h3",{id:"model-training"},"Model Training"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"inception_history = inception_model.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    verbose = 1,\n    # callbacks=[checkpoint_callback, early_stopping_callback]\n)\n\n# loss: 2.6270\n# accuracy: 0.2870\n# val_loss: 2.8781\n# val_accuracy: 0.2502\n")),(0,i.kt)("h3",{id:"model-evaluation"},"Model Evaluation"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"inception_model.evaluate(testing_dataset)\n# loss: 2.8781 - accuracy: 0.2502\n")),(0,i.kt)("h3",{id:"model-finetuning"},"Model Finetuning"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"for i, layer in enumerate(backbone.layers):\n   print(i, layer.name)\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# we chose to train the top 2 inception blocks, i.e. we will freeze\n# the first 249 layers and unfreeze the rest:\nfor layer in backbone.layers[:249]:\n   layer.trainable = False\nfor layer in backbone.layers[249:]:\n   layer.trainable = True\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"inception_model.compile(\n    optimizer=SGD(learning_rate=0.0001, momentum=0.9),\n    loss = loss_function,\n    metrics = metrics\n)\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"inception_history = inception_model.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    shuffle=True,\n    verbose = 1,\n    # callbacks=[checkpoint_callback, early_stopping_callback]\n)\n\n# loss: 2.4939\n# accuracy: 0.3194\n# val_loss: 2.7004\n# val_accuracy: 0.3100\n")),(0,i.kt)("h3",{id:"model-evaluation-1"},"Model Evaluation"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"inception_model.evaluate(testing_dataset)\n# loss: 2.7047 - accuracy: 0.3087\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(inception_history.history['loss'])\nplt.plot(inception_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss', 'val_loss'])\nplt.savefig('assets/InceptionV3_FT_01.webp', bbox_inches='tight')\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"tf Emotion Detection",src:t(56950).Z,width:"576",height:"455"})),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(inception_history.history['accuracy'])\nplt.plot(inception_history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train_accuracy', 'val_accuracy'])\nplt.savefig('assets/InceptionV3_FT_02.webp', bbox_inches='tight')\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"tf Emotion Detection",src:t(64611).Z,width:"584",height:"455"})),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"test_image_bgr = cv.imread('../dataset/snapshots/Viola_Tricolor.jpg')\ntest_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\ntest_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\nimg = tf.constant(test_image_rgb, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nprobs = inception_model(img).numpy()\nlabel = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n\nprint(label, str(probs[0]))\n\nplt.imshow(test_image_rgb)\nplt.title(label)\nplt.axis('off')\n        \nplt.savefig('assets/InceptionV3_Prediction_01.webp', bbox_inches='tight')\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"tf Emotion Detection",src:t(63224).Z,width:"389",height:"411"})),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"test_image_bgr = cv.imread('../dataset/snapshots/Strelitzia.jpg')\ntest_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\ntest_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\nimg = tf.constant(test_image_rgb, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nprobs = inception_model(img).numpy()\nlabel = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n\nprint(label, str(probs[0]))\n\nplt.imshow(test_image_rgb)\nplt.title(label)\nplt.axis('off')\n        \nplt.savefig('assets/InceptionV3_Prediction_02.webp', bbox_inches='tight')\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"tf Emotion Detection",src:t(57479).Z,width:"389",height:"411"})),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"test_image_bgr = cv.imread('../dataset/snapshots/Water_Lilly.jpg')\ntest_image_resized = cv.resize(test_image_bgr, (SIZE, SIZE))\ntest_image_rgb = cv.cvtColor(test_image_resized, cv.COLOR_BGR2RGB)\nimg = tf.constant(test_image_rgb, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nprobs = inception_model(img).numpy()\nlabel = LABELS[tf.argmax(probs, axis=1).numpy()[0]]\n\nprint(label, str(probs[0]))\n\nplt.imshow(test_image_rgb)\nplt.title(label)\nplt.axis('off')\n        \nplt.savefig('assets/InceptionV3_Prediction_03.webp', bbox_inches='tight')\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"tf Emotion Detection",src:t(76902).Z,width:"389",height:"411"})),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"plt.figure(figsize=(16,16))\n\nfor images, labels in testing_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n        pred = \"Predicted: \" + LABELS[\n            tf.argmax(inception_model(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n        ]\n        plt.title(\n           true  + \"\\n\" + pred\n        )\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/InceptionV3_FT_03.webp', bbox_inches='tight')\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"tf Emotion Detection",src:t(14925).Z,width:"1281",height:"1295"})),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"y_pred = []\ny_test = []\n\nfor img, label in testing_dataset:\n    y_pred.append(inception_model(img))\n    y_test.append(label.numpy())\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"conf_mtx = ConfusionMatrixDisplay(\n    confusion_matrix=confusion_matrix(\n        np.argmax(y_test[:-1], axis=-1).flatten(),\n        np.argmax(y_pred[:-1], axis=-1).flatten()\n    ),\n    display_labels=LABELS\n)\n\nfig, ax = plt.subplots(figsize=(16,12))\nconf_mtx.plot(ax=ax, cmap='plasma', include_values=True, xticks_rotation='vertical')\n\nplt.savefig('assets/InceptionV3_FT_04.webp', bbox_inches='tight')\n")),(0,i.kt)("p",null,(0,i.kt)("img",{alt:"tf Emotion Detection",src:t(82379).Z,width:"1296",height:"1160"})),(0,i.kt)("h3",{id:"saving-the-model"},"Saving the Model"),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"tf.keras.saving.save_model(\n    inception_model, 'saved_model/inception_model_model_ft', overwrite=True, save_format='tf'\n)\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# restore the model\nrestored_model2 = tf.keras.saving.load_model('saved_model/inception_model_model_ft')\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"# Check its architecture\nrestored_model2.summary()\n")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-python"},"restored_model2.evaluate(testing_dataset)\n# loss: 2.7047 - accuracy: 0.3087\n")))}m.isMDXComponent=!0},56950:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/InceptionV3_FT_01-453cbc1b1730b63b64f0d35fe0c7d6bb.webp"},64611:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/InceptionV3_FT_02-b2f8b00b9867e437c9344426c03505e2.webp"},14925:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/InceptionV3_FT_03-01be415085ace69506fa6420a151498d.webp"},82379:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/InceptionV3_FT_04-683824ef7291010195b78e09b785d88c.webp"},63224:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/InceptionV3_Prediction_01-55f51bba4706932addf74296189b10f5.webp"},57479:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/InceptionV3_Prediction_02-27f7f31dc410aabd3b056828d7eef7e1.webp"},76902:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/InceptionV3_Prediction_03-b3822b2df41cf5c12b352b10bef1b23b.webp"},68611:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-4b4c922f390788acb724c3c274da1ef9.jpg"}}]);