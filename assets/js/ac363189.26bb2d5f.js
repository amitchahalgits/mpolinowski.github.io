"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[36188],{359559:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>i,metadata:()=>o,toc:()=>d});var t=s(785893),r=s(603905);const i={sidebar_position:4820,slug:"2023-01-02",title:"Tensorflow Serving REST API",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Provide your prediction model through the Tensorflow Serving REST API"},a=void 0,o={id:"IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models/index",title:"Tensorflow Serving REST API",description:"Provide your prediction model through the Tensorflow Serving REST API",source:"@site/docs/IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models/index.md",sourceDirName:"IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models",slug:"/IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models/2023-01-02",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models/2023-01-02",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/AIOps/2023-01-02-tf-serve-own-models/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4820,frontMatter:{sidebar_position:4820,slug:"2023-01-02",title:"Tensorflow Serving REST API",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Provide your prediction model through the Tensorflow Serving REST API"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow Tensorboard",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-03-tf-tensorboard/2023-01-03"},next:{title:"Tensorflow Docker Model Server",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-01-tf-model-server/2023-01-01"}},l={},d=[{value:"Preparing the Model",id:"preparing-the-model",level:2},{value:"Preparing the Dataset",id:"preparing-the-dataset",level:3},{value:"Building the Tensorflow Model",id:"building-the-tensorflow-model",level:3},{value:"Training the Tensorflow Model",id:"training-the-tensorflow-model",level:3},{value:"Saving the Trained Model",id:"saving-the-trained-model",level:3},{value:"Inspecting the Saved Model",id:"inspecting-the-saved-model",level:4},{value:"Tensorflow Serving",id:"tensorflow-serving",level:2},{value:"Load Test Dataset",id:"load-test-dataset",level:3},{value:"Running Predictions",id:"running-predictions",level:3}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.ah)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Guangzhou, China",src:s(83067).Z+"",width:"1500",height:"662"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#preparing-the-model",children:"Preparing the Model"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#preparing-the-dataset",children:"Preparing the Dataset"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#building-the-tensorflow-model",children:"Building the Tensorflow Model"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#training-the-tensorflow-model",children:"Training the Tensorflow Model"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#saving-the-trained-model",children:"Saving the Trained Model"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#inspecting-the-saved-model",children:"Inspecting the Saved Model"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#tensorflow-serving",children:"Tensorflow Serving"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#load-test-dataset",children:"Load Test Dataset"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#running-predictions",children:"Running Predictions"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/mpolinowski/tf-serving",children:"Github Repository"})}),"\n",(0,t.jsxs)(n.p,{children:["In the ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-01-tf-model-server/2023-01-01",children:"previous step"})," I set up Tensorflow Model server using one of the official toy models that come with the ",(0,t.jsx)(n.a,{href:"https://github.com/tensorflow/serving",children:"repository"}),". Now we need to apply this to our own models."]}),"\n",(0,t.jsx)(n.h2,{id:"preparing-the-model",children:"Preparing the Model"}),"\n",(0,t.jsxs)(n.p,{children:["I am going to use the ",(0,t.jsx)(n.a,{href:"https://github.com/zalandoresearch/fashion-mnist",children:"mnist fashion dataset"})," to train a model. The dataset contains of 60,000 training and 10,000 testing sample 28x28 grayscale images associated with a label from 10 classes:"]}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"0"}),": T-Shirt / Top"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"1"}),": Trousers"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"2"}),": Pullover"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"3"}),": Dresses"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"4"}),": Coats"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"5"}),": Sandals"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"6"}),": Shirts"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"7"}),": Sneaker"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"8"}),": Bags"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"9"}),": Ankle Boot"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:"Each pixel 28x28 = 784 has a darkness value assigned ranging from 0-255 with higher number associated with darker areas in the source image."}),"\n",(0,t.jsxs)(n.p,{children:["The desired outcome of this test run will be to train a model to be able to recognize fashion items in images and provide a ",(0,t.jsx)(n.a,{href:"https://www.tensorflow.org/tfx/tutorials/serving/rest_simple",children:"Tensorflow REST API"})," that accepts input images and outputs predictions based on the trained model."]}),"\n",(0,t.jsx)(n.h3,{id:"preparing-the-dataset",children:"Preparing the Dataset"}),"\n",(0,t.jsx)(n.p,{children:"We can first download and pre-process the dataset:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"# prepare data\n## import Fashion MNIST Dataset using Keras \n(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n\n## data normalization -> Between 0 and 1 \nX_train = X_train / 255.0\nX_test = X_test / 255.0\n\n## reshape data to be = (no_of_images, 28, 28, 1) instead of (no_of_images, 28,28)\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n\n## define images classes\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n\n## inspect data\nW_grid = 4\nL_grid = 4\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (15, 15))\naxes = axes.ravel()\n\nn_training = len(X_train)\n\nfor i in np.arange(0, L_grid * W_grid):\n    index = np.random.randint(0, n_training)\n    axes[i].imshow(X_train[index].reshape(28,28))\n    axes[i].set_title(y_train[index])\n    axes[i].axis('off')\n    \nplt.subplots_adjust(hspace = 0.4)\nplt.show\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Tensorflow Serving REST API",src:s(693723).Z+"",width:"1113",height:"816"})}),"\n",(0,t.jsx)(n.h3,{id:"building-the-tensorflow-model",children:"Building the Tensorflow Model"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"# model building\nclassifier = tf.keras.Sequential([\n  tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape = (28,28,1)),\n  tf.keras.layers.MaxPooling2D(2,2),\n  tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(64, activation = 'relu'),\n  tf.keras.layers.Dense(10, activation = 'softmax')\n])\n\nclassifier.summary()\n\n## compile the model\nclassifier.compile(optimizer='adam', \n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n"})}),"\n",(0,t.jsx)(n.h3,{id:"training-the-tensorflow-model",children:"Training the Tensorflow Model"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"# model training\nEPOCHS = 5\nclassifier.fit(X_train, y_train, epochs=EPOCHS)\n\ntest_loss, test_acc = classifier.evaluate(X_test, y_test)\nprint('\\nINFO :: Test accuracy: {}'.format(test_acc))\n"})}),"\n",(0,t.jsxs)(n.p,{children:["After 5 Epochs I get ",(0,t.jsx)(n.code,{children:"INFO :: Test accuracy: 0.919700026512146"})," - so the model is already ~ 92% accurate."]}),"\n",(0,t.jsx)(n.h3,{id:"saving-the-trained-model",children:"Saving the Trained Model"}),"\n",(0,t.jsxs)(n.p,{children:["We now need to ",(0,t.jsx)(n.a,{href:"https://www.tensorflow.org/guide/saved_model",children:"save our trained model as SavedModel"})," - a format that combines a ",(0,t.jsx)(n.strong,{children:"GraphDef"})," with checkpoint files that store weights, all collected in a folder. ",(0,t.jsx)(n.code,{children:"tf.keras.models.save_model"})," is a function used to build a saved model that is suitable for serving using ",(0,t.jsx)(n.strong,{children:"Tensorflow Serving"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"# save the model\n## join the temp model directory with chosen version number\nexport_path = os.path.join(MODEL_DIR, str(MODEL_VERSION))\n\n## save the model using `save_model`\ntf.keras.models.save_model(\n    classifier,\n    export_path,\n    overwrite=True,\n    include_optimizer=True,\n    save_format=None,\n    signatures=None,\n    options=None\n)\n\nprint('\\nINFO :: Trained Model Saved!')\n"})}),"\n",(0,t.jsx)(n.h4,{id:"inspecting-the-saved-model",children:"Inspecting the Saved Model"}),"\n",(0,t.jsxs)(n.p,{children:["We'll use the command line utility ",(0,t.jsx)(n.code,{children:"saved_model_cli"})," to look at the models and SignatureDefs (the methods you can call) in our ",(0,t.jsx)(n.strong,{children:"SavedModel"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"saved_model_cli show --dir models/1 --all \n\n\n...\n\nsignature_def['serving_default']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['conv2d_input'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 28, 28, 1)\n        name: serving_default_conv2d_input:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['dense_1'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 10)\n        name: StatefulPartitionedCall:0\n  Method name is: tensorflow/serving/predict\n\n\n  ...\n"})}),"\n",(0,t.jsx)(n.p,{children:"This allows us to verify the inputs and outputs of the saved model - for example, here we can see that the model takes in images with 28x28 pixel and outputs one of 10 classes as a prediction."}),"\n",(0,t.jsx)(n.h2,{id:"tensorflow-serving",children:"Tensorflow Serving"}),"\n",(0,t.jsxs)(n.p,{children:["Now we can use the ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/AIOps/2023-01-01-tf-model-server/2023-01-01",children:"Tensorflow Serving Docker Container"})," to server our trained model:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"docker run --gpus all -p 8501:8501 \\\n--mount type=bind,source=$(pwd)/models,target=/models/mnist_fashion \\\n-e MODEL_NAME=mnist_fashion -t tensorflow/serving:latest-gpu\n"})}),"\n",(0,t.jsx)(n.h3,{id:"load-test-dataset",children:"Load Test Dataset"}),"\n",(0,t.jsxs)(n.p,{children:["We can now use the ",(0,t.jsx)(n.strong,{children:"Tensorflow Serving"})," REST API to send images, have them analyzed and return predictions. To get started we first need to load the dataset from Keras and select a random image from the Test Set:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"# prepare data\n## import Fashion MNIST Dataset using Keras \n(X_train, y_train), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n\n## data normalization -> Between 0 and 1 \nX_train = X_train / 255.0\nX_test = X_test / 255.0\n\n## reshape data to be = (no_of_images, 28, 28, 1) instead of (no_of_images, 28,28)\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n\n## define images classes\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n\n## display an test image selected below\ndef show(idx, title):\n  plt.figure()\n  plt.imshow(X_test[idx].reshape(28,28))\n  plt.title('\\n\\n{}'.format(title), fontdict={'size': 16})\n  plt.show()\n\n## select a random test image and get it's class label\nrandom = np.random.randint(0, len(X_test)-1)\nshow(random, 'Test Image Class: {}'.format(class_names[y_test[random]]))\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Tensorflow Serving REST API",src:s(232209).Z+"",width:"640",height:"480"})}),"\n",(0,t.jsx)(n.h3,{id:"running-predictions",children:"Running Predictions"}),"\n",(0,t.jsx)(n.p,{children:"Now that we are able to load images from the Test Dataset we can send them to our Tensorflow REST API to get our predictions. Let's say we have an IP camera that detected something suspicious and uploaded 3 snapshots:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:'# running predictions\n## prepare a list of 3 images to be send to the REST API\ndata = json.dumps({"signature_name": "serving_default", "instances": X_test[0:3].tolist()})\n'})}),"\n",(0,t.jsx)(n.p,{children:'We now want to take those images and get prediction on them - like "Was the burglar wearing trousers?":'}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"## send request\nheaders = {\"content-type\": \"application/json\"}\njson_response = requests.post('http://localhost:8501/v1/models/mnist_fashion:predict', data=data, headers=headers)\npredictions = json.loads(json_response.text)['predictions']\n"})}),"\n",(0,t.jsxs)(n.p,{children:["This is using the Python ",(0,t.jsx)(n.code,{children:"requests"})," library to send the images to ",(0,t.jsx)(n.strong,{children:"Tensorflow Serving"}),". Once we receive the response for our request we can display the results. For a single result we can use:"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"## display single result\nshow(0, 'Prediction: {} (class {}) / True: {} (class {})'.format(\n  class_names[np.argmax(predictions[0])], y_test[0], class_names[np.argmax(predictions[0])], y_test[0]))\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Here we are only taking the first prediction (index 0) (for the first of the 3 images we send) and since we use a ",(0,t.jsx)(n.code,{children:"softmax"})," output (the prediction is not binary but a list of probabilities) we can use ",(0,t.jsx)(n.code,{children:"argmax"})," to select the class with the highest probability:"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Tensorflow Serving REST API",src:s(219851).Z+"",width:"688",height:"480"})}),"\n",(0,t.jsx)(n.p,{children:"To return all 3 results for the 3 random images we send we can use a simple loop:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"for i in range(0,3):\n  show(i, 'Prediction: {} (class {}) / True: {} (class {})'.format(\n    class_names[np.argmax(predictions[i])], y_test[i], class_names[np.argmax(predictions[i])], y_test[i]))\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Tensorflow Serving REST API",src:s(179624).Z+"",width:"1962",height:"478"})})]})}function h(e={}){const{wrapper:n}={...(0,r.ah)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(c,{...e})}):c(e)}},603905:(e,n,s)=>{s.d(n,{ah:()=>d});var t=s(667294);function r(e,n,s){return n in e?Object.defineProperty(e,n,{value:s,enumerable:!0,configurable:!0,writable:!0}):e[n]=s,e}function i(e,n){var s=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),s.push.apply(s,t)}return s}function a(e){for(var n=1;n<arguments.length;n++){var s=null!=arguments[n]?arguments[n]:{};n%2?i(Object(s),!0).forEach((function(n){r(e,n,s[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(s)):i(Object(s)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(s,n))}))}return e}function o(e,n){if(null==e)return{};var s,t,r=function(e,n){if(null==e)return{};var s,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)s=i[t],n.indexOf(s)>=0||(r[s]=e[s]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)s=i[t],n.indexOf(s)>=0||Object.prototype.propertyIsEnumerable.call(e,s)&&(r[s]=e[s])}return r}var l=t.createContext({}),d=function(e){var n=t.useContext(l),s=n;return e&&(s="function"==typeof e?e(n):a(a({},n),e)),s},c={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},h=t.forwardRef((function(e,n){var s=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,h=o(e,["components","mdxType","originalType","parentName"]),p=d(s),g=r,f=p["".concat(l,".").concat(g)]||p[g]||c[g]||i;return s?t.createElement(f,a(a({ref:n},h),{},{components:s})):t.createElement(f,a({ref:n},h))}));h.displayName="MDXCreateElement"},693723:(e,n,s)=>{s.d(n,{Z:()=>t});const t=s.p+"assets/images/Tensorflow_Transfer_Learning_01-a2f391d61f664fc368a4329d682defc7.png"},232209:(e,n,s)=>{s.d(n,{Z:()=>t});const t=s.p+"assets/images/Tensorflow_Transfer_Learning_02-e70be95cbc80fbfa21c070ee91c87f80.png"},219851:(e,n,s)=>{s.d(n,{Z:()=>t});const t=s.p+"assets/images/Tensorflow_Transfer_Learning_03-70a2b984892ea79163e3a7b3abe4b921.png"},179624:(e,n,s)=>{s.d(n,{Z:()=>t});const t=s.p+"assets/images/Tensorflow_Transfer_Learning_04-02b0d3286144ea5268fedb95211c8e75.png"},83067:(e,n,s)=>{s.d(n,{Z:()=>t});const t=s.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-296769d73822f07b0ac5dc952f56bfa1.jpg"}}]);