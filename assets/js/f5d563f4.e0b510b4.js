"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[43180],{467579:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>i,metadata:()=>s,toc:()=>d});var a=t(785893),r=t(603905);const i={sidebar_position:5070,slug:"2022-02-20",title:"Yolo App - YOLOv5 Data Preparation",authors:"mpolinowski",tags:["Tensorflow","Machine Learning","Python","YOLO"]},o=void 0,s={id:"IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/index",title:"Yolo App - YOLOv5 Data Preparation",description:"Shenzhen, China",source:"@site/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep",slug:"/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/index.md",tags:[{label:"Tensorflow",permalink:"/docs/tags/tensorflow"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"YOLO",permalink:"/docs/tags/yolo"}],version:"current",sidebarPosition:5070,frontMatter:{sidebar_position:5070,slug:"2022-02-20",title:"Yolo App - YOLOv5 Data Preparation",authors:"mpolinowski",tags:["Tensorflow","Machine Learning","Python","YOLO"]},sidebar:"tutorialSidebar",previous:{title:"Deep Audio",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-04-01-tensorflow-audio-classifier/2022-04-01"},next:{title:"Yolo App - Flask Web Application",permalink:"/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19"}},l={},d=[{value:"Data Preparation",id:"data-preparation",level:2},{value:"Load Labels",id:"load-labels",level:3},{value:"Parse XML Data",id:"parse-xml-data",level:3},{value:"Calculate Bounding Box",id:"calculate-bounding-box",level:3},{value:"Split Testing and Training Data",id:"split-testing-and-training-data",level:2}];function c(e){const n={a:"a",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,r.ah)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Shenzhen, China",src:t(347973).Z+"",width:"1500",height:"688"})}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-15--yolo-app-get-data/2022-02-15",children:"Prepare your Images and get Data"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-16--yolo-app-tensorflow-model/2022-02-16",children:"Train your Tensorflow Model"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-17--yolo-app-prediction-pipeline/2022-02-17",children:"Use your Model to do Predictions"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-18--yolo-app-ocr/2022-02-18",children:"Use Tesseract to Read Number Plates"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-19--yolo-app-flask/2022-02-19",children:"Flask Web Application"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2022-02-20--yolo-app-yolov5-data-prep/2022-02-20",children:"Yolo v5 - Data Prep"})}),"\n"]}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"#data-preparation",children:"Data Preparation"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#load-labels",children:"Load Labels"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#parse-xml-data",children:"Parse XML Data"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#calculate-bounding-box",children:"Calculate Bounding Box"})}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#split-testing-and-training-data",children:"Split Testing and Training Data"})}),"\n"]}),"\n",(0,a.jsx)(n.p,{children:"I now have a clean dataset, a working model and a web application for testing. But the detection process is relatively slow and not suitable for real-time video detection. This is where YOLOv5 comes in."}),"\n",(0,a.jsx)(n.h2,{id:"data-preparation",children:"Data Preparation"}),"\n",(0,a.jsxs)(n.p,{children:["There is only one problem with the data that was used to train the Tensorflow model. There I needed to define the bounding box around detect license plates byt the variables ",(0,a.jsx)(n.code,{children:"xmin"}),", ",(0,a.jsx)(n.code,{children:"xmax"}),", ",(0,a.jsx)(n.code,{children:"ymin"}),", ",(0,a.jsx)(n.code,{children:"ymax"}),". But YOLO expects an X & Y value for the center point of the region of interest and it's height & width."]}),"\n",(0,a.jsx)(n.h3,{id:"load-labels",children:"Load Labels"}),"\n",(0,a.jsx)(n.p,{children:"Let's start by importing the labels files for our images:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"import numpy as np\r\nimport pandas as pd\r\nfrom glob import glob\r\nimport xml.etree.ElementTree as xet\r\nimport cv2\r\nimport os\r\nimport shutil import copy\r\n\r\nimportdf = pd.read_csv('../labels.csv')\r\ndf.head()\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"    filepath \t                xmin \txmax \tymin \tymax\r\n0 \t../resources/cars_170.xml \t224 \t439 \t77 \t  167\r\n1 \t../resources/cars_171.xml \t416 \t620 \t536 \t600\r\n2 \t../resources/cars_172.xml \t184 \t325 \t114 \t148\r\n3 \t../resources/cars_173.xml \t154 \t373 \t91 \t  149\r\n4 \t../resources/cars_174.xml \t131 \t279 \t213 \t256\n"})}),"\n",(0,a.jsx)(n.h3,{id:"parse-xml-data",children:"Parse XML Data"}),"\n",(0,a.jsxs)(n.p,{children:["I now need to convert these bbox values to ",(0,a.jsx)(n.code,{children:"center_x"}),", ",(0,a.jsx)(n.code,{children:"center_y"}),", ",(0,a.jsx)(n.code,{children:"width"})," and ",(0,a.jsx)(n.code,{children:"height"})," and normalize them to their image size. I can start by extracting the image width and height from the generated XML label:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"<annotation>\r\n\t<folder>resources</folder>\r\n\t<filename>cars_1.jpg</filename>\r\n\t<path>/opt/yolo-app/resources/cars_1.jpg</path>\r\n\t<source>\r\n\t\t<database>Unknown</database>\r\n\t</source>\r\n\t<size>\r\n\t\t<width>1600</width>\r\n\t\t<height>1153</height>\r\n\t\t<depth>3</depth>\r\n\t</size>\r\n\t<segmented>0</segmented>\r\n\t<object>\r\n\t\t<name>number_plate</name>\r\n\t\t<pose>Unspecified</pose>\r\n\t\t<truncated>0</truncated>\r\n\t\t<difficult>0</difficult>\r\n\t\t<bndbox>\r\n\t\t\t<xmin>1085</xmin>\r\n\t\t\t<ymin>561</ymin>\r\n\t\t\t<xmax>1354</xmax>\r\n\t\t\t<ymax>683</ymax>\r\n\t\t</bndbox>\r\n\t</object>\r\n</annotation>\n"})}),"\n",(0,a.jsx)(n.p,{children:"The function to parse the image label is:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"# Parsing XML labels\r\ndef xmlparsing(path):\r\n    parser = xet.parse(path).getroot()\r\n    image_path = '../' + parser.find('folder').text + '/' + parser.find('filename').text\r\n    image_size = parser.find('size')\r\n    width = int(image_size.find('width').text)\r\n    height = int(image_size.find('height').text)\r\n    \r\n    return image_path, width, height\n"})}),"\n",(0,a.jsx)(n.p,{children:"Now I can append the image width and height to my Pandas dataframe with:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"# Take filepath from df and function to append\r\n# image_path, width and height from XML label\r\ndf[['image_path','width','height']] = df['filepath'].apply(xmlparsing).apply(pd.Series)\r\ndf.head()\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"    filepath \t                  xmin \txmax \tymin \tymax \timage_path \t                width height\r\n0 \t../resources/cars_170.xml \t224 \t439 \t77 \t  167 \t../resources/cars_170.jpeg \t500 \t234\r\n1 \t../resources/cars_171.xml \t416 \t620 \t536 \t600 \t../resources/cars_171.jpeg \t1070 \t907\r\n2 \t../resources/cars_172.xml \t184 \t325 \t114 \t148 \t../resources/cars_172.jpeg \t500 \t333\r\n3 \t../resources/cars_173.xml \t154 \t373 \t91 \t  149 \t../resources/cars_173.jpeg \t500 \t250\r\n4 \t../resources/cars_174.xml \t131 \t279 \t213 \t256 \t../resources/cars_174.jpeg \t414 \t432\n"})}),"\n",(0,a.jsx)(n.h3,{id:"calculate-bounding-box",children:"Calculate Bounding Box"}),"\n",(0,a.jsx)(n.p,{children:"And now to getting the variables that are needed by Yolo:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"# Calculate center_x, center_y, width and height of bounding box\r\n# and normalize them to image size\r\ndf['center_x'] = (df['xmax'] + df['xmin'])/(2*df['width'])\r\ndf['center_y'] = (df['ymax'] + df['ymin'])/(2*df['height'])\r\n\r\ndf['bb_width'] = (df['xmax'] - df['xmin'])/df['width']\r\ndf['bb_height'] = (df['ymax'] - df['ymin'])/df['height']\r\n\r\ndf.head()\n"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:" \tfilepath         image_path \t      width height \tcenter_x \tcenter_y \tbb_width \tbb_height\r\n0 .../cars_170.xml .../cars_170.jpeg \t500 \t234 \t  0.663000 \t0.521368 \t0.430000 \t0.384615\r\n1 .../cars_171.xml .../cars_171.jpeg \t1070 \t907 \t  0.484112 \t0.626240 \t0.190654 \t0.070562\r\n2 .../cars_172.xml .../cars_172.jpeg \t500 \t333 \t  0.509000 \t0.393393 \t0.282000 \t0.102102\r\n3 .../cars_173.xml .../cars_173.jpeg \t500 \t250 \t  0.527000 \t0.480000 \t0.438000 \t0.232000\r\n4 .../cars_174.xml .../cars_174.jpeg \t414 \t432 \t  0.495169 \t0.542824 \t0.357488 \t0.099537\n"})}),"\n",(0,a.jsx)(n.h2,{id:"split-testing-and-training-data",children:"Split Testing and Training Data"}),"\n",(0,a.jsx)(n.p,{children:"Divide image into files used for training and for testing:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"# Take first 220 images for training\r\ndf_train = df.iloc[:220]\r\n# Take remaining images for testing\r\ndf_test = df.iloc[220:]\n"})}),"\n",(0,a.jsx)(n.p,{children:"Create labels for training images and copy everything into the trainings folder:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"# Training Data\r\ntrain_folder = '../data/train'\r\n\r\ntrain_values = df_train[['image_path', 'center_x', 'center_y', 'bb_width', 'bb_height']].values\r\n\r\n# Create label and copy images to folder\r\nfor fname, x, y, w, h in train_values:\r\n    # Get filename from filepath\r\n    image_name = os.path.split(fname)[-1]\r\n    # Remove file extension\r\n    label_name = os.path.splitext(image_name)[0]\r\n    \r\n    # Copy training images to train folder\r\n    dst_image_path = os.path.join(train_folder, image_name)\r\n    copy(fname,dst_image_path)\r\n    \r\n    # Create image label file\r\n    label_values = f'0 {x} {y} {w} {h}' \r\n    label_path = os.path.join(train_folder, label_name + '.txt')\r\n    with open(label_path , mode='w') as f:\r\n        f.write(label_values)\r\n        f.close()\n"})}),"\n",(0,a.jsx)(n.p,{children:"And repeat this step for the testing images:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-py",children:"# Testing Data\r\ntest_folder = '../data/test'\r\n\r\ntest_values = df_test[['image_path', 'center_x', 'center_y', 'bb_width', 'bb_height']].values\r\n\r\n# Create label and copy images to folder\r\nfor fname, x, y, w, h in test_values:\r\n    # Get filename from filepath\r\n    image_name = os.path.split(fname)[-1]\r\n    # Remove file extension\r\n    label_name = os.path.splitext(image_name)[0]\r\n    \r\n    # Copy training images to train folder\r\n    dst_image_path = os.path.join(test_folder, image_name)\r\n    copy(fname,dst_image_path)\r\n    \r\n    # Create image label file\r\n    label_values = f'0 {x} {y} {w} {h}' \r\n    label_path = os.path.join(test_folder, label_name + '.txt')\r\n    with open(label_path , mode='w') as f:\r\n        f.write(label_values)\r\n        f.close()\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Plate Detection Flask App",src:t(942153).Z+"",width:"1484",height:"624"})})]})}function h(e={}){const{wrapper:n}={...(0,r.ah)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(c,{...e})}):c(e)}},603905:(e,n,t)=>{t.d(n,{ah:()=>d});var a=t(667294);function r(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function i(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);n&&(a=a.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,a)}return t}function o(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?i(Object(t),!0).forEach((function(n){r(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):i(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function s(e,n){if(null==e)return{};var t,a,r=function(e,n){if(null==e)return{};var t,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||(r[t]=e[t]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)t=i[a],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(r[t]=e[t])}return r}var l=a.createContext({}),d=function(e){var n=a.useContext(l),t=n;return e&&(t="function"==typeof e?e(n):o(o({},n),e)),t},c={inlineCode:"code",wrapper:function(e){var n=e.children;return a.createElement(a.Fragment,{},n)}},h=a.forwardRef((function(e,n){var t=e.components,r=e.mdxType,i=e.originalType,l=e.parentName,h=s(e,["components","mdxType","originalType","parentName"]),p=d(t),m=r,g=p["".concat(l,".").concat(m)]||p[m]||c[m]||i;return t?a.createElement(g,o(o({ref:n},h),{},{components:t})):a.createElement(g,o({ref:n},h))}));h.displayName="MDXCreateElement"},942153:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/Plate_Detection_Yolo_App_01-ae7889bb85c928d4ac36b540938e1a82.png"},347973:(e,n,t)=>{t.d(n,{Z:()=>a});const a=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-ffe80356d19fb4b090a3bef79b45aab3.jpg"}}]);