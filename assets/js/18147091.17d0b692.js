"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[44639],{884208:(n,e,o)=>{o.r(e),o.d(e,{assets:()=>l,contentTitle:()=>a,default:()=>u,frontMatter:()=>r,metadata:()=>p,toc:()=>d});var t=o(785893),i=o(603905);const r={sidebar_position:4330,slug:"2023-07-25",title:"Working with ONNX Models",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Open Neural Network Exchange (ONNX)"},a="Open Neural Network Exchange (ONNX)",p={id:"IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/index",title:"Working with ONNX Models",description:"Open Neural Network Exchange (ONNX)",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-07-25-onnx-models",slug:"/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/2023-07-25",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/2023-07-25",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4330,frontMatter:{sidebar_position:4330,slug:"2023-07-25",title:"Working with ONNX Models",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Open Neural Network Exchange (ONNX)"},sidebar:"tutorialSidebar",previous:{title:"Human Emotion Detection with Tensorflow",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/2023-07-26"},next:{title:"Introduction to Caffe2",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-07-21-introduction-to-pytorch-caffe2/2023-07-21"}},l={},d=[{value:"Netron",id:"netron",level:2},{value:"Loading an ONNX Model",id:"loading-an-onnx-model",level:2},{value:"Tensorflow to ONNX",id:"tensorflow-to-onnx",level:2},{value:"Tensorflow Lite to ONNX",id:"tensorflow-lite-to-onnx",level:2},{value:"ONNX to Tensorflow",id:"onnx-to-tensorflow",level:2},{value:"Generate ONNX Prototext",id:"generate-onnx-prototext",level:2},{value:"ONNX to NovaONNX",id:"onnx-to-novaonnx",level:2},{value:"Support Functions",id:"support-functions",level:3}];function s(n){const e={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.ah)(),...n.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:"Guangzhou, China",src:o(441770).Z+"",width:"1500",height:"581"})}),"\n",(0,t.jsx)(e.h1,{id:"open-neural-network-exchange-onnx",children:"Open Neural Network Exchange (ONNX)"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.a,{href:"#open-neural-network-exchange-onnx",children:"Open Neural Network Exchange (ONNX)"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"#netron",children:"Netron"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"#loading-an-onnx-model",children:"Loading an ONNX Model"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"#tensorflow-to-onnx",children:"Tensorflow to ONNX"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"#tensorflow-lite-to-onnx",children:"Tensorflow Lite to ONNX"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"#onnx-to-tensorflow",children:"ONNX to Tensorflow"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"#generate-onnx-prototext",children:"Generate ONNX Prototext"})}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.a,{href:"#onnx-to-novaonnx",children:"ONNX to NovaONNX"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.a,{href:"#support-functions",children:"Support Functions"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.a,{href:"https://github.com/mpolinowski/tf2onnx",children:"Github Repository"})}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.a,{href:"https://onnx.ai/",children:"ONNX"})," is an open format built to represent machine learning models. ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers."]}),"\n",(0,t.jsx)(e.h2,{id:"netron",children:"Netron"}),"\n",(0,t.jsxs)(e.p,{children:["Inspect your ONNX model using Netron. ",(0,t.jsx)(e.a,{href:"https://github.com/lutzroeder/netron",children:"Netron is a viewer for neural networks, deep learning and machine learning models"}),". Netron supports ONNX, TensorFlow Lite, Core ML, Keras, Caffe, Darknet, MXNet, PaddlePaddle, ncnn, MNN and TensorFlow.js. Netron has experimental support for PyTorch, TorchScript, TensorFlow, OpenVINO, RKNN, MediaPipe, ML.NET and scikit-learn."]}),"\n",(0,t.jsxs)(e.p,{children:[(0,t.jsx)(e.a,{href:"https://github.com/lutzroeder/netron#install",children:"Installation on Linux"})," using the latest ",(0,t.jsx)(e.em,{children:"AppImage"}),":"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"wget https://github.com/lutzroeder/netron/releases/download/v7.0.8/Netron-7.0.8.AppImage\nchmod 777 Netron-7.0.8.AppImage\n./Netron-7.0.8.AppImage\n"})}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{alt:"Open Neural Network Exchange (ONNX)",src:o(614102).Z+"",width:"1747",height:"975"})}),"\n",(0,t.jsx)(e.h2,{id:"loading-an-onnx-model",children:"Loading an ONNX Model"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import tensorflow as tf\nimport tf2onnx\n\nimport onnx\nfrom onnx import shape_inference, TensorProto\nfrom onnx import version_converter\nfrom onnx import numpy_helper\nimport onnx.helper as helper\n\nfrom onnxsim import simplify\n\nfrom onnx_tf.backend import prepare\n\nimport json\nimport numpy as np\nimport sys\n"})}),"\n",(0,t.jsx)(e.h2,{id:"tensorflow-to-onnx",children:"Tensorflow to ONNX"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"tf_model = tf.keras.saving.load_model('mobilenet_model')\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"tf_model.summary()\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"input_signature = [tf.TensorSpec([1, 224, 224, 3], tf.float32, name='x')]\n# Use from_function for tf functions\nonnx_model, _ = tf2onnx.convert.from_keras(tf_model, input_signature, opset=12)\nonnx.save(onnx_model, \"mobilenet_model.onnx\")\n"})}),"\n",(0,t.jsx)(e.p,{children:(0,t.jsx)(e.code,{children:"AttributeError: 'FuncGraph' object has no attribute '_captures'"})}),"\n",(0,t.jsxs)(e.blockquote,{children:["\n",(0,t.jsxs)(e.p,{children:["BUG Tensorflow 2.13 / Python 3.11: ",(0,t.jsx)(e.a,{href:"https://github.com/onnx/tensorflow-onnx/issues/2172",children:"GITHUB ISSUE1"}),", ",(0,t.jsx)(e.a,{href:"https://github.com/onnx/tensorflow-onnx/issues/2180",children:"GITHUB ISSUE1"})," AttributeError: 'FuncGraph' object has no attribute '_captures'. Did you mean: 'captures'?"]}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Replace the following in:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.code,{children:"~/.local/lib/python3.11/site-packages/tf2onnx/tf_loader.py"})}),"\n",(0,t.jsx)(e.li,{children:(0,t.jsx)(e.code,{children:"~/.local/lib/python3.11/site-packages/tf2onnx/convert.py"})}),"\n"]}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'    #graph_captures = concrete_func.graph._captures  # pylint: disable=protected-access\n    #captured_inputs = [t_name.name for t_val, t_name in graph_captures.values()]\n\n    if hasattr(concrete_func.graph, "captures"):\n        graph_captures = concrete_func.graph.captures\n        captured_inputs = [t_name.name for t_val, t_name in graph_captures]\n    else:\n        graph_captures = concrete_func.graph._captures\n        captured_inputs = [t_name.name for t_val, t_name in graph_captures.values()]\n'})}),"\n",(0,t.jsx)(e.h2,{id:"tensorflow-lite-to-onnx",children:"Tensorflow Lite to ONNX"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"tf2onnx.convert.from_tflite(\n    tflite_path='mobilenet_model.tflite',\n    output_path='mobilenet_model_tflite.onnx',\n    opset=12\n)\n"})}),"\n",(0,t.jsx)(e.h2,{id:"onnx-to-tensorflow",children:"ONNX to Tensorflow"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# from tf model\nonnx_model = onnx.load("mobilenet_model.onnx")\nonnx.checker.check_model(onnx_model)\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"tf_prep = prepare(onnx_model)\ntf_prep.export_graph('deploy_model')\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'# from tf lite model\nonnx_lite_model = onnx.load("mobilenet_model_tflite.onnx")\nonnx.checker.check_model(onnx_lite_model)\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"tf_prep = prepare(onnx_lite_model)\ntf_prep.export_graph('deploy_lite_model')\n\n#  ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.\n"})}),"\n",(0,t.jsx)(e.h2,{id:"generate-onnx-prototext",children:"Generate ONNX Prototext"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def dump_normal(elem, indent, file) :\n    for s in str(elem).splitlines() :\n        print(indent + s, file=file)\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def dump_initializer(elem, indent, file) : \n    # calculate size.\n    size = 1\n    for d in elem.dims :\n        size *= d\n\n    # in the case of enough small size, output all data.\n    if (size <= 32) :\n        dump_normal(elem, indent, file)\n        return\n\n    # output metadata only, in all other cases.\n    for d in elem.dims :\n        print(indent + "  dims: " + json.dumps(d), file=file)\n        print(indent + "  data_type: " + json.dumps(elem.data_type), file=file)\n        print(indent + "  name: " + json.dumps(elem.name), file=file)\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def onnx2prototxt(onnx_path) :\n\n    # show information\n    out_path = onnx_path + ".prototxt"\n    print("+ creating " + out_path)\n    print("    from " + onnx_path + " ...")\n\n    # load model\n    model = onnx.load(onnx_path)\n\n    # print prototxt\n    with open(out_path, "w") as f :\n        print("ir_version: " + json.dumps(model.ir_version), file=f)\n        print("producer_name: " + json.dumps(model.producer_name), file=f)\n        print("producer_version: " + json.dumps(model.producer_version), file=f)\n        # print("domain: " + json.dumps(model.domain), file=f)\n        print("model_version: " + json.dumps(model.model_version), file=f)\n        # print("doc_string: " + json.dumps(model.doc_string), file=f)\n        print("graph {", file=f)\n        print("  name: " + json.dumps(model.graph.name), file=f)\n\n        for e in model.graph.node :\n            print("  node {", file=f)\n            dump_normal(e, "    ",  f)\n            print("  }", file=f)\n\n        for e in model.graph.initializer :\n            print("  initializer {", file=f)\n            dump_initializer(e, "    ",  f)\n            print("  }", file=f)\n\n        for e in model.graph.input :\n            print("  input {", file=f)\n            dump_normal(e, "    ",  f)\n            print("  }", file=f)\n\n        for e in model.graph.output :\n            print("  output {", file=f)\n            dump_normal(e, "    ",  f)\n            print("  }", file=f)\n\n        print("}", file=f)\n\n        for e in model.opset_import :\n            print("opset_import {", file=f)\n            print("  version: " + json.dumps(e.version), file=f)\n            print("}", file=f)\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def show_usage(script) :\n    print("usage: python " + script + " input.onnx [more.onnx ..]")\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'onnx_path ="mobilenet_model.onnx"\n\nonnx2prototxt(onnx_path)\n'})}),"\n",(0,t.jsx)(e.h2,{id:"onnx-to-novaonnx",children:"ONNX to NovaONNX"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"INPUT = 'mobilenet_model.onnx'\nOUTPUT = 'deploy.onnx'\nSKIP_FUSE_BN = True\nSKIP_ONNX_SIM = False\nSKIP_MODIFY_IDX = False\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"onnx_model = onnx.load(INPUT)\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"# Each dimension of input shape must greater than zero\nonnx_model.graph.input\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"for input in onnx_model.graph.input:\n        print(input.type.tensor_type.shape.dim)\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"# Opset version 8 ~ 12 supported\nonnx_model.opset_import[0].version\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"### Supported Layer Types\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"SUPPORTED_OP_TYPE_LIST = [\n'Abs',\n'Add',\n'AveragePool',\n'BatchNormalization',\n'Clip',\n'Conv',\n'ConvTranspose',\n'Concat',\n'Flatten',\n'Gemm',\n'GlobalAveragePool',\n'GlobalMaxPool',\n'LeakyRelu',\n'LSTM',\n'MatMul',\n'Max',\n'MaxPool',\n'MaxRoiPool',\n'Mul',\n'Pad',\n'PRelu',\n'ReduceMean',\n'Relu',\n'Resize',\n'Sigmoid',\n'Softmax',\n'Sub',\n'Tanh',\n'Transpose',\n'Upsample',\n'Reshape',\n'Slice',\n'Split',\n'Neg',\n'Sub',\n'Tanh',\n'Sqrt',\n'Exp',\n'Div',\n'Log',\n'Pow',\n'Sin',\n'Floor',\n'Round',\n'Squeeze',\n'UnSqueeze'\n]\n"})}),"\n",(0,t.jsx)(e.h3,{id:"support-functions",children:"Support Functions"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def onnx_attribute_to_dict(onnx_attr):\n    #print(onnx_attr)\n    if onnx_attr.HasField('name'):\n        name = getattr(onnx_attr, 'name')\n        #print(name)\n\n    if onnx_attr.HasField('t'):\n        return name, numpy_helper.to_array(getattr(onnx_attr, 't'))\n\n    for attr_type in ['f', 'i', 's']:\n        if onnx_attr.HasField(attr_type):\n            return name, getattr(onnx_attr, attr_type)\n\n    for attr_type in ['floats', 'ints', 'strings']:\n        if getattr(onnx_attr, attr_type):\n            return name, list(getattr(onnx_attr, attr_type))\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def add_input_from_initializer(model : onnx.ModelProto):\n    """\n    Currently onnx.shape_inference doesn\'t use the shape of initializers, so add\n    that info explicitly as ValueInfoProtos.\n    Mutates the model.\n    Args:\n        model: The ModelProto to update.\n    """\n    # All (top-level) constants will have ValueInfos before IRv4 as they are all inputs\n    if model.ir_version < 4:\n        return\n\n    def add_const_value_infos_to_graph(graph : onnx.GraphProto):\n        inputs = {i.name for i in graph.input}\n        existing_info = {vi.name: vi for vi in graph.input}\n        for init in graph.initializer:\n            # Check it really is a constant, not an input\n            if init.name in inputs:\n                continue\n\n            # The details we want to add\n            elem_type = init.data_type\n            shape = init.dims\n\n            # Get existing or create new value info for this constant\n            vi = existing_info.get(init.name)\n            if vi is None:\n                vi = graph.input.add()\n                vi.name = init.name\n\n            # Even though it would be weird, we will not overwrite info even if it doesn\'t match\n            tt = vi.type.tensor_type\n            if tt.elem_type == onnx.TensorProto.UNDEFINED:\n                tt.elem_type = elem_type\n            if not tt.HasField("shape"):\n                # Ensure we set an empty list if the const is scalar (zero dims)\n                tt.shape.dim.extend([])\n                for dim in shape:\n                    tt.shape.dim.add().dim_value = dim\n\n        # Handle subgraphs\n        for node in graph.node:\n            for attr in node.attribute:\n                # Ref attrs refer to other attrs, so we don\'t need to do anything\n                if attr.ref_attr_name != "":\n                    continue\n\n                if attr.type == onnx.AttributeProto.GRAPH:\n                    add_const_value_infos_to_graph(attr.g)\n                if attr.type == onnx.AttributeProto.GRAPHS:\n                    for g in attr.graphs:\n                        add_const_value_infos_to_graph(g)\n\n    return add_const_value_infos_to_graph(model.graph)\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def ReplaceUpsampleWithResize(onnx_model):\n\n    graph = onnx_model.graph\n\n    for i in range(len(graph.node)):\n        if graph.node[i].op_type == \'Upsample\':\n            old_node = graph.node[i]\n            roi = numpy_helper.from_array(np.empty([0], dtype=np.float32), old_node.name + "_roi")\n            onnx_model.graph.initializer.append(roi)\n            roi_value_info = helper.make_tensor_value_info(old_node.name + "_roi", onnx.TensorProto.FLOAT, [0])\n            onnx_model.graph.value_info.append(roi_value_info)\n            inputs = [old_node.input[0], old_node.name + "_roi", old_node.input[1]]\n            mode_string = \'\'\n            for attr in graph.node[i].attribute:\n                if attr.name == \'mode\':\n                    mode_string = attr.s\n            new_node = onnx.helper.make_node(\n                "Resize",\n                coordinate_transformation_mode="asymmetric",\n                cubic_coeff_a=-0.75,\n                mode=mode_string,\n                nearest_mode="floor",\n                inputs=inputs,\n                outputs=old_node.output\n            )\n            graph.node.remove(old_node)\n            graph.node.insert(i, new_node)\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def check_shapes(onnx_model):\n    names = []\n    for input_tensor in onnx_model.graph.input:\n        names.append(input_tensor.name)\n    for output_tensor in onnx_model.graph.output:\n        names.append(output_tensor.name)\n    for init_tensor in onnx_model.graph.initializer:\n        names.append(init_tensor.name)\n    for value in onnx_model.graph.value_info:\n        names.append(value.name)\n\n    for node in onnx_model.graph.node:\n        outputs = node.output\n        for output in outputs:\n            if output not in names:\n                assert False, "Shape checking error. Node: %s Type: %s, cannot get output shape, please check the attribute." % (node.name, node.op_type)\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def Constant_to_initializer(onnxmodel):\n    graph = onnxmodel.graph\n    delete = []\n    for i in range(len(graph.node)):\n        if graph.node[i].op_type=="Constant":\n            # data = np.frombuffer(graph.node[i].attribute[0].t.raw_data, dtype=np.float32)\n            p_t = helper.make_tensor(graph.node[i].output[0], onnx.TensorProto.FLOAT, dims = 0, vals=graph.node[i].attribute[0].t.raw_data, raw=True)\n            delete.append(graph.node[i])\n            graph.initializer.insert(0, p_t)\n    for oldnode in delete:\n        graph.node.remove(oldnode)\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"def modify_layer_dix(graph):\n    outputs = graph.output\n    outputs_dict = {}\n    for i, output in enumerate(outputs):\n        for j, node in enumerate(graph.node):\n            if output.name in node.output:\n                # output_idx : node_idx, layer_idx\n                outputs_dict[i] = [j, j]\n\n    for i in range(len(outputs_dict)):\n        min_index = i  \n        # find min_index\n        for j in range(i+1, len(outputs_dict)):\n            if outputs_dict[j][1] < outputs_dict[min_index][1]:\n                min_index = j\n\n        if min_index != i:\n                # exchange layer idx\n                for k, attr in enumerate(graph.node[outputs_dict[i][0]].attribute):\n                    if attr.name == 'layer_idx':\n                        new_layer_idx = onnx.helper.make_attribute(\"layer_idx\", outputs_dict[min_index][1])\n                        del graph.node[outputs_dict[i][0]].attribute[k]\n                        graph.node[outputs_dict[i][0]].attribute.extend([new_layer_idx])\n                        break\n\n                for k, attr in enumerate(graph.node[outputs_dict[min_index][0]].attribute):\n                    if attr.name == 'layer_idx':\n                        new_layer_idx = onnx.helper.make_attribute(\"layer_idx\", outputs_dict[i][1])\n                        del graph.node[outputs_dict[min_index][0]].attribute[k]\n                        graph.node[outputs_dict[min_index][0]].attribute.extend([new_layer_idx])\n                        break\n\n                # if graph.node[1].attribute\n                outputs_dict[i][1], outputs_dict[min_index][1] = outputs_dict[min_index][1], outputs_dict[i][1]\n\n    return graph\n"})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:'def to_nova_onnx(in_model_path, out_model_path, skip_fuse_bn, skip_onnx_sim, skip_modify_idx):\n    # load model\n    onnx_model = onnx.load(in_model_path)\n\n    if onnx_model.producer_name == \'Novatek NovaOnnx Converter\' or onnx_model.producer_name == \'Novatek Caffe2Onnx Converter\':\n        print("INFO :: This model is already a nova onnx model, skip the conversion process...")\n        return\n    \n    # check input shape\n    for input in onnx_model.graph.input:\n        input_shape = input.type.tensor_type.shape.dim\n        for d in input_shape:\n            if d.dim_value <= 0:\n                assert (False), "ERROR :: Each dimension of input shape must greater than zero, illegal input name = %s"% input.name\n    Constant_to_initializer(onnx_model)\n    # convert model\n    add_input_from_initializer(onnx_model)\n    \n    has_custom_op = 0\n    for node in onnx_model.graph.node:\n        if node.domain != \'\' and node.domain != \'ai.onnx\':\n            has_custom_op = 1\n    if has_custom_op == 1:\n\n        #get all value_info and output name\n        tensor_names = []\n        for vi in onnx_model.graph.value_info:\n            tensor_names.append(vi.name)\n        for output in onnx_model.graph.output:\n            tensor_names.append(output.name)\n        \n        # Add missing tensor_value_info (fake shape)\n        for i in range(len(onnx_model.graph.node)):\n            for output in onnx_model.graph.node[i].output:\n                if output not in tensor_names:\n                    if onnx_model.graph.node[i].op_type == "Gemm" or onnx_model.graph.node[i].op_type == "Flatten":\n                        fake_value_info = helper.make_tensor_value_info(output, TensorProto.FLOAT, [-1,-1])\n                    else:\n                        fake_value_info = helper.make_tensor_value_info(output, TensorProto.FLOAT, [-1,-1,-1,-1])\n                    tensor_names.append(output)\n                    onnx_model.graph.value_info.append(fake_value_info)\n    \n    else:\n        # convert model to opset 12\n        if onnx_model.opset_import[0].version != 12:\n            if onnx_model.opset_import[0].version > 12 or onnx_model.opset_import[0].version < 8:\n                assert (False), ": Opset version of the input model is %d, novaonnx only supports Opset version 8 ~ 12."% onnx_model.opset_import[0].version\n            print("WARNING :: Opset version of the input model is {}, novaonnx support Opset version 12.".format(onnx_model.opset_import[0].version))\n            print("INFO :: Conversion from Opset version {} to Opset version 12.".format(onnx_model.opset_import[0].version))\n            onnx_model = version_converter.convert_version(onnx_model, 12)\n            \n            #version_converter can not convert upsample(deprecated in opset 12), convert it to resize \n            ReplaceUpsampleWithResize(onnx_model)\n        \n        if skip_onnx_sim:\n            onnx_model = shape_inference.infer_shapes(onnx_model)\n            check_shapes(onnx_model)\n        else:\n            # apply onnx simplify\n            onnx_model, check = simplify(onnx_model, skip_fuse_bn = skip_fuse_bn)\n\n            assert check, "WARNING :: Simplified ONNX model could not be validated"\n            \n        for i in range(len(onnx_model.graph.node)):\n            if onnx_model.graph.node[i].op_type not in SUPPORTED_OP_TYPE_LIST:\n                print("WARNING :: Unsupported Layer Type ", onnx_model.graph.node[i].op_type)\n\n    graph = onnx_model.graph\n\n        \n    init_name_list = []\n    for initializer in graph.initializer:\n        init_name_list.append(initializer.name)\n    \n    name_dict = {}\n            \n    #modify Conv weight name\n    for i in range(len(graph.node)):\n        if graph.node[i].op_type == \'Conv\':\n            if graph.node[i].input[1] in init_name_list:\n                name_dict.setdefault(graph.node[i].input[1], graph.node[i].op_type + "_" + graph.node[i].input[1] + "_W")\n                graph.node[i].input[1] = graph.node[i].op_type + "_" + graph.node[i].input[1] + "_W"\n            if len(graph.node[i].input) > 2:\n                if graph.node[i].input[2] in init_name_list:\n                    name_dict.setdefault(graph.node[i].input[2],  graph.node[i].op_type + "_" + graph.node[i].input[2] + "_B")\n                    graph.node[i].input[2] = graph.node[i].op_type + "_" + graph.node[i].input[2] + "_B"\n\n      \n        #modify output tensor_name to (node_name)_Y\n        for k in range(len(graph.node[i].input)):\n            if graph.node[i].input[k] in name_dict:\n                graph.node[i].input[k] = name_dict[graph.node[i].input[k]]\n        for l in range(len(graph.node[i].output)):\n            name_dict.setdefault(graph.node[i].output[l], graph.node[i].op_type + "_" + graph.node[i].output[l] + "_Y")\n            graph.node[i].output[l] = graph.node[i].op_type + "_" + graph.node[i].output[l] + "_Y"\n\n        # Add layer_id attribute for each node\n        new_attr = helper.make_attribute("layer_idx", i)\n        graph.node[i].attribute.append(new_attr)\n        \n        #modify Conv weight name\n        if graph.node[i].op_type == \'AveragePool\' or graph.node[i].op_type == \'MaxPool\':\n            new_attr = helper.make_attribute("pool_at_pad", 1)\n            graph.node[i].attribute.append(new_attr)\n\n    #print(graph.value_info)\n    #modify graph output tensor_name to (node_name)_Y\n    for m in range(len(graph.output)):\n        if graph.output[m].name in name_dict:\n            graph.output[m].name = name_dict[graph.output[m].name]\n            \n    #modify value info name\n    for n in range(len(graph.value_info)):\n        if graph.value_info[n].name in name_dict:\n            graph.value_info[n].name = name_dict[graph.value_info[n].name]\n\n    #modify input name\n    for o in range(len(graph.input)):\n        if graph.input[o].name in name_dict:\n            graph.input[o].name = name_dict[graph.input[o].name] \n            \n    #modify initializer name\n    for p in range(len(graph.initializer)):\n        if graph.initializer[p].name in name_dict:\n            graph.initializer[p].name = name_dict[graph.initializer[p].name] \n    \n    if not skip_modify_idx:\n        graph = modify_layer_dix(graph)\n\n    onnx_model.producer_name = \'Novatek NovaOnnx Converter\'\n    onnx_model.producer_version = \'1.0\'\n    onnx.save(onnx_model, out_model_path)\n    print("INFO :: Converted to NOVA ONNX!")\n'})}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"to_nova_onnx(INPUT, OUTPUT, SKIP_FUSE_BN, SKIP_ONNX_SIM, SKIP_MODIFY_IDX)\n"})})]})}function u(n={}){const{wrapper:e}={...(0,i.ah)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(s,{...n})}):s(n)}},603905:(n,e,o)=>{o.d(e,{ah:()=>d});var t=o(667294);function i(n,e,o){return e in n?Object.defineProperty(n,e,{value:o,enumerable:!0,configurable:!0,writable:!0}):n[e]=o,n}function r(n,e){var o=Object.keys(n);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(n);e&&(t=t.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),o.push.apply(o,t)}return o}function a(n){for(var e=1;e<arguments.length;e++){var o=null!=arguments[e]?arguments[e]:{};e%2?r(Object(o),!0).forEach((function(e){i(n,e,o[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(o)):r(Object(o)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(o,e))}))}return n}function p(n,e){if(null==n)return{};var o,t,i=function(n,e){if(null==n)return{};var o,t,i={},r=Object.keys(n);for(t=0;t<r.length;t++)o=r[t],e.indexOf(o)>=0||(i[o]=n[o]);return i}(n,e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(n);for(t=0;t<r.length;t++)o=r[t],e.indexOf(o)>=0||Object.prototype.propertyIsEnumerable.call(n,o)&&(i[o]=n[o])}return i}var l=t.createContext({}),d=function(n){var e=t.useContext(l),o=e;return n&&(o="function"==typeof n?n(e):a(a({},e),n)),o},s={inlineCode:"code",wrapper:function(n){var e=n.children;return t.createElement(t.Fragment,{},e)}},u=t.forwardRef((function(n,e){var o=n.components,i=n.mdxType,r=n.originalType,l=n.parentName,u=p(n,["components","mdxType","originalType","parentName"]),m=d(o),h=i,c=m["".concat(l,".").concat(h)]||m[h]||s[h]||r;return o?t.createElement(c,a(a({ref:e},u),{},{components:o})):t.createElement(c,a({ref:e},u))}));u.displayName="MDXCreateElement"},614102:(n,e,o)=>{o.d(e,{Z:()=>t});const t=o.p+"assets/images/Working_with_ONNX_Models_01-a290c459b7d16bf27bb8dcbaba8e6d95.png"},441770:(n,e,o)=>{o.d(e,{Z:()=>t});const t=o.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-5a33ed1aeac871d5b7a7594cc7d702c8.jpg"}}]);