"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[15896],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>m});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function l(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?l(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):l(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},l=Object.keys(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var l=Object.getOwnPropertySymbols(e);for(a=0;a<l.length;a++)n=l[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),d=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=d(e.components);return a.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},A=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,l=e.originalType,s=e.parentName,p=o(e,["components","mdxType","originalType","parentName"]),A=d(n),m=r,g=A["".concat(s,".").concat(m)]||A[m]||u[m]||l;return n?a.createElement(g,i(i({ref:t},p),{},{components:n})):a.createElement(g,i({ref:t},p))}));function m(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var l=n.length,i=new Array(l);i[0]=A;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:r,i[1]=o;for(var d=2;d<l;d++)i[d]=n[d];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}A.displayName="MDXCreateElement"},66794:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>u,frontMatter:()=>l,metadata:()=>o,toc:()=>d});var a=n(87462),r=(n(67294),n(3905));const l={sidebar_position:4520,slug:"2023-03-24",title:"Tensorflow 2 - Unsupervised Learning",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Use Autoencoders to Reduce Dimensionality and Feature Discovery"},i=void 0,o={unversionedId:"IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/index",id:"IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/index",title:"Tensorflow 2 - Unsupervised Learning",description:"Use Autoencoders to Reduce Dimensionality and Feature Discovery",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders",slug:"/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4520,frontMatter:{sidebar_position:4520,slug:"2023-03-24",title:"Tensorflow 2 - Unsupervised Learning",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Use Autoencoders to Reduce Dimensionality and Feature Discovery"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow 2 - Unsupervised Learning",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26"},next:{title:"Tensorflow 2 - Transfer Learning",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16"}},s={},d=[{value:"Principle of Dimensionality Reduction",id:"principle-of-dimensionality-reduction",level:2},{value:"Build the Autoencoder",id:"build-the-autoencoder",level:3},{value:"Train the Autoencoder",id:"train-the-autoencoder",level:3},{value:"Visualize the Results",id:"visualize-the-results",level:3},{value:"Autoencoders for Image Data",id:"autoencoders-for-image-data",level:2},{value:"Building the Autoencoder",id:"building-the-autoencoder",level:3},{value:"Run Predictions",id:"run-predictions",level:3},{value:"Autoencoders for Noise Removal",id:"autoencoders-for-noise-removal",level:2},{value:"Build the Denoise Autoencoder",id:"build-the-denoise-autoencoder",level:3},{value:"Run Denoiser",id:"run-denoiser",level:3},{value:"Food",id:"food",level:2},{value:"Prepare the Dataset",id:"prepare-the-dataset",level:4},{value:"Use an Autoencoder to separate Features",id:"use-an-autoencoder-to-separate-features",level:3}],p={toc:d};function u(e){let{components:t,...l}=e;return(0,r.kt)("wrapper",(0,a.Z)({},p,l,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Victoria Harbour, Hongkong",src:n(68225).Z,width:"2385",height:"1054"})),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#tensorflow-unsupervised-learning"},"Tensorflow Unsupervised Learning"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#principle-of-dimensionality-reduction"},"Principle of Dimensionality Reduction"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#build-the-autoencoder"},"Build the Autoencoder")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#train-the-autoencoder"},"Train the Autoencoder")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#visualize-the-results"},"Visualize the Results")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#autoencoders-for-image-data"},"Autoencoders for Image Data"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#building-the-autoencoder"},"Building the Autoencoder")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#run-predictions"},"Run Predictions")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#autoencoders-for-noise-removal"},"Autoencoders for Noise Removal"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#build-the-denoise-autoencoder"},"Build the Denoise Autoencoder")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#run-denoiser"},"Run Denoiser")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#food"},"Food"),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#prepare-the-dataset"},"Prepare the Dataset")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"#use-an-autoencoder-to-separate-features"},"Use an Autoencoder to separate Features"))))))),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/tf-2023"},"Github Repository")),(0,r.kt)("p",null,(0,r.kt)("em",{parentName:"p"},"See also:")),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Fun, fun, tensors: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19"},"Tensor Constants, Variables and Attributes"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21"},"Tensor Indexing, Expanding and Manipulations"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22"},"Matrix multiplications, Squeeze, One-hot and Numpy")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Neural Network Regression: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23"},"Building a Regression Model"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24"},"Model Evaluation"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25"},"Model Optimization"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26"},'Working with a "Real" Dataset'),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26"},"Feature Scaling")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Neural Network Classification: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27"},"Non-linear Data and Activation Functions"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28"},"Model Evaluation and Performance Improvement"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02"},"Multiclass Classification Problems")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Convolutional Neural Networks: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03"},"Binary Image Classification"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05"},"Multiclass Image Classification")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Transfer Learning: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06"},"Feature Extraction"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11"},"Fine-Tuning"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16"},"Scaling")),(0,r.kt)("li",{parentName:"ul"},"Tensorflow 2 - Unsupervised Learning: ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24"},"Autoencoder Feature Detection"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26"},"Autoencoder Super-Resolution"),", ",(0,r.kt)("a",{parentName:"li",href:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-generative-adversial-networks/2023-03-26"},"Generative Adverserial Networks"))),(0,r.kt)("h1",{id:"tensorflow-unsupervised-learning"},"Tensorflow Unsupervised Learning"),(0,r.kt)("h2",{id:"principle-of-dimensionality-reduction"},"Principle of Dimensionality Reduction"),(0,r.kt)("p",null,'Using Autoencoders to remove "noisy dimensions" in our dataset to be able to extract hidden features.'),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"import matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import make_blobs\nfrom sklearn.preprocessing import MinMaxScaler\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.layers import Dense, Flatten, Reshape, GaussianNoise\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import SGD, Adam\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# global variables\nSEED = 42\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# create random feature blobs\ndata = make_blobs(n_samples=300,\n                 n_features=2,\n                 centers=2,\n                 cluster_std=1.0,\n                 random_state=SEED)\n\nX, y = data\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# create random dataset\nnp.random.seed(seed=SEED)\nz_noise = np.random.normal(size=len(X))\nz_noise = pd.Series(z_noise)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# combine data into single dataframe\nfeatures = pd.DataFrame(X)\nfeatures = pd.concat([features,z_noise], axis=1)\nfeatures.columns = ['X1', 'X2', 'Xnoise']\n\n# this generated a dataframe with 3 colums for our data:\nprint(features.head())\n")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null}),(0,r.kt)("th",{parentName:"tr",align:null},"X1"),(0,r.kt)("th",{parentName:"tr",align:null},"X2"),(0,r.kt)("th",{parentName:"tr",align:null},"Xnoise"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"0"),(0,r.kt)("td",{parentName:"tr",align:null},"-7.338988"),(0,r.kt)("td",{parentName:"tr",align:null},"-7.729954"),(0,r.kt)("td",{parentName:"tr",align:null},"0.496714")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"1"),(0,r.kt)("td",{parentName:"tr",align:null},"-7.740041"),(0,r.kt)("td",{parentName:"tr",align:null},"-7.264665"),(0,r.kt)("td",{parentName:"tr",align:null},"-0.138264")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2"),(0,r.kt)("td",{parentName:"tr",align:null},"-1.686653"),(0,r.kt)("td",{parentName:"tr",align:null},"7.793442"),(0,r.kt)("td",{parentName:"tr",align:null},"0.647689")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"3"),(0,r.kt)("td",{parentName:"tr",align:null},"4.422198"),(0,r.kt)("td",{parentName:"tr",align:null},"3.071947"),(0,r.kt)("td",{parentName:"tr",align:null},"1.523030")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"4"),(0,r.kt)("td",{parentName:"tr",align:null},"-8.917752"),(0,r.kt)("td",{parentName:"tr",align:null},"-7.888196"),(0,r.kt)("td",{parentName:"tr",align:null},"-0.234153")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# plotting Y=f(x) shows 2 distinct features\nplt.scatter(features['X1'], features['X2'], c=y)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(58746).Z,width:"543",height:"413"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# add a third dimension from the noise data\n# this noisy dimension(s) are supposed to\n# make it more difficult to see the underlying\n# 2 features\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(features['X1'], features['X2'], features['Xnoise'], c=y)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(30997).Z,width:"404",height:"400"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# normalize the dataset\nscaler = MinMaxScaler()\nscaled_data = scaler.fit_transform(features)\n\n# this generated a dataframe with 3 colums for our data:\nprint(scaled_data[:5])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-py"},"array([[0.123409  , 0.0694226 , 0.52692164],\n       [0.09881332, 0.09166767, 0.4374124 ],\n       [0.4700545 , 0.81158342, 0.54820363],\n       [0.84469708, 0.58585258, 0.67159543],\n       [0.02658684, 0.06185718, 0.42389547]])\n")),(0,r.kt)("h3",{id:"build-the-autoencoder"},"Build the Autoencoder"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# build an encoder that reduces dimensionality from 3 => 2\nencoder = Sequential([\n  Dense(units=2, activation='relu', input_shape=[3])\n])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# and an encoder that brings it back up from 2 => 3\ndecoder = Sequential([\n  Dense(units=3, activation='relu', input_shape=[2])\n])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# compile both layers into the autoencoder model\nautoencoder = Sequential([encoder, decoder])\n\nautoencoder.compile(loss='mse', optimizer=SGD(learning_rate=1.5))\n")),(0,r.kt)("h3",{id:"train-the-autoencoder"},"Train the Autoencoder"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"autoencoder.fit(scaled_data, scaled_data, epochs=5)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# The encoder now reduces the dimensions of our dataset to 2\n# when we run predictions from the encoder we will get\n# 2-dimensional results that should have stripped the \n# noisy 3rd dimension we added\nencoded_2dim = encoder.predict(scaled_data)\n# (300, 2) <= (300, 3)\nprint(encoded_2dim.shape, scaled_data.shape)\nencoded_2dim\n")),(0,r.kt)("h3",{id:"visualize-the-results"},"Visualize the Results"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"plt.scatter(encoded_2dim[:,0], encoded_2dim[:,1], c=y)\n# the encoder simplified our dataset and extracted 2 clearly\n# defined features that might have been obfuscated by the\n# extra dimensions in our dataset\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(82567).Z,width:"573",height:"413"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"decoded_2to3dim = autoencoder.predict(scaled_data)\nprint(decoded_2to3dim.shape, scaled_data.shape)\n#  (300, 3) <= (300, 2) <= (300, 3)\ndecoded_2to3dim\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"fig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\nax.scatter(decoded_2to3dim[:,0], decoded_2to3dim[:,1], decoded_2to3dim[:,2], c=y)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(50755).Z,width:"414",height:"399"})),(0,r.kt)("h2",{id:"autoencoders-for-image-data"},"Autoencoders for Image Data"),(0,r.kt)("p",null,"Create a noisy version of the MNIST digits dataset and train an autoencoder to generate de-noised images from this source."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"(X_train, y_train), (X_test, y_test) = mnist.load_data()\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"plt.imshow(X_train[88])\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(43932).Z,width:"416",height:"413"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# normalize images\nX_train = X_train/255\nX_test = X_test/255\n")),(0,r.kt)("h3",{id:"building-the-autoencoder"},"Building the Autoencoder"),(0,r.kt)("p",null,"The dataset starts out with 28*28 px images = 784 dimensions. The Encoder should now, several times over several layers, approx. cut this number in half until a minimum of dimensions is reached in a hidden layer."),(0,r.kt)("p",null,"The following Decoder should then take those reduced feature maps and reconstruct the original image from it. By validating the against the original, not noisy images we should be able to train the Autoencoder to denoise images."),(0,r.kt)("p",null,"Let's get started by an autoencoder that can read the original image, reduces it to ~3% and then reconstruct the original image from this state:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"encoder = Sequential([\n    # generate (28, 28) => (784) shape\n    Flatten(input_shape=[28, 28], name='input_layer'),\n    # cut dimensions in half \n    Dense(units=392, activation='relu', name=\"reducer50\"),\n    # cut dimensions in half \n    Dense(units=196, activation='relu', name=\"reducer25\"),\n    # cut dimensions in half \n    Dense(units=98, activation='relu', name=\"reducer12\"),\n    # cut dimensions in half \n    Dense(units=49, activation='relu', name=\"reducer6\"),\n    # cut dimensions in ~ half \n    Dense(units=24, activation='relu', name='hidden_layer')\n])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"decoder = Sequential([\n    Dense(units=49, activation='relu', input_shape=[24], name='expander6'),\n    Dense(units=98, activation='relu', name='expander12'),\n    Dense(units=98, activation='relu', name='expander25'),\n    Dense(units=392, activation='relu', name='expander50'),\n    Dense(units=784, activation='sigmoid', name='expander100'),\n    Reshape([28, 28], name='output_layer')\n])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"autoencoder = Sequential([encoder, decoder])\n\nautoencoder.compile(loss='binary_crossentropy',\n#                    optimizer=SGD(learning_rate=1.5),\n                    optimizer=Adam(learning_rate=1e-3),\n                    metrics=['accuracy'])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"tf.random.set_seed(SEED)\n# fit the autoencoder to training dataset\nautoencoder.fit(X_train, X_train, epochs=25,\n               validation_data=[X_test, X_test])\n\n# Epoch 25/25\n# 6s 3ms/step - loss: 0.0898 - accuracy: 0.3063 - val_loss: 0.0923 - val_accuracy: 0.2968\n")),(0,r.kt)("h3",{id:"run-predictions"},"Run Predictions"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# get 10 sample predictions from testing dataset\npassed_images = autoencoder.predict(X_test[:10])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# select 3 images out of 10 samples\nn = [3, 4, 5]\n\nplt.figure(figsize=(12, 12))\n# ROW 1\nplt.subplot(3, 2, 1)\nplt.title(f"Original MNIST Image => {y_test[n[0]]}")\nplt.axis(False)\nplt.imshow(X_test[n[0]])\nplt.subplot(3, 2, 2)\nplt.title("Reconstructed Image")\nplt.axis(False)\nplt.imshow(passed_images[n[0]])\n# ROW 2\nplt.subplot(3, 2, 3)\nplt.title(f"Original MNIST Image => {y_test[n[1]]}")\nplt.axis(False)\nplt.imshow(X_test[n[1]])\nplt.subplot(3, 2, 4)\nplt.title("Reconstructed Image")\nplt.axis(False)\nplt.imshow(passed_images[n[1]])\n# ROW 3\nplt.subplot(3, 2, 5)\nplt.title(f"Original MNIST Image => {y_test[n[2]]}")\nplt.axis(False)\nplt.imshow(X_test[n[2]])\nplt.subplot(3, 2, 6)\nplt.title("Reconstructed Image")\nplt.axis(False)\nplt.imshow(passed_images[n[2]])\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(14351).Z,width:"799",height:"966"})),(0,r.kt)("h2",{id:"autoencoders-for-noise-removal"},"Autoencoders for Noise Removal"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# generating noise\nsample = GaussianNoise(0.2)\nnoisy = sample(X_train[:10], training=True)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'n = 4\n\nplt.figure(figsize=(12, 12))\n# ROW 1\nplt.subplot(1, 2, 1)\nplt.title(f"Original MNIST Image => {y_train[n]}")\nplt.axis(False)\nplt.imshow(X_train[n])\nplt.subplot(1, 2, 2)\nplt.title("Noised Image")\nplt.axis(False)\nplt.imshow(noisy[n])\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(90737).Z,width:"950",height:"465"})),(0,r.kt)("h3",{id:"build-the-denoise-autoencoder"},"Build the Denoise Autoencoder"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"tf.random.set_seed(SEED)\n\nencoder = Sequential([\n    # generate (28, 28) => (784) shape\n    Flatten(input_shape=[28, 28], name='input_layer'),\n    \n    # add noise to source image\n    GaussianNoise(0.2),\n    \n    # cut dimensions in half \n    Dense(units=392, activation='relu', name=\"reducer50\"),\n    # cut dimensions in half \n    Dense(units=196, activation='relu', name=\"reducer25\"),\n    # cut dimensions in half \n    Dense(units=98, activation='relu', name=\"reducer12\"),\n    # cut dimensions in half \n    Dense(units=49, activation='relu', name=\"reducer6\"),\n    # cut dimensions in ~ half \n    Dense(units=24, activation='relu', name='hidden_layer')\n])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"decoder = Sequential([\n    Dense(units=49, activation='relu', input_shape=[24], name='expander6'),\n    Dense(units=98, activation='relu', name='expander12'),\n    Dense(units=98, activation='relu', name='expander25'),\n    Dense(units=392, activation='relu', name='expander50'),\n    Dense(units=784, activation='sigmoid', name='expander100'),\n    Reshape([28, 28], name='output_layer')\n])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"noise_remover = Sequential([encoder, decoder])\n\nnoise_remover.compile(loss='binary_crossentropy',\n                     optimizer=Adam(learning_rate=1e-3),\n                     metrics=['accuracy'])\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"noise_remover.fit(X_train, X_train, epochs=25,\n               validation_data=[X_test, X_test])\n\n# Epoch 25/25\n# 6s 3ms/step - loss: 0.0946 - accuracy: 0.2949 - val_loss: 0.0913 - val_accuracy: 0.2986\n")),(0,r.kt)("h3",{id:"run-denoiser"},"Run Denoiser"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"noisy_samples = sample(X_test[:3], training=True)\n\ndenoised_samples = noise_remover(noisy_samples)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},'# plot results\nplt.figure(figsize=(12, 12))\n# ROW 1\nplt.subplot(3, 3, 1)\nplt.title(f"Original MNIST Image => {y_test[0]}")\nplt.axis(False)\nplt.imshow(X_test[0])\nplt.subplot(3, 3, 2)\nplt.title("Noised Image")\nplt.axis(False)\nplt.imshow(noisy_samples[0])\nplt.subplot(3, 3, 3)\nplt.title("Denoised Image")\nplt.axis(False)\nplt.imshow(denoised_samples[0])\n# ROW 2\nplt.subplot(3, 3, 4)\nplt.title(f"Original MNIST Image => {y_test[1]}")\nplt.axis(False)\nplt.imshow(X_test[1])\nplt.subplot(3, 3, 5)\nplt.title("Noised Image")\nplt.axis(False)\nplt.imshow(noisy_samples[1])\nplt.subplot(3, 3, 6)\nplt.title("Denoised Image")\nplt.axis(False)\nplt.imshow(denoised_samples[1])\n# ROW 3\nplt.subplot(3, 3, 7)\nplt.title(f"Original MNIST Image => {y_test[2]}")\nplt.axis(False)\nplt.imshow(X_test[2])\nplt.subplot(3, 3, 8)\nplt.title("Noised Image")\nplt.axis(False)\nplt.imshow(noisy_samples[2])\nplt.subplot(3, 3, 9)\nplt.title("Denoised Image")\nplt.axis(False)\nplt.imshow(denoised_samples[2])\n')),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(38843).Z,width:"948",height:"966"})),(0,r.kt)("h2",{id:"food"},"Food"),(0,r.kt)("p",null,"Variations in preference for different food types in the UK"),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},(0,r.kt)("inlineCode",{parentName:"p"},"wget https://github.com/emtrujillo-lab/bggn213/blob/3fdf3e1f373545a420de9fb45a2a8e68ee5478fa/Class09/Class9/UK_foods.csv"))),(0,r.kt)("h4",{id:"prepare-the-dataset"},"Prepare the Dataset"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"df = pd.read_csv('./UK_foods.csv', index_col='Unnamed: 0')\ndf\n")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null}),(0,r.kt)("th",{parentName:"tr",align:null},"England"),(0,r.kt)("th",{parentName:"tr",align:null},"Wales"),(0,r.kt)("th",{parentName:"tr",align:null},"Scotland"),(0,r.kt)("th",{parentName:"tr",align:null},"N.Ireland"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Cheese"),(0,r.kt)("td",{parentName:"tr",align:null},"105"),(0,r.kt)("td",{parentName:"tr",align:null},"103"),(0,r.kt)("td",{parentName:"tr",align:null},"103"),(0,r.kt)("td",{parentName:"tr",align:null},"66")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Carcass_meat"),(0,r.kt)("td",{parentName:"tr",align:null},"245"),(0,r.kt)("td",{parentName:"tr",align:null},"227"),(0,r.kt)("td",{parentName:"tr",align:null},"242"),(0,r.kt)("td",{parentName:"tr",align:null},"267")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Other_meat"),(0,r.kt)("td",{parentName:"tr",align:null},"685"),(0,r.kt)("td",{parentName:"tr",align:null},"803"),(0,r.kt)("td",{parentName:"tr",align:null},"750"),(0,r.kt)("td",{parentName:"tr",align:null},"586")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Fish"),(0,r.kt)("td",{parentName:"tr",align:null},"147"),(0,r.kt)("td",{parentName:"tr",align:null},"160"),(0,r.kt)("td",{parentName:"tr",align:null},"122"),(0,r.kt)("td",{parentName:"tr",align:null},"93")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Fats_and_oils"),(0,r.kt)("td",{parentName:"tr",align:null},"193"),(0,r.kt)("td",{parentName:"tr",align:null},"235"),(0,r.kt)("td",{parentName:"tr",align:null},"184"),(0,r.kt)("td",{parentName:"tr",align:null},"209")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Sugars"),(0,r.kt)("td",{parentName:"tr",align:null},"156"),(0,r.kt)("td",{parentName:"tr",align:null},"175"),(0,r.kt)("td",{parentName:"tr",align:null},"147"),(0,r.kt)("td",{parentName:"tr",align:null},"139")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Fresh_potatoes"),(0,r.kt)("td",{parentName:"tr",align:null},"720"),(0,r.kt)("td",{parentName:"tr",align:null},"874"),(0,r.kt)("td",{parentName:"tr",align:null},"566"),(0,r.kt)("td",{parentName:"tr",align:null},"1033")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Fresh_Veg"),(0,r.kt)("td",{parentName:"tr",align:null},"253"),(0,r.kt)("td",{parentName:"tr",align:null},"265"),(0,r.kt)("td",{parentName:"tr",align:null},"171"),(0,r.kt)("td",{parentName:"tr",align:null},"143")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Other_Veg"),(0,r.kt)("td",{parentName:"tr",align:null},"488"),(0,r.kt)("td",{parentName:"tr",align:null},"570"),(0,r.kt)("td",{parentName:"tr",align:null},"418"),(0,r.kt)("td",{parentName:"tr",align:null},"355")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Processed_potatoes"),(0,r.kt)("td",{parentName:"tr",align:null},"198"),(0,r.kt)("td",{parentName:"tr",align:null},"203"),(0,r.kt)("td",{parentName:"tr",align:null},"220"),(0,r.kt)("td",{parentName:"tr",align:null},"187")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Processed_Veg"),(0,r.kt)("td",{parentName:"tr",align:null},"360"),(0,r.kt)("td",{parentName:"tr",align:null},"365"),(0,r.kt)("td",{parentName:"tr",align:null},"337"),(0,r.kt)("td",{parentName:"tr",align:null},"334")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Fresh_fruit"),(0,r.kt)("td",{parentName:"tr",align:null},"1102"),(0,r.kt)("td",{parentName:"tr",align:null},"1137"),(0,r.kt)("td",{parentName:"tr",align:null},"957"),(0,r.kt)("td",{parentName:"tr",align:null},"674")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Cereals"),(0,r.kt)("td",{parentName:"tr",align:null},"1472"),(0,r.kt)("td",{parentName:"tr",align:null},"1582"),(0,r.kt)("td",{parentName:"tr",align:null},"1462"),(0,r.kt)("td",{parentName:"tr",align:null},"1494")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Beverages"),(0,r.kt)("td",{parentName:"tr",align:null},"57"),(0,r.kt)("td",{parentName:"tr",align:null},"73"),(0,r.kt)("td",{parentName:"tr",align:null},"53"),(0,r.kt)("td",{parentName:"tr",align:null},"47")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Soft_drinks"),(0,r.kt)("td",{parentName:"tr",align:null},"1374"),(0,r.kt)("td",{parentName:"tr",align:null},"1256"),(0,r.kt)("td",{parentName:"tr",align:null},"1572"),(0,r.kt)("td",{parentName:"tr",align:null},"1506")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Alcoholic_drinks"),(0,r.kt)("td",{parentName:"tr",align:null},"375"),(0,r.kt)("td",{parentName:"tr",align:null},"475"),(0,r.kt)("td",{parentName:"tr",align:null},"458"),(0,r.kt)("td",{parentName:"tr",align:null},"135")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Confectionery"),(0,r.kt)("td",{parentName:"tr",align:null},"54"),(0,r.kt)("td",{parentName:"tr",align:null},"64"),(0,r.kt)("td",{parentName:"tr",align:null},"62"),(0,r.kt)("td",{parentName:"tr",align:null},"41")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# create a heatmap with pandas\nplt.figure(figsize=(12, 8))\nplt.pcolor(df)\nplt.yticks(np.arange(0.5, len(df.index), 1), df.index)\nplt.xticks(np.arange(0.5, len(df.columns), 1), df.columns)\nplt.xticks(rotation=70, fontsize=12)\nplt.yticks(fontsize=12)\nplt.show()\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(43704).Z,width:"1130",height:"722"})),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"df_t = df.transpose()\ndf_t\n")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null}),(0,r.kt)("th",{parentName:"tr",align:null},"Cheese"),(0,r.kt)("th",{parentName:"tr",align:null},"Carcass_meat"),(0,r.kt)("th",{parentName:"tr",align:null},"Other_meat"),(0,r.kt)("th",{parentName:"tr",align:null},"Fish"),(0,r.kt)("th",{parentName:"tr",align:null},"Fats_and_oils"),(0,r.kt)("th",{parentName:"tr",align:null},"Sugars"),(0,r.kt)("th",{parentName:"tr",align:null},"Fresh_potatoes"),(0,r.kt)("th",{parentName:"tr",align:null},"Fresh_Veg"),(0,r.kt)("th",{parentName:"tr",align:null},"Other_Veg"),(0,r.kt)("th",{parentName:"tr",align:null},"Processed_potatoes"),(0,r.kt)("th",{parentName:"tr",align:null},"Processed_Veg"),(0,r.kt)("th",{parentName:"tr",align:null},"Fresh_fruit"),(0,r.kt)("th",{parentName:"tr",align:null},"Cereals"),(0,r.kt)("th",{parentName:"tr",align:null},"Beverages"),(0,r.kt)("th",{parentName:"tr",align:null},"Soft_drinks"),(0,r.kt)("th",{parentName:"tr",align:null},"Alcoholic_drinks"),(0,r.kt)("th",{parentName:"tr",align:null},"Confectionery"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"England"),(0,r.kt)("td",{parentName:"tr",align:null},"105"),(0,r.kt)("td",{parentName:"tr",align:null},"245"),(0,r.kt)("td",{parentName:"tr",align:null},"685"),(0,r.kt)("td",{parentName:"tr",align:null},"147"),(0,r.kt)("td",{parentName:"tr",align:null},"193"),(0,r.kt)("td",{parentName:"tr",align:null},"156"),(0,r.kt)("td",{parentName:"tr",align:null},"720"),(0,r.kt)("td",{parentName:"tr",align:null},"253"),(0,r.kt)("td",{parentName:"tr",align:null},"488"),(0,r.kt)("td",{parentName:"tr",align:null},"198"),(0,r.kt)("td",{parentName:"tr",align:null},"360"),(0,r.kt)("td",{parentName:"tr",align:null},"1102"),(0,r.kt)("td",{parentName:"tr",align:null},"1472"),(0,r.kt)("td",{parentName:"tr",align:null},"57"),(0,r.kt)("td",{parentName:"tr",align:null},"1374"),(0,r.kt)("td",{parentName:"tr",align:null},"375"),(0,r.kt)("td",{parentName:"tr",align:null},"54")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Wales"),(0,r.kt)("td",{parentName:"tr",align:null},"103"),(0,r.kt)("td",{parentName:"tr",align:null},"227"),(0,r.kt)("td",{parentName:"tr",align:null},"803"),(0,r.kt)("td",{parentName:"tr",align:null},"160"),(0,r.kt)("td",{parentName:"tr",align:null},"235"),(0,r.kt)("td",{parentName:"tr",align:null},"175"),(0,r.kt)("td",{parentName:"tr",align:null},"874"),(0,r.kt)("td",{parentName:"tr",align:null},"265"),(0,r.kt)("td",{parentName:"tr",align:null},"570"),(0,r.kt)("td",{parentName:"tr",align:null},"203"),(0,r.kt)("td",{parentName:"tr",align:null},"365"),(0,r.kt)("td",{parentName:"tr",align:null},"1137"),(0,r.kt)("td",{parentName:"tr",align:null},"1582"),(0,r.kt)("td",{parentName:"tr",align:null},"73"),(0,r.kt)("td",{parentName:"tr",align:null},"1256"),(0,r.kt)("td",{parentName:"tr",align:null},"475"),(0,r.kt)("td",{parentName:"tr",align:null},"64")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Scotland"),(0,r.kt)("td",{parentName:"tr",align:null},"103"),(0,r.kt)("td",{parentName:"tr",align:null},"242"),(0,r.kt)("td",{parentName:"tr",align:null},"750"),(0,r.kt)("td",{parentName:"tr",align:null},"122"),(0,r.kt)("td",{parentName:"tr",align:null},"184"),(0,r.kt)("td",{parentName:"tr",align:null},"147"),(0,r.kt)("td",{parentName:"tr",align:null},"566"),(0,r.kt)("td",{parentName:"tr",align:null},"171"),(0,r.kt)("td",{parentName:"tr",align:null},"418"),(0,r.kt)("td",{parentName:"tr",align:null},"220"),(0,r.kt)("td",{parentName:"tr",align:null},"337"),(0,r.kt)("td",{parentName:"tr",align:null},"957"),(0,r.kt)("td",{parentName:"tr",align:null},"1462"),(0,r.kt)("td",{parentName:"tr",align:null},"53"),(0,r.kt)("td",{parentName:"tr",align:null},"1572"),(0,r.kt)("td",{parentName:"tr",align:null},"458"),(0,r.kt)("td",{parentName:"tr",align:null},"62")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"N.Ireland"),(0,r.kt)("td",{parentName:"tr",align:null},"66"),(0,r.kt)("td",{parentName:"tr",align:null},"267"),(0,r.kt)("td",{parentName:"tr",align:null},"586"),(0,r.kt)("td",{parentName:"tr",align:null},"93"),(0,r.kt)("td",{parentName:"tr",align:null},"209"),(0,r.kt)("td",{parentName:"tr",align:null},"139"),(0,r.kt)("td",{parentName:"tr",align:null},"1033"),(0,r.kt)("td",{parentName:"tr",align:null},"143"),(0,r.kt)("td",{parentName:"tr",align:null},"355"),(0,r.kt)("td",{parentName:"tr",align:null},"187"),(0,r.kt)("td",{parentName:"tr",align:null},"334"),(0,r.kt)("td",{parentName:"tr",align:null},"674"),(0,r.kt)("td",{parentName:"tr",align:null},"1494"),(0,r.kt)("td",{parentName:"tr",align:null},"47"),(0,r.kt)("td",{parentName:"tr",align:null},"1506"),(0,r.kt)("td",{parentName:"tr",align:null},"135"),(0,r.kt)("td",{parentName:"tr",align:null},"41")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# create a heatmap with seaborn\nplt.figure(figsize=(12, 6))\nsns.heatmap(df_t, cmap='RdYlGn_r', linewidths=0.5, annot=False)\n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(7412).Z,width:"902",height:"634"})),(0,r.kt)("h3",{id:"use-an-autoencoder-to-separate-features"},"Use an Autoencoder to separate Features"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# build the autoencoder\nencoder = Sequential([\n    Dense(units=8, activation='relu', input_shape=[17]),\n    Dense(units=4, activation='relu'),\n    Dense(units=2, activation='relu')\n])\n\ndecoder = Sequential([\n    Dense(units=4, activation='relu', input_shape=[2]),\n    Dense(units=8, activation='relu'),\n    Dense(units=17, activation='relu')\n])\n\nautoencoder= Sequential([encoder, decoder])\n\nautoencoder.compile(loss='mse', optimizer=Adam(learning_rate=1e-3))\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# normalize input data\nscaler = MinMaxScaler()\n\nscaled_df = scaler.fit_transform(df_t.values)\nscaled_df.shape\n# (4, 17)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"autoencoder.fit(scaled_df, scaled_df, epochs=25)\n# Epoch 25/25\n# 1/1 [==============================] - 0s 5ms/step - loss: 0.2891\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"# get reduced dimensionality output from encoder\nencoded_2dim = encoder.predict(scaled_df)\nencoded_2dim\n\n# array([[0.        , 1.8262266 ],\n#        [0.        , 3.4182868 ],\n#        [0.        , 1.7019984 ],\n#        [0.20801371, 0.52220476]], dtype=float32)\n")),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"results = pd.DataFrame(data=encoded_2dim,\n                      index=df_t.index,\n                      columns=['C1', 'C2'])\n\nresults.reset_index()\n")),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null}),(0,r.kt)("th",{parentName:"tr",align:null},"index"),(0,r.kt)("th",{parentName:"tr",align:null},"C1"),(0,r.kt)("th",{parentName:"tr",align:null},"C2"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"0"),(0,r.kt)("td",{parentName:"tr",align:null},"England"),(0,r.kt)("td",{parentName:"tr",align:null},"0.000000"),(0,r.kt)("td",{parentName:"tr",align:null},"1.826227")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"1"),(0,r.kt)("td",{parentName:"tr",align:null},"Wales"),(0,r.kt)("td",{parentName:"tr",align:null},"0.000000"),(0,r.kt)("td",{parentName:"tr",align:null},"3.418287")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"2"),(0,r.kt)("td",{parentName:"tr",align:null},"Scotland"),(0,r.kt)("td",{parentName:"tr",align:null},"0.000000"),(0,r.kt)("td",{parentName:"tr",align:null},"1.701998")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"3"),(0,r.kt)("td",{parentName:"tr",align:null},"N.Ireland"),(0,r.kt)("td",{parentName:"tr",align:null},"0.208014"),(0,r.kt)("td",{parentName:"tr",align:null},"0.522205")))),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-python"},"sns.scatterplot(x='C1', y='C2', data=results.reset_index(), hue='index')\n\n# England and Scotland are very close to each other\n# while Wales and N.Ireland \n")),(0,r.kt)("p",null,(0,r.kt)("img",{alt:"Unsupervised Learning with Tensorflow",src:n(37094).Z,width:"567",height:"432"})))}u.isMDXComponent=!0},58746:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_01-78966739aab366fcfef01d0fd83d385b.png"},30997:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_02-1a889fb0961d639f1cc2342df23df54e.png"},82567:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_03-ee9ff1a91a52d7bf3d9115119a84db04.png"},50755:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_04-168fef5c703a4ea32cfb4583bdd03812.png"},43932:(e,t,n)=>{n.d(t,{Z:()=>a});const a="data:image/png;base64,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"},14351:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_06-fa782b76e2e5162de6a009f467911ab7.png"},90737:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_07-d9fefbb7a560bf489c7c8659f8fd33a5.png"},38843:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_08-8fb4597183fe330436e8bc52059387aa.png"},43704:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_09-b2e692fbc6c17e79001510eeaec6ec7f.png"},7412:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_10-6d6e8b69f539d23fa1912fa995335fcf.png"},37094:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/05_Tensorflow_Unsupervised_Learning_11-655cbaf7a3680f431444733200450a03.png"},68225:(e,t,n)=>{n.d(t,{Z:()=>a});const a=n.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-da0f4433cfd061cf6ed148c34ca4eb14.jpg"}}]);