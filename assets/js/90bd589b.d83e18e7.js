"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[11933],{523398:(e,n,r)=>{r.r(n),r.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>d,frontMatter:()=>o,metadata:()=>s,toc:()=>l});var i=r(785893),t=r(603905);const o={sidebar_position:6090,slug:"2021-12-04",title:"OpenCV Image Objects",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},a=void 0,s={id:"IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/index",title:"OpenCV Image Objects",description:"Shenzhen, China",source:"@site/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects",slug:"/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/2021-12-04",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/2021-12-04",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2021-12-04--opencv-image-objects/index.md",tags:[{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Python",permalink:"/docs/tags/python"},{label:"OpenCV",permalink:"/docs/tags/open-cv"}],version:"current",sidebarPosition:6090,frontMatter:{sidebar_position:6090,slug:"2021-12-04",title:"OpenCV Image Objects",authors:"mpolinowski",tags:["Machine Learning","Python","OpenCV"]},sidebar:"tutorialSidebar",previous:{title:"OpenCV Face Detection and Privacy",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-05--opencv-face-detection/2021-12-05"},next:{title:"OpenCV Image Operations",permalink:"/docs/IoT-and-Machine-Learning/ML/2021-12-03--opencv-image-operations/2021-12-03"}},c={},l=[{value:"Setup OpenCV",id:"setup-opencv",level:2},{value:"Image Operations",id:"image-operations",level:2},{value:"Contour Detection",id:"contour-detection",level:3},{value:"Bitwise Operation",id:"bitwise-operation",level:3},{value:"Merging Images",id:"merging-images",level:4},{value:"Select Colour Range",id:"select-colour-range",level:4},{value:"Section Masking",id:"section-masking",level:4}];function p(e){const n={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.ah)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Shenzhen, China",src:r(249103).Z+"",width:"2385",height:"919"})}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#setup-opencv",children:"Setup OpenCV"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#image-operations",children:"Image Operations"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#contour-detection",children:"Contour Detection"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#bitwise-operation",children:"Bitwise Operation"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#merging-images",children:"Merging Images"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#select-colour-range",children:"Select Colour Range"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#section-masking",children:"Section Masking"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.a,{href:"https://github.com/mpolinowski/opencv-image-objects",children:"Github Repo"})}),"\n",(0,i.jsx)(n.h2,{id:"setup-opencv",children:"Setup OpenCV"}),"\n",(0,i.jsx)(n.p,{children:"Create and activate a virtual work environment:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"python -m venv .env\r\nsource .env/bin/activate\r\npython -m pip install --upgrade pip\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Add a file ",(0,i.jsx)(n.code,{children:"dependencies.txt"})," with all project ",(0,i.jsx)(n.strong,{children:"pip dependencies"}),":"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"opencv-python\r\nnumpy\r\nmatplotlib\n"})}),"\n",(0,i.jsx)(n.p,{children:"Install all dependencies with:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"pip install -r dependencies.txt\n"})}),"\n",(0,i.jsx)(n.h2,{id:"image-operations",children:"Image Operations"}),"\n",(0,i.jsx)(n.h3,{id:"contour-detection",children:"Contour Detection"}),"\n",(0,i.jsx)(n.p,{children:"Contour in image is an outline on the objects present in the image. The significance of the objects depend on the requirement and threshold you choose."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import cv2\r\nimport numpy as np\r\nfrom matplotlib import pyplot as plt\r\n\r\nimage = cv2.imread('resources/trafiko.jpg', cv2.IMREAD_UNCHANGED)\r\nimg_grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\r\n\r\n# Set binary tresholds\r\nret, img_threshold = cv2.threshold(img_grayscale, 127, 255, cv2.THRESH_BINARY)\r\ncv2.imshow(\"Object Contours\", img_threshold)\r\n\r\n# Find contours\r\ncontours, _ = cv2.findContours(img_threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\r\n\r\n# Create an empty image for contours\r\ncanvas = np.zeros(image.shape)\r\n\r\ni = 0\r\n\r\nfor contour in contours:\r\n    if i == 0:\r\n        i = 1\r\n        continue\r\n\r\n    # For each of the contours detected, the shape of the contours is\r\n    # approximated using approxPolyDP() function and the\r\n    # contours are drawn in the image using drawContours() function\r\n    approx = cv2.approxPolyDP(contour, 0.01*cv2.arcLength(contour, True), True)\r\n    # Draw polygons on the empty image\r\n    cv2.drawContours(canvas, [contour], 0, (0, 255, 0), 5)\r\n    # Find center of found shapes\r\n    M = cv2.moments(contour)\r\n    if M['m00'] != 0.0:\r\n        x = int(M['m10']/M['m00'])\r\n        y = int(M['m01']/M['m00'])\r\n    # Classifying shapes\r\n    if len(approx) == 3:\r\n       cv2.putText(canvas, 'Triangle', (x, y), cv2.QT_FONT_NORMAL, 0.6, (0, 255, 255), 2)\r\n    elif len(approx) == 4:\r\n       cv2.putText(canvas, 'Rectangle', (x, y), cv2.QT_FONT_NORMAL, 0.6, (255, 255, 255), 2)\r\n    elif len(approx) == 6:\r\n       cv2.putText(canvas, 'Hexagon', (x, y), cv2.QT_FONT_NORMAL, 0.6, (255, 0, 255), 2)\r\n    elif 6 < len(approx) < 15:\r\n       cv2.putText(canvas, 'Circle?', (x, y), cv2.QT_FONT_NORMAL, 0.6, (255, 255, 0), 2)\r\n\r\n# Display results\r\ncv2.imshow('Detected Shapes', canvas)\r\ncv2.imwrite('processed/shapes.jpg', canvas)\r\n\r\ncv2.waitKey(5000)\r\ncv2.destroyAllWindows()\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"OpenCV Image Objects",src:r(176625).Z+"",width:"1411",height:"707"})}),"\n",(0,i.jsx)(n.h3,{id:"bitwise-operation",children:"Bitwise Operation"}),"\n",(0,i.jsx)(n.p,{children:"To manipulating a given image or extract parts of it based on the requirement use of bitwise operators in OpenCV:"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"bitwise_and(source1_array, source2_array, destination_array, mask)"})}),"\n"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"source1_array"})," is the array corresponding to the first input image on which bitwise and operation is to be performed."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"source2_array"})," is the array corresponding to the second input image on which bitwise and operation is to be performed."]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"destination_array"})," is the resulting array by performing bitwise operation on the array corresponding to the first input image and the array corresponding to the second input image"]}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.code,{children:"mask"})," is the mask operation to be performed on the resulting image and it is optional."]}),"\n"]}),"\n",(0,i.jsx)(n.h4,{id:"merging-images",children:"Merging Images"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import cv2\r\nimport numpy as np\r\n\r\nimage_left = cv2.imread('resources/left.jpg')\r\nimage_right = cv2.imread('resources/right.jpg')\r\n\r\n#using bitwise_and operation on the given two images\r\nmerged_image = cv2.bitwise_and(image_left, image_right, mask = None)\r\n#displaying the merged image as the output on the screen\r\ncv2.imshow('Left Image', image_left)\r\ncv2.imshow('Right Image', image_right)\r\ncv2.imshow('Merged Image', merged_image)\r\ncv2.waitKey(0)\r\ncv2.destroyAllWindows()\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"OpenCV Image Objects",src:r(613660).Z+"",width:"1568",height:"337"})}),"\n",(0,i.jsx)(n.h4,{id:"select-colour-range",children:"Select Colour Range"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import cv2\r\nimport numpy as np\r\n\r\nimage_left = cv2.imread('resources/left.jpg')\r\nimage_right = cv2.imread('resources/right.jpg')\r\n\r\nimage_colour = cv2.imread('resources/on_fire.jpg')\r\n\r\n# Using bitwise_and operation on the given two images\r\nmerged_image = cv2.bitwise_and(image_left, image_right, mask = None)\r\n\r\n# Displaying the merged image as the output on the screen\r\ncv2.imshow('Left Image', image_left)\r\ncv2.imshow('Right Image', image_right)\r\ncv2.imshow('Merged Image', merged_image)\r\n\r\n# Working with colour masks\r\nrgb_conversion = cv2.cvtColor(image_colour, cv2.COLOR_BGR2RGB)\r\n\r\n# Define colour range in RGB\r\ndark_yellow = np.array([252, 170, 0])\r\nbright_yellow = np.array([255, 205, 114])\r\n\r\n# Select pixel within the defined colour range\r\nmask_yellow = cv2.inRange(rgb_conversion, dark_yellow, bright_yellow)\r\ncolour_range = cv2.bitwise_and(image_colour, image_colour, mask=mask_yellow)\r\n\r\ncv2.imshow('Original Image', image_colour)\r\ncv2.imshow('Colour Range Selection', colour_range)\r\n\r\ncv2.waitKey(0)\r\ncv2.destroyAllWindows()\n"})}),"\n",(0,i.jsx)(n.h4,{id:"section-masking",children:"Section Masking"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Bitwise masking\r\nimage_colour_copy = image_colour.copy()\r\n# Create mask with 100 rows, 300 columns and 3 colour channels\r\nmask = np.zeros((100 , 300, 3))\r\n# pos = (600, 600)\r\n# set position of upper left corner and lower right corner of mask\r\nvar = image_colour_copy[200:(200+mask.shape[0]), 200:(200+mask.shape[1])] = mask\r\ncv2.imshow('Masked Section', image_colour_copy)\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"OpenCV Image Objects",src:r(516586).Z+"",width:"2146",height:"552"})})]})}function d(e={}){const{wrapper:n}={...(0,t.ah)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(p,{...e})}):p(e)}},603905:(e,n,r)=>{r.d(n,{ah:()=>l});var i=r(667294);function t(e,n,r){return n in e?Object.defineProperty(e,n,{value:r,enumerable:!0,configurable:!0,writable:!0}):e[n]=r,e}function o(e,n){var r=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),r.push.apply(r,i)}return r}function a(e){for(var n=1;n<arguments.length;n++){var r=null!=arguments[n]?arguments[n]:{};n%2?o(Object(r),!0).forEach((function(n){t(e,n,r[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(r)):o(Object(r)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(r,n))}))}return e}function s(e,n){if(null==e)return{};var r,i,t=function(e,n){if(null==e)return{};var r,i,t={},o=Object.keys(e);for(i=0;i<o.length;i++)r=o[i],n.indexOf(r)>=0||(t[r]=e[r]);return t}(e,n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(i=0;i<o.length;i++)r=o[i],n.indexOf(r)>=0||Object.prototype.propertyIsEnumerable.call(e,r)&&(t[r]=e[r])}return t}var c=i.createContext({}),l=function(e){var n=i.useContext(c),r=n;return e&&(r="function"==typeof e?e(n):a(a({},n),e)),r},p={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},d=i.forwardRef((function(e,n){var r=e.components,t=e.mdxType,o=e.originalType,c=e.parentName,d=s(e,["components","mdxType","originalType","parentName"]),g=l(r),h=t,m=g["".concat(c,".").concat(h)]||g[h]||p[h]||o;return r?i.createElement(m,a(a({ref:n},d),{},{components:r})):i.createElement(m,a({ref:n},d))}));d.displayName="MDXCreateElement"},176625:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/OpenCV_Object_Detection_01-a45d1c10eeb7ddf7833c197e0beb63ea.png"},613660:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/OpenCV_Object_Detection_02-d8e415e3af43f6a97372c181b8433c9a.png"},516586:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/OpenCV_Object_Detection_03-8f8f3c41b87c397889a00bfc183f66dc.png"},249103:(e,n,r)=>{r.d(n,{Z:()=>i});const i=r.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-5a0b68587d9242bbb46a1f1aaab44216.jpg"}}]);