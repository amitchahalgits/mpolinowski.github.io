"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[79544],{171147:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>o,contentTitle:()=>s,default:()=>_,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var t=a(785893),r=a(603905);const i={sidebar_position:4540,slug:"2023-03-11",title:"Tensorflow 2 - Transfer Learning",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Fine-tuning Pre-trained Models"},s="Tensorflow Transfer Learning",l={id:"IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/index",title:"Tensorflow 2 - Transfer Learning",description:"Fine-tuning Pre-trained Models",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning",slug:"/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4540,frontMatter:{sidebar_position:4540,slug:"2023-03-11",title:"Tensorflow 2 - Transfer Learning",authors:"mpolinowski",tags:["Python","Machine Learning","Tensorflow"],description:"Fine-tuning Pre-trained Models"},sidebar:"tutorialSidebar",previous:{title:"Tensorflow 2 - Transfer Learning",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16"},next:{title:"Tensorflow 2 - Transfer Learning",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06"}},o={},c=[{value:"Fine-tuning Pre-trained Models",id:"fine-tuning-pre-trained-models",level:2},{value:"Model 0",id:"model-0",level:3},{value:"Model 0",id:"model-0-1",level:3},{value:"Model 1",id:"model-1",level:3},{value:"Add Augmentation Layer",id:"add-augmentation-layer",level:4},{value:"Model 2",id:"model-2",level:3},{value:"Adding ModelCheckpoint Callback",id:"adding-modelcheckpoint-callback",level:3},{value:"Restoring Model from Checkpoint",id:"restoring-model-from-checkpoint",level:3},{value:"Model Fine-tuning",id:"model-fine-tuning",level:2},{value:"Re-Run the Training",id:"re-run-the-training",level:3},{value:"Final Training",id:"final-training",level:2}];function d(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.ah)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Victoria Harbour, Hongkong",src:a(300890).Z+"",width:"1500",height:"618"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#tensorflow-transfer-learning",children:"Tensorflow Transfer Learning"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#fine-tuning-pre-trained-models",children:"Fine-tuning Pre-trained Models"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#model-0",children:"Model 0"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#model-0-1",children:"Model 0"})}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#model-1",children:"Model 1"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#add-augmentation-layer",children:"Add Augmentation Layer"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#model-2",children:"Model 2"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#adding-modelcheckpoint-callback",children:"Adding ModelCheckpoint Callback"})}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#restoring-model-from-checkpoint",children:"Restoring Model from Checkpoint"})}),"\n"]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.a,{href:"#model-fine-tuning",children:"Model Fine-tuning"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#re-run-the-training",children:"Re-Run the Training"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.li,{children:(0,t.jsx)(n.a,{href:"#final-training",children:"Final Training"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.a,{href:"https://github.com/mpolinowski/tf-2023",children:"Github Repository"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"See also:"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Fun, fun, tensors: ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-19-tensorflow-introduction/2023-02-19",children:"Tensor Constants, Variables and Attributes"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-21-tensorflow-tensors-2/2023-02-21",children:"Tensor Indexing, Expanding and Manipulations"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-22-tensorflow-tensors-3/2023-02-22",children:"Matrix multiplications, Squeeze, One-hot and Numpy"})]}),"\n",(0,t.jsxs)(n.li,{children:["Tensorflow 2 - Neural Network Regression: ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-23-tensorflow-neural-network-regression/2023-02-23",children:"Building a Regression Model"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-24-tensorflow-neural-network-regression-evaluation/2023-02-24",children:"Model Evaluation"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-25-tensorflow-neural-network-regression-experiments/2023-02-25",children:"Model Optimization"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-real-dataset/2023-02-26",children:'Working with a "Real" Dataset'}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-26-tensorflow-neural-network-regression-data-preprocessing/2023-02-26",children:"Feature Scaling"})]}),"\n",(0,t.jsxs)(n.li,{children:["Tensorflow 2 - Neural Network Classification: ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-27-tensorflow-neural-network-classification/2023-02-27",children:"Non-linear Data and Activation Functions"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-28-tensorflow-neural-network-classification-model-evaluation/2023-02-28",children:"Model Evaluation and Performance Improvement"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-02-tensorflow-neural-network-multi-classification/2023-03-02",children:"Multiclass Classification Problems"})]}),"\n",(0,t.jsxs)(n.li,{children:["Tensorflow 2 - Convolutional Neural Networks: ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-03-tensorflow-convolutional-neural-network-binary-classifications/2023-03-03",children:"Binary Image Classification"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-05-tensorflow-convolutional-neural-network-multiclass-classifications/2023-03-05",children:"Multiclass Image Classification"})]}),"\n",(0,t.jsxs)(n.li,{children:["Tensorflow 2 - Transfer Learning: ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-06-tensorflow-transfer-learning-feature-extraction/2023-03-06",children:"Feature Extraction"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-11-tensorflow-transfer-learning-fine-tuning/2023-03-11",children:"Fine-Tuning"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-16-tensorflow-transfer-learning-scaling/2023-03-16",children:"Scaling"})]}),"\n",(0,t.jsxs)(n.li,{children:["Tensorflow 2 - Unsupervised Learning: ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-24-tensorflow-unsupervised-learning-autoencoders/2023-03-24",children:"Autoencoder Feature Detection"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-autoencoders-super-resolution/2023-03-26",children:"Autoencoder Super-Resolution"}),", ",(0,t.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-03-26-tensorflow-unsupervised-learning-generative-adversial-networks/2023-03-26",children:"Generative Adverserial Networks"})]}),"\n"]}),"\n",(0,t.jsx)(n.h1,{id:"tensorflow-transfer-learning",children:"Tensorflow Transfer Learning"}),"\n",(0,t.jsx)(n.p,{children:"Transfer Learning leverages a pretrained model that is already extremely performant on general feature detection. Our work will be to re-train this model on our specific dataset and add the specialized knowledge needed to solve our task."}),"\n",(0,t.jsx)(n.p,{children:"Since the model is already pre-trained we can expect that we will only need about 10% of the amount of data that would be needed to train a fresh model."}),"\n",(0,t.jsx)(n.h2,{id:"fine-tuning-pre-trained-models",children:"Fine-tuning Pre-trained Models"}),"\n",(0,t.jsxs)(n.p,{children:["Using a pre-trained model from ",(0,t.jsx)(n.a,{href:"https://www.tensorflow.org/api_docs/python/tf/keras/applications",children:"tf.keras.applictions"})," and fine-tuning it to our problem."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"import datetime\nimport matplotlib.image as mpimg\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport tensorflow as tf\nfrom tensorflow.keras.utils import image_dataset_from_directory\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# global variables\nSEED = 42\nBATCH_SIZE = 32\nIMG_SHAPE = (224, 224)\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# export helper functions from above into helper script\nfrom helper import create_tensorboard_callback, create_checkpoint_callback, plot_accuracy_curves, combine_training_curves\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# get 10% dataset\n# wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n\n# set directories for 10% dataset\ntraining_directory_10 = \"../datasets/10_food_classes_10_percent/train/\"\ntesting_directory_10 = \"../datasets/10_food_classes_10_percent/test/\"\n\ntraining_data_10 = image_dataset_from_directory(training_directory_10,\n                                              labels='inferred',\n                                              label_mode='categorical',\n                                              seed=SEED,\n                                              shuffle=True,\n                                              image_size=IMG_SHAPE,\n                                              batch_size=BATCH_SIZE)\n\ntesting_data_10 = image_dataset_from_directory(testing_directory_10,\n                                              labels='inferred',\n                                              label_mode='categorical',\n                                              seed=SEED,\n                                              shuffle=True,\n                                              image_size=IMG_SHAPE,\n                                              batch_size=BATCH_SIZE)\n\n# get class names\nclass_names_10 = training_data_10.class_names\n\nlen(class_names_10), class_names_10 \n\n# Found 750 files belonging to 10 classes.\n# Found 2500 files belonging to 10 classes.\n\n# (10,\n#  ['chicken_curry',\n#   'chicken_wings',\n#   'fried_rice',\n#   'grilled_salmon',\n#   'hamburger',\n#   'ice_cream',\n#   'pizza',\n#   'ramen',\n#   'steak',\n#   'sushi'])\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# inspect first image batch\n## BatchDataset returns the image data matrices + 1-hot-encoded label matrix\nfor images, labels in training_data_10.take(1):\n    print(images, labels)\n"})}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Start by using ",(0,t.jsx)(n.a,{href:"https://www.tensorflow.org/api_docs/python/tf/keras/applications/efficientnet_v2/EfficientNetV2B0",children:"EfficientNetV2B0"})," as a ",(0,t.jsx)(n.strong,{children:"Feature Extractor"})," (all layers frozen, ImageNet pretrained and without top)."]}),"\n",(0,t.jsx)(n.li,{children:"Find a good sample size to optimize training (data augmentation)."}),"\n",(0,t.jsx)(n.li,{children:"Unfreeze layers from the pre-trained model and run fine-tuning (top 10 layers unfrozen)."}),"\n"]}),"\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Experiment"}),(0,t.jsx)(n.th,{children:"Data"}),(0,t.jsx)(n.th,{children:"Pre-processing"}),(0,t.jsx)(n.th,{children:"Model"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Model 0"}),(0,t.jsx)(n.td,{children:"10% Dataset"}),(0,t.jsx)(n.td,{children:"None"}),(0,t.jsx)(n.td,{children:"Feature Extraction: EfficientNetB0"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Model 1"}),(0,t.jsx)(n.td,{children:"1% Dataset"}),(0,t.jsx)(n.td,{children:"Augmented"}),(0,t.jsx)(n.td,{children:"same as Model 0"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Model 2"}),(0,t.jsx)(n.td,{children:"same as Model 0"}),(0,t.jsx)(n.td,{children:"same as Model 1"}),(0,t.jsx)(n.td,{children:"same as Model 0"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Model 3"}),(0,t.jsx)(n.td,{children:"same as Model 0"}),(0,t.jsx)(n.td,{children:"same as Model 1"}),(0,t.jsx)(n.td,{children:"Fine-tuning: EfficientNetB0"})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Model 4"}),(0,t.jsx)(n.td,{children:"100% Dataset"}),(0,t.jsx)(n.td,{children:"same as Model 1"}),(0,t.jsx)(n.td,{children:"same as Model 3"})]})]})]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Transfer Learning",src:a(821733).Z+"",width:"1220",height:"203"})}),"\n",(0,t.jsx)(n.h3,{id:"model-0",children:"Model 0"}),"\n",(0,t.jsx)(n.p,{children:"Using 10% of the training data and extract feature vectors using EfficientNetB0 from Keras Applications."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# build a model from tf.keras.applications\n# using the keras functional API\n\n# get base model from keras applications\nbase_model = tf.keras.applications.efficientnet.EfficientNetB0(\n    include_top=False\n)\n\n# freeze all layers (don\'t update pre-learned pattern)\nbase_model.trainable = False\n\n# create input layer\ninput_layer = tf.keras.layers.Input(shape=IMG_SHAPE+(3,), name=\'input_layer\')\n\n# start by normalizing your data (not necessary for efficientnet)\n# data = tf.keras.layers.Rescaling(1./255)(input_layer)\n\n# pass (normalized) inputs to base model\ndata = base_model(input_layer)\nprint(f"INFO :: Input Shape: {data.shape}")\n# INFO :: Input Shape: (None, 7, 7, 1280)\n\n# average pool outputs of the base model\ndata = tf.keras.layers.GlobalAveragePooling2D(name="global_average_pooling_layer")(data)\nprint(f"INFO :: Feature Vector Shape: {data.shape}")\n# INFO :: Feature Vector Shape: (None, 1280)\n\n# create output layer\noutput_layer = tf.keras.layers.Dense(10, activation="softmax", name="output_layer")(data)\n\n# build the model 0\nmodel_0 = tf.keras.Model(input_layer, output_layer)\n\n# compile model 0\nmodel_0.compile(loss=\'categorical_crossentropy\',\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=[\'accuracy\'])\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# check model_0\nmodel_0.summary()\n# Model: "model_2"\n# _________________________________________________________________\n#  Layer (type)                Output Shape              Param #   \n# =================================================================\n#  input_layer (InputLayer)    [(None, 224, 224, 3)]     0\n#  efficientnetb0 (Functional)  (None, None, None, 1280) 4049571\n#  global_average_pooling_laye  (None, 1280)             0         \n#  r (GlobalAveragePooling2D)\n#  output_layer (Dense)        (None, 10)                12810\n# =================================================================\n# Total params: 4,062,381\n# Trainable params: 12,810\n# Non-trainable params: 4,049,571\n# _________________________________________________________________\n\n# check base_model layers\nfor layer_number, layer in enumerate(base_model.layers):\n    print(layer_number, layer.name)\n    \n# 0 input_5\n# 1 rescaling_5\n# 2 normalization_2\n# 3 rescaling_6\n# 4 stem_conv_pad\n# 5 stem_conv\n# 6 stem_bn\n# 7 stem_activation\n# 8 block1a_dwconv\n# ...\n# 234 block7a_project_bn\n# 235 top_conv\n# 236 top_bn\n# 237 top_activation\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# fit model 0\nhistory_model_0 = model_0.fit(\n                                training_data_10,\n                                epochs=5,\n                                steps_per_epoch=len(training_data_10),\n                                validation_data=testing_data_10,\n                                # speed up validation by skipping 75%\n                                validation_steps=int(0.25 * len(testing_data_10)),\n                                callbacks=[create_tensorboard_callback(\n                                            '../tensorboard/transfer_learning',\n                                            '10_percent_feature_extraction')\n                                          ])\n\n# Epoch 5/5\n# 6s 267ms/step - loss: 0.5430 - accuracy: 0.8773 - val_loss: 0.5211 - val_accuracy: 0.8799\n"})}),"\n",(0,t.jsx)(n.h3,{id:"model-0-1",children:"Model 0"}),"\n",(0,t.jsx)(n.p,{children:"Same as above but using the EfficientNet v2 B0 model."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"base_model_2 = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n# run in inference mode so batchnorm statistics don't get updated\n# even after unfreezing the base model for fine-tuning\nbase_model_2.trainable = False\n\ninput_layer_2 = tf.keras.layers.Input(shape=IMG_SHAPE+(3,), name='input_layer')\n# run in inference mode so batchnorm statistics don't get updated\n# even after unfreezing the base model for fine-tuning\ndata_2 = base_model_2(input_layer_2, training=False)\ndata_2 = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(data_2)\noutput_layer_2 = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(data_2)\n\nmodel_0_2 = tf.keras.Model(input_layer_2, output_layer_2)\n\nmodel_0_2.compile(loss='categorical_crossentropy',\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=['accuracy'])\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# fit model 0\nhistory_model_0_2 = model_0_2.fit(\n                                training_data_10,\n                                epochs=5,\n                                steps_per_epoch=len(training_data_10),\n                                validation_data=testing_data_10,\n                                # speed up validation by skipping 75%\n                                validation_steps=int(0.25 * len(testing_data_10)),\n                                callbacks=[create_tensorboard_callback(\n                                            '../tensorboard/transfer_learning',\n                                            '10_percent_feature_extraction_model_2')\n                                          ])\n\n# Epoch 5/5\n# 5s 222ms/step - loss: 0.6073 - accuracy: 0.8707 - val_loss: 0.5628 - val_accuracy: 0.8536\n"})}),"\n",(0,t.jsx)(n.h3,{id:"model-1",children:"Model 1"}),"\n",(0,t.jsx)(n.p,{children:"Before I used 10% of the training dataset. Let's try using only 1% while leveraging Tensorflows augmentation functions to add variations to our dataset."}),"\n",(0,t.jsx)(n.p,{children:"The idea is to find the absolut minimum of 'effort' with a small dataset and a light-weight base model to get started with. Experiment with this setup that gives you fast results. And once it is working reasonably well add more training data as well as model complexity to find the maximum in prediction accuracy."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# get 1% dataset\n# wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_1_percent.zip\n\n# set directories for 1% dataset\ntraining_directory_1 = \"../datasets/10_food_classes_1_percent/train/\"\ntesting_directory_1 = \"../datasets/10_food_classes_1_percent/test/\"\n\ntraining_data_1 = image_dataset_from_directory(training_directory_1,\n                                              labels='inferred',\n                                              label_mode='categorical',\n                                              seed=SEED,\n                                              shuffle=True,\n                                              image_size=IMG_SHAPE,\n                                              batch_size=BATCH_SIZE)\n\ntesting_data_1 = image_dataset_from_directory(testing_directory_1,\n                                              labels='inferred',\n                                              label_mode='categorical',\n                                              seed=SEED,\n                                              shuffle=True,\n                                              image_size=IMG_SHAPE,\n                                              batch_size=BATCH_SIZE)\n\n# get class names\nclass_names_1 = training_data_1.class_names\n\nlen(class_names_1), class_names_1 \n\n# Found 70 files belonging to 10 classes.\n# Found 2500 files belonging to 10 classes.\n\n# (10,\n#  ['chicken_curry',\n#   'chicken_wings',\n#   'fried_rice',\n#   'grilled_salmon',\n#   'hamburger',\n#   'ice_cream',\n#   'pizza',\n#   'ramen',\n#   'steak',\n#   'sushi'])\n"})}),"\n",(0,t.jsx)(n.h4,{id:"add-augmentation-layer",children:"Add Augmentation Layer"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'data_augmentation_layer = tf.keras.Sequential([\n    tf.keras.layers.RandomFlip("horizontal_and_vertical"),\n    tf.keras.layers.RandomRotation(0.2),\n    tf.keras.layers.RandomZoom(0.1),\n    tf.keras.layers.RandomContrast(0.2),\n    tf.keras.layers.RandomBrightness(0.2),\n    tf.keras.layers.RandomTranslation(0.1, 0.1),\n    # tf.keras.layers.Rescaling(1./255) # not needed for EfficientNet\n], name="data_augmentation_layer")\n'})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'# visualize augmentations\n## pick random image from training set\ntarget_class = random.choice(class_names_1)\ntarget_dir = training_directory_1 + target_class\nrandom_image = random.choice(os.listdir(target_dir))\nrandom_image_path = target_dir + \'/\' + random_image\nimg = mpimg.imread(random_image_path)\n\n# run image through aug layer\naugmented_img = data_augmentation_layer(img, training=True)\n\nplt.figure(figsize=(12, 12))\nplt.subplot(2, 2, 1)\nplt.title(f"Original Image :: Class => {target_class}")\nplt.axis(False)\nplt.imshow(img)\nplt.subplot(2, 2, 2)\nplt.title("Augmented Image")\nplt.axis(False)\nplt.imshow(augmented_img/255)\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Tensorflow Transfer Learning",src:a(992353).Z+"",width:"950",height:"357"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# build model 1\nbase_model1 = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\nbase_model1.trainable = False\n\ninput_layer1 = tf.keras.layers.Input(shape=IMG_SHAPE+(3,), name='input_layer')\ndata1 = data_augmentation_layer(input_layer1)\n# run in inference mode so batchnorm statistics don't get updated\n# even after unfreezing the base model for fine-tuning\ndata1 = base_model1(data1, training=False)\ndata1 = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(data1)\noutput_layer1 = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(data1)\n\nmodel_1 = tf.keras.Model(input_layer1, output_layer1)\n\nmodel_1.compile(loss='categorical_crossentropy',\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=['accuracy'])\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# fit model 1\nhistory_model_1 = model_1.fit(\n                                training_data_1,\n                                epochs=5,\n                                steps_per_epoch=len(training_data_1),\n                                validation_data=testing_data_1,\n                                # speed up validation by skipping 75%\n                                validation_steps=int(0.25 * len(testing_data_1)),\n                                callbacks=[create_tensorboard_callback(\n                                            '../tensorboard/transfer_learning',\n                                            '1_percent_feature_extraction_model')\n                                          ])\n\n# Epoch 5/5\n# 4s 2s/step - loss: 1.7357 - accuracy: 0.5286 - val_loss: 1.9652 - val_accuracy: 0.3372\n\n# even with only 1% of the data there is still a 34% accuracy over ten\n# classes - while the original paper achieved ~50% over 101 classes\n# https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/\n"})}),"\n",(0,t.jsx)(n.h3,{id:"model-2",children:"Model 2"}),"\n",(0,t.jsx)(n.p,{children:"Let's try the augmentation layer on 10% of the dataset - so the same as model 0 but with added augmentations."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"base_model2 = tf.keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=False)\n# run in inference mode so batchnorm statistics don't get updated\n# even after unfreezing the base model for fine-tuning\nbase_model2.trainable = False\n\ninput_layer2 = tf.keras.layers.Input(shape=IMG_SHAPE+(3,), name='input_layer')\ndata2 = data_augmentation_layer(input_layer2)\n# run in inference mode so batchnorm statistics don't get updated\n# even after unfreezing the base model for fine-tuning\ndata2 = base_model2(data2, training=False)\ndata2 = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(data2)\noutput_layer2 = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"output_layer\")(data2)\n\nmodel_2 = tf.keras.Model(input_layer2, output_layer2)\n\nmodel_2.compile(loss='categorical_crossentropy',\n               optimizer=tf.keras.optimizers.Adam(),\n               metrics=['accuracy'])\n"})}),"\n",(0,t.jsx)(n.h3,{id:"adding-modelcheckpoint-callback",children:"Adding ModelCheckpoint Callback"}),"\n",(0,t.jsxs)(n.p,{children:["Added to ",(0,t.jsx)(n.code,{children:"helper.py"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"# create a training checkpoint callback\ndef create_checkpoint_callback(dir_name, experiment_name):\n    # log progress to log directory\n    filepath = dir_name + \"/\" + experiment_name\n    tf.keras.callbacks.ModelCheckpoint(\n        filepath=filepath, monitor='val_accuracy', verbose=0, save_best_only=True,\n        save_weights_only=True, save_freq='epoch')\n    print(f\"Saving Checkpoint to: {filepath}\")\n    return checkpoint_callback\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# fit model 2\n# training epochs before fine-tuning\npretraining_epochs = 5\n\nhistory_model_2 = model_2.fit(\n                                training_data_10,\n                                epochs=pretraining_epochs,\n                                steps_per_epoch=len(training_data_10),\n                                validation_data=testing_data_10,\n                                validation_steps=len(testing_data_10),\n                                callbacks=[create_tensorboard_callback(\n                                            '../tensorboard/transfer_learning',\n                                            '10_percent_feature_extraction_model_augmented'),\n                                           create_checkpoint_callback('../checkpoints/transfer_learning',\n                                            '10_percent_feature_extraction_model_augmented')\n                                          ])\n\n# Epoch 5/5\n# 15s 634ms/step - loss: 0.9873 - accuracy: 0.7307 - val_loss: 0.8316 - val_accuracy: 0.7724\n# INFO :: Saving TensorBoard Log to: ../tensorboard/transfer_learning/10_percent_feature_extraction_model_augmented/20230315-135701\n# INFO :: Saving Checkpoint to: ../checkpoints/transfer_learning/10_percent_feature_extraction_model_augmented\n"})}),"\n",(0,t.jsx)(n.h3,{id:"restoring-model-from-checkpoint",children:"Restoring Model from Checkpoint"}),"\n",(0,t.jsxs)(n.p,{children:["The ",(0,t.jsx)(n.strong,{children:"ModelCheckpoint"})," callback allows us to return a compiled model back to a past state by loading the saved weights that were generated by a previous training."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# check current validation metrics\nmodel_2_validation_metric_5_epochs = model_2.evaluate(testing_data_10)\nprint(model_2_validation_metric_5_epochs)\n\n# 79/79 [==============================] - 6s 73ms/step - loss: 0.8056 - accuracy: 0.7972\n# [0.805601179599762, 0.7972000241279602]\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# load latest checkpoint and \"restore\" weights\ncheckpoint_path = '../checkpoints/transfer_learning/10_percent_feature_extraction_model_augmented/20230312-201041'\nmodel_2.load_weights(checkpoint_path)\n\n# check validation metrics from loaded weights\nmodel_2_validation_metric_5_epochs_loaded = model_2.evaluate(testing_data_10)\nprint(model_2_validation_metric_5_epochs_loaded)\n\n# 79/79 [==============================] - 6s 74ms/step - loss: 0.6724 - accuracy: 0.8320\n# [0.6724268794059753, 0.8320000171661377]\n"})}),"\n",(0,t.jsx)(n.h2,{id:"model-fine-tuning",children:"Model Fine-tuning"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Freeze the imported model and find best parameters to use it for your prediction problem (as done above)."}),"\n",(0,t.jsx)(n.li,{children:"Train the model with found parameters on a large dataset from your porediction problem."}),"\n",(0,t.jsx)(n.li,{children:'Unfreeze "some" of the layers of the imported model and re-run the training to fine-tune your model.'}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# layers in the trained model\nmodel_2.layers\n\n# [<keras.engine.input_layer.InputLayer at 0x7faa5f7b3df0>,\n#  <keras.engine.sequential.Sequential at 0x7faa5f7b2380>,\n#  <keras.engine.functional.Functional at 0x7faa3ffaf4f0>,\n#  <keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D at 0x7fa9d069fb80>,\n#  <keras.layers.core.dense.Dense at 0x7fa9d07c0eb0>]\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# trainable layers in model\n\nfor layer in model_2.layers:\n    print(layer, layer.trainable)\n    \n# <keras.engine.input_layer.InputLayer object at 0x7faa5f7b3df0> True\n# <keras.engine.sequential.Sequential object at 0x7faa5f7b2380> True\n# <keras.engine.functional.Functional object at 0x7faa3ffaf4f0> False\n# <keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D object at 0x7fa9d069fb80> True\n# <keras.layers.core.dense.Dense object at 0x7fa9d07c0eb0> True\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# layer 2 is the frozen imported model (efficientnetb0)\nfor layer_number, layer in enumerate(model_2.layers[2].layers):\n    print(layer_number, layer.name, layer.trainable)\n    \n# 0 input_1 False\n# 1 rescaling False\n# 2 normalization False\n# 3 stem_conv False\n# 4 stem_bn False\n# 5 stem_activation False\n# ...\n# 257 block6h_activation False\n# 258 block6h_se_squeeze False\n# 259 block6h_se_reshape False\n# 260 block6h_se_reduce False\n# 261 block6h_se_expand False\n# 262 block6h_se_excite False\n# 263 block6h_project_conv False\n# 264 block6h_project_bn False\n# 265 block6h_drop False\n# 266 block6h_add False\n# 267 top_conv False\n# 268 top_bn False\n# 269 top_activation False\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# the entire model is frozen for now\nprint(len(model_2.layers[2].trainable_variables))\n# 0\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# make last 10 layers trainable\n## unfreeze ALL layers\nbase_model2.trainable = True\n\n## re-freeze ALL BUT the last 10 layers\nfor layer in base_model2.layers[:-10]:\n    layer.trainable = False\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# we now have 10 trainable layers\nprint(len(model_2.layers[2].trainable_variables))\n# 10\n\nfor layer in base_model2.layers[-10:]:\n    print(layer.name, layer.trainable)\n# block6h_se_reduce True\n# block6h_se_expand True\n# block6h_se_excite True\n# block6h_project_conv True\n# block6h_project_bn True\n# block6h_drop True\n# block6h_add True\n# top_conv True\n# top_bn True\n# top_activation True\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# recompile the model with the new basemodel\n# to prevent overfitting / to better hold on to pre-training\n# the learning rate during fine-tuning should be lowered 10x\n# default Adam(lr)=1e-3 => 1e-4\nmodel_2.compile(loss='categorical_crossentropy',\n               optimizer=tf.keras.optimizers.Adam(1e-4),\n               metrics=['accuracy'])\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"for layer_number, layer in enumerate(model_2.layers[2].layers):\n    print(layer_number, layer.name, layer.trainable)\n    \n# the model is now compiled with the 10 new trainable layers from base_model (efficientnetb0)\n# 0 input_1 False\n# 1 rescaling False\n# 2 normalization False\n# 3 stem_conv False\n# 4 stem_bn False\n# 5 stem_activation False\n# ...\n# 257 block6h_activation False\n# 258 block6h_se_squeeze False\n# 259 block6h_se_reshape False\n# 260 block6h_se_reduce True\n# 261 block6h_se_expand True\n# 262 block6h_se_excite True\n# 263 block6h_project_conv True\n# 264 block6h_project_bn True\n# 265 block6h_drop True\n# 266 block6h_add True\n# 267 top_conv True\n# 268 top_bn True\n# 269 top_activation True\n"})}),"\n",(0,t.jsx)(n.h3,{id:"re-run-the-training",children:"Re-Run the Training"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# fit model 2\nfine_tuning_epochs = pretraining_epochs + 5\n\nfine_tuning_model_2 = model_2.fit(\n                    training_data_10,\n                    epochs = fine_tuning_epochs,\n                    # start from last pre-training checkpoint\n                    # training from epoch 6 - 10\n                    initial_epoch = history_model_2.epoch[-1],\n                    steps_per_epoch = len(training_data_10),\n                    validation_data = testing_data_10,\n                    validation_steps = len(testing_data_10),\n                    callbacks = [create_tensorboard_callback(\n                                '../tensorboard/transfer_learning',\n                                '10_percent_feature_extraction_model_augmented_finetuning'),\n                               create_checkpoint_callback('../checkpoints/transfer_learning',\n                                '10_percent_feature_extraction_model_augmented_finetuning')\n                              ])\n\n# Epoch 10/10\n# 15s 640ms/step - loss: 0.5083 - accuracy: 0.8480 - val_loss: 0.4590 - val_accuracy: 0.8432\n# INFO :: Saving Checkpoint to: ../checkpoints/transfer_learning/10_percent_feature_extraction_model_augmented_finetuning\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:'plot_accuracy_curves(history_model_2, "Pre-Training", fine_tuning_model_2, "Fine-Tuning")\n'})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Fine-tuning Pre-trained Models",src:a(163457).Z+"",width:"981",height:"505"})}),"\n",(0,t.jsxs)(n.p,{children:["Added helper function to ",(0,t.jsx)(n.code,{children:"helper.py"}),":"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-py",children:"def combine_training_curves(original_history, new_history, pretraining_epochs):\n    # Get original history measurements\n    acc = original_history.history[\"accuracy\"]\n    loss = original_history.history[\"loss\"]\n\n    print(len(acc))\n\n    val_acc = original_history.history[\"val_accuracy\"]\n    val_loss = original_history.history[\"val_loss\"]\n\n    # Combine original history with new history\n    total_acc = acc + new_history.history[\"accuracy\"]\n    total_loss = loss + new_history.history[\"loss\"]\n\n    total_val_acc = val_acc + new_history.history[\"val_accuracy\"]\n    total_val_loss = val_loss + new_history.history[\"val_loss\"]\n\n    print(len(total_acc))\n    print(total_acc)\n\n    # Make plots\n    plt.figure(figsize=(8, 8))\n    plt.subplot(2, 1, 1)\n    plt.plot(total_acc, label='Training Accuracy')\n    plt.plot(total_val_acc, label='Validation Accuracy')\n    plt.plot([pretraining_epochs-1, pretraining_epochs-1],\n              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n    plt.legend(loc='lower right')\n    plt.title('Training and Validation Accuracy')\n\n    plt.subplot(2, 1, 2)\n    plt.plot(total_loss, label='Training Loss')\n    plt.plot(total_val_loss, label='Validation Loss')\n    plt.plot([pretraining_epochs-1, pretraining_epochs-1],\n              plt.ylim(), label='Start Fine Tuning') # reshift plot around epochs\n    plt.legend(loc='upper right')\n    plt.title('Training and Validation Loss')\n    plt.xlabel('epoch')\n    plt.show()\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"combine_training_curves(history_model_2, fine_tuning_model_2, pretraining_epochs=5)\n\n# 5\n# 11\n# [0.2879999876022339, 0.6066666841506958, 0.671999990940094, 0.7293333411216736, 0.7639999985694885, 0.7879999876022339, 0.8173333406448364, 0.8199999928474426, 0.8053333163261414, 0.8346666693687439, 0.8413333296775818]\n\n# The fine-tuning works - accuracy keeps going up during the tuning epochs:\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Fine-tuning Pre-trained Models",src:a(48).Z+"",width:"680",height:"701"})}),"\n",(0,t.jsx)(n.h2,{id:"final-training",children:"Final Training"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsx)(n.li,{children:"Finding parameters to train simple pre-trained models with small datasets."}),"\n",(0,t.jsx)(n.li,{children:"Find the right amount of layers to unfreeze for fine-tuning the pre-trained model."}),"\n",(0,t.jsx)(n.li,{children:"Train the developed model with the found parameters on your whole dataset."}),"\n"]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# get 100% dataset\n# wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_all_data.zip\n\n# set directories for 10% dataset\ntraining_directory_100 = \"../datasets/10_food_classes_all_data/train/\"\ntesting_directory_100 = \"../datasets/10_food_classes_all_data/test/\"\n\ntraining_data_100 = image_dataset_from_directory(training_directory_100,\n                                              labels='inferred',\n                                              label_mode='categorical',\n                                              seed=SEED,\n                                              shuffle=True,\n                                              image_size=IMG_SHAPE,\n                                              batch_size=BATCH_SIZE)\n\ntesting_data_100 = image_dataset_from_directory(testing_directory_100,\n                                              labels='inferred',\n                                              label_mode='categorical',\n                                              seed=SEED,\n                                              shuffle=True,\n                                              image_size=IMG_SHAPE,\n                                              batch_size=BATCH_SIZE)\n\n# get class names\nclass_names_100 = training_data_100.class_names\n\nlen(class_names_100), class_names_100 \n\n# Found 7500 files belonging to 10 classes.\n# Found 2500 files belonging to 10 classes.\n\n# (10,\n#  ['chicken_curry',\n#   'chicken_wings',\n#   'fried_rice',\n#   'grilled_salmon',\n#   'hamburger',\n#   'ice_cream',\n#   'pizza',\n#   'ramen',\n#   'steak',\n#   'sushi'])\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# run the training\n\nmodel_2.compile(loss='categorical_crossentropy',\n               optimizer=tf.keras.optimizers.Adam(1e-4),\n               metrics=['accuracy'])\n\nfinal_training_epochs = fine_tuning_epochs + 5\n\nhistory_model_2_full = model_2.fit(\n                    training_data_100,\n                    epochs = final_training_epochs,\n                    # start from last fine tuning checkpoint\n                    # training from epoch 11 - 15\n                    initial_epoch = fine_tuning_model_2.epoch[-1],\n                    steps_per_epoch = len(training_data_100),\n                    validation_data = testing_data_100,\n                    validation_steps = int(0.25 * len(testing_data_100)),\n                    callbacks = [create_tensorboard_callback(\n                                '../tensorboard/transfer_learning',\n                                '100_percent_feature_extraction_model'),\n                               create_checkpoint_callback('../checkpoints/transfer_learning',\n                                '100_percent_feature_extraction_model')\n                              ])\n\n# Epoch 15/15\n# 70s 299ms/step - loss: 0.5249 - accuracy: 0.8344 - val_loss: 0.3030 - val_accuracy: 0.9013\n# INFO :: Saving Checkpoint to: ../checkpoints/transfer_learning/10_percent_feature_extraction_model_augmented_finetuning\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"print(model_2.evaluate(testing_data_100))\n# 21s 266ms/step - loss: 0.3093 - accuracy: 0.8972\n# [0.3092549443244934, 0.8971999883651733]\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"combine_training_curves(fine_tuning_model_2, history_model_2_full, pretraining_epochs=6)\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Fine-tuning Pre-trained Models",src:a(397638).Z+"",width:"680",height:"701"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-python",children:"# Load TensorBoard\n%load_ext tensorboard\n%tensorboard --logdir '../tensorboard/'\n"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Fine-tuning Pre-trained Models",src:a(637728).Z+"",width:"1590",height:"775"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{alt:"Fine-tuning Pre-trained Models",src:a(702440).Z+"",width:"1597",height:"808"})})]})}function _(e={}){const{wrapper:n}={...(0,r.ah)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},603905:(e,n,a)=>{a.d(n,{ah:()=>c});var t=a(667294);function r(e,n,a){return n in e?Object.defineProperty(e,n,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[n]=a,e}function i(e,n){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var t=Object.getOwnPropertySymbols(e);n&&(t=t.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),a.push.apply(a,t)}return a}function s(e){for(var n=1;n<arguments.length;n++){var a=null!=arguments[n]?arguments[n]:{};n%2?i(Object(a),!0).forEach((function(n){r(e,n,a[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(a,n))}))}return e}function l(e,n){if(null==e)return{};var a,t,r=function(e,n){if(null==e)return{};var a,t,r={},i=Object.keys(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||(r[a]=e[a]);return r}(e,n);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(t=0;t<i.length;t++)a=i[t],n.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var o=t.createContext({}),c=function(e){var n=t.useContext(o),a=n;return e&&(a="function"==typeof e?e(n):s(s({},n),e)),a},d={inlineCode:"code",wrapper:function(e){var n=e.children;return t.createElement(t.Fragment,{},n)}},_=t.forwardRef((function(e,n){var a=e.components,r=e.mdxType,i=e.originalType,o=e.parentName,_=l(e,["components","mdxType","originalType","parentName"]),h=c(a),p=r,g=h["".concat(o,".").concat(p)]||h[p]||d[p]||i;return a?t.createElement(g,s(s({ref:n},_),{},{components:a})):t.createElement(g,s({ref:n},_))}));_.displayName="MDXCreateElement"},821733:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/04_Keras_Sequential_vs_Functional_API-d7c455a06bd4bee1e58e95f982f3d07b.png"},992353:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/04_Tensorflow_Transfer_Learning_07-f05a4e0b368f0d4cf5afdb4ef2ea84e5.png"},163457:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/04_Tensorflow_Transfer_Learning_08-0d6fe1d098a83bbd2ba826776ed4796d.png"},48:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/04_Tensorflow_Transfer_Learning_09-f55bb9a1c1145920dd415db05a2a60b0.png"},397638:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/04_Tensorflow_Transfer_Learning_10-f7eb9d4c00490120962517caa49360a4.png"},637728:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/04_Tensorflow_Transfer_Learning_11-b0e24cbc28563185ec6afa93a800f1ec.png"},702440:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/04_Tensorflow_Transfer_Learning_12-deddf740c2914a3ff4f286a3884de447.png"},300890:(e,n,a)=>{a.d(n,{Z:()=>t});const t=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-0617c01f21d40c2f06bb85d06aa2619b.jpg"}}]);