"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[44950],{874542:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>a,default:()=>h,frontMatter:()=>t,metadata:()=>o,toc:()=>d});var s=i(474848),r=i(28453);const t={sidebar_position:4710,slug:"2023-02-17",title:"Keras for Tensorflow - Convolutional Neural Networks",authors:"mpolinowski",tags:["Python","Machine Learning","Keras","Tensorflow"],description:"Convolutional Neural Networks are ideal for Computer Vision tasks."},a=void 0,o={id:"IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/index",title:"Keras for Tensorflow - Convolutional Neural Networks",description:"Convolutional Neural Networks are ideal for Computer Vision tasks.",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn",slug:"/IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/2023-02-17",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/2023-02-17",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"Keras",permalink:"/docs/tags/keras"},{label:"Tensorflow",permalink:"/docs/tags/tensorflow"}],version:"current",sidebarPosition:4710,frontMatter:{sidebar_position:4710,slug:"2023-02-17",title:"Keras for Tensorflow - Convolutional Neural Networks",authors:"mpolinowski",tags:["Python","Machine Learning","Keras","Tensorflow"],description:"Convolutional Neural Networks are ideal for Computer Vision tasks."},sidebar:"tutorialSidebar",previous:{title:"Keras for Tensorflow - Recurrent Neural Networks",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-rnn/2023-02-18"},next:{title:"Keras for Tensorflow - Artificial Neural Networks",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-02-16-keras-introduction-ann/2023-02-16"}},l={},d=[{value:"Convolution",id:"convolution",level:2},{value:"Convolutional Layers",id:"convolutional-layers",level:3},{value:"Pooling Layers",id:"pooling-layers",level:3},{value:"CNN Image Classifier",id:"cnn-image-classifier",level:2},{value:"Loading the Dataset",id:"loading-the-dataset",level:3},{value:"Preprocessing the Data",id:"preprocessing-the-data",level:3},{value:"Building the Model",id:"building-the-model",level:3},{value:"Model Training",id:"model-training",level:3},{value:"Validate Training",id:"validate-training",level:3}];function c(e){const n={a:"a",blockquote:"blockquote",code:"code",em:"em",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Guangzhou, China",src:i(652292).A+"",width:"2830",height:"1272"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"#convolution",children:"Convolution"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#convolutional-layers",children:"Convolutional Layers"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#pooling-layers",children:"Pooling Layers"})}),"\n"]}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"#cnn-image-classifier",children:"CNN Image Classifier"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#loading-the-dataset",children:"Loading the Dataset"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#preprocessing-the-data",children:"Preprocessing the Data"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#building-the-model",children:"Building the Model"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#model-training",children:"Model Training"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"#validate-training",children:"Validate Training"})}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.a,{href:"https://github.com/mpolinowski/tf-keras-2023",children:"Github Repository"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.a,{href:"https://keras.io/getting_started/",children:"Keras"})," is built on top of TensorFlow 2 and provides an API designed for human beings. Keras follows best practices for reducing cognitive load: it offers consistent & simple APIs, it minimizes the number of user actions required for common use cases, and it provides clear & actionable error messages."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.em,{children:"See also:"})}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-14-keras-introduction/2023-02-14",children:"Keras for Tensorflow - An (Re)Introduction 2023"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-16-keras-introduction-ann/2023-02-16",children:"Keras for Tensorflow - Artificial Neural Networks"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-17-keras-introduction-cnn/2023-02-17",children:"Keras for Tensorflow - Convolutional Neural Networks"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-vgg16/2023-02-18",children:"Keras for Tensorflow - VGG16 Network Architecture"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-rnn/2023-02-18",children:"Keras for Tensorflow - Recurrent Neural Networks"})}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"convolution",children:"Convolution"}),"\n",(0,s.jsxs)(n.p,{children:["Convolutional Neural Networks are ideal for Computer Vision tasks. During the convolution step the image is processed by a filter that can be defined by to parameters ",(0,s.jsx)(n.code,{children:"pooling"})," and ",(0,s.jsx)(n.code,{children:"stride"}),"."]}),"\n",(0,s.jsxs)(n.blockquote,{children:["\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.strong,{children:"Convolution:"})," A function derived from two given functions by integration that expresses the shape of one modified by the other."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Let's take a 4x4 feature matrix and apply a convolutional transformation with ",(0,s.jsx)(n.strong,{children:"max. Pooling"})," filter with a ",(0,s.jsx)(n.code,{children:"2x2"})," kernel and a ",(0,s.jsx)(n.strong,{children:"Stride"})," of ",(0,s.jsx)(n.code,{children:"2"}),":"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"1"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"1"})}),(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"4"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"5"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"6"})}),(0,s.jsx)(n.td,{children:"7"}),(0,s.jsx)(n.td,{children:"8"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"1"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"0"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"3"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"4"})})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:["The filter will extract ",(0,s.jsx)(n.code,{children:"2x2"})," blocks and pools the features by discarding everything but the maximum. Afterwards the stride of ",(0,s.jsx)(n.code,{children:"2"})," moves the filter over a new section of our feature matrix and the process starts anew. We end up with a ",(0,s.jsx)(n.code,{children:"2x2"})," matrix where only the max values have been extracted from the original image input =>"]}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{}),(0,s.jsx)(n.th,{})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"6"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"8"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"3"})}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.strong,{children:"4"})})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:["If we want to keep the input size we can set ",(0,s.jsx)(n.code,{children:"padding='valid'"})," - with this parameter the output matrix would still be of size ",(0,s.jsx)(n.code,{children:"4x4"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"convolutional-layers",children:"Convolutional Layers"}),"\n",(0,s.jsxs)(n.p,{children:["Keras offers ",(0,s.jsx)(n.a,{href:"https://keras.io/api/layers/convolution_layers/",children:"Convolutinal Layers"})," that we can use to turn our Artificial Neural Network (",(0,s.jsx)(n.strong,{children:"ANN"}),") into a Convolutional Neural Network (",(0,s.jsx)(n.strong,{children:"CNN"}),"). A ",(0,s.jsx)(n.a,{href:"https://keras.io/api/layers/convolution_layers/convolution2d/",children:"2D convolution layer"})," can be used for the spatial convolution over images. This layer creates a convolution kernel that is convolved with the layer input to produce a tensor of outputs."]}),"\n",(0,s.jsx)(n.h3,{id:"pooling-layers",children:"Pooling Layers"}),"\n",(0,s.jsxs)(n.p,{children:["Keras offer ",(0,s.jsx)(n.a,{href:"https://keras.io/api/layers/pooling_layers/",children:"Pooling Layers"}),", e.g. the ",(0,s.jsx)(n.a,{href:"https://keras.io/api/layers/pooling_layers/max_pooling2d/",children:"MaxPooling2D layer"})," downsamples the input along its spatial dimensions (height and width) by taking the maximum value over an input window (of size defined by pool_size) for each channel of the input. The window is shifted by strides along each dimension."]}),"\n",(0,s.jsx)(n.p,{children:"The pooling layer serves to progressively reduce the spatial size of the representation, to reduce the number of parameters and amount of computation in the network, and hence to also control overfitting."}),"\n",(0,s.jsx)(n.p,{children:"The intuition is that the exact location of a feature is less important than its rough location relative to other features."}),"\n",(0,s.jsxs)(n.p,{children:["An example convolutional neural network is the ",(0,s.jsx)(n.a,{href:"https://arxiv.org/abs/1409.1556",children:"VGG16 Architecture"}),". The number 16 in the name VGG refers to the fact that it is 16 layers deep neural network (",(0,s.jsx)(n.a,{href:"/docs/IoT-and-Machine-Learning/ML/2023-02-18-keras-introduction-vgg16/2023-02-18",children:"VGGnet"}),"). Pooling layers keep reducing the x and y dimension of the input image while adding depth to it by the use of filters (",(0,s.jsx)(n.a,{href:"http://dx.doi.org/10.29322/IJSRP.9.10.2019.p9420",children:"Image Source"}),"):"]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Keras for Tensorflow - Convolutional Neural Networks",src:i(996563).A+"",width:"280",height:"798"})}),"\n",(0,s.jsx)(n.h2,{id:"cnn-image-classifier",children:"CNN Image Classifier"}),"\n",(0,s.jsx)(n.h3,{id:"loading-the-dataset",children:"Loading the Dataset"}),"\n",(0,s.jsxs)(n.p,{children:["Convolutional Neural Networks are of particular use when working with images. As an example we can use the ",(0,s.jsx)(n.a,{href:"https://github.com/zalandoresearch/fashion-mnist",children:"MNIST Fashion dataset"}),". The dataset can be downloaded with Keras:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"from keras.datasets import fashion_mnist\n\n# using the fashion mnist dataset\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\nprint(x_train.shape)\nprint(x_test.shape)\n"})}),"\n",(0,s.jsx)(n.p,{children:"The training set contains 60k and the validation set 10k images with a size of 28x28 pixels:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"(60000, 28, 28)\n(10000, 28, 28)\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Taking a look at an example images shows us a shoe with the label ",(0,s.jsx)(n.code,{children:"7"})," - which corresponds to ",(0,s.jsx)(n.code,{children:"sneaker"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"print(y_train[666])\nplt.imshow(x_train[666])\nplt.show()\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Keras for Tensorflow - Convolutional Neural Networks",src:i(781002).A+"",width:"1087",height:"522"})}),"\n",(0,s.jsx)(n.h3,{id:"preprocessing-the-data",children:"Preprocessing the Data"}),"\n",(0,s.jsx)(n.p,{children:"Start by normalizing the data:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"# data pre-processing\n## reshape training images\nx_train = x_train.reshape(60000, 28, 28, 1)\nx_test = x_test.reshape(10000, 28, 28, 1)\n\n## normalize training images\nx_train = x_train.astype('float32')/255\nx_test = x_test.astype('float32')/255\n"})}),"\n",(0,s.jsx)(n.p,{children:"Then categorize the labels - the MNIST Fashion Datasets, as seen above, comes with 10 labels:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Label"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"0"}),(0,s.jsx)(n.td,{children:"T-shirt/top"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"1"}),(0,s.jsx)(n.td,{children:"Trouser"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"2"}),(0,s.jsx)(n.td,{children:"Pullover"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"3"}),(0,s.jsx)(n.td,{children:"Dress"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"4"}),(0,s.jsx)(n.td,{children:"Coat"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"5"}),(0,s.jsx)(n.td,{children:"Sandal"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"6"}),(0,s.jsx)(n.td,{children:"Shirt"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"7"}),(0,s.jsx)(n.td,{children:"Sneaker"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"8"}),(0,s.jsx)(n.td,{children:"Bag"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:"9"}),(0,s.jsx)(n.td,{children:"Ankle boot"})]})]})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"# vectorize labels for the 10 categories from 0-9\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\nprint(y_train.shape)\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Now we have 60k labels of 10 classes: ",(0,s.jsx)(n.code,{children:"(60000, 10)"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"building-the-model",children:"Building the Model"}),"\n",(0,s.jsx)(n.p,{children:"This time the model contains a convolutional and maxpooling layer:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"# building the model\nmodel = Sequential()\n## convolutional layer + pooling\nmodel.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n## randomly drop 25% of neurons to prevent overfitting\nmodel.add(Dropout(0.25))\n## flatten before dense layer\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\n# output layer assigns probability of 10 classes\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.summary()\n"})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'Model: "sequential"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)              (None, 28, 28, 32)        320       \n                                                                 \n max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n                                                                  \n dropout (Dropout)            (None, 14, 14, 32)        0         \n                                                                 \n flatten (Flatten)            (None, 6272)              0         \n                                                                 \n dense (Dense)                (None, 128)               802944    \n                                                                 \n dropout_1 (Dropout)          (None, 128)               0         \n                                                                 \n dense_1 (Dense)              (None, 10)                1290      \n                                                                 \n=================================================================\nTotal params: 804,554\nTrainable params: 804,554\nNon-trainable params: 0\n'})}),"\n",(0,s.jsx)(n.h3,{id:"model-training",children:"Model Training"}),"\n",(0,s.jsxs)(n.p,{children:["To store the training progress we can use the ",(0,s.jsx)(n.a,{href:"https://keras.io/api/callbacks/model_checkpoint/",children:"ModelCheckpoint"})," function that will hold on to the weights of our best training epoch:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"from keras.callbacks import ModelCheckpoint\ncheckpoint_filepath = '/checkpoint/model.weights.best.hdf5'\nmodel_checkpoint_callback = ModelCheckpoint(\n      filepath=checkpoint_filepath,\n      save_weights_only=True,\n      monitor='val_accuracy',\n      mode='max',\n      save_best_only=True)\n"})}),"\n",(0,s.jsx)(n.p,{children:"And now we can run the training:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"model.fit(x_train, y_train, batch_size=128, epochs=10, callbacks=[model_checkpoint_callback])\n"})}),"\n",(0,s.jsx)(n.p,{children:"And after 10 epochs I end up with an accuracy of 93%:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"Epoch 10/10\n469/469 [==============================] - 2s 5ms/step - loss: 0.1826 - accuracy: 0.9312\n"})}),"\n",(0,s.jsx)(n.h3,{id:"validate-training",children:"Validate Training"}),"\n",(0,s.jsx)(n.p,{children:"Use the test dataset to validate your fitted models performance"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"# validation run\nval_loss, val_score = model.evaluate(x_test, y_test)\nprint(val_loss, val_score)\n"})}),"\n",(0,s.jsx)(n.p,{children:"I am getting an accuracy of 91.6%:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"0.2373863011598587 0.9168000221252441\n"})}),"\n",(0,s.jsx)(n.p,{children:"And to check out a prediction:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-py",children:"# run prediction\npred = model.predict(x_test)\n## show prediction probabilities\npred_max = np.argmax(pred, axis=1)\nprint(pred[666])\nprint(pred_max[666])\n\n## show corresponding image\n## reshaping data 28x28\n## to be able to show the image\nx = x_test[666].reshape(28, 28)\nplt.imshow(x)\nplt.show()\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The highest probability is for the class with label ",(0,s.jsx)(n.code,{children:"3"})," -> which is a dress:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"[1.61573451e-04 6.19598268e-06 1.45051545e-05 9.99719679e-01\n 1.96860651e-06 8.07112066e-09 9.30368915e-05 6.60802641e-07\n 8.06152855e-07 1.40201507e-06]\n"})}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Keras for Tensorflow - Convolutional Neural Networks",src:i(851429).A+"",width:"1666",height:"463"})})]})}function h(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(c,{...e})}):c(e)}},996563:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/Keras_Introduction_CNN_Model_Training_02-1faa188f8f47c3c83ad138324af21200.png"},781002:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/Keras_Introduction_CNN_Model_Training_03-e47855b12bd46c6eeeb1226f406c0094.png"},851429:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/Keras_Introduction_CNN_Model_Training_04-cc758b91ffff1709fd43b04f77f543c4.png"},652292:(e,n,i)=>{i.d(n,{A:()=>s});const s=i.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-f80e63ee872dae25129198058ac93b4e.jpg"},28453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var s=i(296540);const r={},t=s.createContext(r);function a(e){const n=s.useContext(t);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:a(e.components),s.createElement(t.Provider,{value:n},e.children)}}}]);