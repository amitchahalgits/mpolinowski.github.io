"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[15970],{260824:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>a,contentTitle:()=>c,default:()=>h,frontMatter:()=>r,metadata:()=>l,toc:()=>d});var i=t(785893),s=t(603905);const r={sidebar_position:4110,slug:"2023-09-15",title:"YOLOv8 License Plate Detection",authors:"mpolinowski",tags:["Python","Machine Learning","PyTorch"],description:"Using the YOLOv8 Object Tracker in Combination with EasyOCR"},c="YOLOv8 License Plate Detection",l={id:"IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/index",title:"YOLOv8 License Plate Detection",description:"Using the YOLOv8 Object Tracker in Combination with EasyOCR",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr",slug:"/IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/2023-09-15",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/2023-09-15",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-09-15--yolo8-tracking-and-ocr/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"PyTorch",permalink:"/docs/tags/py-torch"}],version:"current",sidebarPosition:4110,frontMatter:{sidebar_position:4110,slug:"2023-09-15",title:"YOLOv8 License Plate Detection",authors:"mpolinowski",tags:["Python","Machine Learning","PyTorch"],description:"Using the YOLOv8 Object Tracker in Combination with EasyOCR"},sidebar:"tutorialSidebar",previous:{title:"YOLOv8 Nightshift",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-09-17--yolo8-nightshift/2023-09-17"},next:{title:"Scikit-Learn ML Model Explainability",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-09-10--model-explainability-shap/2023-09-11"}},a={},d=[{value:"Pre-Trained YOLOv8",id:"pre-trained-yolov8",level:2},{value:"Retraining YOLOv8",id:"retraining-yolov8",level:2},{value:"Improving Training Results",id:"improving-training-results",level:2},{value:"License Plate Detection",id:"license-plate-detection",level:2},{value:"STEP 1 Implementing the Car Detection",id:"step-1-implementing-the-car-detection",level:3},{value:"STEP 2 Implementing the License Plate Detection",id:"step-2-implementing-the-license-plate-detection",level:3},{value:"STEP 3 Preprocess License Plates",id:"step-3-preprocess-license-plates",level:3},{value:"STEP 4 Read License Plates",id:"step-4-read-license-plates",level:3},{value:"STEP 5 Clean-Up License Plate Format",id:"step-5-clean-up-license-plate-format",level:3},{value:"STEP 6 Visualize the Results",id:"step-6-visualize-the-results",level:3}];function o(e){const n={a:"a",blockquote:"blockquote",br:"br",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,s.ah)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"Guangzhou, China",src:t(653493).Z+"",width:"1500",height:"871"})}),"\n",(0,i.jsx)(n.h1,{id:"yolov8-license-plate-detection",children:"YOLOv8 License Plate Detection"}),"\n",(0,i.jsxs)(n.p,{children:["Using the ",(0,i.jsx)(n.a,{href:"https://docs.ultralytics.com/tasks/detect/",children:"YOLOv8 Object Tracker"})," and ",(0,i.jsx)(n.a,{href:"https://www.jaided.ai/easyocr/",children:"EasyOCR"})," to record License Plates."]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["This guide is based on the ",(0,i.jsx)(n.a,{href:"https://github.com/computervisioneng/automatic-number-plate-recognition-python-yolov8",children:"DeepSORT & EasyOCR Repository"})," by ",(0,i.jsx)(n.a,{href:"https://github.com/computervisioneng",children:"@computervisioneng"}),". But I replaced the ",(0,i.jsx)(n.a,{href:"https://github.com/abewley/sort",children:"DeepSORT Dependency"})," with the YOLOv8 included Track function."]}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://github.com/mpolinowski/yolo-i-know-flowers",children:"Github Repository"})}),"\n"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#yolov8-license-plate-detection",children:"YOLOv8 License Plate Detection"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#pre-trained-yolov8",children:"Pre-Trained YOLOv8"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#retraining-yolov8",children:"Retraining YOLOv8"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#improving-training-results",children:"Improving Training Results"})}),"\n",(0,i.jsxs)(n.li,{children:[(0,i.jsx)(n.a,{href:"#license-plate-detection",children:"License Plate Detection"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#step-1-implementing-the-car-detection",children:"STEP 1 Implementing the Car Detection"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#step-2-implementing-the-license-plate-detection",children:"STEP 2 Implementing the License Plate Detection"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#step-3-preprocess-license-plates",children:"STEP 3 Preprocess License Plates"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#step-4-read-license-plates",children:"STEP 4 Read License Plates"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#step-5-clean-up-license-plate-format",children:"STEP 5 Clean-Up License Plate Format"})}),"\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"#step-6-visualize-the-results",children:"STEP 6 Visualize the Results"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import cv2 as cv\nfrom glob import glob\nimport os\nimport random\nfrom ultralytics import YOLO\n"})}),"\n",(0,i.jsx)(n.h2,{id:"pre-trained-yolov8",children:"Pre-Trained YOLOv8"}),"\n",(0,i.jsxs)(n.p,{children:["The regular YOLOv8 training weights do not contain a ",(0,i.jsx)(n.code,{children:"number_plate"})," class and cannot be used directly for a number plate detection:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# read in video paths\nvideos = glob('inputs/*.mp4')\nprint(videos)\n"})}),"\n",(0,i.jsx)(n.p,{children:"['inputs/uk_dash_1.mp4', 'inputs/uk_dash_2.mp4']"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# pick pre-trained model\nmodel_pretrained = YOLO('yolov8n.pt')\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# read video by index\nvideo = cv.VideoCapture(videos[1])\n\n# get video dims\nframe_width = int(video.get(3))\nframe_height = int(video.get(4))\nsize = (frame_width, frame_height)\n\n# Define the codec and create VideoWriter object\nfourcc = cv.VideoWriter_fourcc(*'DIVX')\nout = cv.VideoWriter('./outputs/uk_dash_2.avi', fourcc, 20.0, size)\n\n# read frames\nret = True\n\nwhile ret:\n    ret, frame = video.read()\n\n    if ret:\n        # detect & track objects\n        results = model_pretrained.track(frame, persist=True)\n\n        # plot results\n        composed = results[0].plot()\n\n        # save video\n        out.write(composed)\n\nout.release()\nvideo.release()\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"YOLOv8 License Plate Detection",src:t(579768).Z+"",width:"1946",height:"438"})}),"\n",(0,i.jsx)(n.h2,{id:"retraining-yolov8",children:"Retraining YOLOv8"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.a,{href:"https://universe.roboflow.com/roboflow-universe-projects/license-plate-recognition-rxg4e",children:"Dataset: Roboflow - License Plate Recognition Computer Vision Project"})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Download the Dataset with YOLOv8 annotation and point YOLO to the ",(0,i.jsx)(n.code,{children:"data.yaml"})," file that comes with the dataset:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-yml",children:"train: ../train/images\nval: ../valid/images\ntest: ../test/images\n\nnc: 1\nnames: ['License_Plate']\n\nroboflow:\n  workspace: roboflow-universe-projects\n  project: license-plate-recognition-rxg4e\n  version: 4\n  license: CC BY 4.0\n  url: https://universe.roboflow.com/roboflow-universe-projects/license-plate-recognition-rxg4e/dataset/4\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# unzip downloaded dataset to `./datasets`\ndataset = \'datasets/data.yaml\'\n\n# load a model\n# backbone = YOLO("yolov8n.yaml")  # build a new model from scratch\nbackbone = YOLO("yolov8n.pt")  # load a pre-trained model (recommended for training)\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Use the model\nresults = backbone.train(data=dataset, epochs=20)  # train the model\n"})}),"\n",(0,i.jsx)(n.p,{children:"20 epochs completed in 2.530 hours.\nOptimizer stripped from runs/detect/train11/weights/last.pt, 6.2MB\nOptimizer stripped from runs/detect/train11/weights/best.pt, 6.2MB"}),"\n",(0,i.jsx)(n.p,{children:"Validating runs/detect/train11/weights/best.pt...\nUltralytics YOLOv8.0.173 \ud83d\ude80 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6070MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\nClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 64/64 [00:17,  3.61it/s]\nall       2046       2132      0.986      0.954      0.984      0.701\nSpeed: 0.3ms preprocess, 5.1ms inference, 0.0ms loss, 0.5ms postprocess per image\nResults saved to \x1b[1mruns/detect/train11\x1b[0m"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"YOLOv8 License Plate Detection",src:t(587708).Z+"",width:"2400",height:"1200"})}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Class"}),(0,i.jsx)(n.th,{children:"Images"}),(0,i.jsx)(n.th,{children:"Instances"}),(0,i.jsx)(n.th,{children:"Box( P"}),(0,i.jsx)(n.th,{children:"R"}),(0,i.jsx)(n.th,{children:"mAP50"}),(0,i.jsx)(n.th,{children:"mAP50-95)"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"all"}),(0,i.jsx)(n.td,{children:"2046"}),(0,i.jsx)(n.td,{children:"2132"}),(0,i.jsx)(n.td,{children:"0.986"}),(0,i.jsx)(n.td,{children:"0.954"}),(0,i.jsx)(n.td,{children:"0.984"}),(0,i.jsx)(n.td,{children:"0.701"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.em,{children:"Speed: 0.3ms preprocess, 5.1ms inference, 0.0ms loss, 0.5ms postprocess per image"})}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.em,{children:"Model summary (fused): 168 layers, 3005843 parameters, 0 gradients"})}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{})]})]})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Evaluate the model's performance on the validation set\nresults = backbone.val()\n"})}),"\n",(0,i.jsx)(n.p,{children:"Ultralytics YOLOv8.0.173 \ud83d\ude80 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6070MiB)\nModel summary (fused): 168 layers, 3005843 parameters, 0 gradients\n\x1b[34m\x1b[1mval: \x1b[0mScanning /opt/app/03_object_detection_with_text_extraction_easyocr/datasets/valid/labels.cache... 2046 images, 3 backgrounds, 0 corrupt: 100%|\u2588\u2588\u2588\u2588\x1b[0m\nClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 128/128 [00:18,  6.74it/s]\nall       2046       2132      0.986      0.954      0.984      0.701\nSpeed: 0.3ms preprocess, 5.7ms inference, 0.0ms loss, 0.6ms postprocess per image\nResults saved to \x1b[1mruns/detect/val\x1b[0m"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"YOLOv8 License Plate Detection",src:t(766487).Z+"",width:"1721",height:"925"})}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Class"}),(0,i.jsx)(n.th,{children:"Images"}),(0,i.jsx)(n.th,{children:"Instances"}),(0,i.jsx)(n.th,{children:"Box( P"}),(0,i.jsx)(n.th,{children:"R"}),(0,i.jsx)(n.th,{children:"mAP50"}),(0,i.jsx)(n.th,{children:"mAP50-95)"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"all"}),(0,i.jsx)(n.td,{children:"2046"}),(0,i.jsx)(n.td,{children:"2132"}),(0,i.jsx)(n.td,{children:"0.986"}),(0,i.jsx)(n.td,{children:"0.954"}),(0,i.jsx)(n.td,{children:"0.984"}),(0,i.jsx)(n.td,{children:"0.701"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:(0,i.jsx)(n.em,{children:"Speed: 0.3ms preprocess, 5.7ms inference, 0.0ms loss, 0.6ms postprocess per image"})}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{}),(0,i.jsx)(n.td,{})]})]})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Perform object detection on an image using the model\nresults = backbone('inputs/cars.png')\n"})}),"\n",(0,i.jsx)(n.p,{children:"image 1/1 /opt/app/03_object_detection_with_text_extraction_easyocr/inputs/cars.png: 384x640 2 License_Plates, 35.9ms\nSpeed: 1.7ms preprocess, 35.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Export the model to ONNX format\n# success = model.export(imgsz=(640, 480), format='onnx', opset=12, optimize=False, half=False)\n# Export to PyTorch format\nsuccess = backbone.export(imgsz=640, format='torchscript', optimize=False, half=False, int8=False)\n# TorchScript: export success \u2705 1.5s, saved as 'runs/detect/train11/weights/best.torchscript' (11.9 MB)\n"})}),"\n",(0,i.jsx)(n.p,{children:"Ultralytics YOLOv8.0.173 \ud83d\ude80 Python-3.10.11 torch-2.0.1 CPU (Intel Core(TM) i7-7700 3.60GHz)"}),"\n",(0,i.jsx)(n.p,{children:"\x1b[34m\x1b[1mPyTorch:\x1b[0m starting from 'runs/detect/train11/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 5, 8400) (6.0 MB)"}),"\n",(0,i.jsx)(n.p,{children:"\x1b[34m\x1b[1mTorchScript:\x1b[0m starting export with torch 2.0.1...\n\x1b[34m\x1b[1mTorchScript:\x1b[0m export success \u2705 1.3s, saved as 'runs/detect/train11/weights/best.torchscript' (11.9 MB)"}),"\n",(0,i.jsxs)(n.p,{children:["Export complete (2.6s)\nResults saved to \x1b[1m/opt/app/03_object_detection_with_text_extraction_easyocr/runs/detect/train11/weights\x1b[0m\nPredict:         yolo predict task=detect model=runs/detect/train11/weights/best.torchscript imgsz=640",(0,i.jsx)(n.br,{}),"\n","Validate:        yolo val task=detect model=runs/detect/train11/weights/best.torchscript imgsz=640 data=datasets/data.yaml",(0,i.jsx)(n.br,{}),"\n","Visualize:       ",(0,i.jsx)(n.a,{href:"https://netron.app",children:"https://netron.app"})]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# pick pre-trained model\nnp_model = YOLO('runs/detect/train11/weights/best.torchscript')\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# read video by index\nvideo = cv.VideoCapture(videos[1])\nret, frame = video.read()\n\n# get video dims\nframe_width = int(video.get(3))\nframe_height = int(video.get(4))\nsize = (frame_width, frame_height)\n\n# Define the codec and create VideoWriter object\nfourcc = cv.VideoWriter_fourcc(*'DIVX')\nout = cv.VideoWriter('./outputs/uk_dash_np_2.avi', fourcc, 20.0, size)\n\n# read frames\nret = True\n\nwhile ret:\n    ret, frame = video.read()\n\n    if ret:\n        # detect & track objects\n        results = np_model.track(frame, persist=True)\n\n        # plot results\n        composed = results[0].plot()\n\n        # save video\n        out.write(composed)\n\nout.release()\nvideo.release()\n"})}),"\n",(0,i.jsx)(n.p,{children:"And now we have a model that is only interested in number plates:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"YOLOv8 License Plate Detection",src:t(526491).Z+"",width:"1933",height:"391"})}),"\n",(0,i.jsx)(n.p,{children:"Though, the confusion matrix shows us that it also sees a lot of plates that do not exist - but at least it does not miss that many:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"YOLOv8 License Plate Detection",src:t(553629).Z+"",width:"3000",height:"2250"})}),"\n",(0,i.jsx)(n.h2,{id:"improving-training-results",children:"Improving Training Results"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:'# unzip downloaded dataset to `./datasets`\ndataset = \'datasets/data.yaml\'\n\n# load a model\n# backbone = YOLO("yolov8n.yaml")  # build a new model from scratch\nbackbone_small = YOLO("yolov8s.pt")  # load a pre-trained model (recommended for training)\n'})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Use the model\nresults_medium = backbone_small.train(data=dataset, epochs=100)  # train the model\n"})}),"\n",(0,i.jsx)(n.p,{children:"Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n57/100      4.57G     0.9052     0.3966      1.064          7        640: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1324/1324 [13:43,  1.61it/s]\nClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 64/64 [00:26,  2.38it/s]\nall       2046       2132      0.981      0.968      0.984      0.709"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# pick pre-trained model\nnp2_model = YOLO('runs/detect/train4/weights/best.pt')\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Evaluate the model's performance on the validation set\nresults = np2_model.val()\n"})}),"\n",(0,i.jsxs)(n.p,{children:["Ultralytics YOLOv8.0.173 \ud83d\ude80 Python-3.10.11 torch-2.0.1 CUDA:0 (NVIDIA GeForce GTX 1060 6GB, 6070MiB)\nModel summary (fused): 168 layers, 11125971 parameters, 0 gradients\nDownloading ",(0,i.jsx)(n.a,{href:"https://ultralytics.com/assets/Arial.ttf",children:"https://ultralytics.com/assets/Arial.ttf"})," to '/root/.config/Ultralytics/Arial.ttf'...\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 755k/755k [00:00, 2.35MB/s]\nClass     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 128/128 [00:35,  3.59it/s]\nall       2046       2132      0.981      0.968      0.984       0.71\nSpeed: 0.3ms preprocess, 13.4ms inference, 0.0ms loss, 0.6ms postprocess per image\nResults saved to \x1b[1mruns/detect/val2\x1b[0m"]}),"\n",(0,i.jsx)(n.h2,{id:"license-plate-detection",children:"License Plate Detection"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"import ast\nimport cv2 as cv\nimport easyocr\nfrom glob import glob\nimport numpy as np\nimport pandas as pd\nimport string\nfrom ultralytics import YOLO\n"})}),"\n",(0,i.jsx)(n.p,{children:"As seen during the training - the model, just using the COCO training weights, is very capable of detecting cars, trucks and buses. But number plates seem to be a bit harder - the model often confuses street signs or just basic backgound noise as a car registration plate. The positive is that it rarely misses a plate."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# regular pre-trained yolov8 model for car recognition\n# coco_model = YOLO('yolov8n.pt')\ncoco_model = YOLO('yolov8s.pt')\n# yolov8 model trained to detect number plates\nnp_model = YOLO('runs/detect/train4/weights/best.pt')\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# read in test video paths\nvideos = glob('inputs/*.mp4')\nprint(videos)\n"})}),"\n",(0,i.jsx)(n.p,{children:"['inputs/uk_dash_1.mp4', 'inputs/uk_dash_2.mp4']"}),"\n",(0,i.jsx)(n.h3,{id:"step-1-implementing-the-car-detection",children:"STEP 1 Implementing the Car Detection"}),"\n",(0,i.jsx)(n.p,{children:"Get the bounding boxes of all vehicles in your video recording with prediction confidence score and object tracking ID"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# read video by index\nvideo = cv.VideoCapture(videos[1])\n\nret = True\nframe_number = -1\n# all vehicle class IDs from the COCO dataset (car, motorbike, truck) https://docs.ultralytics.com/datasets/detect/coco/#dataset-yaml\nvehicles = [2,3,5]\nvehicle_bounding_boxes = []\n\n# read the 10 first frames\nwhile ret:\n    frame_number += 1\n    ret, frame = video.read()\n\n    if ret and frame_number < 10:\n        # use track() to identify instances and track them frame by frame\n        detections = coco_model.track(frame, persist=True)[0]\n        # save cropped detections\n        # detections.save_crop('outputs')\n        # print nodel predictions for debugging\n        # print(results)\n\n        for detection in detections.boxes.data.tolist():\n            # print detection bounding boxes for debugging\n            # print(detection)\n            x1, y1, x2, y2, track_id, score, class_id = detection\n            # I am only interested in class IDs that belong to vehicles\n            if int(class_id) in vehicles and score > 0.5:\n                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n\n# print found bounding boxes for debugging\nprint(vehicle_bounding_boxes)\nvideo.release()\n"})}),"\n",(0,i.jsxs)(n.p,{children:["This code now collects all vehicle bounding boxes from the video and writes them into the ",(0,i.jsx)(n.code,{children:"vehicle_bounding_boxes"})," list. Besides the bbox coordinates this list also contains the tracking ID of the detected vehicle - they should stay the same frame-to-frame for every detected vehicle and serve as a unique identifier. And the score - how confident is the model that this bbox acutally contains a vehicle with calues from ",(0,i.jsx)(n.code,{children:"0"}),"-",(0,i.jsx)(n.code,{children:"1"}),":"]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.code,{children:"[[762.6422729492188, 614.1869506835938, 1121.368408203125, 911.6900024414062, 1.0, 0.9254793524742126], [1196.008056640625, 635.3404541015625, 1526.3975830078125, 828.6062622070312, 2.0, 0.8488578200340271], [1672.98193359375, 613.9304809570312, 1912.382080078125, 819.3222045898438, 3.0, 0.5385741591453552], [758.7203369140625, 612.6467895507812, 1119.0892333984375, 917.7677612304688, 1.0, 0.925308883190155], [1195.9505615234375, 635.4146118164062, 1527.97412109375, 830.3245239257812, 2.0, 0.865635871887207], [1692.5439453125, 613.0050659179688, 1917.7542724609375, 819.2852783203125, 3.0, 0.5493771433830261], [754.7435302734375, 612.3658447265625, 1115.0045166015625, 919.653076171875, 1.0, 0.9127519130706787], [1194.00341796875, 634.9168090820312, 1527.029541015625, 832.383544921875, 2.0, 0.8814489841461182], [1688.8155517578125, 615.6485595703125, 1920.0, 812.7891235351562, 3.0, 0.6132197976112366], [752.8799438476562, 611.2362060546875, 1111.976318359375, 920.200927734375, 1.0, 0.9137689471244812], [1192.805908203125, 634.3713989257812, 1526.1273193359375, 832.46337890625, 2.0, 0.8671290278434753], [1680.4443359375, 616.384033203125, 1920.0, 813.3687744140625, 3.0, 0.6371273994445801], [750.9274291992188, 611.5806884765625, 1110.2657470703125, 915.3110961914062, 1.0, 0.9381350874900818], [1189.63916015625, 634.7803955078125, 1525.4072265625, 833.2440185546875, 2.0, 0.888615071773529], [1669.8206787109375, 616.796142578125, 1920.0, 808.6288452148438, 3.0, 0.5068169236183167], [748.747802734375, 609.5638427734375, 1109.0101318359375, 912.808837890625, 1.0, 0.9158740639686584], [1187.832275390625, 634.11328125, 1524.633056640625, 832.628173828125, 2.0, 0.8583219647407532], [1659.7103271484375, 615.9025268554688, 1920.0, 823.25048828125, 3.0, 0.7755634784698486], [745.1077270507812, 609.5160522460938, 1107.8214111328125, 912.8062133789062, 1.0, 0.9354495406150818], [1186.91455078125, 634.5582885742188, 1524.004150390625, 832.4244995117188, 2.0, 0.8758277297019958], [1650.2227783203125, 613.749267578125, 1920.0, 828.9586791992188, 3.0, 0.7407982349395752], [742.2940673828125, 610.4445190429688, 1106.597900390625, 912.6227416992188, 1.0, 0.9281387329101562], [1186.1158447265625, 634.223876953125, 1523.3406982421875, 832.6515502929688, 2.0, 0.8710047006607056], [1638.47705078125, 614.6183471679688, 1919.968017578125, 833.5314331054688, 3.0, 0.8480165600776672], [741.3974609375, 610.8768920898438, 1105.543701171875, 912.5601806640625, 1.0, 0.9410984516143799], [1185.1246337890625, 633.4691162109375, 1523.3682861328125, 832.612060546875, 2.0, 0.8842733502388], [1627.5872802734375, 616.9085693359375, 1919.9117431640625, 829.2400512695312, 3.0, 0.85666424036026], [741.3576049804688, 610.9183959960938, 1103.5601806640625, 914.4734497070312, 1.0, 0.9404377937316895], [1183.273681640625, 633.708984375, 1522.5953369140625, 833.3422241210938, 2.0, 0.8721591234207153], [1618.3934326171875, 619.4539794921875, 1919.864013671875, 827.6344604492188, 3.0, 0.8759608864784241]]"})}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Using the ",(0,i.jsx)(n.code,{children:"save_crop()"})," function shows me that the first 10 frames of my video contain three different cars:"]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"YOLOv8 License Plate Detection",src:t(841616).Z+"",width:"651",height:"533"})}),"\n",(0,i.jsx)(n.h3,{id:"step-2-implementing-the-license-plate-detection",children:"STEP 2 Implementing the License Plate Detection"}),"\n",(0,i.jsx)(n.p,{children:"Use the bounding box for each vehicle and use the number plate detector model to try to find the corresponding plate within in the confinement of those boxes."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# read video by index\nvideo = cv.VideoCapture(videos[0])\n\nret = True\nframe_number = -1\nvehicles = [2,3,5]\n\n# read the 10 first frames\nwhile ret:\n    frame_number += 1\n    ret, frame = video.read()\n\n    if ret and frame_number < 10:\n        \n        # vehicle detector\n        detections = coco_model.track(frame, persist=True)[0]\n        for detection in detections.boxes.data.tolist():\n            x1, y1, x2, y2, track_id, score, class_id = detection\n            if int(class_id) in vehicles and score > 0.5:\n                vehicle_bounding_boxes = []\n                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n                for bbox in vehicle_bounding_boxes:\n                    print(bbox)\n                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n                    # debugging check if bbox lines up with detected vehicles (should be identical to save_crops() above\n                    # cv.imwrite(str(track_id) + '.jpg', roi)\n                    \n                    # license plate detector for region of interest\n                    license_plates = np_model(roi)[0]\n                    # check every bounding box for a license plate\n                    for license_plate in license_plates.boxes.data.tolist():\n                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n                        # verify detections\n                        print(license_plate, 'track_id: ' + str(bbox[4]))\n                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n                        cv.imwrite(str(track_id) + '.jpg', plate)\n                        \nvideo.release()\n"})}),"\n",(0,i.jsx)(n.p,{children:"By using the tracking ID I can make sure that every license plate - as seen above the video contained several instances of the same 3 cars - is only returned ones:"}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"YOLOv8 License Plate Detection",src:t(173943).Z+"",width:"704",height:"271"})}),"\n",(0,i.jsx)(n.h3,{id:"step-3-preprocess-license-plates",children:"STEP 3 Preprocess License Plates"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# read video by index\nvideo = cv.VideoCapture(videos[0])\n\nret = True\nframe_number = -1\nvehicles = [2,3,5]\n\n# read the 10 first frames\nwhile ret:\n    frame_number += 1\n    ret, frame = video.read()\n\n    if ret and frame_number < 100:\n        \n        # vehicle detector\n        detections = coco_model.track(frame, persist=True)[0]\n        for detection in detections.boxes.data.tolist():\n            x1, y1, x2, y2, track_id, score, class_id = detection\n            if int(class_id) in vehicles and score > 0.5:\n                vehicle_bounding_boxes = []\n                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n                for bbox in vehicle_bounding_boxes:\n                    print(bbox)\n                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n                    \n                    # license plate detector for region of interest\n                    license_plates = np_model(roi)[0]\n                    # process license plate\n                    for license_plate in license_plates.boxes.data.tolist():\n                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n                        # crop plate from region of interest\n                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n                        # de-colorize\n                        plate_gray = cv.cvtColor(plate, cv.COLOR_BGR2GRAY)\n                        # posterize\n                        _, plate_treshold = cv.threshold(plate_gray, 64, 255, cv.THRESH_BINARY_INV)\n                        cv.imwrite(str(track_id) + '_gray.jpg', plate_gray)\n                        cv.imwrite(str(track_id) + '_thresh.jpg', plate_treshold)\n                        \nvideo.release()\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"YOLOv8 License Plate Detection",src:t(560549).Z+"",width:"658",height:"289"})}),"\n",(0,i.jsx)(n.h3,{id:"step-4-read-license-plates",children:"STEP 4 Read License Plates"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Initialize the OCR reader\nreader = easyocr.Reader(['en'], gpu=True)\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def read_license_plate(license_plate_crop):\n    detections = reader.readtext(license_plate_crop)\n\n    for detection in detections:\n        bbox, text, score = detection\n\n        text = text.upper().replace(' ', '')\n        \n        return text, score\n\n    return None, None\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def write_csv(results, output_path):\n    \n    with open(output_path, 'w') as f:\n        f.write('{},{},{},{},{},{},{},{}\\n'.format(\n            'frame_number', 'track_id', 'car_bbox', 'car_bbox_score',\n            'license_plate_bbox', 'license_plate_bbox_score', 'license_plate_number',\n            'license_text_score'))\n\n        for frame_number in results.keys():\n            for track_id in results[frame_number].keys():\n                print(results[frame_number][track_id])\n                if 'car' in results[frame_number][track_id].keys() and \\\n                   'license_plate' in results[frame_number][track_id].keys() and \\\n                   'number' in results[frame_number][track_id]['license_plate'].keys():\n                    f.write('{},{},{},{},{},{},{},{}\\n'.format(\n                        frame_number,\n                        track_id,\n                        '[{} {} {} {}]'.format(\n                            results[frame_number][track_id]['car']['bbox'][0],\n                            results[frame_number][track_id]['car']['bbox'][1],\n                            results[frame_number][track_id]['car']['bbox'][2],\n                            results[frame_number][track_id]['car']['bbox'][3]\n                        ),\n                        results[frame_number][track_id]['car']['bbox_score'],\n                        '[{} {} {} {}]'.format(\n                            results[frame_number][track_id]['license_plate']['bbox'][0],\n                            results[frame_number][track_id]['license_plate']['bbox'][1],\n                            results[frame_number][track_id]['license_plate']['bbox'][2],\n                            results[frame_number][track_id]['license_plate']['bbox'][3]\n                        ),\n                        results[frame_number][track_id]['license_plate']['bbox_score'],\n                        results[frame_number][track_id]['license_plate']['number'],\n                        results[frame_number][track_id]['license_plate']['text_score'])\n                    )\n        f.close()\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"results = {}\n\n# read video by index\nvideo = cv.VideoCapture(videos[0])\n\nret = True\nframe_number = -1\nvehicles = [2,3,5]\n\n# read the 10 first frames\nwhile ret:\n    frame_number += 1\n    ret, frame = video.read()\n\n    if ret and frame_number < 100:\n        results[frame_number] = {}\n        \n        # vehicle detector\n        detections = coco_model.track(frame, persist=True)[0]\n        for detection in detections.boxes.data.tolist():\n            x1, y1, x2, y2, track_id, score, class_id = detection\n            if int(class_id) in vehicles and score > 0.5:\n                vehicle_bounding_boxes = []\n                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n                for bbox in vehicle_bounding_boxes:\n                    print(bbox)\n                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n                    \n                    # license plate detector for region of interest\n                    license_plates = np_model(roi)[0]\n                    # process license plate\n                    for license_plate in license_plates.boxes.data.tolist():\n                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n                        # crop plate from region of interest\n                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n                        # de-colorize\n                        plate_gray = cv.cvtColor(plate, cv.COLOR_BGR2GRAY)\n                        # posterize\n                        _, plate_treshold = cv.threshold(plate_gray, 64, 255, cv.THRESH_BINARY_INV)\n                        \n                        # OCR\n                        np_text, np_score = read_license_plate(plate_treshold)\n                        # if plate could be read write results\n                        if np_text is not None:\n                            results[frame_number][track_id] = {\n                                'car': {\n                                    'bbox': [x1, y1, x2, y2],\n                                    'bbox_score': score\n                                },\n                                'license_plate': {\n                                    'bbox': [plate_x1, plate_y1, plate_x2, plate_y2],\n                                    'bbox_score': plate_score,\n                                    'number': np_text,\n                                    'text_score': np_score\n                                }\n                            }\n\nwrite_csv(results, './results.csv')\nvideo.release()\n"})}),"\n",(0,i.jsx)(n.p,{children:"This returns a list with bounding box metrics for every frame with a successful detection:"}),"\n",(0,i.jsx)("br",{}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"frame_number"}),(0,i.jsx)(n.th,{children:"track_id"}),(0,i.jsx)(n.th,{children:"car_bbox"}),(0,i.jsx)(n.th,{children:"license_plate_bbox"}),(0,i.jsx)(n.th,{children:"license_plate_bbox_score"}),(0,i.jsx)(n.th,{children:"license_number"}),(0,i.jsx)(n.th,{children:"license_number_score"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"0"}),(0,i.jsx)(n.td,{children:"1.0"}),(0,i.jsx)(n.td,{children:"[760.1986694335938 614.2100830078125 1123.09130859375 914.9498901367188]"}),(0,i.jsx)(n.td,{children:"[110.20427703857422 133.25326538085938 238.5574493408203 175.96791076660156]"}),(0,i.jsx)(n.td,{children:"0.7692280411720276"}),(0,i.jsx)(n.td,{children:"BPG6UXN"}),(0,i.jsx)(n.td,{children:"0.7290849695998655"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"1"}),(0,i.jsx)(n.td,{children:"1.0"}),(0,i.jsx)(n.td,{children:"[758.7349243164062 612.4984741210938 1122.470458984375 919.1956787109375]"}),(0,i.jsx)(n.td,{children:"[109.57369995117188 134.78448486328125 238.8947296142578 179.6195831298828]"}),(0,i.jsx)(n.td,{children:"0.767607569694519"}),(0,i.jsx)(n.td,{children:"BP6EUXN"}),(0,i.jsx)(n.td,{children:"0.27891552972114064"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"2"}),(0,i.jsx)(n.td,{children:"1.0"}),(0,i.jsx)(n.td,{children:"[755.6078491210938 612.161865234375 1118.7542724609375 920.3657836914062]"}),(0,i.jsx)(n.td,{children:"[109.76798248291016 134.661376953125 239.85276794433594 180.43345642089844]"}),(0,i.jsx)(n.td,{children:"0.7666334509849548"}),(0,i.jsx)(n.td,{children:"BP66UXN"}),(0,i.jsx)(n.td,{children:"0.7696779876170268"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"3"}),(0,i.jsx)(n.td,{children:"1.0"}),(0,i.jsx)(n.td,{children:"[753.9749755859375 611.0296630859375 1115.607421875 920.6179809570312]"}),(0,i.jsx)(n.td,{children:"[109.80683898925781 134.79702758789062 239.79380798339844 180.0568389892578]"}),(0,i.jsx)(n.td,{children:"0.7609436511993408"}),(0,i.jsx)(n.td,{children:"BPG6UXN"}),(0,i.jsx)(n.td,{children:"0.5947437696221942"})]})]})]}),"\n",(0,i.jsx)(n.h3,{id:"step-5-clean-up-license-plate-format",children:"STEP 5 Clean-Up License Plate Format"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# Mapping dictionaries for character conversion\n# characters that can easily be confused can be \n# verified by their location - an `O` in a place\n# where a number is expected is probably a `0`\ndict_char_to_int = {'O': '0',\n                    'I': '1',\n                    'J': '3',\n                    'A': '4',\n                    'G': '6',\n                    'S': '5'}\n\ndict_int_to_char = {'0': 'O',\n                    '1': 'I',\n                    '3': 'J',\n                    '4': 'A',\n                    '6': 'G',\n                    '5': 'S'}\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def license_complies_format(text):\n    # True if the license plate complies with the format, False otherwise.\n    if len(text) != 7:\n        return False\n\n    if (text[0] in string.ascii_uppercase or text[0] in dict_int_to_char.keys()) and \\\n       (text[1] in string.ascii_uppercase or text[1] in dict_int_to_char.keys()) and \\\n       (text[2] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[2] in dict_char_to_int.keys()) and \\\n       (text[3] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[3] in dict_char_to_int.keys()) and \\\n       (text[4] in string.ascii_uppercase or text[4] in dict_int_to_char.keys()) and \\\n       (text[5] in string.ascii_uppercase or text[5] in dict_int_to_char.keys()) and \\\n       (text[6] in string.ascii_uppercase or text[6] in dict_int_to_char.keys()):\n        return True\n    else:\n        return False\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def format_license(text):\n    license_plate_ = ''\n    mapping = {0: dict_int_to_char, 1: dict_int_to_char, 4: dict_int_to_char, 5: dict_int_to_char, 6: dict_int_to_char,\n               2: dict_char_to_int, 3: dict_char_to_int}\n    for j in [0, 1, 2, 3, 4, 5, 6]:\n        if text[j] in mapping[j].keys():\n            license_plate_ += mapping[j][text[j]]\n        else:\n            license_plate_ += text[j]\n\n    return license_plate_\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def read_license_plate(license_plate_crop):\n    detections = reader.readtext(license_plate_crop)\n\n    for detection in detections:\n        bbox, text, score = detection\n\n        text = text.upper().replace(' ', '')\n\n        # verify that text is conform to a standard license plate\n        if license_complies_format(text):\n            # bring text into the default license plate format\n            return format_license(text), score\n\n    return None, None\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"results = {}\n\n# read video by index\nvideo = cv.VideoCapture(videos[1])\n\nret = True\nframe_number = -1\nvehicles = [2,3,5]\n\n# read the entire video\nwhile ret:\n    ret, frame = video.read()\n    frame_number += 1\n    if ret:\n        results[frame_number] = {}\n        \n        # vehicle detector\n        detections = coco_model.track(frame, persist=True)[0]\n        for detection in detections.boxes.data.tolist():\n            x1, y1, x2, y2, track_id, score, class_id = detection\n            if int(class_id) in vehicles and score > 0.5:\n                vehicle_bounding_boxes = []\n                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n                for bbox in vehicle_bounding_boxes:\n                    print(bbox)\n                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n                    \n                    # license plate detector for region of interest\n                    license_plates = np_model(roi)[0]\n                    # process license plate\n                    for license_plate in license_plates.boxes.data.tolist():\n                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n                        # crop plate from region of interest\n                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n                        # de-colorize\n                        plate_gray = cv.cvtColor(plate, cv.COLOR_BGR2GRAY)\n                        # posterize\n                        _, plate_treshold = cv.threshold(plate_gray, 64, 255, cv.THRESH_BINARY_INV)\n                        \n                        # OCR\n                        np_text, np_score = read_license_plate(plate_treshold)\n                        # if plate could be read write results\n                        if np_text is not None:\n                            results[frame_number][track_id] = {\n                                'car': {\n                                    'bbox': [x1, y1, x2, y2],\n                                    'bbox_score': score\n                                },\n                                'license_plate': {\n                                    'bbox': [plate_x1, plate_y1, plate_x2, plate_y2],\n                                    'bbox_score': plate_score,\n                                    'number': np_text,\n                                    'text_score': np_score\n                                }\n                            }\n\nwrite_csv(results, './results.csv')\nvideo.release()\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"results = pd.read_csv('./results.csv')\n\n# show results for tracking ID `1` - sort by OCR prediction confidence\nresults[results['track_id'] == 1.].sort_values(by='license_text_score', ascending=False)\n"})}),"\n",(0,i.jsxs)("div",{children:[(0,i.jsxs)("table",{children:[(0,i.jsx)("thead",{children:(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{}),(0,i.jsx)("th",{children:"frame_number"}),(0,i.jsx)("th",{children:"track_id"}),(0,i.jsx)("th",{children:"car_bbox"}),(0,i.jsx)("th",{children:"car_bbox_score"}),(0,i.jsx)("th",{children:"license_plate_bbox"}),(0,i.jsx)("th",{children:"license_plate_bbox_score"}),(0,i.jsx)("th",{children:"license_plate_number"}),(0,i.jsx)("th",{children:"license_text_score"})]})}),(0,i.jsxs)("tbody",{children:[(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"175"}),(0,i.jsx)("td",{children:"839"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[775.8486938476562 504.52294921875 1095.532592..."}),(0,i.jsx)("td",{children:"0.925278"}),(0,i.jsx)("td",{children:"[102.20135498046875 212.2305908203125 218.7746..."}),(0,i.jsx)("td",{children:"0.752586"}),(0,i.jsx)("td",{children:"NL60GXO"}),(0,i.jsx)("td",{children:"0.988261"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"29"}),(0,i.jsx)("td",{children:"50"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[846.99609375 521.3043823242188 1254.532104492..."}),(0,i.jsx)("td",{children:"0.931958"}),(0,i.jsx)("td",{children:"[133.1925506591797 275.73577880859375 280.6121..."}),(0,i.jsx)("td",{children:"0.740573"}),(0,i.jsx)("td",{children:"NL60GXO"}),(0,i.jsx)("td",{children:"0.966773"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"146"}),(0,i.jsx)("td",{children:"799"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[810.77734375 522.0484008789062 1130.535888671..."}),(0,i.jsx)("td",{children:"0.914011"}),(0,i.jsx)("td",{children:"[102.2442626953125 215.42474365234375 218.7385..."}),(0,i.jsx)("td",{children:"0.752845"}),(0,i.jsx)("td",{children:"NL60GXO"}),(0,i.jsx)("td",{children:"0.953542"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"147"}),(0,i.jsx)("td",{children:"800"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[810.7708740234375 521.808349609375 1130.57128..."}),(0,i.jsx)("td",{children:"0.912922"}),(0,i.jsx)("td",{children:"[102.17294311523438 215.99032592773438 218.767..."}),(0,i.jsx)("td",{children:"0.754186"}),(0,i.jsx)("td",{children:"NL60GXO"}),(0,i.jsx)("td",{children:"0.953522"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"284"}),(0,i.jsx)("td",{children:"1337"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[843.4232788085938 523.5321044921875 1257.2657..."}),(0,i.jsx)("td",{children:"0.910718"}),(0,i.jsx)("td",{children:"[163.98861694335938 263.2216796875 300.1403503..."}),(0,i.jsx)("td",{children:"0.757695"}),(0,i.jsx)("td",{children:"NL60GXO"}),(0,i.jsx)("td",{children:"0.934405"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"..."}),(0,i.jsx)("td",{children:"..."}),(0,i.jsx)("td",{children:"..."}),(0,i.jsx)("td",{children:"..."}),(0,i.jsx)("td",{children:"..."}),(0,i.jsx)("td",{children:"..."}),(0,i.jsx)("td",{children:"..."}),(0,i.jsx)("td",{children:"..."}),(0,i.jsx)("td",{children:"..."})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"191"}),(0,i.jsx)("td",{children:"1010"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[865.4359741210938 488.0260009765625 1060.5764..."}),(0,i.jsx)("td",{children:"0.861625"}),(0,i.jsx)("td",{children:"[65.1905517578125 123.86817169189453 130.26571..."}),(0,i.jsx)("td",{children:"0.761225"}),(0,i.jsx)("td",{children:"KL60GZO"}),(0,i.jsx)("td",{children:"0.043224"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"355"}),(0,i.jsx)("td",{children:"1462"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[685.121826171875 514.077880859375 888.8001098..."}),(0,i.jsx)("td",{children:"0.832969"}),(0,i.jsx)("td",{children:"[92.80020904541016 110.36637115478516 153.4690..."}),(0,i.jsx)("td",{children:"0.739499"}),(0,i.jsx)("td",{children:"HI60CIO"}),(0,i.jsx)("td",{children:"0.036080"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"392"}),(0,i.jsx)("td",{children:"2306"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[462.48388671875 512.8485717773438 933.4752197..."}),(0,i.jsx)("td",{children:"0.929456"}),(0,i.jsx)("td",{children:"[121.44440460205078 294.94183349609375 269.183..."}),(0,i.jsx)("td",{children:"0.722692"}),(0,i.jsx)("td",{children:"WL60YNL"}),(0,i.jsx)("td",{children:"0.031725"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"517"}),(0,i.jsx)("td",{children:"2684"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[856.17333984375 514.7470703125 1043.54296875 ..."}),(0,i.jsx)("td",{children:"0.887135"}),(0,i.jsx)("td",{children:"[59.788631439208984 116.58961486816406 126.729..."}),(0,i.jsx)("td",{children:"0.738799"}),(0,i.jsx)("td",{children:"HL60CKD"}),(0,i.jsx)("td",{children:"0.030968"})]}),(0,i.jsxs)("tr",{children:[(0,i.jsx)("th",{children:"515"}),(0,i.jsx)("td",{children:"2682"}),(0,i.jsx)("td",{children:"298.0"}),(0,i.jsx)("td",{children:"[852.64794921875 512.9298095703125 1043.665893..."}),(0,i.jsx)("td",{children:"0.893880"}),(0,i.jsx)("td",{children:"[61.673500061035156 121.25975799560547 129.707..."}),(0,i.jsx)("td",{children:"0.746015"}),(0,i.jsx)("td",{children:"ML60CZO"}),(0,i.jsx)("td",{children:"0.016401"})]})]})]}),(0,i.jsx)("p",{children:"488 rows \xd7 8 columns"})]}),"\n",(0,i.jsx)(n.h3,{id:"step-6-visualize-the-results",children:"STEP 6 Visualize the Results"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"def draw_border(img, top_left, bottom_right, color=(0, 255, 0), thickness=6, line_length_x=200, line_length_y=200):\n    x1, y1 = top_left\n    x2, y2 = bottom_right\n\n    cv.line(img, (x1, y1), (x1, y1 + line_length_y), color, thickness)  #-- top-left\n    cv.line(img, (x1, y1), (x1 + line_length_x, y1), color, thickness)\n\n    cv.line(img, (x1, y2), (x1, y2 - line_length_y), color, thickness)  #-- bottom-left\n    cv.line(img, (x1, y2), (x1 + line_length_x, y2), color, thickness)\n\n    cv.line(img, (x2, y1), (x2 - line_length_x, y1), color, thickness)  #-- top-right\n    cv.line(img, (x2, y1), (x2, y1 + line_length_y), color, thickness)\n\n    cv.line(img, (x2, y2), (x2, y2 - line_length_y), color, thickness)  #-- bottom-right\n    cv.line(img, (x2, y2), (x2 - line_length_x, y2), color, thickness)\n\n    return img\n"})}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"# read video by index\nvideo = cv.VideoCapture(videos[1])\n\n# get video dims\nframe_width = int(video.get(3))\nframe_height = int(video.get(4))\nsize = (frame_width, frame_height)\n\n# Define the codec and create VideoWriter object\nfourcc = cv.VideoWriter_fourcc(*'DIVX')\nout = cv.VideoWriter('./outputs/processed.avi', fourcc, 20.0, size)\n\n# reset video before you re-run cell below\nframe_number = -1\nvideo.set(cv.CAP_PROP_POS_FRAMES, 0)\n"})}),"\n",(0,i.jsx)(n.p,{children:"True"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-python",children:"ret = True\n\nwhile ret:\n    ret, frame = video.read()\n    frame_number += 1\n    if ret:\n        df_ = results[results['frame_number'] == frame_number]\n        for index in range(len(df_)):\n            # draw car\n            vhcl_x1, vhcl_y1, vhcl_x2, vhcl_y2 = ast.literal_eval(df_.iloc[index]['car_bbox'].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n            \n            draw_border(\n                frame, (int(vhcl_x1), int(vhcl_y1)),\n                (int(vhcl_x2), int(vhcl_y2)), (0, 255, 0),\n                12, line_length_x=200, line_length_y=200)\n            \n            # draw license plate\n            plate_x1, plate_y1, plate_x2, plate_y2 = ast.literal_eval(df_.iloc[index]['license_plate_bbox'].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n\n            # region of interest\n            roi = frame[int(vhcl_y1):int(vhcl_y2), int(vhcl_x1):int(vhcl_x2)]\n            cv.rectangle(roi, (int(plate_x1), int(plate_y1)), (int(plate_x2), int(plate_y2)), (0, 0, 255), 6)\n\n            # write detected number\n            (text_width, text_height), _ = cv.getTextSize(\n                df_.iloc[index]['license_plate_number'],\n                cv.FONT_HERSHEY_SIMPLEX,\n                2,\n                6)\n\n            cv.putText(\n                frame,\n                df_.iloc[index]['license_plate_number'],\n                (int((vhcl_x2 + vhcl_x1 - text_width)/2), int(vhcl_y1 - text_height)),\n                cv.FONT_HERSHEY_SIMPLEX,\n                2,\n                (0, 255, 0),\n                6\n            )\n\n        out.write(frame)\n        frame = cv.resize(frame, (1280, 720))\n\nout.release()\nvideo.release()\n"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{alt:"processed.webp",src:t(504471).Z+"",width:"1788",height:"476"})})]})}function h(e={}){const{wrapper:n}={...(0,s.ah)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(o,{...e})}):o(e)}},603905:(e,n,t)=>{t.d(n,{ah:()=>d});var i=t(667294);function s(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);n&&(i=i.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,i)}return t}function c(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){s(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,i,s=function(e,n){if(null==e)return{};var t,i,s={},r=Object.keys(e);for(i=0;i<r.length;i++)t=r[i],n.indexOf(t)>=0||(s[t]=e[t]);return s}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)t=r[i],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(s[t]=e[t])}return s}var a=i.createContext({}),d=function(e){var n=i.useContext(a),t=n;return e&&(t="function"==typeof e?e(n):c(c({},n),e)),t},o={inlineCode:"code",wrapper:function(e){var n=e.children;return i.createElement(i.Fragment,{},n)}},h=i.forwardRef((function(e,n){var t=e.components,s=e.mdxType,r=e.originalType,a=e.parentName,h=l(e,["components","mdxType","originalType","parentName"]),p=d(t),x=s,m=p["".concat(a,".").concat(x)]||p[x]||o[x]||r;return t?i.createElement(m,c(c({ref:n},h),{},{components:t})):i.createElement(m,c({ref:n},h))}));h.displayName="MDXCreateElement"},553629:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/confusion_matrix_normalized-fbac84dd568e663b76bfd3d0b78cdd50.webp"},841616:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/detected_cars-67d3bcb7e8683698e567b2e004a23c0d.webp"},173943:(e,n,t)=>{t.d(n,{Z:()=>i});const i="data:image/webp;base64,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"},560549:(e,n,t)=>{t.d(n,{Z:()=>i});const i="data:image/webp;base64,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"},653493:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-864be48f76a28ed6a3e155f7ab51bc74.jpg"},504471:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/processed-5751cab7b691c0c9b52cee8356bce340.webp"},587708:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/results-5cfd13401f48fa7e53cc0ef357764aff.webp"},579768:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/uk_dash-f7d953ee634f62578a3b703c543ac2d7.webp"},526491:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/uk_dash_np-ae2f529ea3d1e10b8d1fe5656f1e641a.webp"},766487:(e,n,t)=>{t.d(n,{Z:()=>i});const i=t.p+"assets/images/validation_batch-a388f384f76d8c8f5215752148bda3be.webp"}}]);