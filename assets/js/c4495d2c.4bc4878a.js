"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[86261],{617817:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>o,contentTitle:()=>r,default:()=>p,frontMatter:()=>i,metadata:()=>l,toc:()=>c});var a=t(474848),s=t(28453);const i={sidebar_position:4570,slug:"2024-02-21",title:"MLFlow with PyTorch Lighning in Docker",authors:"mpolinowski",tags:["Python","Machine Learning","MLFlow","Docker"],description:"Experiment with running pyTorch, Jupyter and MLFlow in Docker"},r="MLFlow Docker",l={id:"IoT-and-Machine-Learning/AIOps/2024-02-21-mlflow-pytorch-lightning-docker/index",title:"MLFlow with PyTorch Lighning in Docker",description:"Experiment with running pyTorch, Jupyter and MLFlow in Docker",source:"@site/docs/IoT-and-Machine-Learning/AIOps/2024-02-21-mlflow-pytorch-lightning-docker/index.md",sourceDirName:"IoT-and-Machine-Learning/AIOps/2024-02-21-mlflow-pytorch-lightning-docker",slug:"/IoT-and-Machine-Learning/AIOps/2024-02-21-mlflow-pytorch-lightning-docker/2024-02-21",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2024-02-21-mlflow-pytorch-lightning-docker/2024-02-21",draft:!1,unlisted:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/AIOps/2024-02-21-mlflow-pytorch-lightning-docker/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"},{label:"MLFlow",permalink:"/docs/tags/ml-flow"},{label:"Docker",permalink:"/docs/tags/docker"}],version:"current",sidebarPosition:4570,frontMatter:{sidebar_position:4570,slug:"2024-02-21",title:"MLFlow with PyTorch Lighning in Docker",authors:"mpolinowski",tags:["Python","Machine Learning","MLFlow","Docker"],description:"Experiment with running pyTorch, Jupyter and MLFlow in Docker"},sidebar:"tutorialSidebar",previous:{title:"MLFlow Hyperparameter Tuning in Docker",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2024-02-24-mlflow-hyperparameter-tuning/2024-02-24"},next:{title:"MLOps with ZenML - SKLearn Classifier Pipeline",permalink:"/docs/IoT-and-Machine-Learning/AIOps/2023-09-27-zenml-intro-sklearn-pipeline/2023-09-27"}},o={},c=[{value:"Create an MLFlow Experiment",id:"create-an-mlflow-experiment",level:2},{value:"Dataset",id:"dataset",level:3},{value:"Model Training",id:"model-training",level:3},{value:"Model Prediction",id:"model-prediction",level:3}];function d(e){const n={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"Guangzhou, China",src:t(370535).A+"",width:"1061",height:"405"})}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"#mlflow-docker",children:"MLFlow Docker"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.a,{href:"#create-an-mlflow-experiment",children:"Create an MLFlow Experiment"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#dataset",children:"Dataset"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#model-training",children:"Model Training"})}),"\n",(0,a.jsx)(n.li,{children:(0,a.jsx)(n.a,{href:"#model-prediction",children:"Model Prediction"})}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,a.jsx)(n.h1,{id:"mlflow-docker",children:"MLFlow Docker"}),"\n",(0,a.jsxs)(n.p,{children:["This is just an experiment to see if I can use MLFlow inside my ",(0,a.jsx)(n.a,{href:"https://github.com/mpolinowski/pytorch-jupyter",children:"pytorch-jupyter"})," Docker container. To do this I added MLFlow to the Dockerfile:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-Dockerfile",children:'FROM pytorch/pytorch:latest\n\n# Set environment variables\nENV DEBIAN_FRONTEND=noninteractive\n\n# Install system dependencies\nRUN apt-get update && \\\n    apt-get install -y \\\n        git \\\n        tini \\\n        python3-pip \\\n        python3-dev \\\n        python3-opencv \\\n        libglib2.0-0\n\n# intall optional python deps\nRUN python -m pip install --upgrade pip\n# jupyter notebooks\nRUN pip install jupyter\n# fastdup https://github.com/visual-layer/fastdup\nRUN pip install fastdup\nRUN pip install opencv-python\nRUN pip install matplotlib matplotlib-inline pandas\nRUN pip install pillow\nRUN pip install pyyaml\n# YOLO 8.1\nRUN pip install ultralytics Cython>=0.29.32 lapx>=0.5.5\n# MLFlow 2.10\nRUN pip install mlflow pytorch_lightning\n\n\n\n# Set the working directory\nWORKDIR /opt/app\n\n# Start the notebook\nRUN chmod +x /usr/bin/tini\nENTRYPOINT ["/usr/bin/tini", "--"]\nCMD ["jupyter", "notebook", "--port=8888", "--no-browser", "--ip=0.0.0.0", "--allow-root"]\n'})}),"\n",(0,a.jsx)(n.p,{children:"Let's build this custom image with:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker build -t pytorch-jupyter . -f Dockerfile\n"})}),"\n",(0,a.jsx)(n.p,{children:"I can now create the container and mount my working directory into the container WORKDIR to get started:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker run --ipc=host --gpus all -ti --rm \\\n    -v $(pwd):/opt/app -p 8888:8888 -p 5000:5000 \\\n    --name pytorch-jupyter \\\n    pytorch-jupyter:latest\n"})}),"\n",(0,a.jsxs)(n.p,{children:["This will start Jupyter on Port ",(0,a.jsx)(n.code,{children:"8888"})," and I can start MLFlow manually:"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"docker exec -ti pytorch-jupyter mlflow ui --host 0.0.0.0\n"})}),"\n",(0,a.jsxs)(n.p,{children:["The MLFlow is now available on ",(0,a.jsx)(n.code,{children:"localhost:5000"})," on my host system:"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(418431).A+"",width:"1159",height:"386"})}),"\n",(0,a.jsx)(n.p,{children:"Just to be sure I stop MLFlow and try to run it directly from a Jupyter Notebook:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-pythno",children:'get_ipython().system_raw("mlflow ui --port 5000 --host 0.0.0.0 &")\n'})}),"\n",(0,a.jsxs)(n.p,{children:["And the UI is still available on ",(0,a.jsx)(n.code,{children:"localhost:5000"})," - nice:"]}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(81572).A+"",width:"1163",height:"607"})}),"\n",(0,a.jsx)(n.h2,{id:"create-an-mlflow-experiment",children:"Create an MLFlow Experiment"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'experiment_name = "emnist_classifier_dnn"\nmlflow.create_experiment(experiment_name)\nmlflow.set_experiment(experiment_name)\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(335469).A+"",width:"1187",height:"475"})}),"\n",(0,a.jsx)(n.h3,{id:"dataset",children:"Dataset"}),"\n",(0,a.jsxs)(n.p,{children:["Starting a classification run on the ",(0,a.jsx)(n.a,{href:"https://www.nist.gov/itl/products-and-services/emnist-dataset",children:"EMNIST Handwritten Character Set"}),":"]}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'emnist_train_data = pd.read_csv("./datasets/emnist-letters-train.csv", header=None)\n\nemnist_test_data = pd.read_csv("./datasets/emnist-letters-test.csv", header=None)\nemnist_test_data = emnist_test_data.sample(frac=1)\n\n# extract labels\ntrain_labels = emnist_train_data.values[:, 0]\ntrain_images = emnist_train_data.values[:, 1:]\n\n# reshape image to the original 28x28 shape\ntrain_images = train_images.reshape(-1, 28, 28)\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(530610).A+"",width:"1178",height:"806"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'dataset_info = """\nThe EMNIST dataset is a set of handwritten character digits derived from the NIST Special Database 19  and converted to a 28x28 pixel image format and dataset structure that directly matches the MNIST dataset . Further information on the dataset contents and conversion process can be found in the paper available at https://arxiv.org/abs/1702.05373v1\n"""\n\nwith open("dataset_info.txt", "w") as f:\n    f.write(dataset_info)\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"with mlflow.start_run(run_name = 'emnist_classifier_dnn_test_run') as current_run:\n    mlflow.log_metric('Accuracy', 0.67)\n\n    params = {\n        'num_nn_layers': 4\n    }\n    \n    mlflow.log_params(params)\n    mlflow.log_figure(fig, 'sample_images.jpg')\n    mlflow.log_artifact('dataset_info.txt')\n    mlflow.set_tag('EMNIST', 'Character Classification')\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(245435).A+"",width:"1377",height:"906"})}),"\n",(0,a.jsx)(n.p,{children:"Perform a train/test/val split and prepare the dataloaders needed for the model training:"}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(467104).A+"",width:"1187",height:"575"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:"train_dl = DataLoader(train, BATCH_SIZE, shuffle=True, drop_last=True, num_workers=1)\nval_dl = DataLoader(val, BATCH_SIZE, num_workers=1)\ntest_dl = DataLoader(test_dataset, BATCH_SIZE, num_workers=1)\n\ndataiter = iter(train_dl)\nbatch_images, batch_labels = next(dataiter)\n"})}),"\n",(0,a.jsx)(n.h3,{id:"model-training",children:"Model Training"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'class EmnistModel(pl.LightningModule):\n    def __init__(self):\n        super().__init__()\n        self.criterion = nn.CrossEntropyLoss()\n\n        self.linear1 = nn.Linear(INPUT_SIZE, 512)\n        self.linear2 = nn.Linear(512, 128)\n        self.linear3 = nn.Linear(128, 32)\n        self.linear4 = nn.Linear(32, OUTPUT_SIZE)\n\n    def forward(self, xb):\n        out = self.linear1(xb)\n        out = F.relu(out)\n\n        out = self.linear2(out)\n        out = F.relu(out)\n\n        out = self.linear3(out)\n        out = F.relu(out)\n\n        out = self.linear4(out)\n        return out\n\n    def configure_optimizers(self):\n        return optim.Adam(self.parameters(), lr = 0.0001)\n\n    def training_step(self, batch, batch_idx):\n        # batches consists of images and labels\n        x, y = batch\n        # labels start at 1 but the classes at 0\n        y -= 1\n\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y.long())\n        pred = y_hat.argmax(dim = 1)\n\n        acc = accuracy(pred, y, task="multiclass", num_classes=26)\n\n        self.log("train_loss", loss, on_epoch=True, prog_bar=True)\n        self.log("train_acc", acc, on_epoch=True, prog_bar=True)\n\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        x, y = batch\n        y -= 1\n\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y.long())\n        pred = y_hat.argmax(dim=1)\n\n        acc = accuracy(pred, y, task="multiclass", num_classes=26)\n        \n        self.log("val_loss", loss, on_epoch=True, prog_bar=True)\n        self.log("val_acc", acc, on_epoch=True, prog_bar=True)\n\n        return acc\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        y -= 1\n\n        y_hat = self(x)\n        loss = self.criterion(y_hat, y.long())\n        pred = y_hat.argmax(dim=1)\n\n        acc = accuracy(pred, y, task="multiclass", num_classes=26)\n        \n        self.log("test_loss", loss, on_epoch=True, prog_bar=True)\n        self.log("test_acc", acc, on_epoch=True, prog_bar=True)\n\n        return acc\n\n    def predict_step(self, batch, batch_idx, dataloaders_idx=0):\n        x, y = batch\n        return self(x)\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'emnist_model = EmnistModel()\nlogger = CSVLogger("logs", name="emnist_classifier_dnn")\ntrainer = pl.Trainer(max_epochs = 10, logger=logger)\nmlflow.pytorch.autolog(log_models = False)\n'})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'with mlflow.start_run() as run:\n    trainer.fit(emnist_model, train_dl, val_dl)\n    trainer.test(dataloaders = test_dl)\n\n    input_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 784))])\n    output_schema = Schema([TensorSpec(np.dtype(np.float32), (-1, 26))])\n\n    signature = ModelSignature(inputs = input_schema, outputs = output_schema)\n\n    mlflow.pytorch.log_model(emnist_model, "emnist_classifier_dnn", signature = signature)\n\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#        Test metric             DataLoader 0\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n#         test_acc            0.8519594669342041\n#         test_loss           0.4712047874927521\n# \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(861577).A+"",width:"1272",height:"747"})}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"metrics = pd.read_csv(f\"{trainer.logger.log_dir}/metrics.csv\")\nmetrics.set_index(\"epoch\", inplace=True)\nmetrics.drop(columns=['step', 'train_loss_step',\n                      'train_acc_step', 'test_acc', 'test_loss'], inplace=True)\nsns.lineplot(data=metrics)\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(315710).A+"",width:"1166",height:"467"})}),"\n",(0,a.jsx)(n.h3,{id:"model-prediction",children:"Model Prediction"}),"\n",(0,a.jsx)(n.p,{children:"Get a sample set of test images:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"test_dataiter = iter(test_dl)\ntest_images, test_labels = next(test_dataiter)\ntest_images.shape, test_labels.shape\n"})}),"\n",(0,a.jsx)(n.p,{children:"Run them trough the trained model to return predictions:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'model_path = f"runs:/{run_id}/emnist_classifier_dnn"\nloaded_model = mlflow.pyfunc.load_model(model_path)\n\npredictions = loaded_model.predict(test_images.numpy())\n'})}),"\n",(0,a.jsx)(n.p,{children:"To display the prediction we first need to get the images back into shape:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"# reshape image to the original 28x28 shape\ntest_images_reshaped = test_images.reshape(-1, 28, 28)\ntest_samples = np.random.randint(0, len(test_images_reshaped), 16)\n"})}),"\n",(0,a.jsx)(n.p,{children:"Now we can plot them using Matplotlib:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:'fig = plt.figure(figsize = (8, 8))\n\nfor i, idx in enumerate(test_samples):\n    true_label = classes[int(test_labels[idx].item()) - 1]\n    pred_label = classes[np.argmax(predictions[idx])]\n    \n    plt.subplot(4, 4, i+1)\n    plt.imshow(test_images[idx] / 255.0, cmap="gray")\n    plt.title(f"True: {true_label} || Pred: {pred_label}")\n    plt.axis(\'off\')\n\nplt.tight_layout()\nplt.show()\n'})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(68199).A+"",width:"1198",height:"797"})}),"\n",(0,a.jsx)(n.p,{children:"Verify the overall performance by creating a confusion matrix over all test predictions:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",children:"x_pred = []\ny_true = []\n\nfor inputs, labels in test_dl:\n    output = loaded_model.predict(inputs.numpy())\n\n    output = np.argmax(output, axis=1).astype('float64').tolist()\n    y_pred.extend(output)\n\n    labels = [x-1 for x in labels.tolist()]\n    y_true.extend(labels)\n\ncm = confusion_matrix(y_true, y_pred)\nconfusion = ConfusionMatrixDisplay(cm, display_labels=classes)\n\nfig, ax = plt.subplots(figsize = (12,8))\nconfusion.plot(ax = ax)\n"})}),"\n",(0,a.jsx)(n.p,{children:(0,a.jsx)(n.img,{alt:"MLFlow in Docker",src:t(457521).A+"",width:"1178",height:"713"})})]})}function p(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},418431:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_01-f0b4ba218155653aea904b5277b5c9da.png"},81572:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_02-c02378e9e89e209c1b7466e1ca043692.png"},335469:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_03-0e882ed4e615ec2790213e7ece59fe64.png"},530610:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_04-a695dccec5002638451ad3a1636d8809.png"},245435:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_05-9b2d43005decc59eee65e4811d38c46b.png"},467104:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_06-a5ad5135964ac885e1db73e66b29c30f.png"},861577:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_07-0a2c4e74805dd0d954ae66327a5f48d9.png"},315710:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_08-74b85b419a4121e3be86bd901dbaf504.png"},68199:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_09-9eb1bfa15598b7bdc53ca2d9adb21dad.png"},457521:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/MLFlow_Docker_10-1b91fed144ce2eabcaef742c64d9363f.png"},370535:(e,n,t)=>{t.d(n,{A:()=>a});const a=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-fe9bbb57ea8da08fea2f3fef2bf2515b.jpg"},28453:(e,n,t)=>{t.d(n,{R:()=>r,x:()=>l});var a=t(296540);const s={},i=a.createContext(s);function r(e){const n=a.useContext(i);return a.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:r(e.components),a.createElement(i.Provider,{value:n},e.children)}}}]);