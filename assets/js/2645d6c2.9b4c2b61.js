"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[91501],{3905:(e,t,a)=>{a.d(t,{Zo:()=>p,kt:()=>d});var n=a(67294);function l(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function i(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function o(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?i(Object(a),!0).forEach((function(t){l(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):i(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function r(e,t){if(null==e)return{};var a,n,l=function(e,t){if(null==e)return{};var a,n,l={},i=Object.keys(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||(l[a]=e[a]);return l}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(n=0;n<i.length;n++)a=i[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(l[a]=e[a])}return l}var s=n.createContext({}),m=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):o(o({},t),e)),a},p=function(e){var t=m(e.components);return n.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},g=n.forwardRef((function(e,t){var a=e.components,l=e.mdxType,i=e.originalType,s=e.parentName,p=r(e,["components","mdxType","originalType","parentName"]),g=m(a),d=l,u=g["".concat(s,".").concat(d)]||g[d]||c[d]||i;return a?n.createElement(u,o(o({ref:t},p),{},{components:a})):n.createElement(u,o({ref:t},p))}));function d(e,t){var a=arguments,l=t&&t.mdxType;if("string"==typeof e||l){var i=a.length,o=new Array(i);o[0]=g;var r={};for(var s in t)hasOwnProperty.call(t,s)&&(r[s]=t[s]);r.originalType=e,r.mdxType="string"==typeof e?e:l,o[1]=r;for(var m=2;m<i;m++)o[m]=a[m];return n.createElement.apply(null,o)}return n.createElement.apply(null,a)}g.displayName="MDXCreateElement"},19066:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>c,frontMatter:()=>i,metadata:()=>r,toc:()=>m});var n=a(87462),l=(a(67294),a(3905));const i={sidebar_position:4320,slug:"2023-07-26",title:"Human Emotion Detection with Tensorflow",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Create a TF Image Classifier that can distinguish between different human emotion based on portrait photos."},o=void 0,r={unversionedId:"IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/index",id:"IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/index",title:"Human Emotion Detection with Tensorflow",description:"Create a TF Image Classifier that can distinguish between different human emotion based on portrait photos.",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector",slug:"/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/2023-07-26",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/2023-07-26",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4320,frontMatter:{sidebar_position:4320,slug:"2023-07-26",title:"Human Emotion Detection with Tensorflow",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Create a TF Image Classifier that can distinguish between different human emotion based on portrait photos."},sidebar:"tutorialSidebar",previous:{title:"Tensorflow VITs",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-07-27-tensorflow-vision-transformer/2023-07-27"},next:{title:"Working with ONNX Models",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/2023-07-25"}},s={},m=[{value:"Building a Basic Model",id:"building-a-basic-model",level:2},{value:"Dataset",id:"dataset",level:3},{value:"LeNet 5 Model",id:"lenet-5-model",level:3},{value:"Model Training",id:"model-training",level:3},{value:"Model Evaluation",id:"model-evaluation",level:4},{value:"Add Data Augmentation to prevent Overfitting",id:"add-data-augmentation-to-prevent-overfitting",level:2},{value:"Model Training",id:"model-training-1",level:3},{value:"Model Evaluation",id:"model-evaluation-1",level:4},{value:"Cutmix Data Augmentation",id:"cutmix-data-augmentation",level:2},{value:"Model Building",id:"model-building",level:3},{value:"Model Training",id:"model-training-2",level:3},{value:"Model Evaluation",id:"model-evaluation-2",level:3},{value:"Saving the Model",id:"saving-the-model",level:3},{value:"Saving the Augmented Dataset",id:"saving-the-augmented-dataset",level:3},{value:"Reconstructing the Augmented Dataset (This part does not work yet!)",id:"reconstructing-the-augmented-dataset-this-part-does-not-work-yet",level:3},{value:"Transfer Learning",id:"transfer-learning",level:2},{value:"Building the Efficient TF Model",id:"building-the-efficient-tf-model",level:3},{value:"Model Training",id:"model-training-3",level:4},{value:"Model Evaluation",id:"model-evaluation-3",level:4},{value:"Saving the Model",id:"saving-the-model-1",level:4},{value:"Building the MobileNet TF Model",id:"building-the-mobilenet-tf-model",level:3},{value:"Model Training",id:"model-training-4",level:4},{value:"Model Evaluation",id:"model-evaluation-4",level:4},{value:"Saving the Model",id:"saving-the-model-2",level:4},{value:"TFLite Conversion",id:"tflite-conversion",level:3},{value:"Finetuning the MobileNet TF Model",id:"finetuning-the-mobilenet-tf-model",level:2},{value:"Model Training",id:"model-training-5",level:3},{value:"Model Evaluation",id:"model-evaluation-5",level:3},{value:"Model Finetuning",id:"model-finetuning",level:3},{value:"Model Evaluation",id:"model-evaluation-6",level:3},{value:"Saving the Model",id:"saving-the-model-3",level:3},{value:"TFLite Conversion",id:"tflite-conversion-1",level:3}],p={toc:m};function c(e){let{components:t,...i}=e;return(0,l.kt)("wrapper",(0,n.Z)({},p,i,{components:t,mdxType:"MDXLayout"}),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"TST, Hong Kong",src:a(36724).Z,width:"1500",height:"549"})),(0,l.kt)("h1",{id:"human-emotion-detection-with-tensorflow"},"Human Emotion Detection with Tensorflow"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#human-emotion-detection-with-tensorflow"},"Human Emotion Detection with Tensorflow"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#building-a-basic-model"},"Building a Basic Model"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#dataset"},"Dataset")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#lenet-5-model"},"LeNet 5 Model")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-training"},"Model Training"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-evaluation"},"Model Evaluation")))))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#add-data-augmentation-to-prevent-overfitting"},"Add Data Augmentation to prevent Overfitting"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-training-1"},"Model Training"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-evaluation-1"},"Model Evaluation")))))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#cutmix-data-augmentation"},"Cutmix Data Augmentation"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-building"},"Model Building")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-training-2"},"Model Training")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-evaluation-2"},"Model Evaluation")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#saving-the-model"},"Saving the Model")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#saving-the-augmented-dataset"},"Saving the Augmented Dataset")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#reconstructing-the-augmented-dataset-this-part-does-not-work-yet"},"Reconstructing the Augmented Dataset (This part does not work yet!)")))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#transfer-learning"},"Transfer Learning"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#building-the-efficient-tf-model"},"Building the Efficient TF Model"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-training-3"},"Model Training")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-evaluation-3"},"Model Evaluation")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#saving-the-model-1"},"Saving the Model")))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#building-the-mobilenet-tf-model"},"Building the MobileNet TF Model"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-training-4"},"Model Training")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-evaluation-4"},"Model Evaluation")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#saving-the-model-2"},"Saving the Model")))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#tflite-conversion"},"TFLite Conversion")))),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#finetuning-the-mobilenet-tf-model"},"Finetuning the MobileNet TF Model"),(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-training-5"},"Model Training")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-evaluation-5"},"Model Evaluation")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-finetuning"},"Model Finetuning")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#model-evaluation-6"},"Model Evaluation")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#saving-the-model-3"},"Saving the Model")),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"#tflite-conversion-1"},"TFLite Conversion"))))))),(0,l.kt)("p",null,(0,l.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/tf-i-know-flowers"},"Github Repository")),(0,l.kt)("h2",{id:"building-a-basic-model"},"Building a Basic Model"),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("a",{parentName:"li",href:"https://www.kaggle.com/datasets/muhammadhananasghar/human-emotions-datasethes"},"Human Emotions Dataset"))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"import cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom PIL import Image\nfrom sklearn.metrics import (\n    classification_report,\n    confusion_matrix,\n    ConfusionMatrixDisplay)\nimport seaborn as sns\n\nimport tensorflow as tf\n# import tensorflow_dataset as tfds\n# import tensorflow_probability as tfp\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.callbacks  import (\n    Callback,\n    CSVLogger,\n    EarlyStopping,\n    LearningRateScheduler,\n    ModelCheckpoint\n)\nfrom tensorflow.keras.layers import (\n    Layer,\n    GlobalAveragePooling2D,\n    Conv2D,\n    MaxPool2D,\n    Dense,\n    Flatten,\n    InputLayer,\n    BatchNormalization,\n    Input,\n    Dropout,\n    RandomFlip,\n    RandomRotation,\n    Resizing,\n    Rescaling\n)\nfrom tensorflow.keras.losses import BinaryCrossentropy, CategoricalCrossentropy\nfrom tensorflow.keras.metrics import CategoricalAccuracy, TopKCategoricalAccuracy\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.regularizers import L2, L1\nfrom tensorflow.keras.utils import image_dataset_from_directory\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"BATCH = 32\nSIZE = 256\nSEED = 444\n\nEPOCHS = 30\nLR = 0.001\nFILTERS = 6\nKERNEL = 3\nSTRIDES = 1\nREGRATE = 0.0\nPOOL = 2\nDORATE = 0.05\nNLABELS = 3\nDENSE1 = 100\nDENSE2 = 10\n")),(0,l.kt)("h3",{id:"dataset"},"Dataset"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"train_directory = './dataset/Emotions Dataset/Emotions Dataset/train'\ntest_directory = './dataset/Emotions Dataset/Emotions Dataset/test'\nLABELS = ['angry', 'happy', 'sad']\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"train_dataset = image_dataset_from_directory(\n    train_directory,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=LABELS,\n    color_mode='rgb',\n    batch_size=BATCH,\n    image_size=(SIZE, SIZE),\n    shuffle=True,\n    seed=SEED,\n#     validation_split=0.2,\n#     subset='validation',\n    interpolation='bilinear',\n    follow_links=False,\n    crop_to_aspect_ratio=False\n)\n\n# Found 6799 images belonging to 3 classes.\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_dataset = image_dataset_from_directory(\n    test_directory,\n    labels='inferred',\n    label_mode='categorical',\n    class_names=LABELS,\n    color_mode='rgb',\n    batch_size=BATCH,\n    image_size=(SIZE, SIZE),\n    shuffle=True,\n    seed=SEED\n)\n\n# Found 2278 images belonging to 3 classes.\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.figure(figsize=(16,16))\n\nfor images, labels in train_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        plt.title(LABELS[tf.argmax(labels[i], axis=0).numpy()])\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/tf_Emotion_Detection_01.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(37058).Z,width:"1258",height:"1274"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"training_dataset = (\n    train_dataset.prefetch(\n        tf.data.AUTOTUNE\n    )\n)\n\ntesting_dataset = (\n    test_dataset.prefetch(\n        tf.data.AUTOTUNE\n    )\n)\n")),(0,l.kt)("h3",{id:"lenet-5-model"},"LeNet 5 Model"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"resize_rescale_layers = Sequential([\n    Resizing(SIZE, SIZE),\n    Rescaling(1./255)\n])\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet = Sequential([\n    InputLayer(input_shape=(None, None, 3)),  \n    resize_rescale_layers,  \n    Conv2D(\n        filters = FILTERS,\n        kernel_size = KERNEL,\n        strides = STRIDES,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),  \n    BatchNormalization(),   \n    MaxPool2D(\n        pool_size = POOL,\n        strides = STRIDES*2\n    ),   \n    Dropout(rate=DORATE),   \n    Conv2D(\n        filters = FILTERS*2+4,\n        kernel_size = KERNEL,\n        strides = STRIDES,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    MaxPool2D(\n        pool_size = POOL,\n        strides = STRIDES*2\n    ),    \n    Flatten(),    \n    Dense(\n        DENSE1,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    Dropout(rate=DORATE),    \n    Dense(\n        DENSE2,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    Dense(\n        NLABELS,\n        activation = 'softmax',\n        name = 'Output'\n    )\n])\n\nmodel_lenet.build(input_shape=(SIZE, SIZE, 3))\nmodel_lenet.summary()\n\n# Total params: 4,668,319\n# Trainable params: 4,668,055\n# Non-trainable params: 264\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"loss_function = CategoricalCrossentropy(\n    from_logits = False,\n    label_smoothing = 0.0,\n    axis = -1,\n    name = 'categorical_crossentropy'\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"metrics = [\n    CategoricalAccuracy(name='accuracy'),\n    TopKCategoricalAccuracy(k=2,name='topk-accuracy')\n]\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet.compile(\n    optimizer = Adam(learning_rate = LR),\n    loss = loss_function,\n    metrics = metrics\n)\n")),(0,l.kt)("h3",{id:"model-training"},"Model Training"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"history_lenet = model_lenet.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    verbose = 1\n)\n\n# loss: 0.0454\n# accuracy: 0.9803\n# topk-accuracy: 0.9982\n# val_loss: 1.1798\n# val_accuracy: 0.7441\n# val_topk-accuracy: 0.8955\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(history_lenet.history['loss'])\nplt.plot(history_lenet.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss', 'val_loss'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(2054).Z,width:"569",height:"455"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(history_lenet.history['accuracy'])\nplt.plot(history_lenet.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train_accuracy', 'val_accuracy'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(68029).Z,width:"569",height:"455"})),(0,l.kt)("h4",{id:"model-evaluation"},"Model Evaluation"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet.evaluate(testing_dataset)\n# loss: 1.1798 - accuracy: 0.7441 - topk-accuracy: 0.8955\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/happy.jpg')\n\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = model_lenet(img).numpy()\nprint(label)\n# [[0.1078622  0.8603977  0.03174012]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# happy\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/sad.jpg')\n\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = model_lenet(img).numpy()\nprint(label)\n# [[9.1999680e-02 2.9016874e-04 9.0771013e-01]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# sad\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/angry.jpg')\n\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = model_lenet(img).numpy()\nprint(label)\n# [[9.9998641e-01 1.3307266e-06 1.2283378e-05]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# angry\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.figure(figsize=(16,16))\n\nfor images, labels in test_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n        pred = \"Predicted: \" + LABELS[\n            tf.argmax(model_lenet(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n        ]\n        plt.title(\n           true  + \"\\n\" + pred\n        )\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/tf_Emotion_Detection_04.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(95988).Z,width:"1258",height:"1295"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"y_pred = []\ny_test = []\n\nfor img, label in testing_dataset:\n    y_pred.append(model_lenet(img))\n    y_test.append(label.numpy())\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"conf_mtx = ConfusionMatrixDisplay(\n    confusion_matrix=confusion_matrix(\n        np.argmax(y_test[:-1], axis=-1).flatten(),\n        np.argmax(y_pred[:-1], axis=-1).flatten()\n    ),\n    display_labels=LABELS\n)\n\nfig, ax = plt.subplots(figsize=(16,12))\nconf_mtx.plot(ax=ax, cmap='plasma', include_values=False)\n        \nplt.savefig('assets/tf_Emotion_Detection_05.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(80593).Z,width:"1160",height:"987"})),(0,l.kt)("h2",{id:"add-data-augmentation-to-prevent-overfitting"},"Add Data Augmentation to prevent Overfitting"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"resize_rescale_layers = Sequential([\n    Resizing(SIZE, SIZE),\n    Rescaling(1./255)\n])\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"data_augmentation = Sequential([\n    RandomRotation(factor=0.25),\n    RandomFlip(mode='horizontal',),\n    RandomContrast(factor=0.1),\n    # RandomBrightness(0.1)\n])\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"training_dataset = (\n    train_dataset\n    .map(lambda image, label: (data_augmentation(image), label))\n    .prefetch(tf.data.AUTOTUNE)\n)\n\n\ntesting_dataset = (\n    test_dataset.prefetch(\n        tf.data.AUTOTUNE\n    )\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet = Sequential([\n    InputLayer(input_shape=(None, None, 3)),  \n    resize_rescale_layers,  \n    Conv2D(\n        filters = FILTERS,\n        kernel_size = KERNEL,\n        strides = STRIDES,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),  \n    BatchNormalization(),   \n    MaxPool2D(\n        pool_size = POOL,\n        strides = STRIDES*2\n    ),   \n    Dropout(rate=DORATE),   \n    Conv2D(\n        filters = FILTERS*2+4,\n        kernel_size = KERNEL,\n        strides = STRIDES,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    MaxPool2D(\n        pool_size = POOL,\n        strides = STRIDES*2\n    ),    \n    Flatten(),    \n    Dense(\n        DENSE1,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    Dropout(rate=DORATE),    \n    Dense(\n        DENSE2,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    Dense(\n        NLABELS,\n        activation = 'softmax',\n        name = 'Output'\n    )\n])\n\nmodel_lenet.build(input_shape=(SIZE, SIZE, 3))\nmodel_lenet.summary()\n\n# Total params: 4,668,319\n# Trainable params: 4,668,055\n# Non-trainable params: 264\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"loss_function = CategoricalCrossentropy(\n    from_logits = False,\n    label_smoothing = 0.0,\n    axis = -1,\n    name = 'categorical_crossentropy'\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"metrics = [\n    CategoricalAccuracy(name='accuracy'),\n    TopKCategoricalAccuracy(k=2,name='topk-accuracy')\n]\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet.compile(\n    optimizer = Adam(learning_rate = LR),\n    loss = loss_function,\n    metrics = metrics\n)\n")),(0,l.kt)("h3",{id:"model-training-1"},"Model Training"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"history_lenet = model_lenet.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    verbose = 1\n)\n\n# loss: 0.5282 - accuracy: 0.7820\n# topk-accuracy: 0.9394\n# val_loss: 0.5216\n# val_accuracy: 0.7871\n# val_topk-accuracy: 0.9407\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(history_lenet.history['loss'])\nplt.plot(history_lenet.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss', 'val_loss'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(69039).Z,width:"567",height:"455"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(history_lenet.history['accuracy'])\nplt.plot(history_lenet.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train_accuracy', 'val_accuracy'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(74059).Z,width:"576",height:"455"})),(0,l.kt)("h4",{id:"model-evaluation-1"},"Model Evaluation"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet.evaluate(testing_dataset)\n# loss: 0.5216 - accuracy: 0.7871 - topk-accuracy: 0.9407\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/happy.jpg')\n\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = model_lenet(img).numpy()\nprint(label)\n# [[0.1078622  0.8603977  0.03174012]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# [[1.0409105e-03 3.4608482e-04 9.9861300e-01]]\n# sad\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/sad.jpg')\n\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = model_lenet(img).numpy()\nprint(label)\n# [[9.1999680e-02 2.9016874e-04 9.0771013e-01]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# [[0.00754709 0.09368072 0.89877224]]\n# sad\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/angry.jpg')\n\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = model_lenet(img).numpy()\nprint(label)\n# [[9.9998641e-01 1.3307266e-06 1.2283378e-05]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# [[0.17887418 0.5655646  0.25556126]]\n# happy\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.figure(figsize=(16,16))\n\nfor images, labels in test_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n        pred = \"Predicted: \" + LABELS[\n            tf.argmax(model_lenet(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n        ]\n        plt.title(\n           true  + \"\\n\" + pred\n        )\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/tf_Emotion_Detection_08.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(63763).Z,width:"1258",height:"1295"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"y_pred = []\ny_test = []\n\nfor img, label in testing_dataset:\n    y_pred.append(model_lenet(img))\n    y_test.append(label.numpy())\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"conf_mtx = ConfusionMatrixDisplay(\n    confusion_matrix=confusion_matrix(\n        np.argmax(y_test[:-1], axis=-1).flatten(),\n        np.argmax(y_pred[:-1], axis=-1).flatten()\n    ),\n    display_labels=LABELS\n)\n\nfig, ax = plt.subplots(figsize=(16,12))\nconf_mtx.plot(ax=ax, cmap='plasma', include_values=False)\n        \nplt.savefig('assets/tf_Emotion_Detection_09.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(32049).Z,width:"1160",height:"987"})),(0,l.kt)("h2",{id:"cutmix-data-augmentation"},"Cutmix Data Augmentation"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"def sample_beta_distribution(size, concentration_0=0.2, concentration_1=0.2):\n    gamma_1_sample = tf.random.gamma(shape=[size], alpha=concentration_1)\n    gamma_2_sample = tf.random.gamma(shape=[size], alpha=concentration_0)\n    return gamma_1_sample / (gamma_1_sample + gamma_2_sample)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"data_augmentation = Sequential([\n    RandomRotation(factor = (0.25),),\n    RandomFlip(mode='horizontal',),\n    RandomContrast(factor=0.1),\n    RandomBrightness(0.1)\n])\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# CutMix data augmentation function\ntrain_ds_one = train_dataset.map(lambda image, label: (data_augmentation(image), label))\ntrain_ds_two = train_dataset.map(lambda image, label: (data_augmentation(image), label))\n\ntrain_ds = tf.data.Dataset.zip((train_ds_two, train_ds_two))\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"@tf.function\ndef get_box(lambda_value):\n    cut_rat = tf.math.sqrt(1.0 - lambda_value)\n\n    cut_w = SIZE * cut_rat  # rw\n    cut_w = tf.cast(cut_w, tf.int32)\n\n    cut_h = SIZE * cut_rat  # rh\n    cut_h = tf.cast(cut_h, tf.int32)\n\n    cut_x = tf.random.uniform((1,), minval=0, maxval=SIZE, dtype=tf.int32)  # rx\n    cut_y = tf.random.uniform((1,), minval=0, maxval=SIZE, dtype=tf.int32)  # ry\n\n    boundaryx1 = tf.clip_by_value(cut_x[0] - cut_w // 2, 0, SIZE)\n    boundaryy1 = tf.clip_by_value(cut_y[0] - cut_h // 2, 0, SIZE)\n    bbx2 = tf.clip_by_value(cut_x[0] + cut_w // 2, 0, SIZE)\n    bby2 = tf.clip_by_value(cut_y[0] + cut_h // 2, 0, SIZE)\n\n    target_h = bby2 - boundaryy1\n    if target_h == 0:\n        target_h += 1\n\n    target_w = bbx2 - boundaryx1\n    if target_w == 0:\n        target_w += 1\n\n    return boundaryx1, boundaryy1, target_h, target_w\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"@tf.function\ndef cutmix(train_ds_one, train_ds_two):\n    (image1, label1), (image2, label2) = train_ds_one, train_ds_two\n\n    alpha = [0.25]\n    beta = [0.25]\n\n    # Get a sample from the Beta distribution\n    lambda_value = sample_beta_distribution(1, alpha, beta)\n\n    # Define Lambda\n    lambda_value = lambda_value[0][0]\n\n    # Get the bounding box offsets, heights and widths\n    boundaryx1, boundaryy1, target_h, target_w = get_box(lambda_value)\n\n    # Get a patch from the second image (`image2`)\n    crop2 = tf.image.crop_to_bounding_box(\n        image2, boundaryy1, boundaryx1, target_h, target_w\n    )\n    # Pad the `image2` patch (`crop2`) with the same offset\n    image2 = tf.image.pad_to_bounding_box(\n        crop2, boundaryy1, boundaryx1, SIZE, SIZE\n    )\n    # Get a patch from the first image (`image1`)\n    crop1 = tf.image.crop_to_bounding_box(\n        image1, boundaryy1, boundaryx1, target_h, target_w\n    )\n    # Pad the `image1` patch (`crop1`) with the same offset\n    img1 = tf.image.pad_to_bounding_box(\n        crop1, boundaryy1, boundaryx1, SIZE, SIZE\n    )\n\n    # Modify the first image by subtracting the patch from `image1`\n    # (before applying the `image2` patch)\n    image1 = image1 - img1\n    # Add the modified `image1` and `image2`  together to get the CutMix image\n    image = image1 + image2\n\n    # Adjust Lambda in accordance to the pixel ration\n    lambda_value = 1 - (target_w * target_h) / (SIZE * SIZE)\n    lambda_value = tf.cast(lambda_value, tf.float32)\n\n    # Combine the labels of both images\n    label = lambda_value * label1 + (1 - lambda_value) * label2\n    return image, label\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Create the new dataset using our `cutmix` utility\ntrain_ds_cmu = (\n    train_ds.shuffle(1024)\n    .map(cutmix, num_parallel_calls=tf.data.AUTOTUNE)\n    .prefetch(tf.data.AUTOTUNE)\n)\n\ntest_ds = (\n    test_dataset.prefetch(tf.data.AUTOTUNE)\n)\n\n# Let's preview 9 samples from the dataset\nimage_batch, label_batch = next(iter(train_ds_cmu))\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'plt.figure(figsize=(10, 10))\nfor i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.title(LABELS[np.argmax(label_batch[i])])\n    plt.imshow(image_batch[i]/255)\n    plt.axis("off")\n')),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(14194).Z,width:"793",height:"812"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"resize_rescale_layers = Sequential([\n    Resizing(SIZE, SIZE),\n    Rescaling(1./255)\n])\n")),(0,l.kt)("h3",{id:"model-building"},"Model Building"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet = Sequential([\n    InputLayer(input_shape=(None, None, 3)),  \n    resize_rescale_layers,  \n    Conv2D(\n        filters = FILTERS,\n        kernel_size = KERNEL,\n        strides = STRIDES,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),  \n    BatchNormalization(),   \n    MaxPool2D(\n        pool_size = POOL,\n        strides = STRIDES*2\n    ),   \n    Dropout(rate=DORATE),   \n    Conv2D(\n        filters = FILTERS*2+4,\n        kernel_size = KERNEL,\n        strides = STRIDES,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    MaxPool2D(\n        pool_size = POOL,\n        strides = STRIDES*2\n    ),    \n    Flatten(),    \n    Dense(\n        DENSE1,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    Dropout(rate=DORATE),    \n    Dense(\n        DENSE2,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    Dense(\n        NLABELS,\n        activation = 'softmax',\n        name = 'Output'\n    )\n])\n\nmodel_lenet.build()\nmodel_lenet.summary()\n\n# Total params: 6,153,119\n# Trainable params: 6,152,855\n# Non-trainable params: 264\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"loss_function = CategoricalCrossentropy(\n    from_logits = False,\n    label_smoothing = 0.0,\n    axis = -1,\n    name = 'categorical_crossentropy'\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"metrics = [\n    CategoricalAccuracy(name='accuracy'),\n    TopKCategoricalAccuracy(k=2,name='topk-accuracy')\n]\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet.compile(\n    optimizer = Adam(learning_rate = LR),\n    loss = loss_function,\n    metrics = metrics\n)\n")),(0,l.kt)("h3",{id:"model-training-2"},"Model Training"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"history_lenet = model_lenet.fit(\n    train_ds_cmu,\n    validation_data = test_ds,\n    epochs = EPOCHS,\n    verbose = 1\n)\n\n# loss: 0.8846\n# accuracy: 0.6149\n# topk-accuracy: 0.8550\n# val_loss: 0.6832\n# val_accuracy: 0.7226\n# val_topk-accuracy: 0.9083\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(history_lenet.history['loss'])\nplt.plot(history_lenet.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss', 'val_loss'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(31079).Z,width:"567",height:"455"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(history_lenet.history['accuracy'])\nplt.plot(history_lenet.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train_accuracy', 'val_accuracy'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(10074).Z,width:"576",height:"455"})),(0,l.kt)("h3",{id:"model-evaluation-2"},"Model Evaluation"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet.evaluate(test_ds)\n# loss: 0.6832 - accuracy: 0.7226 - topk-accuracy: 0.9083\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/happy.jpg')\n\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = model_lenet(img).numpy()\nprint(label)\n# [[0.1078622  0.8603977  0.03174012]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# [[0.1541878  0.37400016 0.47181207]]\n# sad\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/sad.jpg')\n\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = model_lenet(img).numpy()\nprint(label)\n# [[9.1999680e-02 2.9016874e-04 9.0771013e-01]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# [[0.20370252 0.60639006 0.1899074 ]]\n# happy\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/angry.jpg')\n\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = model_lenet(img).numpy()\nprint(label)\n# [[9.9998641e-01 1.3307266e-06 1.2283378e-05]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# [[0.07486102 0.8021671  0.1229719 ]]\n# happy\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.figure(figsize=(16,16))\n\nfor images, labels in test_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n        pred = \"Predicted: \" + LABELS[\n            tf.argmax(model_lenet(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n        ]\n        plt.title(\n           true  + \"\\n\" + pred\n        )\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/tf_Emotion_Detection_13.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(95988).Z,width:"1258",height:"1295"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"y_pred = []\ny_test = []\n\nfor img, label in test_ds:\n    y_pred.append(model_lenet(img))\n    y_test.append(label.numpy())\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"conf_mtx = ConfusionMatrixDisplay(\n    confusion_matrix=confusion_matrix(\n        np.argmax(y_test[:-1], axis=-1).flatten(),\n        np.argmax(y_pred[:-1], axis=-1).flatten()\n    ),\n    display_labels=LABELS\n)\n\nfig, ax = plt.subplots(figsize=(16,12))\nconf_mtx.plot(ax=ax, cmap='plasma', include_values=False)\n\nplt.savefig('assets/tf_Emotion_Detection_14.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(59732).Z,width:"1160",height:"987"})),(0,l.kt)("h3",{id:"saving-the-model"},"Saving the Model"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Save the weights\nmodel_lenet.save_weights('./saved_weights/cutmix_weights')\n\n# # Create a new model instance\n# model_lenet = create_model()\n\n# # Restore the weights\n# model_lenet.load_weights('./checkpoints/my_checkpoint')\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet.save('saved_model/cutmix_model')\n\nrestored_model = tf.keras.models.load_model('saved_model/cutmix_model')\n\n# Check its architecture\nrestored_model.summary()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"restored_model.evaluate(test_ds)\n# loss: 0.6832 - accuracy: 0.7226 - topk-accuracy: 0.9083\n")),(0,l.kt)("h3",{id:"saving-the-augmented-dataset"},"Saving the Augmented Dataset"),(0,l.kt)("p",null,"The TFRecord format is a simple format for storing a sequence of binary records. Protocol buffers are a cross-platform, cross-language library for efficient serialization of structured data."),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"training_unbatched = (\n    train_ds_cmu.unbatch()\n)\n\ntesting_unbatched = (\n    test_ds.unbatch()\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"def create_example(image, label):\n    bytes_feature = Feature(\n        bytes_list = BytesList(value=[image]))\n\n    int_feature = Feature(\n        int64_list = Int64List(value=[label]))\n\n    example = Example(\n        features=Features(feature={\n            'images': bytes_feature,\n            'labels': int_feature,\n        }))\n    \n    return example.SerializeToString()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"def encode_image(image, label):\n    image = tf.image.convert_image_dtype(image, dtype=tf.uint8)\n    image = tf.io.encode_jpeg(image)\n    return image, tf.argmax(label)\n\nencoded_ds = (\n    training_unbatched.map(encode_image)\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"for shard_number in range(SHARDS):\n    \n    sharded_ds = (\n        encoded_ds\n        .shard(SHARDS, shard_number)\n        .as_numpy_iterator()\n    )\n    \n    with TFRecordWriter(PATH.format(shard_number)) as file_writer:\n      for image, label in sharded_ds:\n        file_writer.write(create_example(image, label))\n")),(0,l.kt)("h3",{id:"reconstructing-the-augmented-dataset-this-part-does-not-work-yet"},"Reconstructing the Augmented Dataset (This part does not work yet!)"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"shards_list = [PATH.format(i) for i in range(SHARDS-2)]\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"loaded_training_ds = tf.data.TFRecordDataset(filenames = shards_list)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"def parse_tfrecords(example):    \n    feature_description = {\n            'images': tf.io.FixedLenFeature([], tf.string),\n            'labels': tf.io.FixedLenFeature([], tf.int64)\n        }\n    \n    example = tf.io.parse_single_example(example, feature_description)\n    example['images'] = tf.image.convert_image_dtype(\n        tf.io.decode_image(\n            example['images'], channels = 3\n        ), dtype = tf.float32\n    )\n    \n    return example['images'], example['labels']\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"parsed_ds = (\n    loaded_training_ds\n    .map(parse_tfrecords)\n    .batch(BATCH)\n    .prefetch(tf.data.AUTOTUNE)\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"for i in train_ds_cmu.take(1):\n    print(i)\n    \n# tf.Tensor: shape=(32, 256, 256, 3)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"for i in parsed_ds.take(1):\n    print(i)\n# tf.Tensor: shape=(32, 256, 256, 3)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"model_lenet2 = Sequential([\n    InputLayer(input_shape=(None, None, 3)),  \n    resize_rescale_layers,  \n    Conv2D(\n        filters = FILTERS,\n        kernel_size = KERNEL,\n        strides = STRIDES,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),  \n    BatchNormalization(),   \n    MaxPool2D(\n        pool_size = POOL,\n        strides = STRIDES*2\n    ),   \n    Dropout(rate=DORATE),   \n    Conv2D(\n        filters = FILTERS*2+4,\n        kernel_size = KERNEL,\n        strides = STRIDES,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    MaxPool2D(\n        pool_size = POOL,\n        strides = STRIDES*2\n    ),    \n    Flatten(),    \n    Dense(\n        DENSE1,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    Dropout(rate=DORATE),    \n    Dense(\n        DENSE2,\n        activation = 'relu',\n        kernel_regularizer = L2(REGRATE)\n    ),    \n    BatchNormalization(),    \n    Dense(\n        NLABELS,\n        activation = 'softmax',\n        name = 'Output'\n    )\n])\n\nmodel_lenet2.build()\nmodel_lenet2.summary()\n\n# Total params: 4,668,319\n# Trainable params: 4,668,055\n# Non-trainable params: 264\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},'loss_function2 = SparseCategoricalCrossentropy()\n\nmetrics2 = [SparseCategoricalAccuracy(name="accuracy")]\n\nmodel_lenet2.compile(\n    optimizer = Adam(learning_rate = LR),\n    loss = loss_function2,\n    metrics = metrics2\n)\n')),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"history_lenet2 = model_lenet2.fit(\n    parsed_ds,\n    epochs = EPOCHS,\n    verbose = 1\n)\n")),(0,l.kt)("h2",{id:"transfer-learning"},"Transfer Learning"),(0,l.kt)("h3",{id:"building-the-efficient-tf-model"},"Building the Efficient TF Model"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# # transfer learning\n# backbone = tf.keras.applications.efficientnet.EfficientNetB4(\n#     include_top=False,\n#     weights='imagenet',\n#     input_shape=(SIZE, SIZE, 3)\n# )\n\n# ERROR - EfficientNetv1 cannot be saved:\n# ValueError: Unable to create a Keras model from SavedModel at saved_model/efficient_model. This SavedModel was exported with `tf.saved_model.save`, and lacks the Keras metadata file. Please save your Keras model by calling `model.save` or `tf.keras.models.save_model`. Note that you can still load this SavedModel with `tf.saved_model.load`.\n")),(0,l.kt)("p",null,"Since I was ",(0,l.kt)("a",{parentName:"p",href:"https://github.com/keras-team/keras/issues/17199"},"unable to save the above model")," I checked the ",(0,l.kt)("a",{parentName:"p",href:"https://keras.io/api/applications/#usage-examples-for-image-classification-models"},"Keras Documentation")," for an alternative:"),(0,l.kt)("br",null),(0,l.kt)("table",null,(0,l.kt)("thead",{parentName:"table"},(0,l.kt)("tr",{parentName:"thead"},(0,l.kt)("th",{parentName:"tr",align:null},"Model"),(0,l.kt)("th",{parentName:"tr",align:null},"Size (MB)"),(0,l.kt)("th",{parentName:"tr",align:null},"Top-1 Accuracy"),(0,l.kt)("th",{parentName:"tr",align:null},"Top-5 Accuracy"),(0,l.kt)("th",{parentName:"tr",align:null},"Parameters"),(0,l.kt)("th",{parentName:"tr",align:null},"Depth"),(0,l.kt)("th",{parentName:"tr",align:null},"Time (ms) per inference step (CPU)"),(0,l.kt)("th",{parentName:"tr",align:null},"Time (ms) per inference step (GPU)"))),(0,l.kt)("tbody",{parentName:"table"},(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"MobileNetV2"),(0,l.kt)("td",{parentName:"tr",align:null},"14"),(0,l.kt)("td",{parentName:"tr",align:null},"71.3%"),(0,l.kt)("td",{parentName:"tr",align:null},"90.1%"),(0,l.kt)("td",{parentName:"tr",align:null},"3.5M"),(0,l.kt)("td",{parentName:"tr",align:null},"105"),(0,l.kt)("td",{parentName:"tr",align:null},"25.9"),(0,l.kt)("td",{parentName:"tr",align:null},"3.8")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"EfficientNetB4"),(0,l.kt)("td",{parentName:"tr",align:null},"75"),(0,l.kt)("td",{parentName:"tr",align:null},"82.9%"),(0,l.kt)("td",{parentName:"tr",align:null},"96.4%"),(0,l.kt)("td",{parentName:"tr",align:null},"19.5M"),(0,l.kt)("td",{parentName:"tr",align:null},"258"),(0,l.kt)("td",{parentName:"tr",align:null},"308.3"),(0,l.kt)("td",{parentName:"tr",align:null},"15.1")),(0,l.kt)("tr",{parentName:"tbody"},(0,l.kt)("td",{parentName:"tr",align:null},"EfficientNetV2S"),(0,l.kt)("td",{parentName:"tr",align:null},"88"),(0,l.kt)("td",{parentName:"tr",align:null},"83.9%"),(0,l.kt)("td",{parentName:"tr",align:null},"96.7%"),(0,l.kt)("td",{parentName:"tr",align:null},"21.6M"),(0,l.kt)("td",{parentName:"tr",align:null},"-"),(0,l.kt)("td",{parentName:"tr",align:null},"-"),(0,l.kt)("td",{parentName:"tr",align:null},"-")))),(0,l.kt)("br",null),(0,l.kt)("ul",null,(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"Training Scores"),":",(0,l.kt)("ul",{parentName:"li"},(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"EfficientNetB4"),": loss: ",(0,l.kt)("inlineCode",{parentName:"li"},"0.5003")," - accuracy: ",(0,l.kt)("inlineCode",{parentName:"li"},"0.7954")," - topk_accuracy: ",(0,l.kt)("inlineCode",{parentName:"li"},"0.9451")," ~80MB"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"EfficientNetV2S"),": loss: ",(0,l.kt)("inlineCode",{parentName:"li"},"0.5144")," - accuracy: ",(0,l.kt)("inlineCode",{parentName:"li"},"0.7968")," - topk_accuracy: ",(0,l.kt)("inlineCode",{parentName:"li"},"0.9359")," 104.6MB"),(0,l.kt)("li",{parentName:"ul"},(0,l.kt)("strong",{parentName:"li"},"MobileNetV3SM"),": loss: ",(0,l.kt)("inlineCode",{parentName:"li"},"0.5638")," - accuracy: ",(0,l.kt)("inlineCode",{parentName:"li"},"0.7682")," - topk_accuracy: ",(0,l.kt)("inlineCode",{parentName:"li"},"0.9328")," 12.8MB")))),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# transfer learning\nbackbone = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n    include_top=False,\n    weights='imagenet',\n    input_shape=(SIZE, SIZE, 3),\n    include_preprocessing=True\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"backbone.trainable = False\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"efficient_model = tf.keras.Sequential([\n    Input(shape=(SIZE, SIZE, 3)),\n    backbone,\n    GlobalAveragePooling2D(),\n    Dense(DENSE1, activation='relu'),\n    BatchNormalization(),\n    Dense(DENSE2, activation='relu'),\n    Dense(NLABELS, activation='softmax')\n])\n\nefficient_model.summary()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"checkpoint_callback = ModelCheckpoint(\n    'best_weights',\n    monitor='val_accuracy',\n    mode='max',\n    verbose=1,\n    save_best_only=True\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"loss_function = CategoricalCrossentropy()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"metrics = [CategoricalAccuracy(name='accuracy'), TopKCategoricalAccuracy(k=2, name='topk_accuracy')]\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"efficient_model.compile(\n    optimizer = Adam(learning_rate=LR),\n    loss = loss_function,\n    metrics = metrics\n)\n")),(0,l.kt)("h4",{id:"model-training-3"},"Model Training"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"efficient_history = efficient_model.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    verbose = 1\n)\n")),(0,l.kt)("h4",{id:"model-evaluation-3"},"Model Evaluation"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"efficient_model.evaluate(testing_dataset)\n# loss: 0.5144 - accuracy: 0.7968 - topk_accuracy: 0.9359\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(efficient_history.history['loss'])\nplt.plot(efficient_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss', 'val_loss'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(50078).Z,width:"567",height:"455"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(efficient_history.history['accuracy'])\nplt.plot(efficient_history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train_accuracy', 'val_accuracy'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(2596).Z,width:"584",height:"455"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/happy.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = efficient_model(img).numpy()\nprint(label)\n# [[7.2473467e-06 4.2083409e-02 9.5790941e-01]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# sad\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/sad.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = efficient_model(img).numpy()\nprint(label)\n# [[0.06096885 0.03196466 0.90706646]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# sad\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/angry.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = efficient_model(img).numpy()\nprint(label)\n# [[0.87592113 0.08582695 0.03825196]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# angry\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.figure(figsize=(16,16))\n\nfor images, labels in testing_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n        pred = \"Predicted: \" + LABELS[\n            tf.argmax(efficient_model(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n        ]\n        plt.title(\n           true  + \"\\n\" + pred\n        )\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/tf_Emotion_Detection_17.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(96275).Z,width:"1258",height:"1295"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"y_pred = []\ny_test = []\n\nfor img, label in testing_dataset:\n    y_pred.append(efficient_model(img))\n    y_test.append(label.numpy())\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"conf_mtx = ConfusionMatrixDisplay(\n    confusion_matrix=confusion_matrix(\n        np.argmax(y_test[:-1], axis=-1).flatten(),\n        np.argmax(y_pred[:-1], axis=-1).flatten()\n    ),\n    display_labels=LABELS\n)\n\nfig, ax = plt.subplots(figsize=(16,12))\nconf_mtx.plot(ax=ax, cmap='plasma', include_values=False)\n\nplt.savefig('assets/tf_Emotion_Detection_18.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(41090).Z,width:"1160",height:"987"})),(0,l.kt)("h4",{id:"saving-the-model-1"},"Saving the Model"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"tf.keras.saving.save_model(\n    efficient_model, 'saved_model/efficient_model', overwrite=True, save_format='tf'\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# restore the model\nrestored_model = tf.keras.saving.load_model('saved_model/efficient_model')\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Check its architecture\nrestored_model.summary()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"restored_model.evaluate(testing_dataset)\n# loss: 0.5144 - accuracy: 0.7968 - topk_accuracy: 0.9359\n")),(0,l.kt)("h3",{id:"building-the-mobilenet-tf-model"},"Building the MobileNet TF Model"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# transfer learning\nbackbone2 = tf.keras.applications.MobileNetV3Small(\n    input_shape=(SIZE, SIZE, 3),\n    alpha=1.0,\n    minimalistic=True,\n    include_top=False,\n    weights='imagenet',\n    dropout_rate=0.2,\n    include_preprocessing=True\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"backbone2.trainable = False\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_model = tf.keras.Sequential([\n    Input(shape=(SIZE, SIZE, 3)),\n    backbone2,\n    GlobalAveragePooling2D(),\n    Dense(DENSE1, activation='relu'),\n    BatchNormalization(),\n    Dense(DENSE2, activation='relu'),\n    Dense(NLABELS, activation='softmax')\n])\n\nmobilenet_model.summary()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"checkpoint_callback = ModelCheckpoint(\n    'best_weights',\n    monitor='val_accuracy',\n    mode='max',\n    verbose=1,\n    save_best_only=True\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"loss_function = CategoricalCrossentropy()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"metrics = [CategoricalAccuracy(name='accuracy'), TopKCategoricalAccuracy(k=2, name='topk_accuracy')]\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_model.compile(\n    optimizer = Adam(learning_rate=LR),\n    loss = loss_function,\n    metrics = metrics\n)\n")),(0,l.kt)("h4",{id:"model-training-4"},"Model Training"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"tf.config.run_functions_eagerly(True)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_history = mobilenet_model.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    verbose = 1\n)\n\n# loss: 0.4242\n# accuracy: 0.8263\n# topk_accuracy: 0.9597\n# val_loss: 0.5638\n# val_accuracy: 0.7682\n# val_topk_accuracy: 0.9328\n")),(0,l.kt)("h4",{id:"model-evaluation-4"},"Model Evaluation"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_model.evaluate(testing_dataset)\n# loss: 0.5144 - accuracy: 0.7968 - topk_accuracy: 0.9359\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(mobilenet_history.history['loss'])\nplt.plot(mobilenet_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss', 'val_loss'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(70639).Z,width:"567",height:"455"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(mobilenet_history.history['accuracy'])\nplt.plot(mobilenet_history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train_accuracy', 'val_accuracy'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(49913).Z,width:"584",height:"455"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/happy.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = mobilenet_model(img).numpy()\nprint(label)\n# [[2.512952e-04 9.718944e-01 2.785430e-02]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# happy\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/sad.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = mobilenet_model(img).numpy()\nprint(label)\n# [[4.4993469e-03 9.9456584e-01 9.3488337e-04]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# happy\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/angry.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = mobilenet_model(img).numpy()\nprint(label)\n# [[9.8563331e-01 1.4297843e-02 6.8810325e-05]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# angry\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.figure(figsize=(16,16))\n\nfor images, labels in testing_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n        pred = \"Predicted: \" + LABELS[\n            tf.argmax(mobilenet_model(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n        ]\n        plt.title(\n           true  + \"\\n\" + pred\n        )\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/tf_Emotion_Detection_21.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(92002).Z,width:"1258",height:"1295"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"y_pred = []\ny_test = []\n\nfor img, label in testing_dataset:\n    y_pred.append(mobilenet_model(img))\n    y_test.append(label.numpy())\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"conf_mtx = ConfusionMatrixDisplay(\n    confusion_matrix=confusion_matrix(\n        np.argmax(y_test[:-1], axis=-1).flatten(),\n        np.argmax(y_pred[:-1], axis=-1).flatten()\n    ),\n    display_labels=LABELS\n)\n\nfig, ax = plt.subplots(figsize=(16,12))\nconf_mtx.plot(ax=ax, cmap='plasma', include_values=False)\n\nplt.savefig('assets/tf_Emotion_Detection_22.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(36900).Z,width:"1160",height:"987"})),(0,l.kt)("h4",{id:"saving-the-model-2"},"Saving the Model"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"tf.keras.saving.save_model(\n    mobilenet_model, 'saved_model/mobilenet_model', overwrite=True, save_format='tf'\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# restore the model\nrestored_model2 = tf.keras.saving.load_model('saved_model/mobilenet_model')\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Check its architecture\nrestored_model2.summary()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"restored_model2.evaluate(testing_dataset)\n# loss: 0.5638 - accuracy: 0.7682 - topk_accuracy: 0.9328\n")),(0,l.kt)("h3",{id:"tflite-conversion"},"TFLite Conversion"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Convert the model into TF Lite.\nconverter = tf.lite.TFLiteConverter.from_saved_model('saved_model/mobilenet_model')\ntflite_model = converter.convert()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Save the model.\nwith open('saved_model/mobilenet_model.tflite', 'wb') as f:\n  f.write(tflite_model)\n")),(0,l.kt)("h2",{id:"finetuning-the-mobilenet-tf-model"},"Finetuning the MobileNet TF Model"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# transfer learning\nbackbone = tf.keras.applications.MobileNetV3Small(\n    input_shape=(SIZE, SIZE, 3),\n    alpha=1.0,\n    minimalistic=True,\n    include_top=False,\n    weights='imagenet',\n    dropout_rate=0.2,\n    include_preprocessing=True\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"backbone.trainable = False\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# mobilenet_model = tf.keras.Sequential([\n#     Input(shape=(SIZE, SIZE, 3)),\n#     backbone2,\n#     GlobalAveragePooling2D(),\n#     Dense(DENSE1, activation='relu'),\n#     BatchNormalization(),\n#     Dense(DENSE2, activation='relu'),\n#     Dense(NLABELS, activation='softmax')\n# ])\n\ninput = Input(shape=(SIZE,SIZE,3))\nx = backbone(input, training=False)\n\nx = GlobalAveragePooling2D()(x)\nx = Dense(DENSE1, activation='relu')(x)\nx = BatchNormalization()(x)\nx = Dense(DENSE2, activation='relu')(x)\n\noutput = Dense(NLABELS, activation='softmax')(x)\n\nmobilenet_model = Model(input, output)\nmobilenet_model.summary()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"checkpoint_callback = ModelCheckpoint(\n    'best_weights',\n    monitor='val_accuracy',\n    mode='max',\n    verbose=1,\n    save_best_only=True\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"early_stopping_callback = EarlyStopping(\n    monitor='val_accuracy',\n    patience=10,\n    restore_best_weights=True\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"loss_function = CategoricalCrossentropy()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"metrics = [CategoricalAccuracy(name='accuracy'), TopKCategoricalAccuracy(k=2, name='topk_accuracy')]\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_model.compile(\n    optimizer = Adam(learning_rate=LR),\n    loss = loss_function,\n    metrics = metrics\n)\n")),(0,l.kt)("h3",{id:"model-training-5"},"Model Training"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"tf.config.run_functions_eagerly(True)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_history = mobilenet_model.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    verbose = 1,\n    callbacks=[checkpoint_callback, early_stopping_callback]\n)\n\n# loss: 0.4372\n# accuracy: 0.8188\n# topk_accuracy: 0.9547\n# val_loss: 0.5934\n# val_accuracy: 0.7643\n# val_topk_accuracy: 0.9320\n")),(0,l.kt)("h3",{id:"model-evaluation-5"},"Model Evaluation"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_model.evaluate(testing_dataset)\n# loss: 0.5934 - accuracy: 0.7643 - topk_accuracy: 0.9320\n")),(0,l.kt)("h3",{id:"model-finetuning"},"Model Finetuning"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"backbone.trainable = True\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_model.compile(\n    optimizer = Adam(learning_rate=LR/100),\n    loss = loss_function,\n    metrics = metrics\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_history = mobilenet_model.fit(\n    training_dataset,\n    validation_data = testing_dataset,\n    epochs = EPOCHS,\n    verbose = 1,\n    callbacks=[checkpoint_callback, early_stopping_callback]\n)\n\n# loss: 0.2703\n# accuracy: 0.8912\n# topk_accuracy: 0.9763\n# val_loss: 0.3906\n# val_accuracy: 0.8455\n# val_topk_accuracy: 0.9627\n")),(0,l.kt)("h3",{id:"model-evaluation-6"},"Model Evaluation"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"mobilenet_model.evaluate(testing_dataset)\n# loss: 0.3906 - accuracy: 0.8455 - topk_accuracy: 0.9627\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(mobilenet_history.history['loss'])\nplt.plot(mobilenet_history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train_loss', 'val_loss'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(10359).Z,width:"575",height:"455"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.plot(mobilenet_history.history['accuracy'])\nplt.plot(mobilenet_history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train_accuracy', 'val_accuracy'])\nplt.show()\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(4620).Z,width:"576",height:"455"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/happy.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = mobilenet_model(img).numpy()\nprint(label)\n# [[0.01388984 0.95678276 0.02932744]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# happy\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/sad.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = mobilenet_model(img).numpy()\nprint(label)\n# [[5.297706e-04 9.994018e-01 6.839229e-05]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# happy\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"test_image = cv.imread('./dataset/angry.jpg')\ntest_image = cv.resize(test_image, (SIZE, SIZE))\nimg = tf.constant(test_image, dtype=tf.float32)\nimg = tf.expand_dims(img, axis=0)\n\nlabel = mobilenet_model(img).numpy()\nprint(label)\n# [[9.6875304e-01 3.1238725e-02 8.2295473e-06]]\nprint(LABELS[tf.argmax(label, axis=1).numpy()[0]])\n# angry\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"plt.figure(figsize=(16,16))\n\nfor images, labels in testing_dataset.take(1):\n    for i in range(16):\n        ax = plt.subplot(4,4,i+1)\n        true = \"True: \" + LABELS[tf.argmax(labels[i], axis=0).numpy()]\n        pred = \"Predicted: \" + LABELS[\n            tf.argmax(mobilenet_model(tf.expand_dims(images[i], axis=0)).numpy(), axis=1).numpy()[0]\n        ]\n        plt.title(\n           true  + \"\\n\" + pred\n        )\n        plt.imshow(images[i]/255.)\n        plt.axis('off')\n        \nplt.savefig('assets/tf_Emotion_Detection_25.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(92002).Z,width:"1258",height:"1295"})),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"y_pred = []\ny_test = []\n\nfor img, label in testing_dataset:\n    y_pred.append(mobilenet_model(img))\n    y_test.append(label.numpy())\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"conf_mtx = ConfusionMatrixDisplay(\n    confusion_matrix=confusion_matrix(\n        np.argmax(y_test[:-1], axis=-1).flatten(),\n        np.argmax(y_pred[:-1], axis=-1).flatten()\n    ),\n    display_labels=LABELS\n)\n\nfig, ax = plt.subplots(figsize=(16,12))\nconf_mtx.plot(ax=ax, cmap='plasma', include_values=False)\n\nplt.savefig('assets/tf_Emotion_Detection_26.webp', bbox_inches='tight')\n")),(0,l.kt)("p",null,(0,l.kt)("img",{alt:"tf Emotion Detection",src:a(57183).Z,width:"1160",height:"987"})),(0,l.kt)("h3",{id:"saving-the-model-3"},"Saving the Model"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"tf.keras.saving.save_model(\n    mobilenet_model, 'saved_model/mobilenet_model', overwrite=True, save_format='tf'\n)\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# restore the model\nrestored_model2 = tf.keras.saving.load_model('saved_model/mobilenet_model')\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Check its architecture\nrestored_model2.summary()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"restored_model2.evaluate(testing_dataset)\n# loss: 0.3906 - accuracy: 0.8455 - topk_accuracy: 0.9627\n")),(0,l.kt)("h3",{id:"tflite-conversion-1"},"TFLite Conversion"),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Convert the model into TF Lite.\nconverter = tf.lite.TFLiteConverter.from_saved_model('saved_model/mobilenet_model')\ntflite_model = converter.convert()\n")),(0,l.kt)("pre",null,(0,l.kt)("code",{parentName:"pre",className:"language-python"},"# Save the model.\nwith open('saved_model/mobilenet_model.tflite', 'wb') as f:\n  f.write(tflite_model)\n")))}c.isMDXComponent=!0},36724:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-19827635eae5b5cb12f68c531f406341.jpg"},37058:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_01-f8dcac9b8c5ed255a682b8396d49d9de.webp"},2054:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_02-c0c29fab1a8990daf3dcff9defb33ee8.webp"},68029:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_03-f048c33f81747a7396508070c930290b.webp"},95988:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_04-78c65241c55a6c0c897054bf4c0e916f.webp"},80593:(e,t,a)=>{a.d(t,{Z:()=>n});const n="data:image/webp;base64,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"},69039:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_06-21770d590d980e15ff76b5cce6a35e32.webp"},74059:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_07-5e71c8de8f18e5523f1d83a5d705d01c.webp"},63763:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_08-5a176bc2b03b043f89f2e26591eeeb59.webp"},32049:(e,t,a)=>{a.d(t,{Z:()=>n});const n="data:image/webp;base64,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"},14194:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_10-1b7dca44a6a82efbe8bb31c7bde6108c.webp"},31079:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_11-772c2fb3c0081adf212525b7a187054b.webp"},10074:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_12-79b16823acdf9b9e4d6b6c901e03498c.webp"},59732:(e,t,a)=>{a.d(t,{Z:()=>n});const n="data:image/webp;base64,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"},50078:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_15-dc01b0212b29f5384fd5a32207d5f69c.webp"},2596:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_16-fe2d7c38d8eacb6414ffbbb2db9776ef.webp"},96275:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_17-ef4758c2c68a7a018130777685b62d7b.webp"},41090:(e,t,a)=>{a.d(t,{Z:()=>n});const n="data:image/webp;base64,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"},70639:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_19-6df5bc4d1669291b1ccdb170e082d4fe.webp"},49913:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_20-15e3e01c2063c3fc5631ccbb8c0193b5.webp"},92002:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_21-ce148de439347a4389793bc91b06fbae.webp"},36900:(e,t,a)=>{a.d(t,{Z:()=>n});const n="data:image/webp;base64,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"},10359:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_23-b3ea6e263f87c8ed36e866096f70d09a.webp"},4620:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_24-f8c9d91b410b8133af2343085623ce24.webp"},57183:(e,t,a)=>{a.d(t,{Z:()=>n});const n=a.p+"assets/images/tf_Emotion_Detection_26-7cafe891244da431eb147f46562a6f19.webp"}}]);