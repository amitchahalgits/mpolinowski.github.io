"use strict";(self.webpackChunkmikes_dev_notebook=self.webpackChunkmikes_dev_notebook||[]).push([[44639],{3905:(n,e,t)=>{t.d(e,{Zo:()=>s,kt:()=>_});var o=t(67294);function a(n,e,t){return e in n?Object.defineProperty(n,e,{value:t,enumerable:!0,configurable:!0,writable:!0}):n[e]=t,n}function r(n,e){var t=Object.keys(n);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(n);e&&(o=o.filter((function(e){return Object.getOwnPropertyDescriptor(n,e).enumerable}))),t.push.apply(t,o)}return t}function i(n){for(var e=1;e<arguments.length;e++){var t=null!=arguments[e]?arguments[e]:{};e%2?r(Object(t),!0).forEach((function(e){a(n,e,t[e])})):Object.getOwnPropertyDescriptors?Object.defineProperties(n,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(e){Object.defineProperty(n,e,Object.getOwnPropertyDescriptor(t,e))}))}return n}function p(n,e){if(null==n)return{};var t,o,a=function(n,e){if(null==n)return{};var t,o,a={},r=Object.keys(n);for(o=0;o<r.length;o++)t=r[o],e.indexOf(t)>=0||(a[t]=n[t]);return a}(n,e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(n);for(o=0;o<r.length;o++)t=r[o],e.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(n,t)&&(a[t]=n[t])}return a}var l=o.createContext({}),d=function(n){var e=o.useContext(l),t=e;return n&&(t="function"==typeof n?n(e):i(i({},e),n)),t},s=function(n){var e=d(n.components);return o.createElement(l.Provider,{value:e},n.children)},m={inlineCode:"code",wrapper:function(n){var e=n.children;return o.createElement(o.Fragment,{},e)}},u=o.forwardRef((function(n,e){var t=n.components,a=n.mdxType,r=n.originalType,l=n.parentName,s=p(n,["components","mdxType","originalType","parentName"]),u=d(t),_=a,f=u["".concat(l,".").concat(_)]||u[_]||m[_]||r;return t?o.createElement(f,i(i({ref:e},s),{},{components:t})):o.createElement(f,i({ref:e},s))}));function _(n,e){var t=arguments,a=e&&e.mdxType;if("string"==typeof n||a){var r=t.length,i=new Array(r);i[0]=u;var p={};for(var l in e)hasOwnProperty.call(e,l)&&(p[l]=e[l]);p.originalType=n,p.mdxType="string"==typeof n?n:a,i[1]=p;for(var d=2;d<r;d++)i[d]=t[d];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}u.displayName="MDXCreateElement"},90356:(n,e,t)=>{t.r(e),t.d(e,{assets:()=>l,contentTitle:()=>i,default:()=>m,frontMatter:()=>r,metadata:()=>p,toc:()=>d});var o=t(87462),a=(t(67294),t(3905));const r={sidebar_position:4330,slug:"2023-07-25",title:"Working with ONNX Models",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Open Neural Network Exchange (ONNX)"},i=void 0,p={unversionedId:"IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/index",id:"IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/index",title:"Working with ONNX Models",description:"Open Neural Network Exchange (ONNX)",source:"@site/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/index.md",sourceDirName:"IoT-and-Machine-Learning/ML/2023-07-25-onnx-models",slug:"/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/2023-07-25",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/2023-07-25",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/IoT-and-Machine-Learning/ML/2023-07-25-onnx-models/index.md",tags:[{label:"Python",permalink:"/docs/tags/python"},{label:"Machine Learning",permalink:"/docs/tags/machine-learning"}],version:"current",sidebarPosition:4330,frontMatter:{sidebar_position:4330,slug:"2023-07-25",title:"Working with ONNX Models",authors:"mpolinowski",tags:["Python","Machine Learning"],description:"Open Neural Network Exchange (ONNX)"},sidebar:"tutorialSidebar",previous:{title:"Human Emotion Detection with Tensorflow",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-07-26-tensorflow-human-emotion-detector/2023-07-26"},next:{title:"Introduction to Caffe2",permalink:"/docs/IoT-and-Machine-Learning/ML/2023-07-21-introduction-to-pytorch-caffe2/2023-07-21"}},l={},d=[{value:"Netron",id:"netron",level:2},{value:"Loading an ONNX Model",id:"loading-an-onnx-model",level:2},{value:"Tensorflow to ONNX",id:"tensorflow-to-onnx",level:2},{value:"Tensorflow Lite to ONNX",id:"tensorflow-lite-to-onnx",level:2},{value:"ONNX to Tensorflow",id:"onnx-to-tensorflow",level:2},{value:"Generate ONNX Prototext",id:"generate-onnx-prototext",level:2},{value:"ONNX to NovaONNX",id:"onnx-to-novaonnx",level:2},{value:"Support Functions",id:"support-functions",level:3}],s={toc:d};function m(n){let{components:e,...r}=n;return(0,a.kt)("wrapper",(0,o.Z)({},s,r,{components:e,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Guangzhou, China",src:t(41770).Z,width:"1500",height:"581"})),(0,a.kt)("h1",{id:"open-neural-network-exchange-onnx"},"Open Neural Network Exchange (ONNX)"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#open-neural-network-exchange-onnx"},"Open Neural Network Exchange (ONNX)"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#netron"},"Netron")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#loading-an-onnx-model"},"Loading an ONNX Model")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#tensorflow-to-onnx"},"Tensorflow to ONNX")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#tensorflow-lite-to-onnx"},"Tensorflow Lite to ONNX")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#onnx-to-tensorflow"},"ONNX to Tensorflow")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#generate-onnx-prototext"},"Generate ONNX Prototext")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#onnx-to-novaonnx"},"ONNX to NovaONNX"),(0,a.kt)("ul",{parentName:"li"},(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"#support-functions"},"Support Functions"))))))),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/mpolinowski/tf2onnx"},"Github Repository")),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://onnx.ai/"},"ONNX")," is an open format built to represent machine learning models. ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers."),(0,a.kt)("h2",{id:"netron"},"Netron"),(0,a.kt)("p",null,"Inspect your ONNX model using Netron. ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/lutzroeder/netron"},"Netron is a viewer for neural networks, deep learning and machine learning models"),". Netron supports ONNX, TensorFlow Lite, Core ML, Keras, Caffe, Darknet, MXNet, PaddlePaddle, ncnn, MNN and TensorFlow.js. Netron has experimental support for PyTorch, TorchScript, TensorFlow, OpenVINO, RKNN, MediaPipe, ML.NET and scikit-learn."),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://github.com/lutzroeder/netron#install"},"Installation on Linux")," using the latest ",(0,a.kt)("em",{parentName:"p"},"AppImage"),":"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},"wget https://github.com/lutzroeder/netron/releases/download/v7.0.8/Netron-7.0.8.AppImage\nchmod 777 Netron-7.0.8.AppImage\n./Netron-7.0.8.AppImage\n")),(0,a.kt)("p",null,(0,a.kt)("img",{alt:"Open Neural Network Exchange (ONNX)",src:t(14102).Z,width:"1747",height:"975"})),(0,a.kt)("h2",{id:"loading-an-onnx-model"},"Loading an ONNX Model"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"import tensorflow as tf\nimport tf2onnx\n\nimport onnx\nfrom onnx import shape_inference, TensorProto\nfrom onnx import version_converter\nfrom onnx import numpy_helper\nimport onnx.helper as helper\n\nfrom onnxsim import simplify\n\nfrom onnx_tf.backend import prepare\n\nimport json\nimport numpy as np\nimport sys\n")),(0,a.kt)("h2",{id:"tensorflow-to-onnx"},"Tensorflow to ONNX"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"tf_model = tf.keras.saving.load_model('mobilenet_model')\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"tf_model.summary()\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"input_signature = [tf.TensorSpec([1, 224, 224, 3], tf.float32, name='x')]\n# Use from_function for tf functions\nonnx_model, _ = tf2onnx.convert.from_keras(tf_model, input_signature, opset=12)\nonnx.save(onnx_model, \"mobilenet_model.onnx\")\n")),(0,a.kt)("p",null,(0,a.kt)("inlineCode",{parentName:"p"},"AttributeError: 'FuncGraph' object has no attribute '_captures'")),(0,a.kt)("blockquote",null,(0,a.kt)("p",{parentName:"blockquote"},"BUG Tensorflow 2.13 / Python 3.11: ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/onnx/tensorflow-onnx/issues/2172"},"GITHUB ISSUE1"),", ",(0,a.kt)("a",{parentName:"p",href:"https://github.com/onnx/tensorflow-onnx/issues/2180"},"GITHUB ISSUE1")," AttributeError: 'FuncGraph' object has no attribute '_captures'. Did you mean: 'captures'?")),(0,a.kt)("p",null,"Replace the following in:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"~/.local/lib/python3.11/site-packages/tf2onnx/tf_loader.py")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"~/.local/lib/python3.11/site-packages/tf2onnx/convert.py"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'    #graph_captures = concrete_func.graph._captures  # pylint: disable=protected-access\n    #captured_inputs = [t_name.name for t_val, t_name in graph_captures.values()]\n\n    if hasattr(concrete_func.graph, "captures"):\n        graph_captures = concrete_func.graph.captures\n        captured_inputs = [t_name.name for t_val, t_name in graph_captures]\n    else:\n        graph_captures = concrete_func.graph._captures\n        captured_inputs = [t_name.name for t_val, t_name in graph_captures.values()]\n')),(0,a.kt)("h2",{id:"tensorflow-lite-to-onnx"},"Tensorflow Lite to ONNX"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"tf2onnx.convert.from_tflite(\n    tflite_path='mobilenet_model.tflite',\n    output_path='mobilenet_model_tflite.onnx',\n    opset=12\n)\n")),(0,a.kt)("h2",{id:"onnx-to-tensorflow"},"ONNX to Tensorflow"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# from tf model\nonnx_model = onnx.load("mobilenet_model.onnx")\nonnx.checker.check_model(onnx_model)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"tf_prep = prepare(onnx_model)\ntf_prep.export_graph('deploy_model')\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'# from tf lite model\nonnx_lite_model = onnx.load("mobilenet_model_tflite.onnx")\nonnx.checker.check_model(onnx_lite_model)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"tf_prep = prepare(onnx_lite_model)\ntf_prep.export_graph('deploy_lite_model')\n\n#  ValueError: Tried to convert 'x' to a tensor and failed. Error: None values not supported.\n")),(0,a.kt)("h2",{id:"generate-onnx-prototext"},"Generate ONNX Prototext"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def dump_normal(elem, indent, file) :\n    for s in str(elem).splitlines() :\n        print(indent + s, file=file)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def dump_initializer(elem, indent, file) : \n    # calculate size.\n    size = 1\n    for d in elem.dims :\n        size *= d\n\n    # in the case of enough small size, output all data.\n    if (size <= 32) :\n        dump_normal(elem, indent, file)\n        return\n\n    # output metadata only, in all other cases.\n    for d in elem.dims :\n        print(indent + "  dims: " + json.dumps(d), file=file)\n        print(indent + "  data_type: " + json.dumps(elem.data_type), file=file)\n        print(indent + "  name: " + json.dumps(elem.name), file=file)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def onnx2prototxt(onnx_path) :\n\n    # show information\n    out_path = onnx_path + ".prototxt"\n    print("+ creating " + out_path)\n    print("    from " + onnx_path + " ...")\n\n    # load model\n    model = onnx.load(onnx_path)\n\n    # print prototxt\n    with open(out_path, "w") as f :\n        print("ir_version: " + json.dumps(model.ir_version), file=f)\n        print("producer_name: " + json.dumps(model.producer_name), file=f)\n        print("producer_version: " + json.dumps(model.producer_version), file=f)\n        # print("domain: " + json.dumps(model.domain), file=f)\n        print("model_version: " + json.dumps(model.model_version), file=f)\n        # print("doc_string: " + json.dumps(model.doc_string), file=f)\n        print("graph {", file=f)\n        print("  name: " + json.dumps(model.graph.name), file=f)\n\n        for e in model.graph.node :\n            print("  node {", file=f)\n            dump_normal(e, "    ",  f)\n            print("  }", file=f)\n\n        for e in model.graph.initializer :\n            print("  initializer {", file=f)\n            dump_initializer(e, "    ",  f)\n            print("  }", file=f)\n\n        for e in model.graph.input :\n            print("  input {", file=f)\n            dump_normal(e, "    ",  f)\n            print("  }", file=f)\n\n        for e in model.graph.output :\n            print("  output {", file=f)\n            dump_normal(e, "    ",  f)\n            print("  }", file=f)\n\n        print("}", file=f)\n\n        for e in model.opset_import :\n            print("opset_import {", file=f)\n            print("  version: " + json.dumps(e.version), file=f)\n            print("}", file=f)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def show_usage(script) :\n    print("usage: python " + script + " input.onnx [more.onnx ..]")\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'onnx_path ="mobilenet_model.onnx"\n\nonnx2prototxt(onnx_path)\n')),(0,a.kt)("h2",{id:"onnx-to-novaonnx"},"ONNX to NovaONNX"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"INPUT = 'mobilenet_model.onnx'\nOUTPUT = 'deploy.onnx'\nSKIP_FUSE_BN = True\nSKIP_ONNX_SIM = False\nSKIP_MODIFY_IDX = False\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"onnx_model = onnx.load(INPUT)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# Each dimension of input shape must greater than zero\nonnx_model.graph.input\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"for input in onnx_model.graph.input:\n        print(input.type.tensor_type.shape.dim)\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"# Opset version 8 ~ 12 supported\nonnx_model.opset_import[0].version\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"### Supported Layer Types\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"SUPPORTED_OP_TYPE_LIST = [\n'Abs',\n'Add',\n'AveragePool',\n'BatchNormalization',\n'Clip',\n'Conv',\n'ConvTranspose',\n'Concat',\n'Flatten',\n'Gemm',\n'GlobalAveragePool',\n'GlobalMaxPool',\n'LeakyRelu',\n'LSTM',\n'MatMul',\n'Max',\n'MaxPool',\n'MaxRoiPool',\n'Mul',\n'Pad',\n'PRelu',\n'ReduceMean',\n'Relu',\n'Resize',\n'Sigmoid',\n'Softmax',\n'Sub',\n'Tanh',\n'Transpose',\n'Upsample',\n'Reshape',\n'Slice',\n'Split',\n'Neg',\n'Sub',\n'Tanh',\n'Sqrt',\n'Exp',\n'Div',\n'Log',\n'Pow',\n'Sin',\n'Floor',\n'Round',\n'Squeeze',\n'UnSqueeze'\n]\n")),(0,a.kt)("h3",{id:"support-functions"},"Support Functions"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def onnx_attribute_to_dict(onnx_attr):\n    #print(onnx_attr)\n    if onnx_attr.HasField('name'):\n        name = getattr(onnx_attr, 'name')\n        #print(name)\n\n    if onnx_attr.HasField('t'):\n        return name, numpy_helper.to_array(getattr(onnx_attr, 't'))\n\n    for attr_type in ['f', 'i', 's']:\n        if onnx_attr.HasField(attr_type):\n            return name, getattr(onnx_attr, attr_type)\n\n    for attr_type in ['floats', 'ints', 'strings']:\n        if getattr(onnx_attr, attr_type):\n            return name, list(getattr(onnx_attr, attr_type))\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def add_input_from_initializer(model : onnx.ModelProto):\n    """\n    Currently onnx.shape_inference doesn\'t use the shape of initializers, so add\n    that info explicitly as ValueInfoProtos.\n    Mutates the model.\n    Args:\n        model: The ModelProto to update.\n    """\n    # All (top-level) constants will have ValueInfos before IRv4 as they are all inputs\n    if model.ir_version < 4:\n        return\n\n    def add_const_value_infos_to_graph(graph : onnx.GraphProto):\n        inputs = {i.name for i in graph.input}\n        existing_info = {vi.name: vi for vi in graph.input}\n        for init in graph.initializer:\n            # Check it really is a constant, not an input\n            if init.name in inputs:\n                continue\n\n            # The details we want to add\n            elem_type = init.data_type\n            shape = init.dims\n\n            # Get existing or create new value info for this constant\n            vi = existing_info.get(init.name)\n            if vi is None:\n                vi = graph.input.add()\n                vi.name = init.name\n\n            # Even though it would be weird, we will not overwrite info even if it doesn\'t match\n            tt = vi.type.tensor_type\n            if tt.elem_type == onnx.TensorProto.UNDEFINED:\n                tt.elem_type = elem_type\n            if not tt.HasField("shape"):\n                # Ensure we set an empty list if the const is scalar (zero dims)\n                tt.shape.dim.extend([])\n                for dim in shape:\n                    tt.shape.dim.add().dim_value = dim\n\n        # Handle subgraphs\n        for node in graph.node:\n            for attr in node.attribute:\n                # Ref attrs refer to other attrs, so we don\'t need to do anything\n                if attr.ref_attr_name != "":\n                    continue\n\n                if attr.type == onnx.AttributeProto.GRAPH:\n                    add_const_value_infos_to_graph(attr.g)\n                if attr.type == onnx.AttributeProto.GRAPHS:\n                    for g in attr.graphs:\n                        add_const_value_infos_to_graph(g)\n\n    return add_const_value_infos_to_graph(model.graph)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def ReplaceUpsampleWithResize(onnx_model):\n\n    graph = onnx_model.graph\n\n    for i in range(len(graph.node)):\n        if graph.node[i].op_type == \'Upsample\':\n            old_node = graph.node[i]\n            roi = numpy_helper.from_array(np.empty([0], dtype=np.float32), old_node.name + "_roi")\n            onnx_model.graph.initializer.append(roi)\n            roi_value_info = helper.make_tensor_value_info(old_node.name + "_roi", onnx.TensorProto.FLOAT, [0])\n            onnx_model.graph.value_info.append(roi_value_info)\n            inputs = [old_node.input[0], old_node.name + "_roi", old_node.input[1]]\n            mode_string = \'\'\n            for attr in graph.node[i].attribute:\n                if attr.name == \'mode\':\n                    mode_string = attr.s\n            new_node = onnx.helper.make_node(\n                "Resize",\n                coordinate_transformation_mode="asymmetric",\n                cubic_coeff_a=-0.75,\n                mode=mode_string,\n                nearest_mode="floor",\n                inputs=inputs,\n                outputs=old_node.output\n            )\n            graph.node.remove(old_node)\n            graph.node.insert(i, new_node)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def check_shapes(onnx_model):\n    names = []\n    for input_tensor in onnx_model.graph.input:\n        names.append(input_tensor.name)\n    for output_tensor in onnx_model.graph.output:\n        names.append(output_tensor.name)\n    for init_tensor in onnx_model.graph.initializer:\n        names.append(init_tensor.name)\n    for value in onnx_model.graph.value_info:\n        names.append(value.name)\n\n    for node in onnx_model.graph.node:\n        outputs = node.output\n        for output in outputs:\n            if output not in names:\n                assert False, "Shape checking error. Node: %s Type: %s, cannot get output shape, please check the attribute." % (node.name, node.op_type)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def Constant_to_initializer(onnxmodel):\n    graph = onnxmodel.graph\n    delete = []\n    for i in range(len(graph.node)):\n        if graph.node[i].op_type=="Constant":\n            # data = np.frombuffer(graph.node[i].attribute[0].t.raw_data, dtype=np.float32)\n            p_t = helper.make_tensor(graph.node[i].output[0], onnx.TensorProto.FLOAT, dims = 0, vals=graph.node[i].attribute[0].t.raw_data, raw=True)\n            delete.append(graph.node[i])\n            graph.initializer.insert(0, p_t)\n    for oldnode in delete:\n        graph.node.remove(oldnode)\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"def modify_layer_dix(graph):\n    outputs = graph.output\n    outputs_dict = {}\n    for i, output in enumerate(outputs):\n        for j, node in enumerate(graph.node):\n            if output.name in node.output:\n                # output_idx : node_idx, layer_idx\n                outputs_dict[i] = [j, j]\n\n    for i in range(len(outputs_dict)):\n        min_index = i  \n        # find min_index\n        for j in range(i+1, len(outputs_dict)):\n            if outputs_dict[j][1] < outputs_dict[min_index][1]:\n                min_index = j\n\n        if min_index != i:\n                # exchange layer idx\n                for k, attr in enumerate(graph.node[outputs_dict[i][0]].attribute):\n                    if attr.name == 'layer_idx':\n                        new_layer_idx = onnx.helper.make_attribute(\"layer_idx\", outputs_dict[min_index][1])\n                        del graph.node[outputs_dict[i][0]].attribute[k]\n                        graph.node[outputs_dict[i][0]].attribute.extend([new_layer_idx])\n                        break\n\n                for k, attr in enumerate(graph.node[outputs_dict[min_index][0]].attribute):\n                    if attr.name == 'layer_idx':\n                        new_layer_idx = onnx.helper.make_attribute(\"layer_idx\", outputs_dict[i][1])\n                        del graph.node[outputs_dict[min_index][0]].attribute[k]\n                        graph.node[outputs_dict[min_index][0]].attribute.extend([new_layer_idx])\n                        break\n\n                # if graph.node[1].attribute\n                outputs_dict[i][1], outputs_dict[min_index][1] = outputs_dict[min_index][1], outputs_dict[i][1]\n\n    return graph\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},'def to_nova_onnx(in_model_path, out_model_path, skip_fuse_bn, skip_onnx_sim, skip_modify_idx):\n    # load model\n    onnx_model = onnx.load(in_model_path)\n\n    if onnx_model.producer_name == \'Novatek NovaOnnx Converter\' or onnx_model.producer_name == \'Novatek Caffe2Onnx Converter\':\n        print("INFO :: This model is already a nova onnx model, skip the conversion process...")\n        return\n    \n    # check input shape\n    for input in onnx_model.graph.input:\n        input_shape = input.type.tensor_type.shape.dim\n        for d in input_shape:\n            if d.dim_value <= 0:\n                assert (False), "ERROR :: Each dimension of input shape must greater than zero, illegal input name = %s"% input.name\n    Constant_to_initializer(onnx_model)\n    # convert model\n    add_input_from_initializer(onnx_model)\n    \n    has_custom_op = 0\n    for node in onnx_model.graph.node:\n        if node.domain != \'\' and node.domain != \'ai.onnx\':\n            has_custom_op = 1\n    if has_custom_op == 1:\n\n        #get all value_info and output name\n        tensor_names = []\n        for vi in onnx_model.graph.value_info:\n            tensor_names.append(vi.name)\n        for output in onnx_model.graph.output:\n            tensor_names.append(output.name)\n        \n        # Add missing tensor_value_info (fake shape)\n        for i in range(len(onnx_model.graph.node)):\n            for output in onnx_model.graph.node[i].output:\n                if output not in tensor_names:\n                    if onnx_model.graph.node[i].op_type == "Gemm" or onnx_model.graph.node[i].op_type == "Flatten":\n                        fake_value_info = helper.make_tensor_value_info(output, TensorProto.FLOAT, [-1,-1])\n                    else:\n                        fake_value_info = helper.make_tensor_value_info(output, TensorProto.FLOAT, [-1,-1,-1,-1])\n                    tensor_names.append(output)\n                    onnx_model.graph.value_info.append(fake_value_info)\n    \n    else:\n        # convert model to opset 12\n        if onnx_model.opset_import[0].version != 12:\n            if onnx_model.opset_import[0].version > 12 or onnx_model.opset_import[0].version < 8:\n                assert (False), ": Opset version of the input model is %d, novaonnx only supports Opset version 8 ~ 12."% onnx_model.opset_import[0].version\n            print("WARNING :: Opset version of the input model is {}, novaonnx support Opset version 12.".format(onnx_model.opset_import[0].version))\n            print("INFO :: Conversion from Opset version {} to Opset version 12.".format(onnx_model.opset_import[0].version))\n            onnx_model = version_converter.convert_version(onnx_model, 12)\n            \n            #version_converter can not convert upsample(deprecated in opset 12), convert it to resize \n            ReplaceUpsampleWithResize(onnx_model)\n        \n        if skip_onnx_sim:\n            onnx_model = shape_inference.infer_shapes(onnx_model)\n            check_shapes(onnx_model)\n        else:\n            # apply onnx simplify\n            onnx_model, check = simplify(onnx_model, skip_fuse_bn = skip_fuse_bn)\n\n            assert check, "WARNING :: Simplified ONNX model could not be validated"\n            \n        for i in range(len(onnx_model.graph.node)):\n            if onnx_model.graph.node[i].op_type not in SUPPORTED_OP_TYPE_LIST:\n                print("WARNING :: Unsupported Layer Type ", onnx_model.graph.node[i].op_type)\n\n    graph = onnx_model.graph\n\n        \n    init_name_list = []\n    for initializer in graph.initializer:\n        init_name_list.append(initializer.name)\n    \n    name_dict = {}\n            \n    #modify Conv weight name\n    for i in range(len(graph.node)):\n        if graph.node[i].op_type == \'Conv\':\n            if graph.node[i].input[1] in init_name_list:\n                name_dict.setdefault(graph.node[i].input[1], graph.node[i].op_type + "_" + graph.node[i].input[1] + "_W")\n                graph.node[i].input[1] = graph.node[i].op_type + "_" + graph.node[i].input[1] + "_W"\n            if len(graph.node[i].input) > 2:\n                if graph.node[i].input[2] in init_name_list:\n                    name_dict.setdefault(graph.node[i].input[2],  graph.node[i].op_type + "_" + graph.node[i].input[2] + "_B")\n                    graph.node[i].input[2] = graph.node[i].op_type + "_" + graph.node[i].input[2] + "_B"\n\n      \n        #modify output tensor_name to (node_name)_Y\n        for k in range(len(graph.node[i].input)):\n            if graph.node[i].input[k] in name_dict:\n                graph.node[i].input[k] = name_dict[graph.node[i].input[k]]\n        for l in range(len(graph.node[i].output)):\n            name_dict.setdefault(graph.node[i].output[l], graph.node[i].op_type + "_" + graph.node[i].output[l] + "_Y")\n            graph.node[i].output[l] = graph.node[i].op_type + "_" + graph.node[i].output[l] + "_Y"\n\n        # Add layer_id attribute for each node\n        new_attr = helper.make_attribute("layer_idx", i)\n        graph.node[i].attribute.append(new_attr)\n        \n        #modify Conv weight name\n        if graph.node[i].op_type == \'AveragePool\' or graph.node[i].op_type == \'MaxPool\':\n            new_attr = helper.make_attribute("pool_at_pad", 1)\n            graph.node[i].attribute.append(new_attr)\n\n    #print(graph.value_info)\n    #modify graph output tensor_name to (node_name)_Y\n    for m in range(len(graph.output)):\n        if graph.output[m].name in name_dict:\n            graph.output[m].name = name_dict[graph.output[m].name]\n            \n    #modify value info name\n    for n in range(len(graph.value_info)):\n        if graph.value_info[n].name in name_dict:\n            graph.value_info[n].name = name_dict[graph.value_info[n].name]\n\n    #modify input name\n    for o in range(len(graph.input)):\n        if graph.input[o].name in name_dict:\n            graph.input[o].name = name_dict[graph.input[o].name] \n            \n    #modify initializer name\n    for p in range(len(graph.initializer)):\n        if graph.initializer[p].name in name_dict:\n            graph.initializer[p].name = name_dict[graph.initializer[p].name] \n    \n    if not skip_modify_idx:\n        graph = modify_layer_dix(graph)\n\n    onnx_model.producer_name = \'Novatek NovaOnnx Converter\'\n    onnx_model.producer_version = \'1.0\'\n    onnx.save(onnx_model, out_model_path)\n    print("INFO :: Converted to NOVA ONNX!")\n')),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-python"},"to_nova_onnx(INPUT, OUTPUT, SKIP_FUSE_BN, SKIP_ONNX_SIM, SKIP_MODIFY_IDX)\n")))}m.isMDXComponent=!0},14102:(n,e,t)=>{t.d(e,{Z:()=>o});const o=t.p+"assets/images/Working_with_ONNX_Models_01-a290c459b7d16bf27bb8dcbaba8e6d95.png"},41770:(n,e,t)=>{t.d(e,{Z:()=>o});const o=t.p+"assets/images/photo-kt443t6d_64hdh43hfh6dgjdfhg4_d-5a33ed1aeac871d5b7a7594cc7d702c8.jpg"}}]);